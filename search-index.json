[{"title":"操作系统-进程管理","date":"2024-10-28T14:52:35.000Z","url":"/2024/10/28/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F-%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/","tags":[["锁","/tags/%E9%94%81/"],["操作系统基础","/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80/"],["进程管理","/tags/%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/"]],"categories":[["计算机基础","/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/"],["操作系统","/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"]],"content":"操作系统基础操作系统概述操作系统定义与功能 操作系统（Operating System, OS）是计算机系统中至关重要的软件层，其主要职责是管理计算机硬件与软件资源，为应用程序提供统一的接口和服务。操作系统作为计算机的基石，确保了计算机系统的有效运行和资源的高效利用。 操作系统主要功能 硬件管理：操作系统负责管理计算机的硬件资源，包括但不限于中央处理器（CPU）、内存、输入输出设备等。通过硬件管理，操作系统能够合理分配和调度这些资源，以满足不同应用程序的需求。 软件资源管理：操作系统不仅管理硬件资源，还负责管理软件资源，如文件系统、进程和线程等。通过有效的资源管理，操作系统确保了多个应用程序能够同时运行，且互不干扰。 抽象与屏蔽复杂性：操作系统通过提供抽象层，屏蔽了底层硬件的复杂性，使得应用程序开发者无需深入了解硬件细节即可进行开发。这种抽象层包括文件系统、设备驱动程序等。 内核（Kernel）：内核是操作系统的核心部分，负责执行最基本的任务，如内存管理、进程调度、文件系统管理以及硬件设备的管理。内核是操作系统与硬件之间的桥梁，确保了硬件资源的高效利用和应用程序的顺利执行。 内核与CPU的区别 内核：内核是操作系统的一部分，属于软件层面。它主要负责管理计算机硬件与软件资源，提供系统调用接口，使得应用程序能够访问硬件资源。 CPU：中央处理器（CPU）是计算机的硬件核心，负责执行指令和进行算术逻辑运算。CPU是硬件资源的一部分，其功能由操作系统通过内核进行管理和调度。 用户态和内核态用户态与内核态的概念在操作系统中，进程的运行环境可以根据其访问系统资源的权限分为两种级别：用户态（User Mode）和内核态（Kernel Mode）。 用户态：在用户态下运行的进程仅能访问其自身的用户空间数据，权限较低。当应用程序需要执行某些需要更高权限的操作，如文件读写、网络通信、进程管理等，必须通过系统调用（System Call）向操作系统发起请求，从而进入内核态。 内核态：内核态赋予进程几乎完全的系统资源访问权限，允许其执行底层操作，如直接访问硬件、管理内存、调度进程等。当操作系统接收到来自用户态进程的系统调用请求时，会将该进程切换到内核态，执行相应的内核代码，完成后再次切换回用户态。 内核态的权限级别远高于用户态，因此能够执行更为底层的系统操作。然而，进入内核态涉及复杂的上下文切换和权限检查，开销较大。因此，应尽量减少内核态的切换次数，以提升系统性能和稳定性。 用户态与内核态的必要性用户态与内核态的划分是操作系统安全性和稳定性的基石。其核心原因在于CPU指令集中的特权指令（Privileged Instructions）。 特权指令：某些CPU指令具有潜在的危险性，如直接操作硬件、修改内存映射、中断处理等。这些指令若被普通用户程序随意执行，可能导致系统崩溃或数据损坏。因此，操作系统将这些指令的执行权限限制在内核态，确保只有内核代码能够执行这些特权指令。 资源隔离与保护：如果所有进程都运行在内核态，那么每个进程都将拥有对系统资源的完全访问权限，这将导致资源竞争和潜在的冲突，严重影响系统的性能和效率。通过将进程分为用户态和内核态，操作系统能够有效隔离不同进程的资源访问，防止恶意或意外的操作对系统造成损害。 系统调用什么是系统调用在现代操作系统中，用户程序通常运行在用户态（User Mode），而操作系统内核运行在内核态（Kernel Mode）。当用户程序需要执行某些特权操作（如访问硬件资源、管理进程、操作文件系统等）时，由于用户态的权限限制，无法直接执行这些操作。此时，程序需要通过系统调用（System Call）向操作系统内核发起请求，由内核代为执行这些特权操作。 系统调用是用户程序与操作系统内核之间的接口，它提供了一种机制，使得用户程序能够安全、受控地访问内核提供的各种服务。根据其功能，系统调用大致可以分为以下几类： 文件管理：包括文件的读取、写入、创建、删除、重命名、权限管理等操作。 设备管理：涉及对硬件设备的请求、释放、配置等操作，如I&#x2F;O设备的读写、设备的初始化等。 进程管理：包括进程的创建、终止、调度、同步、通信等操作，如fork()、exec()、wait()、signal()等。 内存管理：涉及内存的分配、回收、映射、保护等操作，如malloc()、free()、mmap()等。 系统调用与普通函数库调用（Library Call）在形式上相似，但本质上存在显著差异。普通函数库调用是在用户态下执行的，调用的是预先编译好的本地函数，而系统调用则是通过特定的指令（如x86架构中的int 0x80或syscall指令）触发，将控制权转移到内核态，由内核执行相应的操作。 系统调用过程系统调用的执行过程涉及用户态与内核态之间的切换，具体步骤如下： 用户态发起系统调用：当用户程序需要执行特权操作时，它会通过特定的指令（如syscall）发起系统调用。此时，程序会传递系统调用号（System Call Number）以及必要的参数，这些参数通常通过寄存器传递。 中断（Trap）：系统调用指令触发一个中断（Trap），导致CPU从用户态切换到内核态。中断发生后，当前用户程序的执行被挂起，CPU的控制权被转移到操作系统内核。 内核态处理系统调用：内核接收到系统调用请求后，根据系统调用号查找相应的内核函数（通常位于系统调用表中），并执行该函数。内核函数负责处理用户程序请求的操作，如访问文件、管理设备、调度进程等。 返回用户态：内核完成系统调用后，会通过特定的指令（如iret或sysret）将控制权返回给用户程序。此时，CPU从内核态切换回用户态，用户程序继续执行，并从系统调用返回点恢复执行。 结果返回：系统调用的结果（如文件读取的数据、进程创建的状态等）通常通过寄存器或内存返回给用户程序。用户程序根据返回值判断系统调用是否成功，并进行相应的处理。 系统调用的过程涉及用户态与内核态之间的多次切换，这种切换带来了一定的开销，但同时也确保了操作系统的安全性和稳定性。通过系统调用，用户程序能够在受控的环境下访问内核资源，避免了直接操作硬件可能带来的风险。 进程与线程什么是进程和线程 进程：进程是计算机程序正在运行的一个实例，是操作系统进行资源分配和调度的基本单位。例如，打开并运行的微信应用程序就是一个进程。每个进程都有独立的内存空间、文件描述符、网络连接等资源。 线程：线程是进程内的一个执行单元，也被称为轻量级进程。一个进程可以包含多个线程，这些线程共享进程的资源（如内存空间、文件句柄、网络连接等），但每个线程有自己的独立栈和寄存器状态。例如，在运行的微信应用程序中，可能有一个线程专门负责推送用户发出的信息，另一个线程负责接收和处理用户输入。 进程和线程的区别 资源分配：进程是操作系统中最小的资源分配单位，每个进程拥有独立的内存空间和系统资源。而线程是进程内的最小执行单位，共享同一进程的资源，如内存中的堆和元数据空间，但每个线程有自己的私有栈和寄存器状态。 切换开销：由于线程更加轻量，线程之间的上下文切换开销较小且较快。相比之下，进程之间的上下文切换开销较大，因为需要保存和恢复更多的状态信息，如页表、文件描述符等。 独立性：进程之间是相互独立的，一个进程的崩溃通常不会影响其他进程。而线程则不一定，因为同一进程下的线程共享资源，一个线程的错误可能会影响其他线程，甚至导致整个进程崩溃。 为什么有进程了还需要线程 切换开销：进程切换的开销较大，而线程切换的开销较小。通过使用线程，可以在同一进程内并发执行多个任务，减少上下文切换的开销。 并发执行：多线程可以并发执行任务，增加CPU的利用率。例如，一个进程可以同时处理用户输入、网络通信和后台任务，而无需等待某个任务完成后再处理下一个任务。 资源共享：同一进程下的线程可以共享进程的资源，如内存空间、文件句柄等。这使得线程间的通信更加高效，无需进行系统调用，减少了开销。 响应性：通过使用多线程，应用程序可以更好地响应用户操作。例如，一个线程可以处理用户界面更新，另一个线程可以处理后台计算任务，从而提高用户体验。 为什么要有多线程多线程技术在现代计算机系统中扮演着至关重要的角色，其主要优势体现在以下几个方面： 提升系统整体使用效率 轻量级和低开销：线程是进程内的执行单元，相比于进程，线程更加轻量化，创建和销毁的开销较小。线程之间的上下文切换开销也远小于进程间的切换，这使得系统能够更高效地管理和调度多个任务。 资源共享：同一进程下的多个线程共享进程的资源，如内存空间、文件句柄、网络连接等。这种资源共享机制减少了资源复制的开销，提高了资源利用率。 并发处理：在单核CPU时代，多线程可以通过时间片轮转（Time-Slicing）机制实现并发执行，避免因单一线程阻塞而导致整个进程停滞。例如，当一个线程进行I&#x2F;O操作时，CPU可以切换到其他线程继续执行，从而提高CPU的利用率。 多核利用：在多核CPU时代，多线程能够充分利用多核处理器的并行计算能力。通过将任务分配到不同的线程，系统可以在多个核心上并行执行任务，显著提升整体性能。 应对互联网发展带来的高并发 高并发处理：随着互联网的快速发展，现代应用系统需要处理大量的并发请求。例如，在电商平台的“双11”购物节期间，系统需要应对数百万级别的并发访问。多线程并发编程能够显著提高系统的并发处理能力，确保在高负载情况下系统仍能稳定运行。 响应性和用户体验：多线程技术使得应用程序能够更好地响应用户操作。例如，一个线程可以处理用户界面更新，另一个线程可以处理后台计算任务，从而提高用户体验。 分布式系统：在分布式系统中，多线程技术可以用于实现负载均衡和任务分发。通过将任务分配到不同的线程或进程，系统可以更高效地利用分布式资源，提高整体系统的吞吐量和可靠性。 线程间同步方式线程同步是指在多线程环境中，确保多个线程能够有序地访问共享资源，避免出现资源冲突和竞态条件。线程同步机制是多线程编程中的关键技术，常见的同步方式包括互斥锁、读写锁、信号量、屏障和事件等。 1.互斥锁（Mutex） 互斥锁（Mutual Exclusion Lock）是最基本的同步机制之一，用于确保在同一时间段内只有一个线程能够访问共享资源。当一个线程获取到互斥锁后，其他试图获取该锁的线程将被阻塞，直到锁被释放。 在Java中，可以使用synchronized关键字或Lock接口来实现互斥锁。适用于需要独占访问共享资源的场景，如临界区保护。 2.读写锁（ReadWrite Lock） 读写锁允许多个线程同时读取共享资源，但只允许一个线程写入共享资源。读写锁适用于读操作远多于写操作的场景，可以提高并发性能。 在Java中，可以使用ReentrantReadWriteLock类来实现读写锁。适用于读多写少的场景，如缓存系统、配置管理等。 3.信号量（Semaphore） 信号量是一种计数器，用于控制同时访问共享资源的线程数量。信号量可以允许多个线程同时访问共享资源，但需要限制最大并发数。 在Java中，可以使用Semaphore类来实现信号量。适用于需要限制并发访问数量的场景，如连接池管理、资源池管理等。 4.屏障（Barrier） 屏障是一种同步原语，用于确保一组线程在某个点上同步。当一个线程到达屏障点时，它会被阻塞，直到所有线程都到达屏障点，然后所有线程继续执行。 在Java中，可以使用CyclicBarrier类来实现屏障。适用于需要多个线程协同工作的场景，如并行计算、数据分片处理等。 5.事件（Event） 事件是一种通知机制，用于在多线程之间传递信号，实现线程间的同步。事件可以用于通知一个或多个线程某个条件已经满足，从而触发相应的操作。 在Java中，可以使用java.util.concurrent.CountDownLatch或java.util.concurrent.Phaser等类来实现事件通知机制。适用于需要线程间协作和通知的场景，如任务调度、事件驱动编程等。 PCB（Process Control Block）PCB是什么PCB（Process Control Block）即进程控制块，是操作系统中用于管理和跟踪进程的核心数据结构。每个进程在操作系统中都有一个唯一的PCB，用于存储与该进程相关的所有信息。PCB是操作系统进行进程调度和管理的基础，它记录了进程的当前状态、资源需求、调度信息等关键数据。 当操作系统创建一个新的进程时，会为该进程分配一个唯一的进程ID（PID），并为该进程创建一个PCB。随着进程的执行，PCB中的内容会不断更新，操作系统根据这些信息来管理和调度进程。 PCB包含的信息PCB通常包含以下几类信息： 进程描述信息 进程ID（PID）：唯一标识进程的整数。 进程名称：通常是可执行文件的名称。 用户ID（UID）：标识进程所属的用户。 组ID（GID）：标识进程所属的用户组。 进程调度信息 进程状态：标识进程当前的状态，如运行态（Running）、就绪态（Ready）、阻塞态（Blocked）等。 优先级：进程的调度优先级，用于决定进程在调度队列中的位置。 阻塞原因：如果进程处于阻塞状态，记录阻塞的原因，如等待I&#x2F;O操作完成、等待信号量等。 调度队列指针：指向进程所在调度队列的指针，用于进程调度。 资源需求状态 内存需求：进程所需的内存空间大小及分配情况。 CPU时间：进程已经使用的CPU时间以及剩余的CPU时间片。 设备资源：进程所需的设备资源，如文件描述符、网络连接等。 状态机的处理状态 寄存器状态：进程在切换时需要保存的寄存器值，如通用寄存器、浮点寄存器等。 程序计数器（PC）：记录进程当前执行的指令地址。 程序状态字（PSW）：记录进程的当前状态信息，如条件码、中断允许位等。 用户栈指针：指向进程的用户栈顶地址。 内核栈指针：指向进程的内核栈顶地址。 其他信息 信号处理信息：记录进程对信号的处理方式，如忽略、捕获、默认处理等。 文件描述符表：记录进程打开的文件描述符及其相关信息。 共享内存段：记录进程与其他进程共享的内存段信息。 线程信息：如果操作系统支持多线程，PCB中可能还包括线程的相关信息。 PCB是操作系统中用于管理和调度进程的关键数据结构，它包含了进程的所有重要信息，如进程描述信息、调度信息、资源需求状态、状态机的处理状态等。操作系统通过PCB来跟踪和管理进程的生命周期，确保进程能够正确地执行和调度。PCB的设计和实现直接影响操作系统的性能和稳定性，是操作系统内核的重要组成部分。 进程的状态进程状态是指进程在其生命周期中所处的不同阶段。与线程状态类似，进程状态可以分为以下五种主要状态： 1. 创建状态（New）：当一个进程被创建时，它首先进入创建状态。在这个阶段，操作系统为进程分配必要的资源，如内存空间、文件描述符等，并初始化进程控制块（PCB）。此时，进程尚未准备好执行，仍处于初始化阶段。 2. 就绪状态（Ready）：当进程完成初始化并准备好执行时，它进入就绪状态。在就绪状态下，进程已经获得了除CPU之外的所有必要资源，等待操作系统调度器分配CPU时间片。一旦调度器选择该进程执行，它将进入运行状态。 3. 运行状态（Running）：当进程被调度器选中并分配到CPU时间片时，它进入运行状态。在运行状态下，进程正在执行其任务，CPU正在处理该进程的指令。如果进程的时间片用完或需要等待某些资源（如I&#x2F;O操作），它将退出运行状态，进入其他状态。 4. 阻塞状态（Blocked）：当进程需要等待某些事件（如I&#x2F;O操作完成、信号量释放等）时，它进入阻塞状态。在阻塞状态下，进程暂时停止执行，直到等待的事件发生。一旦事件发生，进程将重新进入就绪状态，等待再次被调度执行。 5. 结束状态（Terminated）：当进程完成其任务或因某些原因（如异常、用户终止）需要退出时，它进入结束状态。在结束状态下，进程正在从系统中消失，操作系统会回收分配给该进程的资源，并销毁其PCB。进程的结束状态可以是正常退出（如任务完成）或异常退出（如崩溃、被终止）。 状态转换 进程状态之间的转换通常由操作系统内核管理和控制，具体转换如下： 创建状态 -&gt; 就绪状态：进程初始化完成后，进入就绪状态，等待调度。 就绪状态 -&gt; 运行状态：调度器选择就绪状态的进程执行，进程进入运行状态。 运行状态 -&gt; 就绪状态：当进程的时间片用完或被抢占时，进程回到就绪状态。 运行状态 -&gt; 阻塞状态：当进程需要等待某些事件时，进入阻塞状态。 阻塞状态 -&gt; 就绪状态：等待的事件发生后，进程回到就绪状态。 运行状态 -&gt; 结束状态：进程完成任务或被终止，进入结束状态。 进程通信（Inter-Process Communication, IPC）是指在操作系统中，不同进程之间进行数据交换和信息传递的机制。进程通信是多进程编程中的关键技术，常见的通信方式包括管道、有名管道、信号、消息队列、共享内存、信号量和套接字等。 进程通信方式1. 管道（Pipe）&#x2F;匿名管道 管道是一种半双工的通信方式，用于具有亲属关系的进程（如父子进程或兄弟进程）之间的通信。管道数据存放在内存中，遵循先进先出（FIFO）原则。 特点：半双工通信，数据单向流动；只能在具有亲属关系的进程间使用。 应用场景：适用于简单的父子进程间通信。 2. 有名管道（Named Pipe） 有名管道解决了匿名管道只能在具有亲属关系的进程间通信的限制，允许任意两个进程进行通信。有名管道通常存放在文件系统中，具有唯一的名称。 特点：全双工通信，数据双向流动；可以在任意两个进程间使用。 应用场景：适用于需要跨进程通信的场景。 3. 信号（Signal） 信号是一种异步通信机制，用于通知进程某个事件已经发生。信号通常用于处理异常情况或通知进程某些状态变化。 特点：异步通信，信号处理复杂；信号传递的信息量有限。 应用场景：适用于进程间的事件通知和异常处理。 4. 消息队列（Message Queue） 消息队列是一种消息的链表，存放在操作系统的内核中。消息队列具有特定的消息格式，并以特定的消息队列标识符标识。消息队列遵循先进先出原则，但与管道不同的是，消息队列可以传递结构化的消息。 特点：支持结构化消息传递；消息队列存放在内核中，生命周期较长。 应用场景：适用于需要传递复杂消息的进程间通信。 5. 共享内存（Shared Memory） 共享内存允许多个进程访问同一块内存区域，进程可以直接读写共享内存中的数据，从而实现高效的数据交换。共享内存需要引入锁机制来避免数据竞争。 特点：高效的数据交换；需要锁机制来避免数据竞争。 应用场景：适用于需要频繁交换大量数据的进程间通信。 6. 信号量（Semaphore） 信号量是一种计数器，用于控制多个进程对共享资源的访问。信号量通常用于实现进程间的同步，确保在同一时刻只有一个或多个进程访问共享资源。 特点：用于进程同步和资源控制；控制同时访问共享资源的最大进程数。 应用场景：适用于需要控制资源访问的进程间通信。 7. 套接字（Socket） 套接字是一种网络通信机制，用于在不同主机之间进行进程间通信。套接字支持多种协议（如TCP、UDP），可以实现端到端的通信。 特点：支持跨主机的进程间通信；支持多种协议。 应用场景：适用于分布式系统中的进程间通信。 进程的调度算法进程调度算法是操作系统中用于决定哪个进程将获得CPU时间片的关键机制。不同的调度算法有不同的特点和适用场景，常见的调度算法包括先来先服务（FCFS）、短作业优先（SJF）、时间片轮转（RR）、优先级调度（Priority）和多级反馈队列（MFQ）等。 1. 先来先服务（FCFS）先来先服务（First-Come, First-Served, FCFS）是一种简单的调度算法，按照进程进入就绪队列的顺序进行调度。最先进入就绪队列的进程将最先获得CPU资源，直到该进程执行完成或因某些事件阻塞放弃CPU占用。 特点：简单易实现；非抢占式调度；可能导致长作业长时间占用CPU，造成“饥饿”现象。 应用场景：适用于作业执行时间差异不大的场景。 2. 短作业优先（SJF）短作业优先（Shortest Job First, SJF）是一种优先调度预计执行时间最短的进程的算法。从就绪队列中取出预计花费时间最短的任务，为其分配资源，直到任务执行完成或因某些事件阻塞放弃CPU占用。 特点：平均等待时间最短；非抢占式调度；可能导致长作业长时间等待，造成“饥饿”现象。 应用场景：适用于作业执行时间差异较大的场景。 3. 时间片轮转（RR）时间片轮转（Round Robin, RR）是一种公平的调度算法，为每个进程分配固定的时间片（Time Slice），即允许进程运行的时间。当时间片用完后，进程被抢占并放回就绪队列的末尾，等待下一次调度。 特点：公平调度；抢占式调度；时间片大小影响调度性能。 应用场景：适用于需要公平分配CPU资源的场景。 4. 优先级调度（Priority）优先级调度（Priority Scheduling）为每个进程分配一个优先级，优先级高的进程优先获得CPU资源。具有相同优先级的进程按照FCFS的方式执行。 特点：支持优先级调度；可能导致低优先级进程长时间等待，造成“饥饿”现象。 应用场景：适用于需要区分任务优先级的场景。 5. 多级反馈队列（MFQ）多级反馈队列（Multi-Level Feedback Queue, MFQ）是一种复杂的调度算法，结合了优先级调度和时间片轮转的特点。系统维护多个就绪队列，每个队列具有不同的优先级。新加入的任务放在最高优先级的就绪队列，当分配的时间片耗完但任务仍未完成时，将该任务放入次优先级队列，依次降级，直到任务完成。 特点：支持优先级和时间片轮转；动态调整任务优先级；减少“饥饿”现象。 应用场景：适用于需要动态调整任务优先级的场景。 僵尸进程与孤儿进程在Unix&#x2F;Linux系统中，进程通过fork()系统调用创建子进程，子进程是父进程的副本，拥有独立的进程控制块（PCB）。子进程与父进程相互独立，即使父进程终止，子进程仍然可以继续运行。 僵尸进程当子进程调用exit()系统调用结束自己的生命时，内核会释放子进程占用的资源，但子进程的PCB仍然保留在系统中。这些信息只有在父进程调用wait()或waitpid()系统调用时才会被释放，以便父进程了解子进程的退出状态。 僵尸进程是指子进程已经终止，但父进程没有调用wait()或waitpid()系统调用来获取子进程的退出状态，导致子进程的PCB没有及时释放。僵尸进程虽然不再运行，但其PCB仍然占用系统资源，可能导致资源泄漏。 孤儿进程孤儿进程是指父进程已经终止，但子进程仍然在运行的进程。由于父进程已经终止，子进程无法通过父进程调用wait()或waitpid()系统调用，导致其PCB无法被回收。操作系统会检测到孤儿进程，并将其父进程设置为init进程（进程ID为1），由init进程负责回收孤儿进程的PCB。 如何检测僵尸进程在Linux系统中，可以使用以下方法检测僵尸进程： 使用top命令： 打开终端并输入top命令。 在top命令的输出中，S（Status）列下标记为”Z”的进程即为僵尸进程。 使用ps命令： 打开终端并输入ps aux命令。 在ps命令的输出中，STAT列下标记为”Z”的进程即为僵尸进程。 **使用ps命令结合grep**： 打开终端并输入ps aux | grep Z命令。 该命令会列出所有状态为”Z”的进程，即僵尸进程。 死锁什么是死锁？死锁是指在多线程或多进程环境中，两个或多个线程（或进程）因为资源被占用而陷入相互循环等待的状态，导致所有相关线程（或进程）都无法继续执行。死锁是一种常见的并发问题，可能导致系统停滞，影响系统的稳定性和性能。 死锁的必要条件死锁的发生必须同时满足以下四个必要条件： 互斥（Mutual Exclusion）：至少有一个资源必须处于非共享模式，即一次只能被一个线程（或进程）占用。如果另一个线程（或进程）请求该资源，它必须等待资源被释放。 非抢占性（No Preemption）：资源不能被强制剥夺，只能由持有资源的线程（或进程）主动释放。其他线程（或进程）不能强行抢占资源。 持有等待（Hold and Wait）：线程（或进程）在请求其他资源时，必须持有至少一个资源。即线程（或进程）在等待其他资源的同时，不会释放已持有的资源。 循环等待（Circular Wait）：存在一组线程（或进程），每个线程（或进程）都在等待下一个线程（或进程）持有的资源，形成一个闭环。 死锁解决方案死锁问题与其四个必要条件是充要关系，即只要破坏四个条件中的任意一个条件，就可以解除死锁状态。常见的死锁解决方案可以概括为预防、避免、检测和解除。 1. 预防死锁（Deadlock Prevention）预防死锁是通过破坏死锁的必要条件来避免死锁的发生。具体方法包括： 破坏互斥条件：允许资源共享，但这通常不现实，因为某些资源天生就是独占的。 破坏非抢占条件：允许资源被强制剥夺，但这可能导致资源状态不一致，通常不推荐。 破坏持有等待条件：要求线程（或进程）在请求资源时必须释放所有已持有的资源，但这可能导致资源利用率降低。 破坏循环等待条件：对资源进行排序，要求线程（或进程）按照固定顺序请求资源，避免形成循环等待。 2. 避免死锁（Deadlock Avoidance）避免死锁是通过动态分配资源，确保系统始终处于安全状态，避免进入死锁状态。常见的避免死锁算法包括： 银行家算法（Banker’s Algorithm）：在分配资源前，预先检查分配是否会导致系统进入不安全状态，只有在安全状态下才进行资源分配。 3. 检测死锁（Deadlock Detection）检测死锁是通过周期性地检查系统状态，判断是否存在死锁。常见的检测方法包括： 资源分配图（Resource Allocation Graph）：通过构建资源分配图，检查是否存在环路，判断是否存在死锁。 等待图（Wait-For Graph）：通过构建等待图，检查是否存在环路，判断是否存在死锁。 4. 解除死锁（Deadlock Recovery）解除死锁是通过强制终止某些线程（或进程）或剥夺某些资源，打破死锁状态。常见的解除死锁方法包括： 进程终止：强制终止一个或多个陷入死锁的线程（或进程），释放其占用的资源。 资源抢占：选择一个线程（或进程），强制剥夺其占用的资源，分配给其他线程（或进程）。 "},{"title":"分布式-分布式事务","date":"2024-10-27T13:08:20.000Z","url":"/2024/10/27/%E5%88%86%E5%B8%83%E5%BC%8F-%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/","tags":[["分布式事务","/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/"]],"categories":[["分布式","/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"]],"content":"事务为什么需要事务？在复杂的系统操作中，数据一致性是一个关键问题。例如，在转账场景中，A向B转账100元，执行顺序为先扣除A账户中的100元，再向B账户中增加100元。如果系统在扣除A账户的100元后突然宕机，B账户并未增加100元，这将导致数据不一致。为了解决这类问题，事务机制应运而生。事务确保一组操作要么全部完成，要么全部不完成，从而保证数据的一致性和完整性。 数据库事务在日常开发中，特别是在单体架构中，数据库事务是最常见的事务类型。数据库事务可以保证多个数据库操作作为一个逻辑上的整体来执行，遵循“要么全部完成，要么全部不完成”的原则。 数据库事务具有ACID特性，确保数据的可靠性和一致性： 原子性（Atomicity）：事务是最小的执行单位，不可分割。事务的原子性确保动作要么全部完成，要么全部失败。 一致性（Consistency）：执行事务前后，数据要保持一致。例如，在转账事务中，无论转账成功与否，转账者和收款者的总额应保持不变。 隔离性（Isolation）：并发数据库访问时，一个事务不会影响另外一个事务，事务之间是独立的。 持久性（Durability）：一个事务被提交之后，在数据库中的修改是永久的，即使数据库发生故障也不会对其有任何影响。 需要注意的是，A、I、D是实现手段，而C是最终目的。 数据库事务实现原理MySQL默认的InnoDB引擎通过以下机制实现事务的ACID特性： 原子性（Atomicity）：通过undo log（回滚日志）来保证。undo log记录了事务执行前的数据状态，如果事务执行过程中发生错误，可以通过undo log回滚到事务开始前的状态。 持久性（Durability）：通过redo log（重做日志）来保证。redo log记录了事务执行后的数据状态，即使数据库发生故障，也可以通过redo log恢复到事务提交后的状态。 隔离性（Isolation）：通过锁机制和MVCC（多版本并发控制）来保证。锁机制确保事务在执行过程中不会被其他事务干扰，MVCC通过为每个事务创建一个版本号，确保事务之间的数据隔离。 一致性（Consistency）：通过上述机制的协同作用，确保事务执行前后数据的一致性。 事务隔离级别MySQL默认的事务隔离级别是Repeatable-read（可重复读），不同的隔离级别会影响事务的并发性能和数据一致性： Read Uncommitted（读未提交）：最低的隔离级别，事务可以读取到其他事务未提交的数据，可能导致脏读、不可重复读和幻读。 Read Committed（读已提交）：事务只能读取到其他事务已提交的数据，避免了脏读，但可能出现不可重复读和幻读。 Repeatable Read（可重复读）：事务在执行过程中多次读取同一数据时，结果保持一致，避免了不可重复读，但可能出现幻读。 Serializable（串行化）：最高的隔离级别，事务串行执行，避免了所有并发问题，但性能最低。 通过理解事务的ACID特性和实现原理，开发人员可以更好地设计和实现可靠的数据库操作，确保系统的数据一致性和稳定性。 分布式事务在微服务架构下，一个系统被拆分为多个小的微服务，每个微服务可能存在不同的服务器上，并且每个微服务可能都有一个单独的数据库供自己使用。这种情况下，一组操作可能涉及多个微服务以及多个数据库。 例如，在电商系统中，创建一个订单一般会涉及到两个表以上的操作：订单表加1，库存表减1。而订单表和库存表可能分别存放在不同服务器的数据库中。这种场景下想要保证数据的一致性，应该如何实现？ 此时，想通过数据库自带的事务管理可能不太够用了，需要通过分布式事务来实现。 涉及在不同的数据库进行操作时，都应该引入分布式事务。比如在单个数据库的性能达到瓶颈或数据量过大时，我们需要进行分库，分库之后，同一个数据库的表数据分布在了不同的表中。 分布式事务的最终目的，也就是保证多个相关联的数据库之间的数据保持一致。按道理来说既然是保证一致性，那么应该也是保证ACID特性。但由于性能、可用性等方面考虑，分布式事务往往无法保证ACID，而只能选择一个比较折中的方案。 分布式事务解决方案刚性事务在互联网分布式场景中，某些关键业务场景要求数据具备强一致性，因此需要采用能够保证这种特性的解决方案，这类解决方案被称为刚性事务。常见的刚性事务解决方案包括两阶段提交（2PC）、三阶段提交（3PC）等。 2PC 和 3PC 属于业务代码无侵入式的解决方案，它们都是基于 XA 规范衍生出来的实现。 XA 规范是由 X&#x2F;Open 组织提出的分布式事务处理标准，定义了分布式事务管理器（Transaction Manager, TM）和资源管理器（Resource Manager, RM）之间的接口： AP（Application Program）：应用程序本身。 RM（Resource Manager）：资源管理器，是事务的参与者，绝大多数情况下指代的都是数据库，一个分布式事务通常涉及多个RM。 TM（Transaction Manager）：事务管理器&#x2F;协调者，负责管理全局事务，分配事务唯一标识符，监控事务的执行进度，并负责事务的提交、回滚、失败恢复等。 2PC（二阶段提交协议） 2PC（Two-Phase Commit），即两阶段提交协议，是一种经典的分布式事务协议，旨在确保分布式系统中的多个节点在事务提交或回滚时保持一致性。2PC 分为两个阶段：准备阶段（Prepare Phase）和提交阶段（Commit Phase）。 准备阶段（Prepare）准备阶段的核心目标是确认所有事务参与者是否能够成功执行本地数据库操作。 准备阶段的工作流程如下： 询问阶段：事务管理者&#x2F;协调者（Transaction Manager, TM）向所有涉及到事务的参与者（Resource Manager, RM）发送询问消息，询问它们是否可以执行事务操作，并等待 RM 的回复。 执行阶段：RM 接收到询问消息后，执行本地事务操作，如写入 redo log、undo log 等。此时，事务尚未提交。如果 RM 能够成功执行事务操作，则向 TM 响应“Yes”表示已就绪；如果事务执行失败，则响应“No”表示未就绪。 提交阶段（Commit Phase）提交阶段的核心目标是确认所有事务参与者是否能够成功提交本地事务。 当准备阶段的所有参与者都响应“已就绪”状态给 TM 时，进入事务提交阶段： 提交指令：TM 向所有 RM 发送“Commit”指令，表示 RM 可以进行事务提交。 提交事务：RM 接收到“Commit”指令后，开始提交本地事务，并释放占用的数据库资源。 确认提交：RM 提交事务后，向 TM 回复“ACK”确认消息，表示事务已完成提交。 事务结束：TM 收到所有 RM 的确认消息后，整个分布式事务正式结束。 然而，如果在提交阶段有部分参与者响应“未就绪”状态，则表示有部分事务执行失败。根据事务的原子性原则，此时需要进行事务回滚： 回滚指令：TM 向所有 RM 发送“Rollback”指令，表示 RM 需要进行事务回滚。 回滚事务：RM 接收到“Rollback”指令后，开始回滚本地事务，并释放占用的数据库资源。 确认回滚：RM 回滚事务后，向 TM 回复“ACK”确认消息，表示事务回滚已完成。 事务中断：TM 收到所有 RM 的确认消息后，中断整个事务。 总结2PC 的准备阶段旨在确认所有参与者是否能够执行事务操作；提交阶段则确认参与者的事务提交状态。提交阶段的结果由准备阶段决定，是进行提交还是进行回滚。 2PC 的优点： 简单易实现：2PC 的实现相对简单，易于理解和部署。 强一致性：2PC 能够确保事务的强一致性，适用于对数据一致性要求极高的场景。 2PC 的缺点： 同步阻塞：由于需要保持强一致性，2PC 在事务期间会占用资源，导致其他事务被阻塞，降低了系统的可用性。 数据不一致：如果 TM 在事务过程中突然宕机，可能会导致部分参与者已经提交事务，而其他参与者尚未提交，从而引发数据不一致问题。 单点故障：TM 在 2PC 中扮演着至关重要的角色，如果 TM 宕机，其他 RM 将无法继续进行事务操作，导致系统停滞。 3PC（三阶段提交协议） 3PC（Three-Phase Commit）是对 2PC 的改进，通过引入一个预提交阶段（PreCommit Phase）来减少阻塞问题，并提高系统的可用性。3PC 将事务的准备阶段分为两个部分：准备阶段（CanCommit Phase）和预提交阶段（PreCommit Phase），再加上最终的提交阶段（DoCommit Phase）。 准备阶段（CanCommit Phase）准备阶段（CanCommit Phase）的核心目的是确认所有参与者（Resource Manager, RM）的响应能力和是否能够执行本地数据库事务操作。 准备阶段的工作流程如下： 询问阶段：事务管理者&#x2F;协调者（Transaction Manager, TM）向所有 RM 发送“CanCommit”询问消息，询问它们是否能够执行事务操作，并等待 RM 的回复。 响应阶段：RM 接收到“CanCommit”询问消息后，不会执行实际的事务操作，而是根据自身状态判断是否能够执行事务。如果 RM 能够执行事务操作，则向 TM 响应“Yes”表示可以执行；如果 RM 不能执行事务操作，则响应“No”表示不能执行；如果 RM 超时未响应，TM 也会认为 RM 不能执行事务。 预提交阶段（PreCommit Phase）如果准备阶段中所有的 RM 都回复了“Yes”，则进入预提交阶段（PreCommit Phase）。预提交阶段的核心目的是让 RM 执行本地事务操作，但并不提交事务。 预提交阶段的工作流程如下： 预提交指令：TM 向所有 RM 发送“PreCommit”指令，表示 RM 可以执行本地事务操作，但不要提交。 执行事务操作：RM 接收到“PreCommit”指令后，执行本地事务操作，但并不提交事务。如果 RM 成功执行事务操作，则向 TM 响应“Yes”表示事务执行完毕；如果 RM 执行事务操作失败，则响应“No”表示事务执行失败。 超时机制：在预提交阶段，TM 和 RM 都引入了超时机制。如果 TM 在一定时间内未收到 RM 的响应，或者 RM 在执行事务操作时超时，都会触发事务回滚，以解除资源占用，避免事务阻塞。 执行事务提交阶段（DoCommit Phase）进行真正的事务提交。 如果 TM 在预提交阶段收到了所有 RM 响应“Yes”，则进入最终的提交阶段（DoCommit Phase）。 提交阶段的工作流程如下： 提交指令：TM 向所有 RM 发送“DoCommit”指令，表示 RM 可以进行事务提交。 提交事务：RM 接收到“DoCommit”指令后，提交本地数据库事务，并释放占用的资源。 确认提交：RM 提交事务后，向 TM 回复“Committed”确认消息，表示事务已完成提交。 事务结束：TM 收到所有 RM 的“Committed”确认消息后，整个 3PC 事务正式结束。 如果在预提交阶段有任一 RM 响应“No”或者超时未响应，TM 会向所有 RM 发送“Abort”指令，中断事务。此时中断事务的损失对 RM 来说并不大，因为事务还未进行提交。 总结3PC 通过引入预提交阶段，减少了 2PC 中的阻塞问题，并提高了系统的可用性。3PC 的工作流程如下： CanCommit Phase：确认 RM 的响应能力和是否能够执行事务操作。 PreCommit Phase：RM 执行本地事务操作，但并不提交，引入超时机制以避免阻塞。 DoCommit Phase：进行真正的事务提交，确保所有 RM 都成功提交事务。 3PC 的优点： 减少阻塞：通过引入预提交阶段，减少了 2PC 中的阻塞问题，提高了系统的可用性。 超时机制：引入了超时机制，避免了因单点故障导致的事务阻塞。 3PC 的缺点： 复杂性增加：相较于 2PC，3PC 的实现更为复杂，增加了系统的复杂性。 性能开销：由于引入了额外的阶段和超时机制，3PC 的性能开销相对较大。 柔性事务基于分布式系统的 CAP 理论与 BASE 理论，日常的分布式架构下更多需要保证的是整体系统的可用性，在数据的一致性方面可以进行一定的妥协，更多采用的是“最终一致性”方案，此类方案称为柔性事务。常见的柔性事务解决方案包括 TCC（补偿事务）、消息队列事务（MQ 事务）、Saga 等。 TCC（补偿事务）TCC（Try-Confirm-Cancel）是一种补偿型事务模型，它将事务分为三个阶段：尝试阶段（Try Phase）、确认阶段（Confirm Phase）和取消阶段（Cancel Phase）。TCC 通过显式地定义事务的尝试、确认和取消逻辑，来实现分布式事务的最终一致性。 尝试阶段（Try Phase）尝试阶段的核心目标是尝试执行事务操作，并准备好业务所需的资源。 尝试阶段的工作流程如下： 业务检查：业务系统进行必要的业务检查，确保事务操作可以执行。 资源预留：业务系统预留必要的资源，如数据库锁、缓存资源等，但并不提交事务。 确认阶段（Confirm Phase）确认阶段的核心目标是确认执行事务操作，并处理尝试阶段预留的业务资源。 确认阶段的工作流程如下： 确认执行：当所有参与者的尝试阶段都执行成功后，事务协调者（Transaction Coordinator, TC）向所有参与者发送确认指令（Confirm）。 资源提交：参与者接收到确认指令后，提交事务并释放预留的资源。 取消阶段（Cancel Phase）取消阶段的核心目标是取消执行事务操作，并释放尝试阶段预留的资源。 取消阶段的工作流程如下： 取消执行：如果任何一个参与者的尝试阶段执行失败，或者在确认阶段出现失败，事务协调者向所有参与者发送取消指令（Cancel）。 资源释放：参与者接收到取消指令后，回滚事务并释放预留的资源。 失败处理与重试机制在 TCC 的确认阶段或取消阶段，如果出现失败，TCC 会记录事务日志并持久化到某种存储介质上，如本地磁盘文件或关系型数据库等。事务日志包含了事务的执行状态。 如果检测到在确认或取消阶段执行事务出现失败状态，TCC 会进行重试该阶段的事务逻辑。重试次数一般为 6 次，若超过重试次数仍然失败，则需要人工介入处理。 事务日志的管理事务日志在事务执行成功后可以被删除，以节省资源。事务日志的管理通常由事务协调者负责，确保在事务成功提交后清理相关日志。 业务侵入性TCC 不需要依赖于底层的数据库资源，更多地是需要手动实现事务的尝试、确认和取消逻辑，因此属于业务侵入式分布式事务解决方案。开发人员需要在业务代码中显式地实现 TCC 的三个阶段，增加了开发复杂度，但同时也提供了更高的灵活性和控制力。 MQ事务消息队列（Message Queue, MQ）事务允许事务流应用将生产、处理、消费消息的整个过程看作是一个原子操作。常见的消息队列系统如 RocketMQ、Kafka、Pulsar、QMQ 等都提供了事务相关的功能。下面以 RocketMQ 为例，详细介绍 MQ 事务的工作原理和处理机制。 RocketMQ 事务消息RocketMQ 的事务消息机制采用了类似于两阶段提交（2PC）的流程，确保消息的生产和消费过程的原子性。 事务消息的基本流程 发送半事务消息： 生产者在消息队列中开启一个事务，然后发送“半事务”消息（Half Message）给 RocketMQ 的 Broker。此时，“半事务消息”对于消费者来说是不可见的。 Broker 接收到“半事务消息”后，响应“半事务消息发送成功”信息给生产者。 执行本地事务： 生产者收到 Broker 的“发送成功”响应后，开始执行本地事务操作。 根据本地事务的执行状态，生产者决定向 Broker 发送“Commit”或“Rollback”指令。 提交或回滚事务消息： 如果生产者发送“Commit”指令，Broker 将“半事务消息”转换为真正的消息，并投递给消费者进行消费。 如果生产者发送“Rollback”指令，Broker 将丢弃该“半事务消息”，不进行投递。 失败处理与事务反查机制如果在第 4 步，生产者发送“Commit”或“Rollback”消息失败了，RocketMQ 的 Broker 会定期查询生产者对应事务的本地事务执行情况，并根据反查结果决定提交或回滚这个“半事务消息”。 事务反查机制的实现依赖于业务代码实现的对应接口。RocketMQ 提供了事务反查的回调接口，业务系统需要实现该接口，以便 Broker 在需要时查询本地事务的状态。 消息消费失败处理如果消息消费失败，RocketMQ 会进入消息重试机制，再次尝试消费消息。如果消息重试超过了最大次数，RocketMQ 会认为这个消费有问题，然后将其放入死信队列（Dead Letter Queue, DLQ）中，由人工手动排查处理。 QMQ 事务消息QMQ 的事务消息机制相对简单，它借助了数据库自带的事务功能，采用了类似于 eBay 提出的本地消息表方案，将分布式事务拆分成本地事务进行处理。 本地消息表方案 业务操作与消息表写入： 业务系统在执行本地事务操作的同时，将消息发送状态写入本地消息表。这两个操作在一个事务中提交，确保业务操作成功时消息表也写入成功。 消息发送： 单独起一个线程定时轮询消息表，将未处理的消息发送到消息中间件（如 RocketMQ、Kafka 等）。 消息发送成功后，更新消息状态为成功或直接删除消息。 优点与适用场景QMQ 的事务消息方案中，即使消息队列挂掉，也不会影响数据库事务的执行，因此更加适应于大多数业务场景。这种方法同样适用于其他消息队列，只是 QMQ 封装得更好，提供了开箱即用的解决方案。"},{"title":"分布式-服务治理（下）","date":"2024-10-21T07:24:49.000Z","url":"/2024/10/21/%E5%88%86%E5%B8%83%E5%BC%8F-%E6%9C%8D%E5%8A%A1%E6%B2%BB%E7%90%86%EF%BC%88%E4%B8%8B%EF%BC%89/","tags":[["监控系统","/tags/%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F/"],["日志管理","/tags/%E6%97%A5%E5%BF%97%E7%AE%A1%E7%90%86/"]],"categories":[["分布式","/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"]],"content":"监控系统监控中心的作用建立完善的监控体系是确保系统稳定性和性能优化的关键。监控中心的主要作用包括： 数据可视化：通过可视化工具直观展示系统的运行状态、资源使用情况等关键指标，帮助运维人员快速了解系统健康状况。 长期趋势预测：通过对监控数据的持续收集和统计分析，预测系统指标的发展趋势，例如通过磁盘使用率的趋势分析，提前规划资源扩容，避免资源瓶颈。 故障预警与告警：当系统指标出现异常时，及时通知管理员，以便迅速采取措施处理故障，确保业务的连续性和稳定性。 常见监控对象与指标 硬件监控：CPU状态、磁盘状态、电源状态、内存状态、宽带状态、机器温度等 服务器监控：CPU、内存、磁盘、网络 数据库监控：数据库连接数量、QPS（每秒查询次数）、TPS（每秒事务处理次数）、缓存命中率、主从延时、慢查询、锁状态等 中间件监控： Nginx：活跃连接数、等待连接数、抛弃连接数、请求量、耗时、错误率 Tomcat：最大线程数、当前线程数、请求量、耗时、堆内存使用情况、GC次数和耗时 缓存：成功连接数、阻塞连接数、已使用内存、缓存命中率、内存碎片率、请求量、耗时 详细队列：连接数、队列数、生产速率、消费速率、消息堆积量 应用监控： Http接口：URL存活、请求量、耗时、异常量 RPC接口：请求量、耗时、超时量、拒绝量 JVM：内存各分区大小、GC次数、GC耗时、当前线程数、线程死锁数 线程池：活跃线程数、任务队列大小、任务执行耗时、拒绝任务数 连接池：总连接数、活跃连接数 日志监控：访问日志、错误日志 监控系统的基本流程市面上的监控系统虽然在具体实现上有所差异，但其基本流程大致相同，主要包括以下几个关键步骤： 数据采集 数据采集是监控系统的基础，其方式多种多样，主要包括： 日志埋点采集：通过工具如Filebeat等进行日志的上报和解析，获取系统运行日志中的关键信息。 JMX标准接口：利用Java Management Extensions (JMX)标准接口，获取Java应用的监控指标。 REST API：被监控对象提供REST API接口，监控系统通过调用API获取数据，例如Elasticsearch (ES)。 系统命令行：通过执行系统命令获取监控数据，如使用top、vmstat等命令获取系统资源使用情况。 SDK埋点：通过统一的SDK进行侵入式的埋点和上报，适用于需要高精度监控的场景。 数据传输 数据传输是将采集到的数据发送给监控系统的关键步骤，通常采用以下协议和模式： TCP&#x2F;UDP协议：数据通过TCP或UDP协议进行传输，适用于实时性要求较高的场景。 HTTP协议：数据通过HTTP协议进行传输，适用于需要跨网络传输的场景。 Push模式：监控系统主动将数据推送到监控中心，适用于数据量较小且实时性要求高的场景。 Pull模式：监控中心主动从被监控对象拉取数据，适用于数据量较大且实时性要求不高的场景。 数据存储 数据存储是监控系统的核心环节，主要用于保存采集到的监控数据，以便后续的分析和展示。常见的存储方式包括： 时序数据库：如InfluxDB、Prometheus等，适用于存储时间序列数据，支持高效的时间查询和聚合操作。 关系型数据库：如MySQL、PostgreSQL等，适用于存储结构化数据，支持复杂的查询和分析。 分布式文件系统：如HDFS、Ceph等，适用于存储大规模的日志数据，支持高吞吐量的读写操作。 监控展示 监控展示是将存储的监控数据以图形化方式展示出来，帮助运维人员直观了解系统状态。 监控告警 监控告警是监控系统的重要功能，通过预设的阈值和规则，及时通知运维人员处理异常情况。常见的告警方式包括： 邮件通知：通过邮件发送告警信息，适用于日常监控和通知。 短信通知：通过短信发送告警信息，适用于紧急情况下的快速响应。 电话通知：通过电话语音通知，适用于需要立即处理的严重故障。 Webhook：通过Webhook将告警信息推送到其他系统，如Slack、钉钉等，实现自动化处理。 监控系统技术选型Prometheus是一款由Go语言开发的开源监控和告警工具，以其强大的时序数据库和灵活的查询语言而著称。Prometheus的基本原理是通过HTTP长连接以Pull（监控服务器主动拉取被监控组件数据）的方式进行监控，被监控组件只需提供HTTP接口即可接入监控系统。 Prometheus的特性 服务发现机制：Prometheus提供了开箱即用的服务发现机制，能够自动发现监控端点，支持多种服务发现方式，如静态配置、DNS、Kubernetes、Consul等。 时序数据库TSDB：Prometheus自研的时序型数据库TSDB（Time Series Database），专门用于存储时间序列数据，支持高效的查询和聚合操作。 查询语言PromQL：Prometheus提供了强大的查询语言PromQL（Prometheus Query Language），支持丰富的聚合函数和表达式，能够灵活地进行数据分析和处理。 告警规则：Prometheus支持灵活的告警规则配置，包括告警收敛（分组、抑制、静默）、多级路由等高级功能，确保告警的准确性和及时性。 生态完善：Prometheus拥有丰富的生态系统，包括各种Exporter、Alertmanager、Grafana等组件，能够满足不同场景的监控需求。 基本架构 Prometheus Server：核心组件，负责收集、存储监控信息。支持静态配置和动态服务发现，从监控对象获取数据并存储到本地磁盘。Prometheus Server本身也是一个时序型数据库，通过自定义的PromQL对数据进行查询分析。 Exporter：用于采集数据的组件，负责从被监控对象获取数据并暴露HTTP接口供Prometheus Server拉取。常见的Exporter包括Node Exporter（监控主机）、MySQL Exporter（监控MySQL数据库）等。 Pushgateway：主要用于瞬时任务的场景，防止Prometheus Server在任务执行完毕前未能及时拉取监控数据。Pushgateway作为数据中转站，接收瞬时任务的监控数据并缓存，供Prometheus Server后续拉取。 日志管理日志系统在分布式架构中，日志分散在不同的服务器节点上，传统的日志查看方式需要登录到各个服务器，使用Linux命令逐个排查，效率低下且耗时耗力。为了解决这一问题，集中式日志管理系统应运而生。日志系统本质上是一个集中管理日志的系统，旨在提供高效、便捷的日志采集、处理、存储、展示、查询和告警功能。 一个完善的日志系统应具备以下核心功能： 日志采集：支持多种日志格式以及数据源的采集。 日志数据清洗&#x2F;处理：采集到的原始日志数据通常包含噪声和冗余信息，需要进行清洗，去除无效数据和重复数据。对清洗后的日志数据进行进一步处理，如格式转换、字段提取、数据聚合等，以便于后续的存储和分析。 存储日志：支持对接多种存储方式，如Elasticsearch（ES）、Hadoop、关系型数据库等，根据日志数据的特点选择合适的存储方案。 展示日志：支持可视化展示日志。 查询和分析日志：提供友好的查询接口，支持多种条件进行查询和统计分析，以帮助用户快速排除问题。 告警：支持内置告警功能，根据预设的规则和阈值，自动触发告警通知。 ELKELK是最原始的日志系统架构，由三个项目的首字母组成，即Elasticsearch、Logstash和Kibana。随着技术的发展，ELK架构也在不断演进，引入了新的组件以提升性能和功能。 旧 ELK 架构旧的ELK架构按功能顺序如下： Logstash：用于日志的收集和处理，支持多种日志格式。Logstash主要负责日志的采集、清洗和格式化。 Elasticsearch：这是一个使用Java开发的分布式搜索引擎，能够解决模糊查询等存在的性能问题。在ELK系统中，Elasticsearch主要用于日志的存储和搜索。 Kibana：Kibana是专门用来与Elasticsearch配合使用的，可以自定义表格对Elasticsearch中的数据进行挖掘分析和可视化。在ELK系统中，Kibana主要用于对Elasticsearch中搜索出来的日志进行可视化展示。 新 ELK 架构原始ELK架构存在一个问题：Logstash资源占用过高，尤其是在大规模日志采集场景下，Logstash的性能瓶颈较为明显。 为了解决这一问题，Elastic推出了Beats。Beats基于名为libbeat的Go语言框架，包含多个成员，每个成员负责不同的数据采集任务。 Beats 组件 Filebeat：用于采集日志文件，支持多种日志格式，能够高效地采集和传输日志数据。 Metricbeat：用于采集服务器的各种指标数据，如CPU、内存、磁盘、网络等，支持多种操作系统和应用程序。 Packetbeat：用于采集网络数据包，支持多种网络协议，能够分析网络流量和性能。 Heartbeat：用于监控服务的可用性，通过定期发送心跳包检测服务的健康状态。 Winlogbeat：用于采集Windows事件日志，支持多种Windows事件日志格式。 Auditbeat：用于采集系统审计数据，支持Linux和macOS系统的审计日志。 Functionbeat：用于在无服务器环境中采集数据，支持AWS Lambda等无服务器平台。 Journalbeat：用于采集Linux系统日志，支持systemd journal日志格式。 Beats采集的数据可以直接发送到Elasticsearch，或者在Logstash进一步处理之后再发送到Elasticsearch。Beats的引入大大扩展了ELK架构的功能，使其不仅限于日志采集，还能支持各种指标和网络数据的采集。 新 ELK 架构的优势 资源占用低：Beats组件资源占用较低，适合大规模日志采集场景，减轻了Logstash的负担。 功能扩展：Beats组件不仅支持日志采集，还支持各种指标和网络数据的采集，扩展了ELK架构的应用场景。 灵活性高：Beats组件可以根据需求选择使用，灵活配置，满足不同场景的监控需求。 新 ELK 架构的工作流程 数据采集：Filebeat等Beats组件负责采集日志、指标和网络数据，并将其发送到Logstash或直接发送到Elasticsearch。 数据处理：Logstash负责对采集到的数据进行清洗、格式化和处理，然后发送到Elasticsearch。 数据存储：Elasticsearch负责存储处理后的数据，并提供高效的搜索和分析功能。 数据展示：Kibana负责对Elasticsearch中的数据进行可视化展示，生成仪表盘、图表和报表，帮助用户快速了解系统状态。 通过引入Beats组件，新ELK架构在性能和功能上得到了显著提升，能够更好地满足现代分布式系统的监控需求。 EFKEFK中的F指的是Fluentd。EFK日志系统架构与原始ELK架构类似，只不过日志的收集和处理角色变成了Fluentd。 Fluentd是一款开源的日志收集器，使用Ruby编写，相较于Logstash更加的轻量化，性能也更加优越，内存占用低。 轻量级日志系统 LokiELK（Elasticsearch、Logstash、Kibana）日志系统虽然功能丰富、稳定可靠，但其资源消耗较大，成本较高。对于许多用户来说，ELK的许多功能可能并不常用。因此，Grafana Labs团队开源了Loki，这是一个小巧易用的日志系统，原生支持Grafana，并且特别适合Prometheus和Kubernetes用户。 Loki 架构Loki的架构非常简单，主要由三个组件组成： Loki：主服务器，负责存储日志和处理查询。 Promtail：代理，负责收集日志并将其发送给Loki。 Grafana：用于日志数据的可视化展示。 Loki的设计理念类似于Prometheus，但主要为日志服务。Loki特别适合存储Kubernetes Pod日志，能够高效地处理大规模日志数据。 Loki 的优势 轻量级：Loki的资源消耗较低，适合中小型企业或对资源敏感的场景。 原生支持Grafana：Loki与Grafana无缝集成，提供强大的可视化功能。 适合Kubernetes：Loki特别优化了Kubernetes日志的存储和查询，适合云原生环境。 Loki 的工作流程 日志采集：Promtail负责从各种数据源（如文件、容器日志等）采集日志数据。 日志传输：Promtail将采集到的日志数据发送到Loki服务器。 日志存储：Loki将日志数据存储在本地或分布式存储系统中。 日志查询：用户通过Grafana查询和分析Loki中的日志数据，生成可视化图表和报表。 ClickHouse + ClickVisual越来越多的互联网公司开始尝试使用ClickHouse存储日志，以替代传统的Elasticsearch。ClickHouse是一种高性能的OLAP数据库，适合大规模日志数据的存储和查询。相比Elasticsearch，ClickHouse更加节省资源，能够无压力地全量写入日志数据。 ClickHouse 的优势 节省资源：ClickHouse的资源消耗较低，适合大规模日志数据的存储。 高性能：ClickHouse在处理大规模数据时表现出色，虽然查询性能相比Elasticsearch可能稍慢，但仍能满足大多数需求。 灵活性：ClickHouse支持多种数据类型和查询方式，适合不同场景的日志存储需求。 ClickVisualClickVisual是一个基于ClickHouse构建的轻量级日志分析和数据可视化平台，由石墨文档开源。ClickVisual提供了日志采集、存储、查询和可视化功能，适合中小型企业使用。 ClickVisual 的改进尽管ClickVisual在日志存储和分析方面表现出色，但仍存在一些问题，如全文检索效率低、强依赖Kafka等。为了解决这些问题，ClickVisual进行了以下改进： 使用Vector替代Kafka引擎：提高了日志摄入的灵活性和稳定性，降低了运维成本，并支持流量控制，避免ClickHouse内存爆满。 引入Null表引擎：实现原始日志（从Vector写入的）转换成按照日志解析格式解析之后的真实日志表。 支持高效全文检索：在真实日志表中存储原始日志并构建跳数索引，实现了高效的近似全文检索。 ClickHouse + ClickVisual 的工作流程 日志采集：使用Vector等工具从各种数据源采集日志数据。 日志传输：Vector将采集到的日志数据发送到ClickHouse。 日志存储：ClickHouse将日志数据存储在本地或分布式存储系统中。 日志查询：用户通过ClickVisual查询和分析ClickHouse中的日志数据，生成可视化图表和报表。 通过引入ClickHouse和ClickVisual，企业可以构建一个高效、灵活且节省资源的日志管理系统，满足不同规模的日志存储和分析需求。"},{"title":"分布式-服务治理（上）","date":"2024-10-21T07:24:40.000Z","url":"/2024/10/21/%E5%88%86%E5%B8%83%E5%BC%8F-%E6%9C%8D%E5%8A%A1%E6%B2%BB%E7%90%86%EF%BC%88%E4%B8%8A%EF%BC%89/","tags":[["服务注册与发现","/tags/%E6%9C%8D%E5%8A%A1%E6%B3%A8%E5%86%8C%E4%B8%8E%E5%8F%91%E7%8E%B0/"],["配置管理","/tags/%E9%85%8D%E7%BD%AE%E7%AE%A1%E7%90%86/"]],"categories":[["分布式","/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"]],"content":"服务注册与发现微服务架构的核心机制在微服务架构下，一个分布式系统通常由多个微服务组成。当用户发起一个请求时，可能需要多个服务协同工作，以此相互配合来维持系统的正常运行。然而，随着业务需求的不断变化，微服务的节点数量可能会动态调整，这就带来了一系列的挑战。 试想一下，一个微服务可能存在多个节点，在需要的时候我们会临时增加或减少该微服务的节点数量。传统的做法是将这些节点的配置信息写死在微服务的配置代码中。当我们动态调整微服务时，就需要手动地去更新配置信息，并且重新启动服务，这样一来就增加了维护成本。 为了解决上述问题，我们需要一个统一管理的平台，让微服务间自动地完成协调治理。当有新增的节点时，能够自动识别并增加到自己的配置；当有挂掉的节点时，微服务能够自动识别并将其从可用列表中删除。服务注册与发现机制就是为此而设计的，微服务的可用列表统一由注册中心维护。通过注册中心，微服务可以动态地获取可用的服务列表。当服务配置更新时，注册中心会将变更推送给相关调用的微服务，无需手动更新，从而降低了维护成本，实现了服务的优雅上下线。 一个完善的服务注册与发现中心应具备以下功能： 服务的注册与服务查询（最基本） 服务状态变更通知、服务健康检查、不可用服务剔除 服务权重配置 服务注册与发现基本流程 服务注册当启动一个服务时，该服务会向注册中心发送自己的服务信息（地址、端口、服务名称等），注册中心将这些信息保存起来，这就是服务注册。 流程步骤： 服务启动：微服务启动时，初始化并配置服务信息。 注册请求：微服务向注册中心发送注册请求，包含服务名称、IP地址、端口号等信息。 注册中心处理：注册中心接收到注册请求后，将服务信息存储在服务注册表中。 服务发现一个服务要调用另外一个服务的节点，于是向注册中心请求所需服务的可用节点信息，这就是服务发现。当服务获取到调用服务的可用节点信息后，通常会将该信息缓存到本地，方便下次使用，同时也能够保证当注册中心挂掉时，不影响当前服务正常调用被调用的服务。 流程步骤： 服务调用请求：调用方服务向注册中心发送服务发现请求，请求所需服务的可用节点信息。 注册中心响应：注册中心返回可用的服务节点列表，包含服务名称、IP地址、端口号等信息。 本地缓存：调用方服务将获取到的服务节点信息缓存到本地，方便下次使用。 健康检测为了保证服务的可用性，注册中心还会通过“心跳机制”来检测服务是否可用。如果服务不可用，注册中心会主动剔除该服务并通知相关服务，更新服务地址信息。 流程步骤： 心跳检测：注册中心定期向微服务发送心跳检测包，微服务在规定时间内响应心跳包。 服务状态更新：如果注册中心在一定时间内未收到微服务的响应，则认为该服务不可用，并将其从可用列表中剔除。 状态变更通知：注册中心将服务状态变更通知推送给相关调用的微服务，调用方更新被调用服务地址信息。 总结：服务注册与发现机制通过服务注册、服务发现和健康检测三个核心流程，实现了微服务架构中的动态服务管理和优雅上下线。通过服务注册，微服务向注册中心注册自己的信息；通过服务发现，调用方服务获取被调用服务的可用节点信息；通过健康检测，注册中心确保服务的可用性，并在服务状态变更时通知相关调用方。 配置管理在微服务架构中，随着业务规模的扩展，服务器节点数量不断增加，导致程序配置的复杂性和管理难度显著提升。传统的配置管理方式逐渐暴露出以下问题： 配置文件碎片化：随着服务数量的增加，配置文件数量急剧增长，导致配置管理的复杂性增加，难以进行统一管理。 配置更新效率低下：传统方式下，配置修改后通常需要重启服务器才能生效，这不仅增加了运维成本，还可能导致服务中断。 配置安全性不足：配置信息通常硬编码在代码库中，容易暴露敏感信息，且难以进行权限控制和审计。 为了应对这些挑战，配置中心（Configuration Center）应运而生。配置中心通过集中化管理微服务的配置信息，提供了一系列高级功能，以提升配置管理的效率和安全性。 配置中心的核心功能一个完善的配置中心应具备以下核心功能： 权限控制：配置的修改和发布应设置严格的权限控制机制，确保只有授权人员才能进行相关操作，从而保障配置的安全性和合规性。 日志记录与审计：配置中心应详细记录所有配置操作的日志，包括修改、发布、回滚等操作，以便于后续的问题排查和审计。 配置推送机制： 推送模式：配置中心主动将配置变更推送给应用服务器，要求服务器与配置中心保持长连接。虽然实现复杂度较高，但能够实现配置的实时更新，适用于对实时性要求较高的场景。 拉取模式：应用服务器主动从配置中心获取最新的配置信息。这种方式实现简单，但实时性较差，适用于对配置更新频率要求不高的场景。 灰度发布：配置中心应支持配置的灰度发布功能，即只将配置变更推送给部分服务器，以便在不影响整体服务的情况下进行配置验证和测试。 版本管理与回滚：配置中心应记录所有发布的配置版本，并支持一键回滚到指定版本。这不仅有助于快速恢复配置，还能提供配置变更的历史记录，便于问题追溯和分析。 常见配置中心在微服务架构中，选择合适的配置中心对于提升系统的可维护性和扩展性至关重要。目前市场上存在多种配置中心解决方案，包括Apollo、Nacos、Kubernetes ConfigMap、Disconf和Spring Cloud Config等。 功能 Apollo Nacos Spring Cloud Config UI配置界面 有 有 无（通过Git操作） 配置实时生效 支持（HTTP长轮询1s内） 支持（HTTP长轮询1s内） 不支持（重启生效，或手动refresh） 版本控制 支持 支持 支持（Git实现） 权限控制 支持 支持 支持（Git实现） 灰度发布 支持 支持 不支持 告警通知 支持 支持 不支持 监听查询 支持 支持 支持 多语言 主流语言，Open API 主流语言，Open API 仅支持Spring应用 多环境 支持 支持 不支持 Apollo和Nacos都是国内公司开源的知名项目，Apollo是携程开源的，Nacos则是阿里开源的。Apollo的配置中心功能更加齐全，而Nacos在一些细微的功能上则略显简单，比如说在Nacos1.1.0版本才支持的灰度发布，但是Nacos可以作为服务注册中心。Spring Cloud Config作为Spring生态组件，可以方便与Spring Cloud体系无缝衔接，但整体的设计比较简单。"},{"title":"分布式-基础理论&算法","date":"2024-10-21T02:58:26.000Z","url":"/2024/10/21/%E5%88%86%E5%B8%83%E5%BC%8F-%E5%9F%BA%E7%A1%80%E7%90%86%E8%AE%BA/","tags":[["CAP","/tags/CAP/"],["BASE","/tags/BASE/"],["Raft","/tags/Raft/"]],"categories":[["分布式","/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"]],"content":"分布式理论CAP定理：深入理解与应用简介CAP定理，即Consistency（一致性）、Availability（可用性）和Partition Tolerance（分区容错性），是分布式系统设计中的一个基本理论。在计算机科学的分布式系统设计中，CAP定理提供了一个框架来理解系统在面对网络分区时的行为。 Consistency（一致性）：所有节点在同一时间点访问到的数据是一致的。这意味着任何读操作都能读取到最新的写操作结果。 Availability（可用性）：非故障节点在合理的时间内返回合理的响应。这意味着系统即使在部分节点故障的情况下，仍然能够对外提供服务。 Partition Tolerance（分区容错性）：系统在出现网络分区时，仍然能够继续运行。网络分区是指系统中的节点被分割成多个不连通的子集。 补充 什么是网络分区？ 在分布式系统中，网络分区是指由于网络故障或其他原因，系统中的节点被分割成多个不连通的子集。每个子集内部的节点可以正常通信，但子集之间的通信被中断。 架构模型CAP定理通常被理解为“一个分布式系统最多只能同时满足两个特性”，但实际上存在一个重要的误解：Partition Tolerance（分区容错性）是必须的。因此，实际上只有CP（一致性和分区容错性）和AP（可用性和分区容错性）两种架构模型，而不存在CA（一致性和可用性）架构。 为什么分区容错性是必须的？ 在实际的分布式系统中，网络分区是不可避免的。即使网络设计得再好，也无法完全避免网络故障。因此，系统必须能够在网络分区的情况下继续运行，这意味着分区容错性是必须的。 接下来，我们深入了解CP和AP架构模型： CP（一致性和分区容错性）CP架构模型保证了系统的一致性和分区容错性。在这种架构下，系统在网络分区时仍然能够保持数据的一致性，但可能会牺牲可用性。例如，在银行系统中，所有节点的数据必须保持一致，即使出现网络分区，系统仍然需要确保数据的一致性。这意味着在数据同步期间，系统可能无法对外提供服务。 应用场景： 银行系统：所有交易记录必须保持一致，即使出现网络分区，系统仍然需要确保数据的一致性。 分布式数据库：如HBase、MongoDB等，这些系统通常采用CP架构来保证数据的一致性。 AP（可用性和分区容错性）AP架构模型保证了系统的可用性和分区容错性。在这种架构下，系统在网络分区时仍然能够对外提供服务，但可能会牺牲一致性。例如，在聊天系统中，多个用户可以同时发送消息，但对方收到的消息可能不是最新的，存在一定的不一致性。 应用场景： 聊天系统：用户可以随时发送消息，即使消息的顺序可能不完全一致。 分布式缓存：如Redis、Memcached等，这些系统通常采用AP架构来保证高可用性。 CAP应用案例Zookeeper：CP架构Zookeeper是一个分布式协调服务，广泛用于分布式系统中的配置管理、命名服务、分布式锁等场景。Zookeeper采用CP架构，主要原因如下： 强一致性：Zookeeper通过ZAB（Zookeeper Atomic Broadcast）协议来保证数据的一致性。ZAB协议确保所有节点在同一时间点看到的数据是一致的，即使在网络分区的情况下，Zookeeper也会选择牺牲可用性来保证一致性。 Leader选举：Zookeeper使用Leader选举机制来确保在网络分区时，只有一个Leader节点能够处理写操作。其他节点在Leader选举完成之前无法处理写操作，从而保证了数据的一致性。 Eureka：AP架构Eureka是一个服务注册与发现系统，用于微服务架构中的服务注册与发现。Eureka采用AP架构，主要原因如下： 高可用性：Eureka的设计目标是高可用性。在网络分区的情况下，Eureka仍然能够对外提供服务，即使存在一定的不一致性。Eureka通过多个Eureka Server实例来实现高可用性，每个实例都可以独立处理服务注册与发现请求。 最终一致性：Eureka采用最终一致性模型。在网络分区的情况下，不同分区的Eureka Server实例可能会暂时不一致，但随着网络恢复，数据会最终达到一致状态。 Nacos：支持CP和AP架构Nacos是一个动态服务发现、配置管理和服务管理平台，支持CP和AP架构，主要原因如下： Raft协议：Nacos的CP模式基于Raft协议，确保数据的一致性和分区容错性。Raft协议通过Leader选举和日志复制来保证数据的一致性，适用于需要强一致性的场景。 Distro协议：Nacos的AP模式基于Distro协议，确保系统的高可用性和分区容错性。Distro协议通过数据分片和异步复制来实现高可用性，适用于需要高可用性的场景。 BASE理论：深入解析与应用简介BASE理论，即Basically Available（基本可用）、Soft state（软状态）和Eventually Consistent（最终一致性），是对CAP理论的补充和扩展。BASE理论的核心思想是：即使无法做到强一致性，也可以根据每个应用的自身业务特点，采用适当的方式来保证最终一致性。 BASE理论可以理解为CAP理论中AP架构模型的补充。在AP架构中，系统牺牲了一致性来保证可用性，但并不是完全放弃一致性。BASE理论提供了一种在保证系统可用性的同时，逐步实现数据一致性的方法。 详解Basically Available（基本可用）基本可用，是指在分布式系统出现故障时，允许损失部分可用性来保证整体系统的基本可用性。 什么叫允许损失部分可用性？ 响应时间上的损失：比如正常访问时间是0.3秒，但由于系统故障，允许响应时间延长到4秒。这种情况下，系统仍然能够对外提供服务，尽管响应时间有所延长。 系统功能上的损失：可以抛弃一些不必要的功能，来保证系统核心功能的可用。例如，在数据访问量巨大时，系统性能有限，可以通过服务降级（关闭不必要的活动）来腾出性能，以供核心业务正常工作。 Soft state（软状态）软状态，即允许系统中的数据存在中间状态（此时系统数据不一致），但认为该状态并不会影响系统整体的可用性。即系统的数据在不同节点间的数据同步存在延迟。 软状态的应用场景： 分布式缓存：在分布式缓存系统中，不同节点的数据副本可能存在短暂的延迟，但系统仍然能够对外提供服务。 消息队列：在消息队列系统中，消息的传递可能存在延迟，但系统仍然能够保证消息的最终传递。 Eventually Consistent（最终一致性）最终一致性，强调的是在系统不同节点中的数据副本，在一段时间后达成完全一致。也就是说，最终一致性可以允许数据不需要实时同步，而是保证最终数据能够达成一致。 最终一致性的实现方法： 读时修复：在读取数据的时候，检查数据的不一致，进行修复。例如，在读取数据时，如果发现数据不一致，可以通过读取其他节点的数据来进行修复。 写时修复：在写入数据时，检查数据的不一致，进行修复。例如，在写入数据时，如果发现数据不一致，可以通过写入其他节点的数据来进行修复。 异步修复：最常用的方式，定时检测数据副本的一致性，进行修复。例如，通过定时任务或事件触发机制，定期检查数据副本的一致性，并进行修复。 一致性3种级别 强一致性：写了什么，读出来就是什么。例如，在单节点系统或采用强一致性协议的分布式系统中，数据在写入后立即对所有节点可见。 弱一致性：不一定读取到的就是最新写入的数据，也不能保证某个时刻能保持一致，只能保证在未来某个时刻达到一致。例如，在某些分布式缓存系统中，数据可能在一段时间内不一致。 最终一致性：弱一致性的升级，系统可以保证在一定时间内达到数据一致。例如，在采用最终一致性模型的分布式数据库中，数据在一段时间后会达到一致状态。 分布式算法Raft算法详解背景在当今高度动态的数据中心和应用服务环境中，系统的资源配置需要根据负载情况进行动态调整，以实现资源的高效利用。例如，在双十一期间，电商平台的访问量会大幅增加，而在淡季时，访问量则会显著减少。为了应对这种情况，我们需要能够动态地进行系统扩缩容，即在不影响客户正常使用的情况下，完成配置的升降级，使系统能够自适应地调整资源。 分布式共识算法就是为了应对这些挑战而设计的。Raft算法是Paxos算法的一个具体实现，旨在提供一种易于理解和实现的分布式共识机制。 拜占庭将军问题为了更好地理解分布式共识算法，我们可以先通过一个经典的例子——拜占庭将军问题来引入。 假设多位拜占庭将军中没有叛军，信使的信息可靠但有可能被暗杀的情况下，将军们如何达成是否要进攻的一致性决定？ 解决方案大致可以理解为：先在所有的将军中选出一个大将军，用来做出所有的决定。 举例如下：假如现在一共有3个将军A、B和C，每个将军都有一个随机时间的倒计时器，倒计时一结束，这个将军就把自己当成大将军候选人，然后派信使传递选举投票的信息给将军B和C。如果将军B和C还没有把自己当作候选人（自己的倒计时还没有结束），并且没有把选举票投给其他人，它们就会把票投给将军A。信使回到将军A时，将军A知道自己收到了足够的票数，成为大将军。在有了大将军之后，是否需要进攻就由大将军A决定，然后再派信使通知另外两个将军，自己已经成为了大将军。如果一段时间还没收到将军B和C的回复（信使可能会被暗杀），那就再重派一个信使，直到收到回复。 共识算法共识是可容错系统中的一个基本问题：即使面对故障，服务器也可以在共享状态上达成一致。 共识算法允许一组节点像一个整体一样进行工作，即使其中的某些节点发生了故障。其正确性来源于复制状态机的性质：一组服务器的状态机计算相同状态的副本，即使部分服务器状态机宕机了，它们依旧能够正常运行。 Raft算法基础节点类型在Raft算法中，节点可以分为三种类型： Leader（领导者）：负责处理所有客户端请求，并将日志条目复制到其他节点。 Follower（跟随者）：被动地接收来自Leader的日志条目，并响应Leader的请求。 Candidate（候选者）：在Leader选举过程中，节点会暂时成为候选者，直到选举出新的Leader。 任期（Term）Raft算法将时间划分为任意长度的任期（Term），每个任期由一个单调递增的整数表示。任期可以理解为选举周期，每个任期开始时，节点会尝试选举出一个Leader。如果选举成功，Leader将管理整个任期；如果选举失败，任期将结束，新的任期将开始。 日志（Log）日志是Raft算法中用于存储状态机操作序列的数据结构。每个日志条目包含一个操作指令和一个任期号。Leader负责将日志条目复制到其他节点，并确保所有节点的日志一致。 Leader选举Leader选举是Raft算法的核心过程之一。当系统启动或当前Leader失效时，节点会进入选举状态，尝试选举出一个新的Leader。 选举触发：当一个节点在一段时间内没有收到Leader的心跳消息时，它会认为当前Leader失效，并开始选举过程。 投票过程：节点将自己的任期号加1，并转换为候选者状态。然后，它向其他节点发送投票请求。如果一个节点在当前任期内没有投票给其他候选者，并且候选者的日志至少与自己的日志一样新，它就会投票给该候选者。 选举结果：如果一个候选者收到了大多数节点的投票，它就成为新的Leader。如果多个候选者同时发起选举，可能会导致选举失败，此时任期将结束，新的任期将开始。 日志复制日志复制是Raft算法中确保数据一致性的关键过程。Leader负责将客户端请求转换为日志条目，并将这些日志条目复制到其他节点。 日志条目添加：Leader接收到客户端请求后，将请求转换为日志条目，并将其添加到自己的日志中。 日志条目复制：Leader将新的日志条目发送给所有Follower，并等待大多数Follower确认接收。 日志条目提交：一旦大多数Follower确认接收了日志条目，Leader就会将该日志条目标记为已提交，并通知所有节点提交该日志条目。 安全性Raft算法通过一系列机制确保系统的安全性，包括选举限制、节点崩溃处理和时间与可用性管理。 选举限制为了防止不一致的节点被选为Leader，Raft算法对选举过程进行了限制： 日志匹配：只有日志至少与大多数节点一样新的候选者才能被选为Leader。这样可以确保新Leader的日志是最新的，从而避免数据丢失或不一致。 节点崩溃Raft算法能够处理节点崩溃的情况，确保系统在部分节点失效时仍然能够正常运行： Leader崩溃：如果Leader崩溃，系统会进入选举状态，选举出新的Leader。在此期间，客户端请求可能会被延迟，但系统最终会恢复一致性。 Follower崩溃：如果Follower崩溃，Leader会继续复制日志条目，并在Follower恢复后继续同步日志。 时间与可用性Raft算法通过合理的时间管理来确保系统的可用性： 心跳超时：Leader定期向Follower发送心跳消息，以维持其领导地位。如果Follower在一段时间内没有收到心跳消息，它会认为Leader失效，并开始选举过程。 选举超时：节点在选举过程中会设置一个随机的选举超时时间，以避免多个节点同时发起选举，导致选举失败。 总结Raft算法通过Leader选举、日志复制和安全性机制，提供了一种易于理解和实现的分布式共识解决方案。Raft算法的核心思想是通过Leader来管理系统的日志复制和状态一致性，确保即使在部分节点失效的情况下，系统仍然能够正常运行。"},{"title":"计算机网络-网络场景","date":"2024-10-13T15:33:32.000Z","url":"/2024/10/13/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C-%E7%BD%91%E7%BB%9C%E5%9C%BA%E6%99%AF/","categories":[["计算机基础","/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/"],["计算机网络","/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"]],"content":"输入URL到页面展示过程可以从网络结构五层模型一步步进行解析，便于理解： 简单梳理一下过程： 简要过程 1.在浏览器中输入指定的URL； 2.浏览器通过DNS协议，获得域名对应的IP； 3.浏览器根据IP地址和对应的端口号，向目标服务器发起TCP连接请求； 4.浏览器在TCP连接上，向服务器请求一个HTTP报文，请求获取网页内容； 5.服务器收到HTTP请求报文后，处理请求，并返回一个HTTP报文给浏览器； 6.浏览器收到HTTP报文后，解析响应体中的HTML代码，渲染网页的结构和样式，同时根据HTML中的其他资源(图片、CSS、JS等)，再次发起HTTP请求，获取资源的内容，知道网页渲染完毕。 7.浏览器在不许不要和服务器进行通信时，可以关闭TCP连接，或者等待服务器关闭连接。 详细过程 解析URL： 浏览器分析URL所需要使用的传输协议和请求的资源路径。如果请求的协议或者主机名非法，浏览器会将输入的内容交由搜索引擎来进行下一步的搜索操作；如果没有问题，则进行下一个过程。 缓存判断： 浏览器默认是开启了网页缓存的。若请求的资源在缓存中未失效则直接使用，否则向服务器发起新的请求。 DNS解析： 如果资源不在本地缓存中，都先要进行DNS解析。浏览器会向本地DNS服务器发送域名解析请求，本地DNS服务器会逐级查询，最终找到对应的IP地址。 获取MAC地址： 当浏览器获得目标IP后，数据传输还不知道具体的主机MAC地址。应用层下发数据到传输层，TCP协议会指定源端口号和目的端口号，然后再下发给网络层。 网络层会将本地地址作为源地址，获取目的IP地址作为目的地址，然后下发给数据链路层。 数据链路层的发送需要知道通信双方的MAC地址，本机的MAC地址作为源MAC地址，目的MAC地址需要分情况处理。 通过IP地址与本机的子网掩码相结合，可以判断是否与请求的主机IP在同一个子网内。若在同一个子网内，可以使用ARP协议获取到目的主机的MAC地址；若不在同一个子网内，那么请求应该转发给网关，由它代为转发，此时同样采用ARP协议获取网关的MAC地址，目的主机MAC地址为网关的MAC地址。 建立TCP连接： 接下来要进行TCP的三次握手。主机将使用目标IP和目标MAC地址发送一个TCP SYN包，请求建立一个TCP连接，然后交给路由器转发。 等路由器转到目标服务器后，目标服务器回复一个SYN-ACK包，确认连接请求。 然后主机继续发送一个ACK包，确认收到了服务器的确认，然后TCP连接建立完成。 HTTPS和TLS四次握手： 如果使用的是HTTPS协议，在通信前还需要进行TLS四次握手。 客户端发送Client Hello消息，包含支持的TLS版本、加密套件列表和随机数。 服务器发送Server Hello消息，选择TLS版本和加密套件，并发送服务器证书和随机数。 客户端验证服务器证书，生成预主密钥，并使用服务器公钥加密后发送给服务器。 服务器解密预主密钥，双方生成会话密钥，完成握手。 发送HTTP请求： 建立完TCP连接之后，可以正式开始请求资源了。浏览器向服务器发送HTTP请求，请求中包含了用户所需要的资源信息，如网页的结构样式、JS和文件等等。 如果是第一次发起请求，通常要获取的内容是网页的URL，再根据渲染后的网页请求所需的内容。 服务器处理请求并返回响应： 服务器收到请求之后，会根据请求的内容进行相应的处理，生成HTTP响应并返回结果。 响应包括状态行、响应头和响应体。状态行包含HTTP版本、状态码和状态描述。响应头发送关于响应的附加信息，如内容类型、缓存控制等。响应体包含实际的资源内容，如HTML页面、图片等。 网络层最开始的起点：打开浏览器输入URL，点击确认。 问题来了，啥是URL？URL有啥用？ URLURL（Union Resource locators），即统一资源定位器。网络上的所有资源都通过URL来定位，每一个文件对应着一个URL。理论上URL和文件一一对应，实际上也有一些URL会重定向到另一个位置，所以也可以是多对一的关系。 URL的结构 协议：URL 的前缀通常表示了该网址采用了何种应用层协议，通常有两种——HTTP 和 HTTPS。当然也有一些不太常见的前缀头，比如文件传输时用到的ftp:。 域名：域名便是访问网址的通用名，这里也有可能是网址的 IP 地址，域名可以理解为 IP 地址的可读版本，毕竟绝大部分人都不会选择记住一个网址的 IP 地址。 端口：如果指明了访问网址的端口的话，端口会紧跟在域名后面，并用一个冒号隔开。 资源路径：域名（端口）后紧跟的就是资源路径，从第一个/开始，表示从服务器上根目录开始进行索引到的文件路径，上图中要访问的文件就是服务器根目录下/path/to/myfile.html。早先的设计是该文件通常物理存储于服务器主机上，但现在随着网络技术的进步，该文件不一定会物理存储在服务器主机上，有可能存放在云上，而文件路径也有可能是虚拟的（遵循某种规则） 参数：参数是浏览器在向服务器提交请求时，在 URL 中附带的参数。服务器解析请求时，会提取这些参数。参数采用键值对的形式key=value，每一个键值对使用&amp;隔开。 锚点：锚点是URL中的一部分，用于指定页面中的特定位置。锚点通常以#开头，紧跟在URL的末尾。例如，#section1表示页面加载后，浏览器应该滚动到页面中ID为section1的元素位置。 DNS键入了 URL 之后，第一个重头戏登场——DNS 服务器解析。DNS（Domain Name System）域名系统，要解决的是 域名和 IP 地址的映射问题 。毕竟，域名只是一个网址便于记住的名字，而网址真正存在的地址其实是 IP 地址。 HTTP&#x2F;HTTPS利用DNS拿到目标主机的IP之后，浏览器便可以向目标IP发送HTTP请求报文，获取所需要的资源。根据请求的网站不同，可能采用的HTTP协议或安全性增强的HTTPS协议。 传输层由于HTTP协议是基于TCP协议的，在应用层的数据封装好之后，交给传输层，经TCP协议继续封装。TCP协议保证了数据的可靠性，是数据包传输的主力协议。 网络层在网络层，不再是端到端之间的通信，而是来到了主机与中间系统的交互。 网络层的最核心功能是路由与转发。 路由：将分组从路由器的输入端口转移到合适的输出端口 转发：确定分组从源到目的端所经过的路径。 "},{"title":"计算机网络-传输层","date":"2024-10-13T09:18:49.000Z","url":"/2024/10/13/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C-%E4%BC%A0%E8%BE%93%E5%B1%82/","tags":[["TCP","/tags/TCP/"],["UDP","/tags/UDP/"]],"categories":[["计算机基础","/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/"],["计算机网络","/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"]],"content":"TCPTCP头结构详解TCP（Transmission Control Protocol）是一种面向连接的、可靠的传输层协议。TCP头部包含了多个字段，用于实现连接管理、数据传输控制和错误检测等功能。以下是对TCP头部结构的详细解析： TCP头结构TCP头部通常包含20字节的固定部分和可选的40字节选项部分，总共最多60字节。以下是TCP头部的各个字段： 字段名称 位数 作用 源端口号（Source Port） 16 标识发送端应用程序的端口号。 目标端口号（Destination Port） 16 标识接收端应用程序的端口号。 序号（Sequence Number） 32 在建立连接时由计算机生成的随机数作为初始值，通过SYN包传给接收端主机。每发送一次数据，就“累加”一次该“数字字节数”的大小。用于解决网络包乱序问题。 确认号（Acknowledgment Number） 32 指下一次“期望”收到的数据的序列号。发送端收到这个确认应答以后可以认为在这个序号以前的数据都已经被正常接收。。 数据偏移（Data Offset） 4 指示TCP头部的长度（以32位字为单位），即TCP头部的总字节数。 保留字段（Reserved） 6 保留字段，未使用，必须设置为0。 控制位（Control Bits） 6 包含多个控制标志位，用于控制TCP连接的建立、维护和终止。 窗口大小（Window Size） 16 指示发送端可以接收的数据量（以字节为单位），用于流量控制。 校验和（Checksum） 16 用于检测TCP头部和数据在传输过程中是否发生错误。 紧急指针（Urgent Pointer） 16 当URG标志位为1时，指示紧急数据的结束位置。 选项（Options） 长度可选，最大32位 可选字段，用于扩展TCP功能，如最大段大小（MSS）、窗口缩放因子等。 控制位（Control Bits）详解 标志位 作用(相应位为1时有效) URG 紧急指针有效，表示数据包中包含紧急数据，接收端应优先处理。 ACK 确认号有效，表示确认号字段包含有效的确认信息。 PSH 推送数据，接收端应尽快将数据交给应用程序，而不等待缓冲区满。 RST 用于重置连接，当连接出现异常时，发送RST包重置连接。 SYN 用于建立连接，发送端和接收端通过交换SYN和SYN-ACK包来同步初始序号。 FIN 用于终止连接，发送端和接收端通过交换FIN和ACK包来关闭连接。 TCP三次握手TCP是面向连接的协议，所以在使用TCP之前必须通过TCP三次握手来建立TCP连接，流程图如下： 三次握手过程 初始状态 客户端：处于CLOSE状态。 服务器端：主动监听某个端口，处于LISTEN状态。 第一次握手（SYN） 客户端： 生成一个随机的初始序号（ISN，Initial Sequence Number），记为client_isn。 将client_isn放入TCP头部的序号字段中。 将控制位SYN设置为1，表示这是一个同步请求。 发送SYN包给服务器端。 发送完后，客户端进入SYN-SENT状态。 第二次握手（SYN-ACK） 服务器端： 收到客户端发来的SYN包。 生成一个随机的初始序号（ISN），记为server_isn。 将server_isn放入TCP头部的序号字段中。 将客户端发来的SYN包中的序号加1（即client_isn + 1）存放到TCP头部的确认号字段中。 将控制位SYN和ACK设置为1，表示这是一个同步确认响应。 发送SYN-ACK包给客户端。 发送完后，服务器端进入SYN-RCVD状态。 第三次握手（ACK） 客户端： 收到服务器端发来的SYN-ACK包。 将TCP头部的序号字段值加1（即client_isn + 1）。 将服务器端发来的序号加1（即server_isn + 1）存放到TCP头部的确认号字段中。 将控制位ACK设置为1，表示这是一个确认响应。 此时可以在报文后携带应用层的数据。 发送ACK包给服务器端。 发送完后，客户端进入ESTABLISHED状态。 服务器端： 收到客户端发来的ACK包。 服务器端进入ESTABLISHED状态。 步骤 客户端状态 服务器端状态 描述 1 CLOSE LISTEN 客户端和服务器端初始状态。 2 SYN-SENT LISTEN 客户端发送SYN包，进入SYN-SENT状态。 3 SYN-SENT SYN-RCVD 服务器端收到SYN包，进入SYN-RCVD状态，发送SYN-ACK包。 4 ESTABLISHED SYN-RCVD 客户端收到SYN-ACK包，进入ESTABLISHED状态，发送ACK包。 5 ESTABLISHED ESTABLISHED 服务器端收到ACK包，进入ESTABLISHED状态，连接建立完成。 三次握手的特点 前两次握手不携带数据：第一次握手（SYN）和第二次握手（SYN-ACK）不携带应用层数据，只包含TCP头部信息。 第三次握手可以携带数据：第三次握手（ACK）可以携带应用层数据，因为此时双方都已经确认了对方的初始序号，连接已经建立。 同步初始序号：通过三次握手，客户端和服务器端同步了初始序号（ISN），确保双方在数据传输过程中能够正确识别数据包的顺序。 确认机制：通过确认号（Acknowledgment Number），双方可以确认对方已经接收到的数据包，确保数据的可靠传输。 TCP为什么要进行三次握手 三次握手才可以防止历史连接（主要原因）：假设只进行两次握手，当网络拥塞时客户端发送了多个数据，假如旧的SYN包先到达服务器端，服务器端收到后向客户端返回SYN-ACK包后就立即进入了ESTABLISH状态，虽然客户端能够分辨出这是历史连接，但服务器端并没有中间状态来预防，而是直接建立了一个历史连接，浪费了资源。 三次握手才可以同步序列号 三次握手才可以避免浪费资源 "},{"title":"计算机网络-应用层(下)","date":"2024-10-13T04:18:49.000Z","url":"/2024/10/13/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C-%E5%BA%94%E7%94%A8%E5%B1%82(%E4%B8%8B)/","tags":[["JWT","/tags/JWT/"],["WebSoket","/tags/WebSoket/"],["Nginx","/tags/Nginx/"]],"categories":[["计算机基础","/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/"],["计算机网络","/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"]],"content":"JWT 令牌JWT 令牌和传统方式有什么区别JWT（JSON Web Token）是一种基于令牌的身份验证机制，与传统的会话管理方式（如Cookie和Session）在多个方面存在显著差异。以下是对JWT令牌与传统方式的详细比较： 1.无状态性 JWT：JWT是无状态的令牌，服务器不需要在服务器端存储会话信息。JWT令牌本身包含了所有必要的信息，如用户身份、权限等。服务器在用户首次登录时获取用户信息并加密生成JWT令牌，返回给客户端。客户端在后续请求中携带JWT令牌，服务器通过验证令牌来确认用户身份。 传统方式（如Session）：传统方式通常需要在服务器端存储会话信息。服务器为每个用户生成一个唯一的Session ID，并将其通过Cookie或其他方式传递给客户端。客户端在后续请求中携带Session ID，服务器根据Session ID查找对应的用户状态信息。这种方式需要在服务器端维护会话状态，增加了服务器的负担。 2.安全性 JWT：JWT使用密钥对令牌进行签名，确保令牌的完整性和真实性。即使令牌在传输过程中被截获，攻击者也无法篡改令牌内容而不被发现。JWT还可以使用加密算法对令牌进行加密，进一步提高安全性。 传统方式（如Session）：传统方式的安全性依赖于服务器端存储的会话信息。虽然Session数据存储在服务器端，不易受到客户端攻击，但仍然可能存在Session劫持的风险，特别是在Session ID通过不安全的通道（如未加密的HTTP）传输时。 3.跨域支持 JWT：JWT可以在不同域之间传递，适用于跨域访问的场景。通过在请求头或参数中携带JWT令牌，可以实现无需Cookie的跨域身份验证。JWT的无状态性和自包含特性使其非常适合在分布式系统和微服务架构中使用。 传统方式（如Cookie）：传统方式（如Cookie）在跨域访问时存在一定的限制。Cookie通常只能在同一域名下使用，跨域访问需要特殊处理（如CORS配置）。此外，Cookie还容易受到跨站请求伪造（CSRF）攻击，需要采取额外的安全措施。 4。可扩展性 JWT：JWT的可扩展性非常好，因为JWT是无状态的，服务器不需要存储JWT信息。JWT可以轻松地在分布式系统中使用，适用于大规模和高并发的应用场景。 传统方式（如Session）：传统方式的可扩展性较差，因为需要在服务器端存储和管理会话信息。随着用户数量的增加，服务器需要维护大量的会话数据，可能会增加服务器的负担。 5.适用场景 JWT：适用于需要无状态身份验证的场景，如单点登录（SSO）、API访问控制、微服务架构等。JWT的无状态性和自包含特性使其非常适合在分布式系统和微服务架构中使用。 传统方式（如Session）：适用于需要服务器端存储大量数据的场景，如用户登录状态、购物车信息等。传统方式在需要维护复杂会话状态的应用中仍然有其优势。 JWT 令牌详解JWT（JSON Web Token）是一种基于令牌的身份验证机制，广泛应用于现代Web应用和API中。JWT令牌是一种紧凑且自包含的方式，用于在客户端和服务器之间安全地传输信息。以下是对JWT令牌的详细解析： JWT的结构 JWT令牌由三部分组成，分别是头部（Header）、载荷（Payload）和签名（Signature），这三部分通过.分隔。 1. 头部（Header）头部通常包含两部分信息：令牌类型（typ）和使用的签名算法（alg）。例如： alg：指定使用的签名算法，如HMAC SHA256（HS256）、RSA SHA256（RS256）等。 typ：指定令牌类型，通常为JWT。 2. 载荷（Payload）载荷包含实际需要传输的数据，通常包括用户身份信息、权限信息等。载荷可以包含自定义的声明（Claims），也可以包含一些标准声明（Registered Claims）。例如： sub：主题（Subject），通常是用户的唯一标识。 name：用户名。 iat：签发时间（Issued At），表示令牌的创建时间。 其他常见的标准声明包括： iss：签发者（Issuer）。 exp：过期时间（Expiration Time）。 nbf：生效时间（Not Before）。 jti：JWT ID，唯一标识符。 3. 签名（Signature）签名用于验证令牌的完整性和真实性。签名是通过将头部和载荷进行Base64编码后，使用指定的算法和密钥生成的。例如，使用HMAC SHA256算法生成签名的过程如下： JWT的工作流程 用户登录：用户在客户端输入用户名和密码进行登录，客户端将登录请求发送到服务器。 服务器验证：服务器验证用户的身份，如果验证成功，服务器生成JWT令牌。 生成JWT：服务器将用户信息（如用户ID、权限等）放入JWT的载荷中，使用密钥对头部和载荷进行签名，生成JWT令牌。 返回JWT：服务器将生成的JWT令牌返回给客户端。 客户端存储JWT：客户端将JWT令牌存储在本地（如浏览器存储、本地存储或移动设备）。 后续请求：客户端在后续请求中携带JWT令牌，通常通过HTTP请求头（Authorization: Bearer ）或URL参数传递。 服务器验证JWT：服务器接收到请求后，验证JWT令牌的签名和有效性。如果验证通过，服务器处理请求；否则，拒绝请求。 JWT的优点 无状态性：JWT是无状态的，服务器不需要存储JWT信息，适用于分布式系统和微服务架构。 安全性：JWT使用签名和加密算法确保令牌的完整性和真实性，防止篡改和伪造。 跨域支持：JWT可以在不同域之间传递，适用于跨域访问的场景。 可扩展性：JWT的可扩展性非常好，适用于大规模和高并发的应用场景。 JWT的缺点 令牌大小：JWT令牌的大小可能会比较大，特别是当载荷中包含大量信息时。 无法撤销：JWT令牌一旦签发，除非过期，否则无法撤销。如果需要撤销令牌，通常需要额外的机制（如黑名单）。 安全性依赖密钥：JWT的安全性依赖于密钥的安全性，如果密钥泄露，攻击者可以伪造JWT令牌。 JWT 如何解决集群部署问题传统的请求方式基于Cookie和会话机制，数据信息保存在服务器或数据库中，而在集群部署情况下，每台服务器的数据是独立的，如要实现共享需要额外的共享操作，这就会消耗额外的性能和空间。 而不同于传统方式，JWT令牌是无状态的，会话所需要的数据被加密到令牌当中，这样能够样用户即使切换到新的服务器也不需要再重新登陆，服务器只需要对令牌进行校验解析即可获取到用户的信息。 由于JWT令牌是自包含的，服务器可以独立地对令牌进行校验，而不需要依赖于其他服务器或共享存储，使得集群中的每个服务器都能独立地处理请求，增加集群系统的可伸缩性和容错性。 JWT 缺点JWT的缺点 无法撤销令牌：JWT令牌一旦签发，除非过期，否则无法撤销。这意味着如果令牌被泄露或需要强制注销用户，服务器无法直接撤销令牌，只能等待令牌自然过期。 令牌大小：JWT令牌的大小可能会比较大，特别是当载荷中包含大量信息时。这可能会增加网络传输的开销，特别是在移动设备或低带宽环境下。 安全性依赖密钥：JWT的安全性依赖于密钥的安全性，如果密钥泄露，攻击者可以伪造JWT令牌。因此，密钥的管理和保护至关重要。 解决方案 黑名单策略 为了解决JWT令牌无法撤销的问题，可以采用黑名单策略。具体步骤如下： 维护黑名单：服务器维护一个黑名单数据结构（如Redis、内存数据库），用于存储已撤销的JWT令牌。 拦截过滤：在处理请求时，服务器首先检查JWT令牌是否在黑名单中。如果在黑名单中，服务器拒绝请求；否则，继续验证令牌的有效性。 定期清理：定期清理黑名单中的过期令牌，避免黑名单数据无限增长。 设置合理的过期时间 为了减少令牌泄露的风险，可以设置合理的JWT令牌过期时间。较短的过期时间可以降低令牌被滥用的风险，但也会增加用户频繁登录的频率。 使用刷新令牌机制 为了平衡安全性和用户体验，可以使用刷新令牌（Refresh Token）机制。具体步骤如下： 签发访问令牌和刷新令牌：在用户登录成功后，服务器签发一个短期有效的访问令牌（Access Token）和一个长期有效的刷新令牌（Refresh Token）。 使用访问令牌：客户端在后续请求中使用访问令牌进行身份验证。如果访问令牌过期，客户端可以使用刷新令牌向服务器请求新的访问令牌。 撤销刷新令牌：如果需要强制注销用户，服务器可以撤销刷新令牌，从而阻止用户获取新的访问令牌。 使用HTTPS加密传输 为了防止令牌在传输过程中被截获，建议使用HTTPS加密传输JWT令牌。HTTPS可以确保令牌在传输过程中的安全性，防止中间人攻击。 密钥管理 为了提高JWT的安全性，需要采取以下密钥管理措施： 使用强加密算法：使用强加密算法（如HS256、RS256）生成JWT，确保令牌的不可伪造性。 密钥轮换：定期轮换密钥，避免密钥长时间使用带来的安全风险。 密钥保护：确保密钥的安全存储，避免密钥泄露。 JWT 前端存储方案JWT（JSON Web Token）是目前最流行的跨域认证解决方案之一。客户端收到服务器返回的JWT令牌后，通常需要将其存储在客户端本地。常见的存储方案包括Local Storage、Session Storage和Cookie。以下是对这三种存储方案的详细解析： Local Storage 较大的存储空间：Local Storage提供了较大的存储空间（通常为5MB），可以存储较长的JWT令牌。 不会随HTTP请求发送：Local Storage中的数据不会自动随HTTP请求发送到服务器，减少了网络传输的开销。 XSS风险：Local Storage容易受到跨站脚本攻击（XSS）。攻击者可以通过注入恶意JavaScript代码读取存储在Local Storage中的JWT令牌，从而盗取用户身份凭证。 Session Storage 较大的存储空间：Session Storage同样提供了较大的存储空间（通常为5MB），可以存储较长的JWT令牌。 仅限于当前浏览器窗口：Session Storage中的数据仅限于当前浏览器窗口，关闭窗口后数据会被清除，适合短期存储。 用户体验问题：Session Storage中的数据在刷新网页或关闭窗口后会被清除，导致用户需要重新验证身份，影响用户体验。 XSS风险：Session Storage同样容易受到XSS攻击，攻击者可以通过注入恶意JavaScript代码读取存储在Session Storage中的JWT令牌。 Cookie 自动发送：Cookie中的数据会自动随HTTP请求发送到服务器，服务器可以方便地验证JWT令牌。 安全性增强：可以通过设置HTTPOnly和Secure属性来提高Cookie的安全性。HTTPOnly属性可以防止JavaScript访问Cookie，减少XSS攻击的风险；Secure属性可以确保Cookie只在HTTPS连接中传输，防止中间人攻击。 存储空间限制：单个Cookie的大小通常限制在4KB左右，并且大多数浏览器对单个域名下的Cookie数量也有一定的限制（通常为20个左右）。 跨域问题：Cookie在跨域访问时存在一定的限制，需要特殊处理（如CORS配置）。 WebSocket了解WebSocketWebSocket工作过程HTTP长连接与WebSocket的区别HTTP长连接和WebSocket是两种不同的网络通信技术，它们在实现机制、适用场景和性能特点上存在显著差异。以下是对这两种技术的详细比较： HTTP长连接HTTP长连接（也称为持久连接或Keep-Alive连接）是基于HTTP协议的一种连接复用技术。在HTTP&#x2F;1.1中，默认情况下连接是持久的，即客户端和服务器之间的连接在完成一次请求后不会立即关闭，而是保持打开状态，以便后续请求可以复用该连接。 适用场景 静态资源请求：适用于频繁请求静态资源的场景，如网页中的图片、CSS、JavaScript文件等。 短时间内的多次请求：适用于客户端在短时间内需要多次请求服务器资源的场景。 性能特点 减少连接建立开销：通过复用连接，减少了每次请求的TCP连接建立和关闭的开销，提高了网络传输效率。 减少延迟：减少了每次请求的往返时间（RTT），降低了网络延迟。 适用范围有限：HTTP长连接主要适用于短时间内的多次请求，对于需要长时间保持连接的场景（如实时通信），HTTP长连接并不适用。 WebSocketWebSocket是一种全双工通信协议，允许客户端和服务器之间进行双向实时通信（TCP协议本身是全双工的，但我们常用的HTTP&#x2F;1.1虽然基于TCP协议，却是半双工的，因为HTTP是应答模式）。WebSocket协议在HTTP协议的基础上进行升级，通过一次握手过程建立持久连接，之后双方可以通过该连接进行实时数据传输。 适用场景 实时通信：适用于需要实时通信的场景，如在线聊天、实时游戏、股票行情等。 实时数据推送：适用于服务器需要主动向客户端推送数据的场景，如实时通知、实时监控等。 性能特点 全双工通信：WebSocket支持全双工通信，客户端和服务器可以同时发送和接收数据，实现实时双向通信。 低延迟：WebSocket连接建立后，数据传输的延迟较低，适合实时通信场景。 轻量级协议：WebSocket协议本身较为轻量，数据传输的开销较小，适合高频数据传输。 区别总结 特性 HTTP长连接 WebSocket 实现机制 基于HTTP协议的连接复用技术 基于HTTP协议升级的全双工通信协议 适用场景 静态资源请求、短时间内的多次请求 实时通信、实时数据推送 通信方式 半双工（请求-响应模式） 全双工（双向实时通信） 连接保持 连接保持时间有限，适用于短时间请求 持久连接，适用于长时间实时通信 协议开销 每次请求需要携带HTTP头信息 协议开销较小，适合高频数据传输 数据传输延迟 每次请求的往返时间（RTT）较高 数据传输延迟较低，适合实时通信 NginxNginx负载均衡算法 轮询：按照请求顺序依次分配给后端请求。这种算法最简单，但无法应对单点缓慢以及用户连续请求情况。 IP哈希：根据客户端IP地址来计算哈希值，分配到对应的后端服务器，能够保证客户端总能请求到同一台服务器。 URL哈希：按访问的URL哈希结果来分配后端服务器，可以进一步增加后端服务器缓存的使用率。 最短响应时间：根据后端服务器的响应时间来进行分配，响应速度越快的服务器会收到的请求越多，能够充分利用后端服务器的性能，实现负载均衡。 加权轮询：按照权重分配请求给后端服务器，权重越高的服务器会收到更多的请求，适用于后端服务器性能不同的情况，提高高性能服务器利用率，实现负载均衡。 "},{"title":"计算机网络-应用层(上)","date":"2024-10-12T08:33:32.000Z","url":"/2024/10/12/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C-%E5%BA%94%E7%94%A8%E5%B1%82(%E4%B8%8A)/","tags":[["HTTP","/tags/HTTP/"],["DNS","/tags/DNS/"],["Cookie","/tags/Cookie/"],["Session","/tags/Session/"]],"categories":[["计算机基础","/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/"],["计算机网络","/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"]],"content":"HTTPHTTP报文 HTTP报文分为请求报文和响应报文，它们各自具有特定的结构和组成部分： 请求报文： 请求行：包含请求方法、请求目标(URL等)和请求协议版本。 请求头：包含请求的附加信息，如Host、User-Agent、Content-Type等。 空行：用于分割请求头和请求体 请求体：可选，包含请求的参数。 响应报文： 响应行：包含HTTP协议版本、状态码和状态信息。 响应头：包含响应的附加信息，如Content-Type、Content-Length等。 空行：用于分割响应头部和响应体 响应体：包含响应的数据。 HTTP常用状态码HTTP状态码是服务器对客户端请求的响应状态的标识，它们帮助客户端理解请求的处理结果。状态码分为五类，每一类都有特定的含义。以下是一些常用的HTTP状态码及其解释： 1xx（信息性状态码）这类状态码表示请求已被接收，继续处理，是协议处理中的一种中间状态，使用的比较少。 100 Continue：服务器已接收到请求头，并且客户端应继续发送请求体。 101 Switching Protocols：服务器已理解客户端的请求，并将通过Upgrade消息头通知客户端采用不同的协议来完成这个请求。 2xx（成功状态码）这类状态码表示请求已成功被服务器接收、理解并接受。 200 OK：请求成功。一般用于GET与POST请求。 201 Created：请求已经被实现，而且有一个新的资源已经依据请求的需要而建立，且其URI已经随Location头信息返回。 202 Accepted：服务器已接受请求，但尚未处理。 204 No Content：服务器成功处理了请求，但没有返回任何内容。 206 Partial Content：服务器已经成功处理了部分GET请求。 3xx（重定向状态码）这类状态码表示需要客户端采取进一步的操作才能完成请求。 300 Multiple Choices：被请求的资源有一系列可供选择的回馈信息，每个都有自己特定的地址和浏览器驱动的商议信息。 301 Moved Permanently：被请求的资源已永久移动到新位置，并且将来任何对此资源的引用都应该使用本响应返回的若干个URI之一。 302 Found：请求的资源现在临时从不同的URI响应请求。 304 Not Modified：客户端发送了一个带条件的GET请求且该请求已被允许，而文档的内容（自上次访问以来或者根据请求的条件）并没有改变。 307 Temporary Redirect：请求的资源现在临时从不同的URI响应请求。 4xx（客户端错误状态码）这类状态码表示客户端可能发生了错误，妨碍了服务器的处理。 400 Bad Request：服务器无法理解请求的格式，客户端不应当尝试再次使用相同的内容发起请求。 401 Unauthorized：请求要求用户的身份认证。 403 Forbidden：服务器已经理解请求，但是拒绝执行它。 404 Not Found：请求失败，请求所希望得到的资源未被在服务器上发现。 405 Method Not Allowed：请求行中指定的请求方法不能被用于请求相应的资源。 408 Request Timeout：服务器等候请求时发生超时。 410 Gone：被请求的资源在服务器上已经不再可用，而且没有任何已知的转发地址。 429 Too Many Requests：用户在给定的时间内发送了太多的请求。 5xx（服务器错误状态码）这类状态码表示服务器在处理请求的过程中发生了错误。 500 Internal Server Error：服务器遇到了一个未曾预料的状况，导致了它无法完成对请求的处理。 501 Not Implemented：服务器不支持当前请求所需要的某个功能。 502 Bad Gateway：作为网关或者代理工作的服务器尝试执行请求时，从上游服务器接收到无效的响应。 503 Service Unavailable：由于临时的服务器维护或者过载，服务器当前无法处理请求。 504 Gateway Timeout：作为网关或者代理工作的服务器尝试执行请求时，未能及时从上游服务器（URI标识出的服务器，例如HTTP、FTP、LDAP）或者辅助服务器（例如DNS）收到响应。 GET 和 POST 的区别GET 和 POST 是 HTTP 协议中两种常用的请求方法，它们在不同的场景和目的下有不同的特点和用法。一般来说，可以从以下几个方面来区分二者： 语义(主要区别)：根据REF规范，GET通常用于获取或查询资源，而POST常用于创建或者修改资源。 幂等：GET 请求是幂等的，即多次重复执行不会改变资源的状态，而 POST 请求是不幂等的，即每次执行可能会产生不同的结果或影响资源的状态。 格式：GET请求的参数通常放在URL中，形成查询字符串，而POST请求参数通常放在请求体中，可以有多种编码格式。GET请求的URL长度会受到浏览器的限制，而POST的请求体大小并没有明确的限制。 缓存：由于GET是幂等的，可以被浏览器或者其他中间节点缓存起来以提高i性能和效率；而POST请求则不适合缓存，因为每次请求可能都会对结果造成影响，需要实时的响应。 安全性： GET 请求和 POST 请求如果使用 HTTP 协议的话，那都不安全，因为 HTTP 协议本身是明文传输的，必须使用 HTTPS 协议来加密传输数据。另外，GET 请求相比 POST 请求更容易泄露敏感数据，因为 GET 请求的参数通常放在 URL 中。 HTTP的长连接HTTP协议采用的是“请求”-&gt;“应答”的模式，客户端主动发起请求，服务端才会响应。 由于HTTP是基于TCP协议实现的，客户端与服务器间进行HTTP通信，需要先建立TCP连接，然后客户端发起HTTP请求，服务端收到请求后进行处理、响应，随后释放TCP连接。 但是如果每次都要进行这么一个流程：建立TCP连接 -&gt; 请求资源 -&gt; 响应 -&gt; 释放连接，那么这种方式就是HTTP短连接。 一次连接只能请求一个资源，当多次请求时就会造成频繁的连接建立与释放过程，降低了性能，所以就有了长连接的方式。HTTP中的 Keep-Alive 实现在第一个HTTP请求完成之后，暂时不断开TCP连接以让后续的HTTP请求都沿用该连接的功能，避免了连接建立与销毁的额外开销，这个方法称为HTTP长连接。 HTTP长连接的特点是，TCP连接双方有一方提出了断开连接才会释放，否则保持TCP连接状态。 HTTP为什么不安全HTTP（HyperText Transfer Protocol）是一种应用层协议，其本身存在一些安全问题，主要原因在于它是明文传输的。以下是HTTP不安全的几个主要原因： 窃听风险 明文传输：HTTP协议在传输过程中不进行加密，数据以明文形式在网络上传输。这意味着任何在通信链路上的中间人都可以截获并读取通信内容。 敏感信息泄露：由于数据未加密，窃听者可以轻易获取到用户的敏感信息，如登录凭证、信用卡信息等。 篡改风险 数据完整性缺失：HTTP协议不提供数据完整性校验机制，攻击者可以在数据传输过程中篡改数据。例如，攻击者可以修改网页内容、注入恶意代码或篡改表单数据。 中间人攻击：攻击者可以拦截并修改HTTP请求和响应，导致用户接收到被篡改的信息。 冒充风险 身份验证缺失：HTTP协议不提供服务器或客户端的身份验证机制，攻击者可以冒充合法的服务器或客户端进行通信。 钓鱼攻击：攻击者可以创建一个与合法网站外观相似的虚假网站，诱使用户输入敏感信息，从而窃取用户的登录凭证或其他敏感数据。 HTTPS如何解决HTTP的安全问题HTTPS（HyperText Transfer Protocol Secure）通过在HTTP与TCP层之间加入SSL&#x2F;TLS协议，很好地解决了上述安全问题。 信息加密 SSL&#x2F;TLS协议：HTTPS使用SSL（Secure Sockets Layer）或TLS（Transport Layer Security）协议对数据进行加密。SSL&#x2F;TLS协议通过公钥加密技术（如RSA）和会话密钥（对称加密）来保护数据的机密性。 加密传输：即使在通信链路上获取到通信内容，攻击者也无法直接读取信息，因为数据已经被加密。 校验机制 数据完整性校验：SSL&#x2F;TLS协议使用消息认证码（MAC）来确保数据的完整性。MAC通过在数据中添加一个校验值，确保数据在传输过程中未被篡改。 防止篡改：如果数据在传输过程中被篡改，接收方可以通过校验值检测到数据的完整性被破坏，从而拒绝接收被篡改的数据。 身份证书 数字证书：HTTPS使用数字证书来验证服务器的身份。数字证书由受信任的第三方证书颁发机构（CA）签发，包含服务器的公钥和身份信息。 身份验证：客户端在建立HTTPS连接时，会验证服务器的数字证书，确保连接到的是合法的服务器，而不是冒充的虚假服务器。 防止冒充：通过数字证书的身份验证机制，HTTPS可以有效防止中间人攻击和钓鱼攻击。 HTTP与HTTPS的区别 端口号：HTTP端口号默认是80；HTTPS端口号默认是443。 URL前缀：HTTP的URL前缀是http://；HTTPS则是https://。 安全性和资源消耗：HTTP基于TCP协议，采用明文传输的方式，故而存在安全风险；而HTTPS协议在与HTTP与TCP中间插入了SSL&#x2F;TSL安全协议，使得报文能够加密传输。但也因为多加了一层协议的缘故，HTTPS协议需要额外建立一次TSL四次握手，相较于HTTP多消耗了一些性能。 SEO(搜索引擎优化)：搜索引擎通常更加青睐于使用HTTPS的网站，故而搜索结果中采用了HTTPS的网站会优先显示，对SEO产生影响。 HTTPS握手过程HTTPS（HyperText Transfer Protocol Secure）通过在HTTP与TCP层之间加入SSL&#x2F;TLS协议，提供了安全的通信通道。SSL&#x2F;TLS协议的核心是握手过程，它确保了通信双方的身份验证、密钥交换和加密算法的协商。以下是HTTPS握手过程的详细步骤： TSL第一次握手：客户端发起连接 Client Hello：客户端向服务器发送Client Hello消息，包含以下信息： 支持的SSL&#x2F;TLS版本：客户端支持的最高SSL&#x2F;TLS版本。 加密套件列表：客户端支持的加密算法和密钥交换算法。 随机数（Client Random）：客户端生成的随机数，用于后续的密钥生成。 会话ID（可选）：如果客户端希望恢复之前的会话，会发送会话ID。 TSL第二次握手：服务器响应 Server Hello：服务器接收到Client Hello消息后，发送Server Hello消息，包含以下信息： 选择的SSL&#x2F;TLS版本：服务器选择的SSL&#x2F;TLS版本。 选择的加密套件：服务器从客户端提供的列表中选择一个加密套件。 随机数（Server Random）：服务器生成的随机数，用于后续的密钥生成。 会话ID（可选）：如果服务器同意恢复之前的会话，会发送会话ID。 服务器证书：服务器发送自己的数字证书给客户端。证书包含服务器的公钥和身份信息，由受信任的第三方证书颁发机构（CA）签发。 服务器密钥交换（可选）：如果选择的加密套件需要额外的密钥交换信息，服务器会发送Server Key Exchange消息。 服务器Hello Done：服务器发送Server Hello Done消息，表示服务器已完成握手消息的发送。 TSL第三次握手：客户端验证证书与密钥生成 ​ 验证证书 证书验证：客户端验证服务器的数字证书，确保证书是有效的、未过期的，并且由受信任的CA签发。客户端还会检查证书中的域名是否与服务器的域名匹配。 生成预主密钥：如果证书验证通过，客户端生成一个预主密钥（Pre-Master Secret），并使用服务器的公钥加密后发送给服务器。 ​ 密钥生成 生成会话密钥：客户端和服务器使用预主密钥、客户端随机数和服务器随机数，通过伪随机函数（PRF）生成会话密钥（Session Key）。会话密钥用于后续的加密和解密通信内容。 TSL第四次握手 客户端完成握手 Client Key Exchange：客户端发送Client Key Exchange消息，包含加密后的预主密钥。 Change Cipher Spec：客户端发送Change Cipher Spec消息，通知服务器后续的通信将使用协商好的加密算法和会话密钥。 Finished：客户端发送Finished消息，包含使用会话密钥加密的握手消息摘要，用于验证握手过程的完整性。 ​ 服务器完成握手 Change Cipher Spec：服务器发送Change Cipher Spec消息，通知客户端后续的通信将使用协商好的加密算法和会话密钥。 Finished：服务器发送Finished消息，包含使用会话密钥加密的握手消息摘要，用于验证握手过程的完整性。 ​ 安全通信 加密通信：握手完成后，客户端和服务器之间的所有通信都将使用会话密钥进行加密和解密，确保数据的机密性和完整性。 HTTP&#x2F;1.0与HTTP&#x2F;1.1区别 连接方式：HTTP&#x2F;1.0采用短连接方式，HTTP&#x2F;1.1支持长连接。 状态响应码：HTTP&#x2F;1.1加入了大量的状态响应码。比如100(Continue)在请求大资源前的预热请求、409(Conflict)请求与当前资源的规定冲突等。 带宽：HTTP&#x2F;1.0中，存在一些带宽资源浪费现象，例如客户端只需要对象的某一部分，而服务器却将整个对象送过来了，并且不支持断点续传功能。 Host头处理：HTTP&#x2F;1.1引入了Host头，允许在一个IP地址上托管多个域名，从而支持虚拟主机的功能。 HTTP&#x2F;1.1与HTTP&#x2F;2.0区别 多路复用（Multiplexing）：HTTP&#x2F;2.0 在同一连接上可以同时传输多个请求和响应（可以看作是 HTTP&#x2F;1.1 中长链接的升级版本），互不干扰。HTTP&#x2F;1.1 则使用串行方式，每个请求和响应都需要独立的连接，而浏览器为了控制资源会有 6-8 个 TCP 连接的限制。。这使得 HTTP&#x2F;2.0 在处理多个请求时更加高效，减少了网络延迟和提高了性能。 二进制帧（Binary Frames）：HTTP&#x2F;2.0 使用二进制帧进行数据传输，而 HTTP&#x2F;1.1 则使用文本格式的报文。二进制帧更加紧凑和高效，减少了传输的数据量和带宽消耗。 头部压缩（Header Compression）：HTTP&#x2F;1.1 支持Body压缩，Header不支持压缩。HTTP&#x2F;2.0 支持对Header压缩，使用了专门为Header压缩而设计的 HPACK 算法，减少了网络开销。 服务器推送（Server Push）：HTTP&#x2F;2.0 支持服务器推送，可以在客户端请求一个资源时，将其他相关资源一并推送给客户端，从而减少了客户端的请求次数和延迟。而 HTTP&#x2F;1.1 需要客户端自己发送请求来获取相关资源。 HTTP、SOCKET和TCP的区别HTTP是应用层的协议，定义了客户端和服务器间数据的传输规范；Socket是通信的一端，提供了网路通信的接口；TCP是传输层协议，负责为端到端之间提供可靠的数据传输服务。它们在网络中充当不同的角色。 HTTP如何保存用户状态HTTP（HyperText Transfer Protocol）是一种无状态的协议，这意味着每次请求都是独立的，服务器不会保存客户端的状态信息。然而，在实际应用中，许多场景需要保存用户的状态，例如用户登录状态、购物车内容等。为了解决这个问题，引入了Session机制。 Session机制Session机制的主要作用是通过服务端记录用户的状态。典型的场景是购物车，当用户添加商品到购物车时，系统需要知道是哪个用户操作的，因为HTTP协议是无状态的。服务端为特定的用户创建特定的Session之后，就可以标识这个用户并且跟踪这个用户。 Session的工作原理 创建Session：当用户首次访问服务器时，服务器会为该用户创建一个唯一的Session ID，并将该Session ID与用户的状态信息（如用户ID、购物车内容等）关联起来。服务器可以选择将Session信息保存在内存、数据库（如Redis）或其他持久化存储中。 传递Session ID：服务器将Session ID返回给客户端，通常通过在响应头中设置Set-Cookie字段，将Session ID存储在客户端的Cookie中。客户端在后续的请求中，会将Session ID通过请求头中的Cookie字段发送给服务器。 Session跟踪：服务器接收到客户端的请求时，会从请求头中提取Session ID，并根据Session ID查找对应的用户状态信息。服务器可以根据Session信息进行用户身份验证、状态管理等操作。 Session销毁：服务器会在一定时间内保存Session信息，过了时间限制，就会销毁这个Session。用户退出登录或关闭浏览器时，服务器也会销毁对应的Session。 Cookie被禁用怎么办？如果客户端禁用了Cookie，服务器无法通过Cookie传递Session ID，此时可以使用URL重写技术，即把Session ID附加在URL路径后面。 DNS了解DNSDNS(Domain Name System，域名系统)，它是互联网中用于将域名转化为对应的IP的分布式数据库系统。DNS扮演着一个重要的角色，使得人们不需要记得难记得IP地址而转向方便的域名，即可访问互联网资源。 DNS中的域名采用句点分割，比如www.example.com，此处句点代表不同层次之间得界限。在域名中，越靠右的位置代表其层级越高。（毕竟域名是外国人搞得，外国人姓在右名在左）。实际上最右边还有一个点，代表根域名，根域在最顶层。 因此，客户端只要找到任意DNS服务器，就可以回到其根域服务器，然后逐级找到目标DNS服务器。 DNS解析过程详解域名系统（DNS）是互联网中用于将域名转换为IP地址的关键基础设施。以下是DNS解析过程的详细步骤： 客户端发起DNS查询：当用户在浏览器中输入“www.example.com”时，客户端（通常是操作系统或浏览器）会向本地DNS服务器发起DNS查询请求，以获取该域名对应的IP地址。 本地DNS服务器处理请求：本地DNS服务器接收到查询请求后，首先会检查其本地缓存。如果缓存中存在该域名的IP地址记录，则直接将该IP地址返回给客户端，从而避免了后续的递归查询过程。若缓存中不存在该记录，本地DNS服务器将启动递归查询。 根域名服务器的角色：本地DNS服务器向根域名服务器发起查询。根域名服务器不直接解析具体的域名，而是指示本地DNS服务器向负责顶级域名（TLD）的DNS服务器进行进一步查询。例如，对于“www.example.com”，根域名服务器会告知本地DNS服务器“.com”顶级域名服务器的地址。 顶级域名服务器的参与：本地DNS服务器随后向“.com”顶级域名服务器发起查询。顶级域名服务器进一步指示本地DNS服务器向负责“example.com”区域的权威DNS服务器进行查询。 权威DNS服务器的解析：权威DNS服务器是域名解析的最终来源，它存储了域名与IP地址的映射关系。本地DNS服务器向权威DNS服务器发起查询，权威DNS服务器返回“www.example.com”对应的IP地址。 本地DNS服务器的响应：本地DNS服务器接收到权威DNS服务器的响应后，将IP地址返回给客户端，并在本地缓存中存储该记录，以便后续查询时能够快速响应。 客户端发起HTTP请求：客户端接收到IP地址后，使用该IP地址发起HTTP请求，与目标服务器建立连接，从而完成域名解析的全过程。 深入解析 递归查询与迭代查询：在上述过程中，本地DNS服务器执行的是递归查询，即它代表客户端完成整个查询过程。而根域名服务器、顶级域名服务器和权威DNS服务器执行的是迭代查询，它们仅提供下一步查询的指示，而不直接返回最终结果。 DNS缓存机制：DNS缓存是提高解析效率的关键机制。本地DNS服务器、ISP的DNS服务器以及操作系统都可能缓存DNS记录。缓存的有效期由DNS记录的TTL（Time to Live）值决定，TTL值越小，缓存的有效期越短，DNS解析的实时性越高。 权威DNS服务器：权威DNS服务器是域名解析的最终权威，它存储了域名的权威记录（如A记录、CNAME记录等）。权威DNS服务器通常由域名注册商或企业自行管理，确保域名解析的准确性和安全性。 DNS基于UDP协议DNS底层基于UDP协议，而不是TCP协议。主要考虑的因素是基于UDP协议具有的低延迟、轻量级、简单快速的特性。其高性能更加适合于DNS对需要快速响应的域名解析要求。 低延时：UDP是无连接的协议，不需要建立连接减少了等待时间。 简单快速：UDP没有连接管理和流量控制，传输效率更高。 轻量级：UDP头部较小，占用网络资源少，适合DNS这种小而且频繁的数据交换。 Cookie 与 SessionHTTP协议的无状态性及其状态保持机制HTTP的无状态性HTTP（Hypertext Transfer Protocol）被设计为一种无状态协议，这意味着每个HTTP请求都是独立的，服务器不会保存关于客户端的状态信息。具体来说，服务器在处理一个请求时，不会依赖于之前或之后的请求，每个请求都被视为一个全新的交互。 无状态性的优点 简单性：无状态协议的设计相对简单，服务器不需要维护复杂的会话状态，从而简化了服务器的实现和维护。 可扩展性：无状态协议更容易实现负载均衡和高可用性，因为每个请求都可以独立处理，服务器之间不需要共享状态信息。 可靠性：由于每个请求都是独立的，服务器在处理请求时不会因为之前的请求失败而受到影响。 状态保持机制尽管HTTP本身是无状态的，但在实际应用中，许多场景需要服务器能够识别和跟踪客户端的状态。为了实现这一需求，HTTP引入了一些状态保持机制，其中最常见的是Cookie和Session。 CookieCookie是一种在客户端（通常是浏览器）存储的小型文本文件，用于在客户端和服务器之间传递状态信息。服务器可以在HTTP响应中设置Cookie，客户端在后续请求中自动携带这些Cookie，从而实现状态保持。 SessionSession是一种在服务器端存储用户状态的机制。服务器为每个用户生成一个唯一的Session ID，并将其通过Cookie或其他方式传递给客户端。客户端在后续请求中携带Session ID，服务器根据Session ID查找对应的用户状态信息。 为什么HTTP仍然是无状态的？虽然Cookie和Session等机制能够在一定程度上实现状态保持，但HTTP协议本身仍然被认为是无状态的。这是因为： 独立请求：服务器对于每个HTTP请求都是独立的，服务器不会自动保存或关联请求之间的状态信息。每个请求都需要携带足够的信息来理解请求的意图。 无状态设计：HTTP协议的设计初衷是无状态的，Cookie和Session等机制只是为了弥补无状态协议在某些场景下的不足，而不是改变HTTP协议的无状态特性。 Cookie 与 Session 的区别在Web开发中，Cookie和Session是两种常用的状态管理技术，它们在存储位置、数据容量、安全性以及生命周期等方面存在显著差异。以下是对这两种技术的详细比较： 存储位置 Cookie：Cookie的数据存储在客户端（通常是浏览器）。当浏览器向服务器发起请求时，会自动附带Cookie中的数据。Cookie是HTTP协议的一部分，服务器可以通过HTTP响应头（Set-Cookie）设置Cookie，客户端在后续请求中通过HTTP请求头（Cookie）携带这些数据。 Session：Session的数据存储在服务器端。服务器会为每一个用户分配一个唯一的Session ID，通过Cookie或URL重写的方式发送给客户端，后续客户端的请求都要附带Session ID。服务器根据Session ID找到之前会话保留的数据。 数据容量 Cookie：单个Cookie文件的大小通常限制在4KB左右，并且大多数浏览器对单个域名下的Cookie数量也有一定的限制（通常为20个左右）。因此，Cookie的数据容量相对较小。 Session：Session数据保存在服务器中，仅受限于服务器的存储容量。因此，Session可以存储更多的数据，适用于需要存储大量用户状态信息的场景。 安全性 Cookie：Cookie相对不安全，因为数据存储在客户端，容易受到跨站脚本攻击（XSS）和跨站请求伪造（CSRF）的威胁。虽然可以通过设置HTTPOnly属性来防止JavaScript访问Cookie，但仍有可能受到CSRF攻击。 Session：Session通常被认为比Cookie更安全，因为数据保存在服务器端，不易受到客户端攻击。然而，Session仍然可能存在Session劫持的风险，特别是在Session ID通过不安全的通道（如未加密的HTTP）传输时。 生命周期 Cookie：Cookie可以设置过期时间，过期后自动删除；也可以设置为会话Cookie，浏览器关闭后自动删除。Cookie的生命周期可以通过服务器端的设置进行控制。 Session：Session默认在浏览器关闭时关闭会话，Session数据被删除。服务器也可以设置Session的过期时间，当Session超过一定时间没有活动时，Session也会失效。Session的生命周期通常由服务器端的管理策略决定。 Cookie、Session 和 Token 的区别在Web开发中，Cookie、Session和Token是三种常用的状态管理技术，它们在实现机制、存储位置、安全性、可扩展性等方面存在显著差异。以下是对这三种技术的详细比较： 实现机制 Cookie：Cookie是一种在客户端存储的小型文本文件，用于在客户端和服务器之间传递状态信息。服务器可以通过HTTP响应头（Set-Cookie）设置Cookie，客户端在后续请求中通过HTTP请求头（Cookie）携带这些数据。 Session：Session是一种在服务器端存储用户状态的机制。服务器为每个用户生成一个唯一的Session ID，并将其通过Cookie或其他方式传递给客户端。客户端在后续请求中携带Session ID，服务器根据Session ID查找对应的用户状态信息。 Token：Token是一种基于令牌的身份验证机制。服务器在用户登录成功后生成一个Token，并将其返回给客户端。客户端在后续请求中携带Token，服务器通过验证Token来确认用户身份。Token通常是无状态的，服务器不需要存储Token信息。 存储位置 Cookie：Cookie的数据存储在客户端（通常是浏览器）。 Session：Session的数据存储在服务器端。 Token：Token的数据通常存储在客户端（如浏览器、本地存储或移动设备），服务器不需要存储Token信息。 安全性 Cookie：Cookie相对不安全，因为数据存储在客户端，容易受到跨站脚本攻击（XSS）和跨站请求伪造（CSRF）的威胁。虽然可以通过设置HTTPOnly和Secure属性来提高安全性，但仍有可能受到攻击。 Session：Session通常被认为比Cookie更安全，因为数据保存在服务器端，不易受到客户端攻击。然而，Session仍然可能存在Session劫持的风险，特别是在Session ID通过不安全的通道（如未加密的HTTP）传输时。 Token：Token通常被认为比Cookie和Session更安全，因为Token是无状态的，服务器不需要存储Token信息。Token通常使用加密算法生成，并且可以通过签名和加密来防止篡改和伪造。Token的安全性依赖于加密算法和传输通道的安全性。 可扩展性 Cookie：Cookie的可扩展性较差，因为数据存储在客户端，受限于浏览器对Cookie数量和大小的限制。 Session：Session的可扩展性较好，因为数据存储在服务器端，可以通过分布式存储和负载均衡来提高系统的可扩展性。然而，Session需要服务器端存储和管理，可能会增加服务器的负担。 Token：Token的可扩展性非常好，因为Token是无状态的，服务器不需要存储Token信息。Token可以轻松地在分布式系统中使用，适用于大规模和高并发的应用场景。 如果客户端禁用了Cookie，Session还能用吗？默认情况下禁用了Cookie之后，Session无法正常使用，因为大多数Web服务都依赖于Cookie来传递Session ID。 当然，针对该问题有以下方案： URL重写：将Session ID附加到URL中作为参数。缺点是容易泄漏Session ID。 隐藏表单字段：在提交请求表单，单独划一个属性字段来存储Session ID。此方式只适合通过表单提交的交互方式。 "},{"title":"计算机网络-网络模型","date":"2024-10-12T02:27:27.000Z","url":"/2024/10/12/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C-%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B/","tags":[["网络模型","/tags/%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B/"]],"categories":[["计算机基础","/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/"],["计算机网络","/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"]],"content":"网络分层模型 OSI七层模型为了实现多种设备在网络中的互操作性，并解决不同设备在网络互联中存在的兼容性问题，国际标准化组织（ISO）制定了开放式系统互联通信参考模型（OSI模型）。该模型共分为七层，从上至下依次为：应用层、表示层、会话层、传输层、网络层、数据链路层和物理层。 每一层在网络通信中承担不同的职能： 应用层：为应用程序提供统一的接口，使应用程序能够访问网络服务。 表示层：负责数据的格式转换、加密和压缩，以确保数据能够在不同系统之间正确表示和传输。 会话层：管理进程间的通信会话，包括会话的建立、维护和终止。 传输层：提供端到端的数据传输服务，确保数据的可靠性和完整性。 网络层：决定数据在网络中的传输路径，使用路由算法选择最佳路径。 数据链路层：对数据帧进行编码、误差校验和MAC寻址，确保数据在物理链路上的可靠传输。 物理层：透明地传输比特流，定义物理介质的电气、机械和功能特性。 TCP&#x2F;IP四层模型TCP&#x2F;IP四层模型是目前广泛采用的网络通信模型，可以视为OSI模型的简化版本。它由以下四层构成：应用层、传输层、网络层和网络接口层。 应用层应用层主要提供两个终端设备上的应用程序之间进行信息交换的服务。它定义了信息交换的格式，并将消息交给下一层传输层进行传输。应用层的数据单位称为报文。 传输层传输层的主要任务是负责两台终端设备进程之间的通信数据传输服务。应用进程通过该服务传输应用层的报文。传输层创建的两个主要协议是： TCP（传输控制协议）：提供可靠的、面向连接的数据传输服务。 UDP（用户数据报协议）：提供无连接的、不可靠的数据传输服务。 网络层网络层负责为分组交换网上的不同主机提供通信服务。由于网络层使用IP协议，因此分组也称为IP数据报。网络层的主要功能包括： IP寻址：为每个网络接口分配唯一的IP地址。 路由选择：使用路由算法选择最佳路径，将数据报从源主机传输到目的主机。 网络接口层网络接口层负责将网络层的数据报封装成适合在物理网络上传输的帧，并进行物理地址（MAC地址）的寻址。它包括数据链路层和物理层的所有功能，确保数据在物理链路上的可靠传输。 常见网络协议应用层应用层是OSI模型和TCP&#x2F;IP模型中的最高层，负责为终端用户提供网络服务。应用层协议定义了应用程序之间如何进行通信，包括数据格式、传输方式和错误处理等。以下是一些常见的应用层协议： HTTP（Hypertext Transfer Protocol，超文本传输协议）： 基于协议：TCP 端口号：80（默认）安全版本（HTTPS）：443 用途：HTTP是一种用于传输超文本和多媒体内容的协议，主要用于Web浏览器与Web服务器之间的通信。当我们使用浏览器浏览网页时，网页内容就是通过HTTP协议加载的。 特点：无状态协议，使用请求-响应模型。 SMTP（Simple Mail Transfer Protocol，简单邮件传输协议）： 基于协议：TCP 端口号：25（默认） 用途：SMTP用于发送电子邮件。它定义了邮件从发送方到接收方邮件服务器之间的传输过程。 特点：只负责发送邮件，不负责接收。 POP3（邮局协议版本3）&#x2F; IMAP（互联网邮件访问协议）： 基于协议：TCP 端口号：POP3110（默认）| IMAP143（默认） 用途：POP3和IMAP都是用于接收电子邮件的协议。POP3通常将邮件下载到本地设备，而IMAP允许用户在服务器上管理邮件。 特点：POP3适合离线阅读，IMAP适合在线管理。 FTP（File Transfer Protocol，文件传输协议）： 基于协议：TCP 端口号：21（控制连接）| 数据连接：20（主动模式） 用途：FTP用于在计算机之间传输文件。它支持上传和下载文件，并提供用户认证和文件权限管理。 特点：使用两个独立的连接，一个用于控制，一个用于数据传输。 Telnet（远程登录协议）： 基于协议：TCP 端口号：23 用途：Telnet用于通过一个终端登录到远程服务器，实现远程管理和控制。 特点：明文传输，安全性较低。 SSH（Secure Shell Protocol，安全外壳协议）： 基于协议：TCP 端口号：22 用途：SSH通过加密和认证机制实现安全的远程访问和文件传输。它替代了Telnet，提供了更高的安全性。 特点：加密传输，支持多种认证方式。 RTP（Real-time Transport Protocol，实时传输协议）： 基于协议：通常基于UDP，但也支持TCP 用途：RTP提供了端到端的实时传输数据的功能，常用于音视频流媒体传输。 特点：低延迟，适用于实时通信。 DNS（Domain Name System，域名系统）： 基于协议：UDP 端口号：53（默认） 用途：DNS用于解决域名和IP地址之间的映射问题，将人类可读的域名转换为机器可读的IP地址。 特点：分布式数据库系统，支持递归查询和迭代查询。 传输层传输层是OSI模型和TCP&#x2F;IP模型中的第四层，负责为应用层提供端到端的数据传输服务。传输层的主要任务是确保数据在源主机和目的主机之间的可靠传输。以下是传输层中两个最常见的协议： TCP（Transmission Control Protocol，传输控制协议）： 特点：TCP提供面向连接的、可靠的数据传输服务。它通过三次握手建立连接，确保数据包按顺序到达，并在必要时重传丢失的数据包。 应用场景：适用于需要高可靠性和顺序性的应用，如Web浏览（HTTP）、文件传输（FTP）、电子邮件（SMTP）等。 UDP（User Datagram Protocol，用户数据报协议）： 特点：UDP提供无连接的、尽最大努力的数据传输服务。它不保证数据包的顺序和可靠性，也不进行流量控制和拥塞控制。 应用场景：适用于实时性要求高、对数据可靠性要求相对较低的应用，如音视频流媒体（RTP）、在线游戏、DNS查询等。 网络层网络层是OSI模型和TCP&#x2F;IP模型中的第三层，负责为数据包在网络中的传输提供路由和寻址服务。网络层的主要任务是确保数据包能够从源主机传输到目的主机，即使它们位于不同的网络中。以下是网络层中一些常见的协议： IP（Internet Protocol，网际协议）： 作用：IP是TCP&#x2F;IP协议族中最重要的协议之一，属于网络层的协议。它定义了数据包的格式、对数据包进行路由和寻址，以便它们可以跨越网络传播到达正确的目的地。 特点：IP协议是无连接的，不保证数据包的可靠传输，只负责尽力而为地传输。 版本： IPv4：使用32位地址，地址空间有限。 IPv6：使用128位地址，解决了IPv4地址耗尽的问题。 ARP（Address Resolution Protocol，地址解析协议）： 作用：ARP解决的是网络层地址到链路层地址之间的转换问题。因为一个IP数据包在物理传输上总需要知道下一跳（物理上的下一个目的地）在哪，但是IP属于逻辑地址，MAC才是真正的物理地址，ARP解决了从IP地址转换到MAC地址的一些问题。 工作原理：当主机需要发送数据包到同一网络中的另一台主机时，它会使用ARP请求广播，询问目标IP地址对应的MAC地址。目标主机收到请求后，会发送ARP响应，包含自己的MAC地址。 ICMP（Internet Control Message Protocol，互联网控制报文协议）： 作用：ICMP是一种用于传输网络状态和错误信息的协议，常用于诊断网络和故障排查。 常见用途： Ping：用于测试网络连通性。 Traceroute：用于跟踪数据包从源主机到目的主机所经过的路径。 NAT（Network Address Translation，网络地址转换协议）： 作用：NAT用于在私有网络和公共网络之间转换IP地址。它允许内部网络中的多个设备共享一个公共IP地址访问互联网。 类型： 静态NAT：一对一的地址转换。 动态NAT：多对多的地址转换。 PAT（Port Address Translation，端口地址转换）：多对一的地址转换，通过端口号区分不同的内部设备。 OSPF（Open Shortest Path First，开放式最短路径优先）： 作用：OSPF是一种内部网关协议（IGP），用于在自治系统（AS）内部动态计算路由表。它使用链路状态算法，能够快速适应网络拓扑的变化。 特点：支持大规模网络，收敛速度快，支持多路径负载均衡。 RIP（Routing Information Protocol，路由信息协议）： 作用：RIP是一种距离向量路由协议，用于在小型网络中动态计算路由表。它通过定期广播路由信息来更新路由表。 特点：简单易用，但收敛速度慢，适用于小型网络。 BGP（Border Gateway Protocol，边界网关协议）： 作用：BGP是一种外部网关协议（EGP），用于在不同的自治系统之间交换路由信息。它负责互联网中不同网络之间的路由选择。 特点：支持大规模网络，能够处理复杂的网络拓扑和策略路由。 "},{"title":"JVM-垃圾回收","date":"2024-10-05T00:29:26.000Z","url":"/2024/10/05/Java-JVM%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6/","tags":[["垃圾回收","/tags/%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6/"]],"categories":[["编程语言","/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"],["Java","/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Java/"],["JVM","/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Java/JVM/"]],"content":"Java中的垃圾回收机制垃圾回收（Garbage Collection, GC）是Java虚拟机（JVM）自动管理内存的一种机制。它负责自动回收那些不再被引用的对象所占用的内存，从而减少了内存泄漏和内存管理错误的可能性。垃圾回收机制通过多种方式触发，以确保内存的有效利用和系统的稳定性。 垃圾回收的基本概念1. 垃圾回收的目标垃圾回收的主要目标是： 自动内存管理：自动回收不再使用的对象，释放其占用的内存。 减少内存泄漏：防止程序因未释放不再使用的对象而导致内存泄漏。 提高程序稳定性：通过自动内存管理，减少因手动内存管理错误导致的程序崩溃。 2. 垃圾回收的基本原理垃圾回收器通过以下步骤实现内存回收： 标记（Marking）：垃圾回收器首先标记所有活动对象（即仍在使用的对象）。 清除（Sweeping）：垃圾回收器清除未被标记的对象，释放其占用的内存。 整理（Compacting）：在某些垃圾回收算法中，垃圾回收器会将存活的对象移动到内存的一端，以减少内存碎片。 垃圾回收的触发方式垃圾回收可以通过多种方式触发，具体包括： 1. 内存不足时当JVM检测到堆内存不足，无法为新的对象分配内存时，会自动触发垃圾回收机制。这种情况下，垃圾回收器会尝试回收不再使用的对象，以释放内存空间。 2. 手动请求虽然垃圾回收是自动的，开发者可以通过调用以下方法建议JVM进行垃圾回收： System.gc() Runtime.getRuntime().gc() 需要注意的是，这些方法只是建议JVM进行垃圾回收，并不能保证立即执行。JVM会根据当前的内存使用情况和垃圾回收策略来决定是否立即执行垃圾回收。 3. JVM参数配置启动Java应用程序时，可以通过设置JVM参数来调整垃圾回收行为。常见的JVM参数包括： -Xmx：设置最大堆内存大小。 -Xms：设置初始堆内存大小。 -XX:+UseG1GC：启用G1垃圾回收器。 -XX:+UseConcMarkSweepGC：启用并发标记清除垃圾回收器。 这些参数可以影响垃圾回收的触发条件和行为，从而优化内存管理和程序性能。 4. 对象数量或内存使用达到阈值垃圾回收器内部实现了一些策略，以监控对象的创建和内存的使用。当对象数量或内存使用达到相应的阈值时，垃圾回收器会触发垃圾回收。这些阈值通常由垃圾回收器的算法和配置决定。 垃圾回收器的类型Java提供了多种垃圾回收器，每种垃圾回收器适用于不同的应用场景和性能需求。常见的垃圾回收器包括： Serial GC：单线程垃圾回收器，适用于单核处理器和小内存应用。 Parallel GC：多线程垃圾回收器，适用于多核处理器和大内存应用。 G1 GC：适用于大内存应用，具有低延迟和高吞吐量的特点。 CMS GC：并发标记清除垃圾回收器，适用于低延迟应用。 判断垃圾的方法在Java中，判断对象是否是垃圾（即不再被使用，可以被垃圾回收器回收）主要依据两种主流的垃圾回收算法实现：引用计数法和可达性分析算法。 引用计数法 原理 引用计数法为每个对象分配一个引用计数器。每当一个地方引用该对象时，计数器加1；当引用失效时，计数器减1。当计数器为0时，表示对象不再被任何对象引用，可以被回收。 缺点 循环引用问题：无法解决循环引用问题，即两个对象互相引用，但不再被其他任何对象引用。这时引用计数器不会为0，导致对象无法被回收，从而造成内存泄漏。 可达性分析算法Java虚拟机（JVM）主要采用可达性分析算法来判断对象是否是垃圾。 原理 可达性分析算法从一组称为GC Roots（垃圾收集根）的对象出发，向下追溯它们引用的对象，以及这些对象引用的其他对象，以此类推。如果一个对象在GC Roots中没有任何引用链路相连（即从GC Roots出发，无法到达该对象），那么认为该对象不可达，可以被回收。 GC Roots对象 GC Roots对象包括以下几种： 虚拟机栈（栈帧中的局部变量表）中引用的对象：当前方法栈帧中的局部变量引用的对象。 方法区中静态属性引用的对象：类的静态变量引用的对象。 本地方法栈中JNI引用的对象：本地方法（Native Method）引用的对象。 活跃线程的引用：当前正在运行的线程引用的对象。 为何需要垃圾回收算法Java虚拟机（JVM）引入垃圾回收机制是为了解决内存管理的问题。在传统的编程语言中，开发人员需要手动分配和释放内存，这容易导致内存泄漏、内存溢出等问题。Java作为一门高级编程语言，旨在提供更简单、更安全的编程环境，因此引入了垃圾回收机制来自动管理内存。 垃圾回收机制的主要目标是自动检测和回收不再使用的对象，从而释放它们所占用的内存。具体来说，垃圾回收机制有以下几个重要目标： 1. 避免内存泄漏 内存泄漏是指一些对象被分配了内存却无法被释放，导致内存资源浪费。垃圾回收机制通过自动检测不再使用的对象并回收其内存，避免了内存泄漏的发生。 2. 防止内存溢出 内存溢出是指程序需要的内存超出了可用内存，导致程序崩溃或异常。垃圾回收机制通过及时回收不再使用的对象，释放内存空间，防止内存溢出的发生。 3. 简化内存管理 手动管理内存需要开发人员显式地分配和释放内存，这不仅增加了编程的复杂性，还容易引入错误。垃圾回收机制自动管理内存，简化了开发人员的内存管理工作，使他们能够专注于业务逻辑的实现。 4. 提高程序稳定性 垃圾回收机制通过自动管理内存，减少了因内存管理错误导致的程序崩溃和异常。这提高了程序的稳定性和可靠性，使Java应用程序能够在更广泛的场景下稳定运行。 垃圾回收算法垃圾回收算法是Java虚拟机（JVM）中用于自动管理内存的关键机制。不同的垃圾回收算法适用于不同的应用场景和性能需求。以下是几种常见的垃圾回收算法及其原理和优缺点。 标记-清除算法（Mark-Sweep）标记-清除算法分为两个阶段： 标记阶段：通过可达性分析标记出所有可以被清除的对象。 清除阶段：对标记的对象进行统一回收，释放其占用的内存。 优点 简单直观：实现简单，易于理解和实现。 缺点 效率问题：标记和清除两个阶段的效率都不高，尤其是在大型应用中。 内存碎片：清除阶段后，内存中会产生大量不连续的碎片，导致内存利用率降低。 复制算法（Copying）复制算法的原理是将内存分为两块，每次申请内存时都使用其中一块。当内存不够时，将这一块内存中所有存活的对象复制到另一块内存中，然后再把旧的一块全部清理掉。 优点 解决内存碎片问题：通过复制存活对象到另一块内存，避免了内存碎片问题。 高效：适用于对象存活率较低的场景，复制过程高效。 缺点 内存利用率低：内存只使用了一半，利用率严重不足。 不适合大内存应用：对于大内存应用，复制算法的开销较大。 标记-整理算法（Mark-Compact）原理标记-整理算法的标记过程与标记-清除算法一致，但不立即进行清理，而是将所有存活对象移动到内存的一端，移动结束后清理掉剩余内存。 优点 解决内存碎片问题：通过整理存活对象，避免了内存碎片问题。 适合老年代：适用于老年代中对象存活率较高的场景。 缺点 效率问题：整理阶段的效率较低，尤其是在大型应用中。 分代回收算法（Generational Collection）分代收集算法将内存划分为新生代和老年代，分配的依据是对象的生命周期，或者说是经历的GC次数。对象创建时，一般在新生代申请内存，当经历一次GC后还存活，那么对象的年龄+1。当年龄超过一定值后（一般默认是15，可以通过-XX:MaxTenuringThreshold来设定），如果该对象还存活，就将该对象放进老年代。 垃圾回收器垃圾回收器（Garbage Collector, GC）是Java虚拟机（JVM）中用于自动管理内存的关键组件。不同的垃圾回收器采用不同的算法和策略，以适应不同的应用场景和性能需求。以下是几种常见的垃圾回收器及其特点。 1. Serial收集器（Serial Collector） 复制算法（Copying） 新生代单线程收集器：Serial收集器是新生代单线程收集器，标记和清理过程都是单线程的。 简单高效：适用于单核处理器和小内存应用，实现简单，效率较高。 2. ParNew收集器（ParNew Collector） 复制算法（Copying） 新生代并行收集器：ParNew收集器是新生代并行收集器，相当于Serial收集器的多线程版本。 多线程并行：通过多线程并行处理，提高了垃圾回收的效率。 3. Parallel Scavenge收集器（Parallel Scavenge Collector） 复制算法（Copying） 新生代并行收集器：Parallel Scavenge收集器是新生代并行收集器，追求高吞吐量，高效利用CPU资源。 高吞吐量：适用于需要高吞吐量的应用场景，如后台计算任务。 4. Serial Old收集器（Serial Old Collector） 标记-整理算法（Mark-Compact） 老年代单线程收集器：Serial Old收集器是老年代单线程收集器，标记和整理过程都是单线程的。 简单高效：适用于单核处理器和小内存应用，实现简单，效率较高。 5. Parallel Old收集器（Parallel Old Collector） 标记-整理算法（Mark-Compact） 老年代并行收集器：Parallel Old收集器是老年代并行收集器，追求高吞吐量，高效利用CPU资源。 高吞吐量：适用于需要高吞吐量的应用场景，如后台计算任务。 CMS收集器（Concurrent Mark Sweep Collector） 标记-清除算法（Mark-Sweep） 老年代并行收集器：CMS收集器是老年代并行收集器，以获取最短回收停顿时间为目标。 高并发、低停顿时间：追求最短GC停顿时间，适用于需要低延迟的应用场景，如Web服务器。 7. G1收集器（Garbage-First Collector） 标记-整理算法（Mark-Compact） Java堆并行收集器：G1收集器是JDK 1.7提供的一个新的收集器，回收的是整个Java堆（包括新生代和老年代）。 分代收集：不同于之前的收集器，G1收集器采用分代收集策略，适用于大内存应用。 低延迟：追求低延迟和高吞吐量，适用于需要高性能的应用场景。 垃圾回收器 算法 特点 适用场景 Serial收集器 复制算法 新生代单线程收集器，简单高效 单核处理器、小内存应用 ParNew收集器 复制算法 新生代并行收集器，多线程并行 多核处理器、小内存应用 Parallel Scavenge收集器 复制算法 新生代并行收集器，追求高吞吐量 高吞吐量应用，如后台计算任务 Serial Old收集器 标记-整理算法 老年代单线程收集器，简单高效 单核处理器、小内存应用 Parallel Old收集器 标记-整理算法 老年代并行收集器，追求高吞吐量 高吞吐量应用，如后台计算任务 CMS收集器 标记-清除算法 老年代并行收集器，追求最短回收停顿时间，高并发、低停顿时间 低延迟应用，如Web服务器 G1收集器 标记-整理算法 Java堆并行收集器，分代收集策略，追求低延迟和高吞吐量 大内存应用，高性能应用 垃圾回收算法中的Stop-the-World阶段在垃圾回收过程中，Stop-the-World（STW）阶段是指在执行垃圾回收时，应用程序的所有线程都会暂停，直到垃圾回收完成。STW阶段的存在是为了确保垃圾回收器能够安全地执行内存管理和回收操作，避免在垃圾回收过程中出现数据不一致或内存泄漏等问题。 复制算法中的STW阶段复制算法主要应用于CMS新生代（ParNew收集器是CMS收集器默认的新生代收集器）和G1垃圾回收器中。复制算法可以分为三个阶段： 标记阶段：通过可达性分析算法，标记出可以被回收的对象。 转移阶段：把活跃的对象转移到新的内存分区上。 重定位阶段：因为对象转移，内存地址发生了改变，因此需要将指向对象的旧指针调整到新的地址上。 STW阶段分析 标记阶段：通常是STW的，因为需要确保在标记过程中对象的引用关系不会发生变化。 转移阶段：通常是STW的，因为需要确保在转移过程中对象的引用关系不会发生变化。 重定位阶段：通常是STW的，因为需要确保在重定位过程中对象的引用关系不会发生变化。 G1垃圾回收器中的STW阶段G1垃圾回收器的混合回收过程可以分为标记阶段、清理阶段和复制阶段。 标记阶段停顿分析 初始标记阶段：初始标记阶段是指从GC Roots出发标记所有子节点的过程，该阶段是STW的。由于GC Roots数量不多，通常该阶段耗时较短。 并发标记阶段：并发标记阶段是指从GC Roots开始对堆中对象进行可达性分析，找出存活对象。因为该阶段是并行的，也就是应用线程可以和GC线程同时活动，因此不是STW的，即使可达性分析耗时相对较长。 再标记阶段：重新标记那些在并发阶段状态发生改变的对象。此阶段是STW的。 清理阶段停顿分析 清理阶段：清点出有存活对象的分区和没有存活对象的分区，该阶段不会立即清理垃圾对象，也不会执行存活对象的复制。该阶段是STW的。 复制阶段停顿分析 转移阶段：需要分配新的内存和复制对象。转移阶段是STW的。分配新内存耗时短，但复制对象耗时长，需要复制对象的成员变量，对象的结构越复杂耗时越长。 可以看出，G1垃圾回收器的停顿时间瓶颈主要在于转移阶段的STW。 Minor GC、Major GC和Full GC在Java中，垃圾回收机制是自动管理内存的重要组成部分。根据触发时机和作用范围，垃圾回收可以分为Minor GC、Major GC和Full GC。理解这些垃圾回收的类型及其特点，对于优化Java应用程序的内存管理和性能具有重要意义。 Minor GC作用范围Minor GC只针对年轻代（Young Generation）进行回收，包括Eden分区和Survivor分区。 触发条件当Eden分区空间不足时，会触发一次Minor GC。Minor GC会将Eden分区和Survivor分区的存活对象转移到另一个Survivor分区或老年代（Old Generation）中。 特点 频繁触发：由于新生代中的对象生命周期较短，Minor GC通常触发的比较频繁。 高效：Minor GC的回收效率高，因为大部分新生代对象都是短命对象，回收后可以释放大量内存。 停顿时间短：由于回收范围较小，Minor GC的停顿时间通常较短。 Major GC作用范围Major GC主要针对老年代进行回收，但不仅限于老年代。 触发条件当老年代分区空间不足，或者系统检测到新生代晋升到老年代的速度较快时，可能会触发Major GC。 特点 频率较低：相比Minor GC，Major GC发生的频率更低，因为老年代中的对象存活率较高。 耗时长：每次Major GC需要的时间会更长，因为老年代中的对象存活率更高，回收过程更复杂。 停顿时间较长：由于回收范围较大，Major GC的停顿时间通常较长。 Full GC作用范围Full GC对整个堆（包括年轻代、老年代和永久代&#x2F;元空间）进行回收。 触发条件Full GC的触发条件包括： 显式调用：直接调用System.gc()或Runtime.getRuntime().gc()方法时，虽然JVM不会立即进行GC回收，但会尝试执行Full GC。 晋升失败：Minor GC后，存活的新生代对象尝试晋升到老年代中，若此时老年代分区没有足够的空间容纳存活对象，则会触发Full GC，对整个堆进行回收。 永久代&#x2F;元空间不足：当永久代（Java 8之前）或元空间（Java 8及之后）内存不足时，会触发Full GC。 特点 昂贵操作：Full GC是最昂贵的GC操作，因为它需要停止所有工作的线程，遍历整个堆内存来查找可以被回收的对象。 停顿时间长：由于回收范围最大，Full GC的停顿时间通常最长。 减少触发：为了提高应用程序的性能，应尽量减少Full GC的触发。 垃圾回收类型 作用范围 触发条件 特点 Minor GC 年轻代（Eden和Survivor） Eden分区空间不足 频繁触发、高效、停顿时间短 Major GC 老年代 老年代分区空间不足或新生代晋升速度较快 频率较低、耗时长、停顿时间较长 Full GC 整个堆（年轻代、老年代、永久代&#x2F;元空间） 显式调用System.gc()、晋升失败、永久代&#x2F;元空间不足 昂贵操作、停顿时间长、应尽量减少触发 CMS和G1垃圾收集器CMS（Concurrent Mark Sweep）和G1（Garbage-First）是Java虚拟机（JVM）中两种常见的垃圾收集器，它们都实现了对内存的自动管理，但在使用范围、STW时间、垃圾碎片、垃圾回收过程和浮动垃圾处理等方面存在显著差异。 区别1. 使用范围不一样 CMS收集器：CMS收集器是老年代收集器，可以配合新生代收集器Serial和ParNew一起使用。CMS主要用于老年代的垃圾回收，通过并发标记和清除算法减少停顿时间。 G1收集器：G1收集器可以单独对整个堆空间（包括新生代和老年代）进行收集，不需要配合其他收集器。G1采用分代收集策略，适用于大内存应用，具有低延迟和高吞吐量的特点。 2. STW时间 CMS收集器：CMS追求的是最少停顿时间，通过并发标记和清除算法减少停顿时间。但在某些情况下，如并发模式失败时，CMS可能会退化为Serial Old收集器，导致较长的停顿时间。 G1收集器：G1收集器可以预测垃圾回收停顿时间（建立可预测的停顿时间模型）。G1通过将堆内存划分为多个区域（Region），并根据区域的使用情况和垃圾回收的优先级进行回收，从而实现可预测的停顿时间。 3. 垃圾碎片 CMS收集器：CMS采用的是“标记-清除”算法进行回收，可能会产生大量垃圾碎片。垃圾碎片会导致内存利用率降低，增加内存分配的复杂性。 G1收集器：G1收集器采用“标记-整理”算法进行垃圾回收，会将存活的对象统一移动到内存的一端，然后清除剩余的空间，不会产生垃圾碎片。G1通过整理存活对象，避免了内存碎片问题。 4. 垃圾回收过程不一样 CMS收集器：CMS的垃圾回收过程包括初始标记、并发标记、重新标记和并发清除四个阶段。其中，初始标记和重新标记阶段是STW的，并发标记和并发清除阶段是并行的。 G1收集器：G1的垃圾回收过程包括初始标记、并发标记、最终标记、筛选回收和并发清理五个阶段。其中，初始标记、最终标记和筛选回收阶段是STW的，并发标记和并发清理阶段是并行的。 5. 浮动垃圾 CMS收集器：CMS在并发清除阶段，垃圾回收线程和应用线程是并行的，二者同时工作会产生浮动垃圾（即在垃圾回收过程中新产生的垃圾对象）。浮动垃圾过多时，CMS会退化为Serial Old收集器，导致效率降低。CMS必须预留一部分空间用于存放浮动垃圾。 G1收集器：G1在筛选回收阶段同样是多个线程并发清除垃圾，此时用户线程也会产生一部分垃圾对象，但这部分可回收的垃圾对象并不会立即清理，而是留到下次执行清理时才被回收。G1通过延迟清理浮动垃圾，避免了CMS中的浮动垃圾问题。 特性 CMS收集器 G1收集器 使用范围 老年代收集器，配合新生代收集器使用 整个堆空间收集器，不需要配合其他收集器 STW时间 追求最少停顿时间，但可能退化为Serial Old 可预测停顿时间模型 垃圾碎片 采用“标记-清除”算法，可能产生大量垃圾碎片 采用“标记-整理”算法，不会产生垃圾碎片 垃圾回收过程 初始标记、并发标记、重新标记、并发清除 初始标记、并发标记、最终标记、筛选回收、并发清理 浮动垃圾 产生浮动垃圾，过多时退化为Serial Old 延迟清理浮动垃圾，避免浮动垃圾问题 理解CMS和G1垃圾收集器的区别和特点，对于优化Java应用程序的内存管理和性能具有重要意义。通过合理选择和配置垃圾收集器，可以减少停顿时间、避免内存碎片和浮动垃圾问题，提高应用程序的稳定性和响应速度。 适用场景CMS适用场景： 低延迟需求：主要针对延迟敏感的应用程序。 老年代收集：主要针对老年代的垃圾回收。 碎片化管理：容易出现内存碎片，可能需要定期进行Full GC来压缩空间。 G1适用场景： 大堆内存：适用于需要管理大内存堆的场景，能够应对GB级别的内存管理。 对内存碎片敏感：G1能够通过紧凑整理来减少内存碎片，降低内存碎片对性能的影响。 比较平衡的性能：G1能够在控制较低STW时间的同时，保持较高的吞吐量。 G1回收器G1回收器的特点G1（Garbage-First）回收器是Java虚拟机（JVM）中的一种先进的垃圾收集器，其最大的特点是引入了分区的思路，弱化了年代的概念。G1回收器通过合理利用垃圾收集各个周期的资源，解决了其他收集器（如CMS）的众多缺陷。 1. 分区（Region） G1回收器将堆内存划分为多个大小相等的区域（Region），每个区域可以是新生代、老年代或混合代。这种分区的方式使得G1能够更灵活地管理内存，避免了传统分代收集器中固定分代的限制。 2. 弱化年代概念 G1回收器弱化了年代的概念，不再严格区分新生代和老年代。G1通过动态调整每个区域的角色，根据对象的存活时间和垃圾回收的需求，灵活地进行垃圾回收。 3. 混合收集（Mixed Collection） G1回收器采用混合收集策略，即在垃圾回收过程中同时回收新生代和老年代的区域。这种混合收集的方式提高了垃圾回收的效率，减少了停顿时间。 4. 可预测的停顿时间 G1回收器通过建立可预测的停顿时间模型，可以根据应用程序的需求设置预期的停顿时间。G1会根据设置的停顿时间，动态调整垃圾回收的策略，以确保垃圾回收过程不会对应用程序的性能产生过大的影响。 G1相比CMS的改进 算法改进 CMS：CMS采用“标记-清除”算法，可能会产生内存碎片。内存碎片会导致内存利用率降低，增加内存分配的复杂性。 G1：G1采用“标记-整理”算法，解决了内存碎片问题。G1通过整理存活对象，将存活对象移动到内存的一端，然后清除剩余的空间，避免了内存碎片问题。 停顿时间可控 CMS：CMS追求最少停顿时间，但在某些情况下（如并发模式失败时），CMS可能会退化为Serial Old收集器，导致较长的停顿时间。 G1：G1可以通过设置预期停顿时间，来控制垃圾收集时间，避免应用雪崩现象。G1会根据设置的停顿时间，动态调整垃圾回收的策略，以确保垃圾回收过程不会对应用程序的性能产生过大的影响。 并行与并发 CMS：CMS在并发标记和并发清除阶段可以与应用线程并行执行，但在初始标记和重新标记阶段是STW的。 G1：G1能够更充分利用CPU多核环境下的硬件优势，来缩短STW的时间。G1在并发标记和并发清理阶段可以与应用线程并行执行，减少了停顿时间。 GC只会对堆进行GC吗？JVM的垃圾回收器不仅仅会对堆进行垃圾回收，也会对其他内存区域进行垃圾回收。虽然堆是垃圾回收的主要目标，但方法区和其他内存区域同样需要进行垃圾回收以释放不再使用的内存资源。 1. 堆（Heap）作用堆是JVM运行时内存管理的重要部分，主要用于存放对象实例。垃圾回收的重点是释放无用的对象实例以解除其占用的内存空间资源。 垃圾回收 新生代（Young Generation）：包括Eden区和Survivor区，主要存放新创建的对象。新生代的垃圾回收称为Minor GC。 老年代（Old Generation）：存放经过多次垃圾回收后仍然存活的对象。老年代的垃圾回收称为Major GC或Full GC。 2. 方法区（Method Area）作用方法区用于存放类信息、常量、静态变量等数据。方法区在Java 8之前称为永久代（Permanent Generation），在Java 8及之后称为元空间（Metaspace）。 垃圾回收 类卸载：方法区中的类信息在某些情况下会被卸载，例如当一个类不再被引用且没有其他类依赖它时。类卸载是方法区垃圾回收的一部分。 常量池回收：方法区中的常量池也会进行垃圾回收，回收不再使用的常量。 3. 其他内存区域作用除了堆和方法区，JVM还包括其他内存区域，如虚拟机栈、本地方法栈和程序计数器。 垃圾回收 虚拟机栈（VM Stack）：虚拟机栈用于存储方法的局部变量表、操作数栈、动态链接、方法出口等信息。虚拟机栈中的数据通常随着方法的执行和结束而自动管理，不需要显式的垃圾回收。 本地方法栈（Native Method Stack）：本地方法栈用于存储本地方法（Native Method）的调用信息。与虚拟机栈类似，本地方法栈中的数据通常随着方法的执行和结束而自动管理。 程序计数器（Program Counter Register）：程序计数器用于存储当前线程所执行的字节码指令的地址。程序计数器是线程私有的，不需要垃圾回收。 "},{"title":"JVM-类初始化与类加载","date":"2024-10-05T00:29:17.000Z","url":"/2024/10/05/Java-JVM%E7%B1%BB%E5%88%9D%E5%A7%8B%E5%8C%96%E4%B8%8E%E7%B1%BB%E5%8A%A0%E8%BD%BD/","tags":[["类加载","/tags/%E7%B1%BB%E5%8A%A0%E8%BD%BD/"],["类初始化","/tags/%E7%B1%BB%E5%88%9D%E5%A7%8B%E5%8C%96/"]],"categories":[["编程语言","/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"],["Java","/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Java/"],["JVM","/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Java/JVM/"]],"content":"对象创建的详细过程 在Java中，对象的创建是一个复杂且多步骤的过程，涉及类加载、内存分配、初始化等多个环节。以下是创建对象的详细步骤及其背后的原理： 类加载检查 当Java虚拟机（JVM）遇到一个new指令时，首先会在常量池中查找该对象的符号引用，并检查该类是否已经被加载、解析和初始化。如果该类尚未被加载，JVM将触发类加载过程。类加载过程包括加载、验证、准备、解析和初始化五个阶段，确保类在内存中正确地表示和初始化。 内存分配 类加载完成后，JVM将为新生对象分配内存。内存分配的大小在类加载阶段已经确定，这通常是通过类的元数据信息（如字段和方法的数量）计算得出。内存分配的方式取决于Java堆的内存模型，可能采用指针碰撞（Bump-the-Pointer）或空闲列表（Free List）等策略。分配内存的过程实际上是从Java堆中划分出一块固定大小的内存空间。 初始化零值 内存分配完成后，JVM需要对对象分配到的所有内存空间进行初始化零值操作。这一步骤确保对象的字段在未显式赋值的情况下，也能访问到默认的零值（如int为0，boolean为false等）。初始化零值操作不包括对象头（Object Header），对象头中存储的是对象的元数据信息。 对象头设置 初始化零值完成后，JVM需要对对象进行必要的设置，这些设置信息存储在对象头中。对象头包含以下关键信息： 类元数据指针：指向该对象所属类的元数据信息。 哈希码：用于唯一标识对象的哈希码。 GC分代信息：记录对象的分代年龄，用于垃圾回收（GC）策略。 锁状态：记录对象的锁状态，用于同步机制。 这些信息对于对象的运行时行为和垃圾回收机制至关重要。 执行&lt;init&gt;方法 完成上述步骤后，JVM已经创建了一个基本结构的对象，但尚未执行任何用户定义的初始化逻辑。接下来，JVM会调用对象的&lt;init&gt;方法（即构造方法），执行用户定义的初始化逻辑。&lt;init&gt;方法的执行包括： 调用父类的构造方法：如果当前类是子类，JVM会先调用父类的构造方法。 初始化字段：按照字段的声明顺序，初始化字段的值。 执行构造方法体：执行构造方法中的用户代码。 &lt;init&gt;方法的执行确保对象的状态符合用户的预期，从而完成对象的创建过程。 对象的生命周期对象的生命周期是指对象从创建到销毁的整个过程，这一过程通常包括三个主要阶段：创建、使用和销毁。理解对象的生命周期对于掌握编程语言的内存管理和资源分配机制至关重要。 1. 创建阶段 在创建阶段，对象通过内存分配和初始化过程被引入到程序中。具体步骤如下： 内存分配：在Java中，对象的创建通常通过new关键字触发。new关键字会指示Java虚拟机（JVM）在堆内存中为对象分配必要的内存空间。 实例化：内存分配完成后，JVM会调用对象的构造函数（Constructor）。构造函数负责执行对象的初始化操作，包括设置对象的初始状态、分配必要的资源等。这一过程确保对象在创建后处于一个有效且可用的状态。 2. 使用阶段 在对象的使用阶段，对象被程序中的其他部分引用，并执行相应的操作。具体包括： 引用与操作：对象通过引用变量被程序的其他部分访问。程序可以通过调用对象的方法（Methods）和访问对象的属性（Fields）来执行各种操作。这些操作可能涉及对象状态的修改、数据的处理、与其他对象的交互等。 生命周期管理：在对象的使用过程中，程序需要确保对象的生命周期管理得当。例如，避免出现内存泄漏（Memory Leak），即对象不再被使用但仍占用内存空间。合理的生命周期管理有助于提高程序的性能和稳定性。 3. 销毁阶段 当对象不再被引用时，JVM会通过垃圾回收机制（Garbage Collection, GC）自动回收对象所占用的内存空间。销毁阶段的具体过程如下： 垃圾回收：垃圾回收器是JVM的一部分，负责自动管理内存。它会定期检测堆内存中不再被引用的对象，并将其标记为可回收状态。垃圾回收器使用多种算法（如标记-清除、复制、标记-整理等）来确定哪些对象可以被回收。 内存释放：一旦对象被标记为可回收，垃圾回收器会在适当的时候执行回收操作，释放对象所占用的内存空间。这一过程是自动进行的，程序员无需显式调用销毁方法。 资源回收：除了内存回收，对象的销毁还可能涉及其他资源的释放，如文件句柄、数据库连接等。在某些情况下，程序员需要通过显式调用close()或dispose()等方法来确保资源的正确释放。 类加载器概述 在Java虚拟机（JVM）中，类加载器（Class Loader）是负责将类的字节码加载到内存中的组件。类加载器按照层次结构组织，形成了所谓的“双亲委派模型”（Parent Delegation Model）。以下是Java中常见的类加载器及其功能： 1. 启动类加载器（Bootstrap Class Loader） 职责：启动类加载器是JVM中最顶层的类加载器，负责加载Java的核心库，如rt.jar中的类。这些类包括java.lang.*、java.util.*等。 实现：启动类加载器通常由JVM的一部分通过C++语言实现，因此无法直接在Java程序中引用。 特点：由于其特殊性，启动类加载器没有父加载器，它是所有其他类加载器的祖先。 2. 扩展类加载器（Extension Class Loader） 职责：扩展类加载器负责加载Java扩展目录（如$JAVA_HOME/lib/ext）中的JAR包和类库。这些扩展类库提供了额外的功能，但不是Java核心库的一部分。 实现：扩展类加载器是Java语言实现的，继承自java.lang.ClassLoader。它的父加载器是启动类加载器。 特点：扩展类加载器允许Java平台在不修改核心库的情况下扩展功能。 3. 系统类加载器&#x2F;应用程序类加载器（System Class Loader&#x2F;Application Class Loader） 职责：系统类加载器负责加载用户路径（如CLASSPATH环境变量指定的路径）上的类库。通常，我们编写的应用程序默认使用的就是该类加载器。 实现：系统类加载器同样是Java语言实现的，继承自java.lang.ClassLoader。它的父加载器是扩展类加载器。 特点：系统类加载器是大多数Java应用程序的默认类加载器，负责加载应用程序的类和依赖库。 4. 自定义类加载器（Custom Class Loader） 职责：开发者可以根据需求定制类加载器，以实现特定的加载策略。例如，从网络、数据库或其他非标准位置加载类。 实现：自定义类加载器通常继承自java.lang.ClassLoader，并重写findClass()或loadClass()方法。 特点：自定义类加载器提供了灵活性，允许开发者根据具体需求实现个性化的类加载逻辑。 双亲委派模型双亲委派模型（Parent Delegation Model）双亲委派模型是Java类加载器体系的核心机制，它定义了类加载器之间的层次关系和加载顺序。其核心思想如下： 委派机制：当一个类加载器收到类加载请求时，它不会立即尝试加载类，而是将请求委派给父类加载器。每一层次的类加载器都会遵循这一原则，直到请求到达顶层的启动类加载器。 加载顺序：如果父类加载器无法加载该类（即在父类加载器的搜索路径中找不到该类），子类加载器才会尝试加载。这种机制确保了类的加载顺序和层次结构，避免了类的重复加载和潜在的冲突。 安全性：双亲委派模型增强了Java平台的安全性，因为它确保了核心库的类只能由启动类加载器加载，防止了恶意代码替换核心类库的可能性。 双亲委派模型的作用1. 保证类的唯一性通过委派机制，双亲委派模型确保了所有类加载请求都会传给启动类加载器。这一机制避免了不同类加载器重复加载相同类的情况，确保了Java核心类库的统一性。同时，它也防止了用户自定义的类覆盖Java核心类库的可能性，从而保证了类的唯一性。 2. 保证安全性由于Java核心类库被启动类加载器加载，而启动类加载器只加载信任的核心类库，双亲委派模型可以防止恶意代码类冒充核心类，增加系统的安全性。这种机制确保了核心类库的完整性和安全性，防止了潜在的安全漏洞。 3. 支持隔离和层次划分双亲委派模型支持不同层次的类加载器服务于不同的类加载需求。例如： 启动类加载器：加载Java核心库类代码。 扩展类加载器：加载框架的扩展代码。 应用程序类加载器：加载用户的代码。 这种层次划分可以实现沙盒安全机制，保证各个层级加载器的职责分明，也便于维护和扩展。每个层次的类加载器只负责加载特定范围内的类，从而实现了类加载的隔离和层次划分。 4. 便于维护和扩展双亲委派模型的层次结构使得类加载器的职责清晰，便于维护和扩展。开发者可以根据需求定制自定义类加载器，并将其插入到现有的类加载器层次结构中。这种灵活性使得Java平台能够适应不同的应用场景和需求，增强了系统的可扩展性。 类加载过程 类从被虚拟机加载到内存开始，到卸载出内存为止，它的整个生命周期包括以下七个阶段： 加载（Loading） 加载阶段是类加载过程的第一个阶段，主要完成以下任务： 获取二进制字节流：通过类的全限定名（包名+类名），获取该类的.class文件的二进制字节流。这个过程可以通过文件系统、网络、动态生成等方式实现。 转换为运行时数据结构：将二进制字节流所代表的静态存储结构，转化为方法区（Method Area）运行时的数据结构。方法区是JVM中的一块内存区域，用于存储类的结构信息。 生成Class对象：在内存中生成一个代表该类的java.lang.Class对象，作为方法区该类的各种数据的访问入口。这个Class对象是反射机制的基础，通过它可以获取类的所有信息。 连接（Linking） 连接阶段包括验证、准备和解析三个子阶段，统称为连接。 ​ 2.1 验证（Verification） 验证阶段的目的是确保.class文件中的字节流包含的信息符合当前虚拟机的要求，保证这个被加载的类的正确性，不会危害到虚拟机的安全。验证阶段大致包括以下四个阶段的检验动作： 文件格式校验：检查字节流是否符合Class文件格式的规范，如魔数、版本号、常量池等。 元数据验证：对类的元数据信息进行语义分析，确保其符合Java语言规范，如类是否有父类、是否继承了不允许继承的类等。 字节码验证：通过数据流和控制流分析，确保方法体的字节码符合逻辑，如操作数栈的数据类型与指令代码序列是否匹配、跳转指令是否指向合理的位置等。 符号引用验证：在解析阶段之前，确保符号引用能够正确解析为直接引用，如检查符号引用中的类、字段、方法是否存在且具有正确的访问权限。 ​ 2.2 准备（Preparation） 准备阶段为类中的静态字段分配内存，并设置初始值。具体包括： 分配内存：为类的静态字段分配内存空间。 设置初始值：为静态字段设置默认初始值，如int类型初始值为0，boolean类型初始值为false。被final修饰的static字段不会在此阶段设置，因为final在编译时就已经分配好了。 ​ 2.3 解析（Resolution） 解析阶段是虚拟机将常量池中的“符号引用”替换为“直接引用”的过程。具体包括： 符号引用：符号引用是以一组符号来描述所引用的目标，符号可以是任何形式的字面量，只要使用时可以无歧义地定位到目标即可。 直接引用：直接引用可以是直接指向目标的指针、相对偏移量或者是一个可以间接定位到目标的句柄。直接引用是和虚拟机实现的内存布局相关的。如果有了直接引用，那引用的目标必定是已存在于内存中的。 初始化（Initialization） 初始化阶段是类加载的最后一个阶段，主要任务是执行类的构造器方法（&lt;clinit&gt;方法）。具体包括： 执行&lt;clinit&gt;方法：&lt;clinit&gt;方法是编译器自动生成的，用于收集类中的静态字段赋值语句和静态代码块。初始化阶段会按照代码顺序执行这些赋值语句和静态代码块。 线程安全：&lt;clinit&gt;方法在多线程环境中是线程安全的，虚拟机会保证在多线程环境下只有一个线程执行&lt;clinit&gt;方法，其他线程会被阻塞。 使用（Using） 使用阶段是指类或对象在程序中被实际使用的过程，包括创建对象实例、调用类的方法、访问类的字段等。 卸载（Unloading） 卸载阶段是指类从内存中被移除的过程。类只有在以下情况下才会被卸载： 所有对象实例被回收：该类的所有对象实例都已被垃圾回收器回收。 类加载器被回收：加载该类的类加载器已被回收。 Class对象无引用：类对应的java.lang.Class对象没有在任何地方被引用，无法在任何地方通过反射访问该类的方法。 "},{"title":"JVM-内存模型","date":"2024-10-05T00:28:49.000Z","url":"/2024/10/05/Java-JVM%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B/","tags":[["内存模型","/tags/%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B/"]],"categories":[["编程语言","/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"],["Java","/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Java/"],["JVM","/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Java/JVM/"]],"content":"了解JVM内存模型根据Java虚拟机规范（JVM Specification）第8版，JVM运行时内存结构主要由以下几个部分组成：虚拟机栈（Java Virtual Machine Stacks）、堆（Heap）、元空间（Metaspace）、程序计数器（Program Counter Register）以及本地方法栈（Native Method Stacks）。此外，JVM还可以直接访问操作系统提供的本地内存，这部分内存被称为直接内存（Direct Memory）。 元空间（Metaspace）元空间是JVM规范中方法区（Method Area）的实现，其本质与Java 7及之前版本中的永久代（Permanent Generation）类似。然而，元空间与永久代最大的区别在于，元空间并不位于JVM管理的内存区域，而是直接使用操作系统的本地内存。这种设计使得元空间的大小不再受限于JVM的堆内存限制，而是可以根据实际需求动态扩展。 Java虚拟机栈（Java Virtual Machine Stacks）每个Java线程在创建时都会分配一个独立的虚拟机栈。栈中存储的是栈帧（Stack Frame），每个方法调用都会生成一个栈帧。栈帧中包含了局部变量表（Local Variable Table）、操作数栈（Operand Stack）、动态链接（Dynamic Linking）、方法返回地址（Return Address）等信息。局部变量表主要存储基本数据类型（如int、float等）和对象引用（Reference）。虚拟机栈的大小可以是固定的，也可以是动态扩展的。 本地方法栈（Native Method Stacks）本地方法栈与虚拟机栈的功能类似，主要区别在于虚拟机栈用于执行Java方法，而本地方法栈用于执行Native方法（即使用C&#x2F;C++等本地语言编写的方法）。本地方法栈的实现方式与虚拟机栈类似，也可以是固定大小或动态扩展的。 程序计数器（Program Counter Register）程序计数器是一个线程私有的内存区域，用于记录当前线程执行的字节码指令的地址。在多线程环境下，处理器在任意时刻只会执行一个线程的指令。为了确保线程切换后能够恢复到正确的执行位置，每个线程都需要维护一个独立的程序计数器。程序计数器的大小通常为一个字长（Word），即32位或64位，具体取决于JVM的实现。 堆内存（Heap）堆内存是JVM中所有线程共享的内存区域，用于存储对象实例和数组。堆内存的大小在JVM启动时就已经确定，并且可以通过JVM参数进行调整。堆内存的管理主要依赖于垃圾回收器（Garbage Collector, GC），当堆内存不足以分配新的对象实例时，JVM会抛出OutOfMemoryError异常。 在JDK 1.8及之后的版本中，字符串常量池（String Constant Pool）从永久代中移出，并被放置在堆内存中。这种设计优化了字符串常量的内存管理，避免了永久代内存溢出的问题。 直接内存（Direct Memory）直接内存并不属于JVM运行时数据区的一部分，也不是JVM规范中定义的内存区域。然而，在JDK 1.4中引入的NIO（New I&#x2F;O）类库中，提供了一种基于通道（Channel）和缓冲区（Buffer）的新的I&#x2F;O方式。NIO允许通过Native函数库直接分配堆外内存，并通过一个存储在堆内存中的DirectByteBuffer对象来引用和操作这块内存。这种设计在某些高性能场景下可以显著提升性能，因为它避免了Java堆和Native堆之间频繁的数据复制操作。 扩展：JVM参数配置与分区在Java的JVM（Java虚拟机）中，配置JVM参数可以影响JVM的内存分配和性能。JVM的内存分区主要包括以下几个部分： 堆内存（Heap Memory）：用于存储对象实例。 非堆内存（Non-Heap Memory）：包括方法区（Method Area）、运行时常量池（Runtime Constant Pool）、JIT编译代码等。 栈内存（Stack Memory）：每个线程都有自己的栈，用于存储局部变量、方法调用等。 本地方法栈（Native Method Stack）：用于执行本地方法（非Java代码）。 PC寄存器（Program Counter Register）：每个线程都有自己的PC寄存器，用于存储当前执行指令的地址。 以下是一些常见的JVM参数及其与内存分区的关系： JVM参数 描述 影响的内存分区 -Xms&lt;size&gt; 设置JVM启动时的初始堆内存大小。 堆内存（Heap Memory） -Xmx&lt;size&gt; 设置JVM允许的最大堆内存大小。 堆内存（Heap Memory） -Xmn&lt;size&gt; 设置年轻代（Young Generation）的大小。 堆内存（Heap Memory） -XX:NewRatio=&lt;ratio&gt; 设置年轻代与老年代的比例。 堆内存（Heap Memory） -XX:SurvivorRatio=&lt;ratio&gt; 设置Eden区与Survivor区的比例。 堆内存（Heap Memory） -XX:MaxMetaspaceSize=&lt;size&gt; 设置方法区的最大大小（在Java 8及更高版本中，方法区被称为Metaspace）。 非堆内存（Non-Heap Memory） -XX:MetaspaceSize=&lt;size&gt; 设置方法区的初始大小。 非堆内存（Non-Heap Memory） -Xss&lt;size&gt; 设置每个线程的栈大小。 栈内存（Stack Memory） -XX:MaxDirectMemorySize=&lt;size&gt; 设置直接内存（Direct Memory）的最大大小。 非堆内存（Non-Heap Memory） -XX:InitialHeapSize=&lt;size&gt; 设置JVM启动时的初始堆内存大小（等同于-Xms）。 堆内存（Heap Memory） -XX:MaxHeapSize=&lt;size&gt; 设置JVM允许的最大堆内存大小（等同于-Xmx）。 堆内存（Heap Memory） -XX:PermSize=&lt;size&gt; 设置永久代（PermGen）的初始大小（在Java 8之前有效）。 非堆内存（Non-Heap Memory） -XX:MaxPermSize=&lt;size&gt; 设置永久代的最大大小（在Java 8之前有效）。 非堆内存（Non-Heap Memory） 注意事项： 堆内存：主要用于存储对象实例，是JVM内存中最大的一部分。通过-Xms和-Xmx可以控制堆内存的初始大小和最大大小。 非堆内存：包括方法区、运行时常量池等，主要用于存储类的元数据、常量、静态变量等。在Java 8及更高版本中，方法区被称为Metaspace，通过-XX:MaxMetaspaceSize和-XX:MetaspaceSize进行配置。 栈内存：每个线程都有自己的栈，用于存储局部变量、方法调用等。通过-Xss可以设置每个线程的栈大小。 直接内存：通过-XX:MaxDirectMemorySize可以设置直接内存的最大大小，直接内存通常用于NIO操作。 通过合理配置这些JVM参数，可以优化JVM的内存使用，避免内存溢出等问题，提升应用程序的性能。 虚拟机栈栈中存放的是指针还是对象？在Java虚拟机（JVM）内存模型中，栈（Stack）用于存储线程的局部变量和方法调用的上下文，而堆（Heap）则是用于存储所有类的实例对象和数组。 栈中存储的是对象引用当我们在栈中讨论“存储”时，指的是存储基本类型的数据和对象的引用，而不是对象本身。具体来说： 基本类型数据：如int、float、boolean等，这些数据直接存储在栈中。 对象引用：当我们在方法中声明一个对象时，比如MyObject o = new MyObject();，这里的o实际上是存储在栈中的引用（Reference），而不是对象本身。这个引用是一个固定大小的数据（例如在64位系统中是8字节），它指向堆中分配给对象的内存空间。 考虑以下代码片段： 在这个例子中： primitive是一个基本类型变量，其值42直接存储在栈中。 obj是一个对象引用，它存储在栈中，指向堆中MyObject类的实例对象。 关键点总结 栈中存储的是对象引用：栈中存储的不是对象本身，而是指向堆中对象实例的引用。 堆中存储对象实例：所有类的实例对象和数组都存储在堆中。 引用的固定大小：对象引用的大小是固定的，通常在64位系统中是8字节。 为什么区分引用和对象很重要？理解栈中存储的是对象引用而不是对象本身，对于以下几个方面非常重要： 内存管理：栈中的引用是轻量级的，而堆中的对象实例可能占用较大的内存空间。区分引用和对象有助于更好地理解内存分配和垃圾回收机制。 性能优化：栈的操作速度通常比堆快，因为栈遵循先进后出原则，操作简单且快速。通过引用访问堆中的对象实例，可以减少内存访问的开销。 并发和线程安全：栈中的数据是线程私有的，而堆中的数据是共享的。理解这一点有助于设计线程安全的代码，避免数据竞争和并发问题。 堆堆的划分Java堆（Heap）是JVM内存管理中一个重要的区域，主要用于存放对象实例和数组。随着JVM的发展和不同垃圾回收器（Garbage Collector, GC）的实现，堆的划分可能会有所不同。然而，通常可以将堆分为以下几个部分： 1. 新生代（Young Generation）新生代是堆内存中用于存放新创建对象的区域。新生代通常分为以下几个子区域： 1.1 Eden SpaceEden Space是新生代中最大的一个区域，大多数新创建的对象首先存储在这里。由于Eden分区较小，当Eden分区满了的时候，会触发一次Minor GC（新生代垃圾回收）。Minor GC的主要目的是回收那些不再被引用的对象，并将存活的对象移动到Survivor Space。 1.2 Survivor SpaceSurvivor Space通常分为两个相等大小的区域，称为S0（Survivor 0）和S1（Survivor 1）。在每次Minor GC回收完成之后，存活下来的对象会被移动到其中的一个Survivor空间。这两个区域轮流充当对象的中转站，帮助区分短暂存活的对象和长期存活的对象。 2. 老年代（Old Generation）老年代是堆内存中用于存放生命周期较长的对象的区域。经历一次或多次Minor GC回收后仍然存活的对象会被移动到老年代分区。老年代中的对象生命周期较长，因此Major GC（也称Full GC，涉及老年代的GC回收）发生的频率较低，但其执行时间通常会比Minor GC时间要长。老年代的空间通常要比新生代要大，以存储更多长期存活的对象。 3. 元空间（Metaspace）从Java 8开始，永久代（Permanent Generation）被元空间（Metaspace）替代，用于存储类元数据信息，比如类的结构信息、方法信息、常量池等。元空间并不在堆中，而是使用本地内存（Native Memory），这解决了永久代容易造成内存溢出的问题。元空间的大小可以根据实际需求动态扩展，不再受限于JVM的堆内存限制。 4. 大对象区（Humongous Region）在某些JVM实现（如G1垃圾收集器）中，为大对象分配了专门的区域，称为大对象区域（Humongous Region）。大对象指需要大量连续内存空间的对象，如大数组。这类对象直接分配在老年代，以避免频繁的新生代晋升而产生内存碎片化。大对象区域的设计有助于优化大对象的内存分配和回收，减少内存碎片。 JVM 堆和栈堆和栈的区别在Java虚拟机（JVM）中，堆（Heap）和栈（Stack）是两个关键的内存区域，它们各自承担着不同的职责，并且在性能、生命周期、存储空间和可见性等方面有着显著的差异。 用途 栈主要用于存储线程在调用方法时产生的栈帧（Stack Frame）。每个栈帧包含了方法的局部变量、操作数栈、动态链接、方法返回地址等信息。栈帧的生命周期与方法调用的生命周期一致，当方法调用结束时，对应的栈帧即刻被销毁。栈的操作遵循先进后出（LIFO）的原则，因此操作简单且快速。 堆是JVM中所有线程共享的内存区域，用于存储对象实例和数组。堆内存的管理主要依赖于垃圾回收器（Garbage Collector, GC），当堆内存不足以分配新的对象实例时，JVM会抛出OutOfMemoryError异常。堆内存的大小在JVM启动时就已经确定，并且可以通过JVM参数进行调整。 2. 生命周期 栈中的数据具有明确的生命周期，当一个方法调用结束时，对应的栈帧即刻销毁。栈帧中的局部变量和操作数栈等数据也随之消失。因此，栈中的数据生命周期是短暂的，仅在方法调用期间存在。 堆中的数据生命周期一般是不确定的，交由GC进行管理。对象实例和数组在堆中创建后，其生命周期取决于是否存在对该对象的引用。当一个对象不再被引用时，GC会在适当的时机回收该对象占用的内存。 3. 存取速度 栈中的数据存储和访问速度通常要比堆快。这是因为栈遵循先进后出原则，操作简单且快速。栈帧的创建和销毁都是在固定的内存位置进行，因此访问速度较快。 堆的结构相对复杂，其存储和访问速率也就相对较慢。堆中的数据需要通过指针进行间接访问，且堆内存的管理涉及垃圾回收，这会消耗相应的性能。垃圾回收器需要扫描堆中的对象，判断哪些对象可以被回收，这个过程可能会导致一定的性能开销。 4. 存储空间 栈的空间相对较小且固定，由操作系统进行管理。每个线程在创建时都会分配一个独立的栈空间，栈的大小可以通过JVM参数进行配置。如果栈空间不足（例如递归层次过深或局部变量过大），JVM会抛出StackOverflowError异常。 堆的空间较大，由JVM进行管理，并且可以动态扩展。堆内存的大小在JVM启动时就已经确定，并且可以通过JVM参数进行调整。堆溢出通常是由于对象实例过多，超出了堆内存的大小，导致JVM抛出OutOfMemoryError异常。 5. 可见性 栈的数据是“线程私有”的，每个线程都有自己独立的栈空间。栈中的数据仅对当前线程可见，其他线程无法访问。这种设计确保了线程之间的数据隔离，避免了数据竞争和并发问题。 堆是所有线程共享的内存区域，堆中的数据对所有线程可见。对象实例和数组在堆中创建后，可以被多个线程共享和访问。这种设计使得堆成为多线程环境下数据共享的主要场所。 方法区方法区中方法执行过程在Java虚拟机（JVM）中，方法的执行过程涉及多个步骤，包括方法调用的解析、栈帧的创建、方法的执行以及返回处理。以下是对这些步骤的详细解析： 解析方法调用 当程序通过对象或类直接调用某个方法时，JVM首先需要解析方法调用。这个过程主要包括以下几个步骤： 符号引用解析：JVM会通过方法符号的引用（Symbolic Reference），找到实际方法的地址。符号引用存储在常量池中，包含了方法的名称、描述符（Descriptor）和所属类的信息。 动态链接：在运行时，JVM会将符号引用解析为直接引用（Direct Reference），即方法在内存中的实际地址。这个过程称为动态链接（Dynamic Linking）。 栈帧创建 在调用方法之前，JVM会为该方法创建一个栈帧（Stack Frame）。栈帧是方法调用和执行的基本单位，包含了以下几个关键部分： 局部变量表（Local Variable Table）：用于存储方法的局部变量，包括基本数据类型和对象引用。局部变量表的大小在编译时就已经确定。 操作数栈（Operand Stack）：用于存储方法执行过程中的中间结果和操作数。操作数栈的大小也在编译时确定。 动态链接（Dynamic Linking）：指向运行时常量池中该方法的符号引用，用于支持方法调用过程中的动态链接。 方法返回地址（Return Address）：存储方法调用完成后的返回地址，用于恢复调用者的执行环境。 执行方法 方法的执行过程涉及以下几个关键操作： 字节码指令执行：JVM会逐条执行方法内的字节码指令。这些指令可能涉及局部变量的读写、操作数栈的操作、跳转控制、对象的创建、方法调用等。 局部变量操作：局部变量表中的数据可以通过字节码指令进行读取和写入。例如，iload指令用于将局部变量表中的int类型数据加载到操作数栈，istore指令用于将操作数栈中的int类型数据存储到局部变量表。 操作数栈操作：操作数栈用于存储方法执行过程中的中间结果和操作数。例如，iadd指令用于将操作数栈顶的两个int类型数据相加，并将结果压入操作数栈。 跳转控制：JVM支持条件和无条件跳转指令，用于实现循环、条件判断等控制结构。例如，if_icmpge指令用于比较操作数栈顶的两个int类型数据，如果第一个数据大于或等于第二个数据，则跳转到指定的字节码指令。 对象创建和方法调用：JVM支持对象创建和方法调用指令。例如，new指令用于创建一个新的对象实例，并将其引用压入操作数栈；invokevirtual指令用于调用对象的实例方法。 返回处理 方法执行完毕后，JVM会进行返回处理，主要包括以下几个步骤： 返回值处理：如果方法有返回值，JVM会将返回值压入调用者的操作数栈。例如，ireturn指令用于将操作数栈顶的int类型数据作为返回值返回给调用者。 栈帧销毁：方法执行完毕后，JVM会销毁当前方法的栈帧，恢复调用者的执行环境。栈帧的销毁包括释放局部变量表和操作数栈的内存空间。 恢复调用者环境：JVM会根据方法返回地址，恢复调用者的执行环境，继续执行调用者方法的下一条指令。 方法区中的内容在Java虚拟机（JVM）中，方法区（Method Area）是一个重要的内存区域，用于存储类的元数据信息。方法区在Java 8及之后的版本中被元空间（Metaspace）替代，但它们的功能和内容基本一致。以下是方法区中存储的主要内容： 类型信息（Type Information） 类型信息包括类的结构信息，如类的名称、父类、接口、修饰符（如public、final等）、字段信息、方法信息等。这些信息在类加载过程中被解析并存储在方法区中。 常量池（Constant Pool） 常量池是一个包含类中所有常量（如字符串常量、整数常量、类和接口的符号引用等）的表。常量池在编译时生成，并在类加载过程中被解析和存储在方法区中。常量池中的常量可以被类中的字段、方法和代码引用。 静态变量（Static Variables） 静态变量是类级别的变量，它们在类加载时被初始化，并在整个类的生命周期内保持不变。静态变量存储在方法区中，可以被类的所有实例共享。 方法字节码（Method Bytecode） 方法字节码是类中方法的实现代码，以字节码的形式存储在方法区中。字节码是JVM能够理解和执行的指令集，它包含了方法的逻辑和操作。方法字节码在类加载过程中被加载到方法区，并在方法调用时被JVM解释执行。 符号引用（Symbolic References） 符号引用是常量池中的一种常量类型，用于表示类、方法、字段等的引用。符号引用在编译时生成，并在类加载过程中被解析为直接引用（Direct Reference），即内存中的实际地址。符号引用在方法调用、字段访问等操作中起到关键作用。 运行时常量池（Runtime Constant Pool） 运行时常量池是常量池在运行时的表示形式，包含了类加载过程中解析后的常量和符号引用。运行时常量池存储在方法区中，用于支持方法调用、字段访问等操作。 常量池缓存（Constant Pool Cache） 常量池缓存是运行时常量池的一个优化机制，用于缓存频繁使用的常量和符号引用。常量池缓存可以减少常量池的访问开销，提高方法调用和字段访问的性能。 引用String保存在哪里？String保存在字符串常量池中，不同于其他对象，它的值是不可变的，且可以被多个引用共享。 点击String的源码，可以看到String类被final关键字修饰： String s = new String(&quot;abc&quot;) 执行过程中涉及的内存分区在Java中，String s = new String(&quot;abc&quot;) 这行代码的执行过程涉及多个内存分区，包括堆内存（Heap）、字符串常量池（String Pool）和栈内存（Stack）。以下是对这个过程的详细解析： 1. 堆内存（Heap）new String(&quot;abc&quot;) 中的 new 关键字用于创建一个新的 String 对象实例。这个对象实例在运行时被创建，并存储在堆内存中。堆内存是JVM中用于存储对象实例和数组的区域。 2. 字符串常量池（String Pool）&quot;abc&quot; 是一个字符串常量，它在编译时就已经确定。JVM会在字符串常量池中查找是否已经存在值为 &quot;abc&quot; 的字符串对象。字符串常量池是JVM中用于存储字符串常量的特殊区域，它有助于减少字符串对象的重复创建，从而节省内存。 如果字符串常量池中已经存在值为 &quot;abc&quot; 的字符串对象，则直接返回该对象的引用。 如果字符串常量池中不存在值为 &quot;abc&quot; 的字符串对象，则在堆内存中创建一个新的 String 对象，并将其引用存储到字符串常量池中。 3. 栈内存（Stack）String s 是一个局部变量，它在栈内存中存储。栈内存用于存储方法的局部变量、操作数栈、方法调用等信息。在这个例子中，s 是一个指向堆内存中 String 对象的引用。 执行过程详细步骤 字符串常量池查找： JVM首先在字符串常量池中查找是否已经存在值为 &quot;abc&quot; 的字符串对象。 如果存在，则直接返回该对象的引用。 如果不存在，则在堆内存中创建一个新的 String 对象，并将其引用存储到字符串常量池中。 创建 String 对象：使用 new 关键字在堆内存中创建一个新的 String 对象，并将字符串常量池中的 &quot;abc&quot; 对象的引用传递给该对象。 栈内存中的引用：在栈内存中创建一个局部变量 s，并将其指向堆内存中新创建的 String 对象。 注意 注意：此时&quot;abc&quot; == s是返回的结果是false，而&quot;abc&quot;.equals(s)返回结果是true。 因为==比较的是二者的引用是否相同，”abc”的引用指向字符串常量池，而s的引用指向新创建的字符串实例对象；二者的值内容是相同的，故而equals方法返回结果是true。 引用类型及其区别在Java中，引用类型主要有四种：强引用（Strong Reference）、软引用（Soft Reference）、弱引用（Weak Reference）和虚引用（Phantom Reference）。这些引用类型在垃圾回收（Garbage Collection, GC）过程中的行为有所不同，适用于不同的应用场景。 1. 强引用（Strong Reference）强引用是Java中最常见的引用类型，通常通过赋值操作创建。例如： 特点：强引用指向的对象永远不会被垃圾回收器回收。只有当强引用被显式地置为 null 或超出作用域时，垃圾回收器才会回收该对象。 应用场景：适用于大多数对象引用场景，确保对象在不再需要时能够被显式地释放。 2. 软引用（Soft Reference）软引用使用 SoftReference 类来描述，适用于那些有用但不是必要的对象。例如： 特点：软引用指向的对象在系统内存不足时会被垃圾回收器回收。垃圾回收器会在发生内存溢出之前尝试回收软引用对象，以释放内存。 应用场景：适用于缓存场景，允许在内存紧张时自动释放缓存对象，避免内存溢出。 3. 弱引用（Weak Reference）弱引用使用 WeakReference 类来描述，强度比软引用更低。例如： 特点：弱引用指向的对象在下一次垃圾回收时会被回收，无论内存是否充足。垃圾回收器会在下一次GC时回收弱引用对象。 应用场景：适用于需要临时持有对象引用，但允许对象在不再使用时被回收的场景，如缓存、监听器等。 4. 虚引用（Phantom Reference）虚引用使用 PhantomReference 类来描述，是最弱的引用关系。虚引用必须与 ReferenceQueue 一起使用。例如： 特点：虚引用指向的对象在垃圾回收器准备回收对象时会被放入 ReferenceQueue 中，但对象本身并不会被立即回收。虚引用主要用于跟踪对象的垃圾回收状态。 应用场景：适用于需要跟踪对象的垃圾回收状态，并在对象被回收时执行某些操作的场景，如管理堆外内存、资源清理等。 弱引用应用场景弱引用（Weak Reference）是一种引用类型，它不会阻止其引用的对象被垃圾回收器回收。在Java中，弱引用通过 java.lang.ref.WeakReference 类来实现。弱引用的主要用途是创建非强制性的对象引用，这些引用可以在内存压力时被清理，避免内存泄漏。 1. 缓存系统 弱引用可以用于缓存系统，当系统内存压力较大时，垃圾回收器会自动清理弱引用对象，从而释放内存资源。这种方式可以避免缓存对象占用过多的内存，导致内存溢出。 2. 对象池 弱引用可以用于对象池（Object Pool），管理暂时不使用的对象。当对象不再被强引用时，可以被垃圾回收器回收，从而避免对象池占用过多的内存。 在这个示例中，WeakReferenceObjectPool 类使用弱引用实现了一个简单的对象池。当对象不再被强引用时，可以被垃圾回收器回收，从而避免对象池占用过多的内存。 3. 避免缓存泄露 弱引用可以用于避免缓存泄露（Cache Leak）。在某些情况下，缓存对象可能会长时间占用内存，导致内存泄漏。使用弱引用可以确保缓存对象在不再使用时能够被垃圾回收器回收。 在这个示例中，WeakReferenceCacheLeakAvoidance 类使用弱引用实现了一个避免缓存泄露的缓存系统。当缓存对象不再被强引用时，可以被垃圾回收器回收，从而避免内存泄漏。 内存泄漏与内存溢出在Java应用程序中，内存泄漏（Memory Leak）和内存溢出（Out of Memory, OOM）是两个常见的内存管理问题。理解这两个概念及其产生的原因，对于优化Java应用程序的性能和稳定性至关重要。 内存泄漏（Memory Leak）内存泄漏是指程序在运行过程中已不再需要某个对象，却因为持有该对象的强引用而导致其无法被垃圾回收（Garbage Collection, GC），从而导致可用内存逐渐减小。随着时间的推移，内存泄漏会导致应用程序的性能下降，甚至崩溃。 内存泄漏的常见原因 静态集合： 使用静态数据结构（如 HashMap、ArrayList）存储对象，且未及时清理。静态集合的生命周期与应用程序的生命周期相同，如果集合中存储了大量不再使用的对象，会导致这些对象无法被回收。 事件监听： 未取消对事件源的监听，导致对对象的持续引用。事件监听器通常会持有对监听对象的引用，如果未及时取消监听，会导致对象无法被回收。 线程： 未关闭的线程可能持有对对象的引用，导致无法回收。线程的生命周期通常较长，如果线程中持有对对象的引用，会导致这些对象无法被回收。 内存溢出（Out of Memory, OOM）内存溢出是指JVM在申请内存时，无法找到足够的内存而抛出 OutOfMemoryError。通常是由于堆内存不足，无法存放新创建的对象。内存溢出会导致应用程序立即崩溃，影响系统的稳定性和可用性。 内存溢出的常见原因 大量对象创建： 程序中创建了大量对象，且这些对象的生命周期较长，导致堆内存不足。 持久引用： 对象被持久引用（如静态变量、缓存等），导致这些对象无法被回收，最终导致堆内存不足。 递归调用： 递归调用可能导致栈内存溢出（StackOverflowError），尤其是在递归深度较大的情况下。 JVM 内存溢出情况在Java虚拟机（JVM）中，内存溢出（Out of Memory, OOM）是指JVM在申请内存时，无法找到足够的内存而抛出 OutOfMemoryError。内存溢出会导致应用程序立即崩溃，影响系统的稳定性和可用性。以下是JVM中常见的内存溢出情况及其原因： 堆内存溢出（Heap OutOfMemoryError） 堆内存溢出是指JVM在堆内存中无法分配足够的空间来存储新创建的对象，导致抛出 OutOfMemoryError。 大量对象创建：程序中创建了大量对象，且这些对象的生命周期较长，导致堆内存不足。 持久引用：对象被持久引用（如静态变量、缓存等），导致这些对象无法被回收，最终导致堆内存不足。 内存泄漏：程序中存在内存泄漏，导致不再使用的对象无法被回收，最终导致堆内存不足。 栈溢出（StackOverflowError） 栈溢出是指线程的栈空间不足，导致抛出 StackOverflowError。栈溢出通常发生在递归调用深度过大或方法调用层次过深的情况下。 递归调用：递归调用深度过大，导致栈空间不足。 方法调用层次过深：方法调用层次过深，导致栈空间不足。 局部变量过多：方法中局部变量过多，导致栈空间不足。 元空间溢出（Metaspace OutOfMemoryError） 元空间溢出是指JVM在元空间（Metaspace）中无法分配足够的空间来存储类的元数据信息，导致抛出 OutOfMemoryError。元空间在Java 8及之后的版本中替代了永久代（PermGen）。 类加载过多：程序中加载了大量类，导致元空间不足。 动态生成类：使用动态代理、字节码生成等技术动态生成大量类，导致元空间不足。 元空间配置不足：元空间的大小配置不足，无法满足程序的需求。 直接内存溢出（Direct Memory OutOfMemoryError） 直接内存溢出是指JVM在直接内存（Direct Memory）中无法分配足够的空间，导致抛出 OutOfMemoryError。直接内存是JVM通过Native函数库直接分配的内存，不受JVM堆内存的限制。 NIO操作：使用NIO（New I&#x2F;O）类库进行大量直接内存分配，导致直接内存不足。 直接内存配置不足：直接内存的大小配置不足，无法满足程序的需求。 内存泄漏：程序中存在直接内存泄漏，导致直接内存不足。 "},{"title":"Spring Cloud","date":"2024-09-30T03:49:12.000Z","url":"/2024/09/30/Spring-SpringCloud/","tags":[["SpringCloud","/tags/SpringCloud/"]],"categories":[["编程语言","/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"],["Java","/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Java/"],["Spring","/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Java/Spring/"]],"content":"Spring Cloud 与 Spring BootSpring Boot和Spring Cloud是Spring生态系统中的两个重要框架，它们各自专注于不同的领域，但在构建现代分布式系统时，它们通常结合使用。以下是对Spring Boot和Spring Cloud的详细解释及其结合使用的场景： Spring Boot 是一个用于构建单个Spring应用的框架，旨在简化Spring应用的初始搭建和开发过程。Spring Boot通过提供开箱即用的配置、自动配置和内嵌服务器等功能，极大地提高了开发效率。 Spring Cloud 是一个用于构建分布式系统中的微服务架构工具。Spring Cloud提供了一系列工具和库，用于实现微服务架构中的常见模式和功能，如服务注册与发现、负载均衡、断路器、网关等。 Spring Boot和Spring Cloud可以结合使用，通过Spring Boot来构建微服务中的单个应用，再结合Spring Cloud来实现微服务中的各个功能。 常见微服务组件在微服务架构中，常见的组件包括注册中心、负载均衡、服务通信、配置中心、集中式日志管理、分布式链路追踪和服务保护。这些组件共同协作，确保微服务架构的高可用性、可扩展性和可维护性。以下是对这些组件的详细解释及其在微服务架构中的作用： 1. 注册中心 注册中心是微服务架构中最核心的组件。它负责新节点的注册和维护，解决了“如何发现新的节点以及检查各个节点运行状态”的问题。微服务节点在启动时会将自己的服务名称、IP、端口号等信息登记在注册中心，注册中心会定时检查该节点的运行状态。注册中心通常采用心跳机制，最大程度保证登记过的节点是可用的。 常见实现： Eureka：Netflix开源的注册中心组件。 Consul：HashiCorp开源的注册中心组件。 Zookeeper：Apache开源的分布式协调服务。 2. 负载均衡 负载均衡解决了“如何发现服务及负载均衡如何实现”的问题。通常，微服务在相互调用时，并不是直接通过IP、端口进行访问调用，而是先通过服务名在注册中心查询该服务拥有哪些节点。注册中心将可用节点列表返回给服务调用者，这个过程叫服务发现。由于服务高可用的要求，服务调用者会收到多个节点，必须从中进行选择。因此，服务调用端必须内置负载均衡器，通过负载均衡策略选择适合的节点构建实质性的通信连接。 常见实现： Ribbon：Netflix开源的客户端负载均衡组件。 Feign：Netflix开源的声明式REST客户端，内置Ribbon。 3. 服务通信 服务通信解决了“服务间如何实现消息通信”的问题。服务间通信采用轻量级协议，通常是HTTP RESTful风格。但由于HTTP RESTful风格过于灵活，必须加以约束，通常应用时对其封装。 常见实现： Spring Cloud OpenFeign：基于Feign的声明式REST客户端。 Spring Cloud Gateway：基于Spring WebFlux的API网关。 4. 配置中心 配置中心解决了“如何集中管理各个服务节点的配置”问题。在微服务架构下，每个节点都会有自己的配置文件，如JDBC配置、环境配置等。有的服务可能会存在十几个节点，如果将配置文件分散地存储在各个节点中，一旦存在部分配置修改，所有的节点配置文件都需要进行配置修改，这样会徒增运维人员的工作量。配置中心便是用于解决该问题，其将配置从各个节点中剥离，集中转存到统一的配置中心。 常见实现： Spring Cloud Config：Spring Cloud提供的配置中心组件。 Apollo：携程开源的配置中心组件。 5. 集中式日志管理 集中式日志管理主要解决了“如何收集各节点日志并统一管理”的问题。微服务架构默认将应用日志分别保存到部署节点上，当需要对日志进行统一收集分析时，必须收集所有节点的日志。业内常见的方案有ELK（Elasticsearch、Logstash、Kibana）和EFK（Elasticsearch、Fluentd、Kibana）。通过搭建独立的日志收集系统，定时抓取各个节点增量日志，形成有效的统计报表。 常见实现： ELK Stack：Elasticsearch、Logstash、Kibana。 EFK Stack：Elasticsearch、Fluentd、Kibana。 6. 分布式链路追踪 分布式链路追踪解决了“如何直观地了解到各个节点间调用链路”的问题。系统中一个复杂的业务流程，可能会出现调用多个微服务的情况，我们需要了解整个业务具体的服务调用流程是怎么样的，以及业务涉及到的每个微服务的运行状态。通过链路可视化展现，可以帮助开发人员快速分析系统瓶颈以及出现的错误的服务。 常见实现： Spring Cloud Sleuth：Spring Cloud提供的分布式链路追踪组件。 Zipkin：Twitter开源的分布式链路追踪系统。 7. 服务保护 服务保护主要是解决了“如何对服务链路进行保护，防止服务雪崩”的问题。在业务运行时，微服务相互调用支撑，如果某个微服务出现高延迟导致线程池满载，或是业务处理失败，这里就需要引入服务保护组件来实现高延迟服务的快速降级，避免系统崩溃。 常见实现： Hystrix：Netflix开源的断路器组件。 Resilience4j：轻量级的容错库，提供断路器、限流、重试等功能。 Spring Cloud Alibaba实现的微服务架构 Spring Cloud Alibaba是Spring Cloud的子项目，提供了丰富的微服务组件，帮助开发者快速构建微服务架构。以下是Spring Cloud Alibaba中常见的微服务组件： Nacos：集注册中心、配置中心和命名服务于一体的组件。 Sentinel：服务保护组件，提供流量控制、熔断降级、系统负载保护等功能。 RocketMQ：分布式消息中间件，支持高吞吐量、低延迟的消息传递。 Seata：分布式事务解决方案，支持多种分布式事务模式。 负载均衡算法负载均衡算法是分布式系统中用于将请求分发到多个后端服务器的关键技术。不同的负载均衡算法适用于不同的场景，以下是常见的负载均衡算法及其详细解释： 1. 简单轮询算法（Round Robin） 简单轮询算法将请求按顺序分发给各个后端服务器，并不关心当前服务器的状态。每个请求依次分配给不同的服务器，循环往复。 2. 加权轮询算法（Weighted Round Robin） 加权轮询算法根据服务器自身的性能设置权重，按权重和请求顺序分发给后端服务器，以此可以让性能高的服务器处理更多的请求。 3. 简单随机算法（Random） 4. 加权随机算法（Weighted Random） 加权随机算法根据服务器自身的状态设置权重，权重越高，随机分发到的概率越大。 5. 一致性哈希算法（Consistent Hashing） 一致性哈希算法根据请求的客户端的ID或者请求参数进行哈希计算，利用该哈希结果取模映射出对应的服务器，这样可以使得同一个客户端能够请求到相同的服务器。 6. 最小活跃数算法（Least Connections） 最小活跃数算法统计每台服务器正在处理的请求数，也就是请求活跃数，将请求分发给活跃数最小的后台服务器。 服务降级服务降级是指当服务器压力剧增时，根据实际业务情况以及流量，对一些服务和页面进行有策略的不处理或者使用简单的方式进行处理，从而释放服务器资源以保证核心业务的正常运行。服务器的资源是有限的，而请求是无限的。在用户请求的高峰期，大量的请求会造成服务高延迟、不可用甚至是服务器宕机。相较于让整个服务器不可用，不如舍弃部分服务，让出服务器资源，“舍小保大”，保证核心业务的可用性。 服务降级的常见策略 关闭非核心服务：在服务器压力剧增时，关闭一些非核心服务，减少服务器负载。 简化服务逻辑：对一些复杂的服务逻辑进行简化处理，减少计算和数据库操作。 返回缓存数据：对于一些读操作，直接返回缓存数据，减少数据库查询。 返回默认值或错误信息：对于一些无法处理的请求，返回默认值或错误信息，避免进一步的资源消耗。 限流：限制请求的速率，防止过多的请求涌入服务器。 熔断：当某个服务出现故障时，立即熔断该服务，避免故障扩散。 服务降级的实现方式1. 手动降级 手动降级是指通过人工干预的方式，手动关闭或简化某些服务。这种方式适用于一些简单的场景，但不适用于大规模的分布式系统。 2. 自动降级 自动降级是指通过自动化工具或框架，根据预设的策略自动进行服务降级。常见的自动降级框架包括Hystrix、Resilience4j等。 Hystrix实现服务降级Hystrix是Netflix开源的断路器组件，提供了服务降级、熔断、限流等功能。以下是使用Hystrix实现服务降级的示例代码： 引入依赖 启用Hystrix在Spring Boot应用中启用Hystrix： 定义降级方法在服务方法上使用@HystrixCommand注解，并指定降级方法： 配置Hystrix在application.yml中配置Hystrix： 服务熔断服务熔断是应对微服务雪崩的一种链路保护机制。在微服务架构中，服务之间的调用是通过服务间调用实现的，例如服务A调用服务B，服务B调用服务C。如果服务C某次处理业务时间过长或者服务C暂时不可用，那么随着时间的推移，对服务C的调用会越来越多，最终导致服务C崩溃。由于服务链路的调用还在继续，对服务B的调用也会持续增加，最终服务B也会垮掉，导致雪崩效应。 服务熔断是应对服务雪崩的一种链路保护机制。当调用服务链路中的某个服务不可用或者响应时间过长时，会进行服务熔断，不再有对该服务的调用，快速返回错误信息。当检测到该节点恢复正常后，恢复链路调用。 服务熔断的工作原理服务熔断通常包括以下几个状态： 关闭状态（Closed）：正常情况下，熔断器处于关闭状态，服务调用正常进行。 打开状态（Open）：当服务调用失败次数达到一定阈值或响应时间超过设定值时，熔断器进入打开状态。此时，所有对该服务的调用都会立即失败，返回错误信息。 半开状态（Half-Open）：在打开状态持续一段时间后，熔断器会进入半开状态。此时，允许部分请求通过，如果这些请求成功，则认为服务恢复正常，熔断器回到关闭状态；如果请求仍然失败，则熔断器回到打开状态。 服务熔断的实现方式HystrixHystrix是Netflix开源的断路器组件，提供了服务熔断、降级、限流等功能。以下是使用Hystrix实现服务熔断的示例代码： 引入依赖 启用Hystrix 在Spring Boot应用中启用Hystrix： 定义熔断方法 在服务方法上使用@HystrixCommand注解，并指定熔断方法： 配置Hystrix 在application.yml中配置Hystrix： Resilience4jResilience4j是另一个轻量级的容错库，提供了服务熔断、限流、重试等功能。以下是使用Resilience4j实现服务熔断的示例代码： 引入依赖 配置Resilience4j 在application.yml中配置Resilience4j： 定义熔断方法 在服务方法上使用@CircuitBreaker注解，并指定熔断方法： "},{"title":"MyBatis","date":"2024-09-30T03:48:57.000Z","url":"/2024/09/30/Spring-MyBatis/","tags":[["MyBatis","/tags/MyBatis/"]],"categories":[["编程语言","/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"],["Java","/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Java/"],["Spring","/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Java/Spring/"]],"content":"传统JDBC与MyBatis在Java应用程序中，数据库操作是一个重要的组成部分。传统JDBC（Java Database Connectivity）是Java提供的一种标准API，用于与关系型数据库进行交互。然而，传统JDBC存在一些不足之处，如代码冗余、手动管理数据库连接等。MyBatis作为一种持久层框架，提供了更灵活、高效的数据库操作方式。以下是MyBatis相较于传统JDBC的优点： 基于SQL语句编程，相当灵活 MyBatis允许开发者直接编写SQL语句，并将SQL语句写在XML文件中。这种方式使得SQL语句的管理和维护更加方便，同时也支持编写动态SQL，提高了SQL语句的可重用性。 减少了50%的代码量，消除了JDBC大量冗余代码 MyBatis通过提供简洁的API和自动化的数据库连接管理，减少了传统JDBC中大量的冗余代码。开发者无需手动管理数据库连接的打开和关闭，也无需编写繁琐的SQL语句拼接代码。 与数据库兼容性高 MyBatis与数据库的兼容性非常高，只要JDBC兼容的数据库，MyBatis都支持。这意味着开发者可以在不同的数据库之间轻松切换，而无需修改大量的代码。 提供映射标签，支持对象与数据库的ORM字段关系映射 MyBatis提供了丰富的映射标签，支持对象与数据库的ORM（Object-Relational Mapping）字段关系映射。开发者可以通过简单的配置，将数据库表中的字段映射到Java对象的属性上，从而简化了数据操作的复杂性。 JDBC连接数据库步骤Java JDBC连接数据库的一般步骤如下： 1. 加载数据库驱动 在连接数据库之前，需要加载相应的数据库驱动。不同的数据库有不同的驱动类名。该步骤在Spring Boot中通常通过配置文件自动完成。 2. 建立数据库连接 使用驱动类中的getConnection(url, userName, password)方法来连接数据库。 3. 创建Statement实例对象 通过上一步获得的数据库连接对象，调用createStatement方法创建一个Statement对象，用于执行SQL语句。 4. 执行SQL语句 使用Statement对象的executeQuery或executeUpdate方法执行SQL语句。 5. 取出SQL运行结果 执行SQL语句后，可以通过ResultSet对象获取查询结果。 6. 关闭连接 在执行完数据库操作后，要关闭数据库连接以避免占用资源。关闭连接需要逐级进行，即先关闭ResultSet，再关闭Statement，最后是Connection。 原生MyBatis的应用在Spring Boot项目中使用原生的MyBatis进行数据库操作，需要按照以下步骤进行配置和开发。以下是详细的步骤说明： 1. 配置MyBatis 引入MyBatis依赖 在项目的pom.xml中引入MyBatis的依赖。 配置数据源 在项目的application.yml或application.properties中配置数据源。 创建SQL映射文件 在项目结构中创建SQL映射文件Mapper。xml，通常放在src/main/resources/mapper目录下。 2. 创建实体 创建用于映射数据库表的实体类，字段名与类型需要与数据库中对应表保持一致。 3. 编写SQL映射文件 创建XML文件，定义SQL语句和映射关系。 4. 编写DAO接口 创建DAO接口，定义数据库操作方法。 5. 编写具体的SQL语句 在SQL映射文件中实现DAO接口，编写具体的SQL语句。 6. 调用DAO操作方法 在服务层或控制层调用DAO中的方法。 MyBatis中#与$区别在MyBatis中，#&#123;&#125;和$&#123;&#125;是两种不同的参数占位符，它们在处理SQL语句时有着不同的行为和用途。以下是对这两种占位符的详细解释及其区别： #&#123;&#125; 占位符MyBatis在处理#&#123;&#125;时，会创建预编译的SQL语句，将#&#123;&#125;替换为?，在具体执行SQL时会为预编译中的?赋值，调用PreparedStatement的set方法来赋值。 预编译SQL：预编译的SQL执行效率高，因为数据库可以缓存预编译的SQL语句，减少了解析和编译的开销。 防止SQL注入：预编译的SQL语句可以防止SQL注入攻击，因为参数值会被正确地转义和处理。 安全性高：适合传递参数，特别是用户输入的参数。 $&#123;&#125; 占位符MyBatis在处理$&#123;&#125;时，只会创建普通的SQL语句，然后在执行SQL语句时将参数拼接到SQL中。 优点： 灵活性高：适合用于动态SQL拼接，如动态表名、列名等。 缺点： 不能防止SQL注入：因为参数直接拼接到SQL语句中，如果参数未经过校验、过滤，可能会导致安全问题。 执行效率低：每次执行SQL语句时都需要重新解析和编译SQL，效率较低。 区别总结 特性 #&#123;&#125; 占位符 $&#123;&#125; 占位符 处理方式 预编译SQL，替换为?，调用set方法 直接拼接参数到SQL语句中 执行效率 高（预编译SQL） 低（每次都需要解析和编译SQL） 安全性 高（防止SQL注入） 低（不能防止SQL注入） 适用场景 传递参数（特别是用户输入的参数） 动态SQL拼接（如动态表名、列名等） **优先使用#&#123;&#125;**：在大多数情况下，优先使用#&#123;&#125;占位符，因为它提供了更高的安全性和执行效率。 **谨慎使用$&#123;&#125;**：仅在需要动态拼接SQL语句时使用$&#123;&#125;，并确保对参数进行严格的校验和过滤，以防止SQL注入攻击。 MyBatis与MyBatis Plus区别MyBatis Plus是一个基于MyBatis的增强工具库，旨在简化开发并提高开发效率。以下是MyBatis Plus相较于MyBatis的主要区别和增强功能： CURD操作 MyBatis Plus通过集成BaseMapper接口，提供了一系列内置的快捷方法，使得CURD操作更加简单，无需编写重复的SQL语句。 代码生成器 MyBatis Plus提供了代码生成器功能，可以根据数据库表结构自动生成实体类、mapper接口以及XML映射文件，减少了手动编写的工作量。 通用方法封装 MyBatis Plus封装了许多常用的方法，如条件构造器、排序、分页查询等，简化了开发过程。 分页插件 MyBatis Plus内置了分页插件，可以轻松实现分页查询功能。 多租户支持 MyBatis Plus：MyBatis Plus提供了多租户支持，可以轻松实现多租户数据隔离的功能。 注解支持 MyBatis Plus提供了丰富的注解支持，如@TableName、@TableId、@TableField等，简化了实体类的配置。 "},{"title":"Spring Boot","date":"2024-09-30T03:48:44.000Z","url":"/2024/09/30/Spring-SpringBoot/","tags":[["SpringBoot","/tags/SpringBoot/"]],"categories":[["编程语言","/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"],["Java","/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Java/"],["Spring","/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Java/Spring/"]],"content":"为什么使用Spring Boot？Spring Boot是Spring框架的一个扩展，旨在简化Spring应用的初始搭建和开发过程。它通过提供开箱即用的组件、自动化配置和快速启动等特性，极大地提高了开发效率和应用性能。以下是使用Spring Boot的主要原因： 简化开发 Spring Boot提供了很多开箱即用的组件和自动化配置，使得开发人员能够更加关注于程序的开发设计，而不必花费大量时间在繁琐的部署和配置上。 主要特性： 约定优于配置：Spring Boot遵循“约定优于配置”的原则，通过默认配置减少了开发人员的配置工作。 内嵌服务器：Spring Boot内嵌了Tomcat、Jetty等服务器，无需手动部署WAR文件。 依赖管理：Spring Boot通过spring-boot-starter依赖，简化了依赖管理，减少了版本冲突问题。 快速启动 Spring Boot提供了快速的程序应用启动方式，使得开发人员能够快速验证和迭代代码。 主要特性： 快速启动：Spring Boot应用启动速度快，通常只需几秒钟即可启动。 热部署：Spring Boot支持热部署，开发人员可以在不重启应用的情况下修改代码并立即看到效果。 自动化配置 Spring Boot通过自动配置功能，根据项目中的依赖和约定俗成的规则来配置程序，减少了配置的复杂性。 主要特性： 自动配置：Spring Boot根据项目中的依赖自动配置应用，减少了手动配置的工作量。 条件化配置：Spring Boot支持条件化配置，根据环境、配置文件等条件自动选择合适的配置。 强大的生态系统 Spring Boot构建在Spring框架之上，继承了Spring的强大生态系统，提供了丰富的扩展和集成支持。 主要特性： Spring Data：简化数据库访问和操作。 Spring Security：提供安全认证和授权功能。 Spring Cloud：支持微服务架构，提供服务发现、配置管理、断路器等功能。 Spring Boot 采用的设计模式Spring Boot作为Spring框架的扩展，继承了Spring框架中广泛使用的设计模式。这些设计模式不仅提高了代码的可维护性和可扩展性，还使得Spring Boot能够灵活应对各种复杂的应用场景。以下是Spring Boot中常用的一些设计模式及其应用： 1. 单例模式（Singleton Pattern） 应用场景：Spring Bean默认是单例模式。 特点：在整个应用中，每个Bean定义只会创建一个实例，并将其缓存起来，供多个用户共享。 2. 模板模式（Template Pattern） 应用场景：Spring Bean的创建过程设计模板模式，体现扩展性，类似Callback回调实现方式。 特点：模板模式定义了一个算法的骨架，并允许子类在不改变算法结构的情况下重新定义算法的某些步骤。 3.简单工厂模式（Simple Factory Pattern） 应用场景：Spring中BeanFactory是简单工厂模式的体现，类似工厂类方法获取Bean实例。 特点：简单工厂模式通过一个工厂类来创建不同类型的对象，客户端无需知道具体的创建逻辑。 4.工厂模式（Factory Method Pattern） 应用场景：Spring中FactoryBean体现工厂方法模式，为不同产品提供不同的工厂。 特点：工厂方法模式定义了一个创建对象的接口，但由子类决定实例化哪个类。 5.代理模式（Proxy Pattern） 应用场景：Spring AOP中动态代理主要通过代理模式实现。 特点：代理模式为其他对象提供一种代理以控制对这个对象的访问。 6.观察者模式（Observer Pattern） 应用场景：Spring的事件机制（ApplicationEvent）体现了观察者模式。 特点：观察者模式定义了一种一对多的依赖关系，当一个对象的状态发生改变时，所有依赖于它的对象都得到通知并被自动更新。 7.策略模式（Strategy Pattern） 应用场景：Spring AOP的动态代理通过两种不同的动态代理实现（JDK动态代理和CGLIB动态代理），通过不同的策略接口和不同策略类，在运行时动态选择。 特点：策略模式定义了一系列算法，并将每个算法封装起来，使它们可以互换。 8.适配器模式（Adapter Pattern） 应用场景：Spring MVC针对不同方式定义的Controller，利用适配器模式统一函数定义，定义了统一接口HandlerAdapter及其对应的适配器类。 特点：适配器模式将一个类的接口转换成客户端所期望的另一个接口。 9.装饰器模式（Decorator Pattern） 应用场景：Spring Security中通过装饰器模式对请求进行安全处理。 特点：装饰器模式动态地给一个对象添加一些额外的职责，而不改变其结构。 Spring Boot 的“约定大于配置”Spring Boot中的“约定大于配置”原则是一种设计理念，旨在通过减少配置和提供合理的默认值，使得开发者可以更快速地构建和部署应用程序，同时降低入门门槛和维护成本。以下是对这一原则的详细解释及其在Spring Boot中的实现方式。 自动化配置 Spring Boot通过自动化配置功能，根据项目的依赖和环境自动配置应用程序的行为。开发者无需手动配置大量的XML文件或Java配置类，Spring Boot会根据约定自动完成大部分配置。 主要特性： 自动配置类：Spring Boot提供了大量的自动配置类，这些类根据项目的依赖自动配置应用程序的行为。 条件化配置：Spring Boot支持条件化配置，根据环境、配置文件等条件自动选择合适的配置。 默认配置 Spring Boot在没有明确配置的情况下，会使用合理的默认值来初始化应用程序。这些默认值通常是经过精心设计的，能够满足大多数应用场景的需求。 主要特性： 默认端口：Spring Boot默认使用8080端口启动Web应用。 默认数据源：Spring Boot默认配置HikariCP作为数据库连接池。 默认日志配置：Spring Boot默认使用Logback作为日志框架。 示例代码 约定优于配置 Spring Boot遵守“约定优于配置”的设计哲学，即通过约定好的方式来提供默认行为，减少开发者所需要做出的决策。开发者只需遵循Spring Boot的约定，即可快速构建应用程序。 主要特性： 包结构约定：Spring Boot默认扫描主类所在包及其子包中的组件。 配置文件约定：Spring Boot默认加载application.properties或application.yml配置文件。 静态资源约定：Spring Boot默认将src/main/resources/static目录下的文件作为静态资源。 起步依赖 Spring Boot提供了一系列起步依赖（Starter Dependencies），这些依赖包含了常用的框架功能，可以帮助开发者快速搭建项目。起步依赖通过Maven或Gradle管理，简化了依赖配置。 主要特性： 简化依赖管理：起步依赖包含了常用框架的依赖，减少了手动配置的工作量。 版本管理：起步依赖统一管理依赖版本，避免了版本冲突问题。 示例代码 Spring Boot 项目结构在Spring Boot项目中，合理的项目结构和代码层级划分对于项目的可维护性和可扩展性至关重要。虽然不同的企业可能会有内部通用的项目结构和代码层级划分指导意见，但以下结构是基于《阿里巴巴Java开发手册》的一个典型示例，适用于大多数Spring Boot项目。 开放接口层（Controller层）：可直接封装Service接口暴露成RPC接口；通过Web封装成HTTP接口；网关控制层等。 终端显示层（View层）：各个终端的模板渲染并执行显示的层。 Web层：主要是对访问控制进行转发，包括对请求参数的校验、请求的转发、请求的过滤等。 Service层：相对具体的逻辑业务层，负责处理具体的业务逻辑。 Manager层：通用业务处理层，包括对第三方服务的封装、对复杂业务逻辑的拆分等。 DAO层：数据库访问层，与具体的数据库进行交互，负责数据的增删改查操作。 第三方服务层：包括其他部门的RPC服务接口、基础平台、其他公司的HTTP接口等。 外部数据接口：处理与外部系统或服务的交互，如调用外部API、处理外部数据等。 假设有一个用户与系统发生交互，其逻辑流程如下图： 代码目录流转逻辑如下： Spring Boot 自动装配原理什么是自动装配Spring Boot的自动装配是通过Spring Framework的@EnableAutoConfiguration注解实现的。这种机制允许开发者在项目中引入相关的依赖，Spring Boot根据这些依赖自动配置应用程序的上下文和功能。自动装配极大地简化了配置过程，使得开发者能够更快速地构建和部署应用程序。 Spring Boot配置了一套接口规范，这套规范规定：Spring Boot在启动时会扫描外部引用jar包中的META-INF/spring.factories文件，将文件中的配置类型信息加载到Spring容器，并执行类中定义的各种操作。对于外部jar来说，只需要按照Spring Boot定义的标准，就能将自己的功能装配到Spring Boot。 通俗一点讲，就是在Spring Boot中只需要通过注解或者一些简单的配置，就可以开启和配置各种功能，比如数据库访问等。 Spring Boot 自动装配原理1.@EnableAutoConfiguration注解 @EnableAutoConfiguration是Spring Boot自动装配的核心注解。它通过@Import注解引入了一个AutoConfigurationImportSelector类，该类负责扫描并加载自动配置类。 2.AutoConfigurationImportSelector类 AutoConfigurationImportSelector类实现了DeferredImportSelector接口，它会在Spring Boot启动时被调用，负责加载自动配置类。 3.META-INF/spring.factories文件 META-INF/spring.factories文件是Spring Boot自动装配的关键配置文件。它定义了需要自动配置的类列表。 4.自动配置类 自动配置类通常使用@Configuration注解，并根据条件进行配置。Spring Boot提供了多种条件注解，如@ConditionalOnClass、@ConditionalOnProperty等，用于根据类路径、配置属性等条件决定是否加载配置。 自动装配的流程 启动Spring Boot应用：Spring Boot应用启动时，会扫描主类上的@SpringBootApplication注解。 加载@EnableAutoConfiguration注解：@SpringBootApplication注解包含了@EnableAutoConfiguration注解，触发自动装配机制。 加载AutoConfigurationImportSelector类：@EnableAutoConfiguration注解通过@Import注解引入AutoConfigurationImportSelector类。 扫描META-INF/spring.factories文件：AutoConfigurationImportSelector类通过SpringFactoriesLoader扫描所有jar包中的META-INF/spring.factories文件，加载自动配置类。 加载自动配置类：根据META-INF/spring.factories文件中的配置，加载并实例化自动配置类。 条件化配置：自动配置类根据条件注解（如@ConditionalOnClass、@ConditionalOnProperty等）决定是否生效。 注册Bean：符合条件的自动配置类中的Bean被注册到Spring容器中。 Spring Boot 启动器Spring Boot 启动器（Starter）Spring Boot 启动器（Starter）是一组预配置的依赖集合，旨在简化Spring Boot应用程序的依赖管理和配置过程。每个启动器都包含了特定功能所需的所有依赖项，开发者只需引入相应的启动器，即可快速集成和使用该功能。以下是一些常见的Spring Boot启动器及其用途： spring-boot-starter-web：最常用的起步依赖之一，包含了Spring MVC和Tomcat嵌入式服务器。适用于构建Web应用程序和RESTful服务。 spring-boot-starter-security：提供了Spring Security的基本配置，帮助开发者快速实现应用的权限控制。 mybatis-spring-boot-starter：由MyBatis团队提供的启动器，用于简化MyBatis在Spring Boot中的集成过程。 spring-boot-starter-data-jpa &#x2F; spring-boot-starter-jdbc：这两个启动器都是为了方便项目对数据库进行操作。前者用于集成Spring Data JPA，后者用于集成Spring JDBC。 spring-boot-starter-data-redis：用于集成Redis缓存和数据库存储服务。包含了与Redis交互的客户端（默认是Jedis），以及Spring Data Redis的支持。 spring-boot-starter-test：包含了用于单元测试或集成测试所需要的库，如JUnit、Spring Test等，便于进行测试驱动开发（TDD）。 Spring Starter 创建过程创建一个Spring Boot Starter的过程涉及多个步骤，包括创建Maven项目、添加自动化配置、创建配置属性类、创建服务和控制器、发布Starter以及在主应用中使用Starter。以下是详细的步骤说明： 第一步：创建Maven项目首先需要创建一个新的Maven项目。在pom.xml中添加Spring Boot的starter parent和一些必要的依赖。 第二步：添加自动化配置在src/main/resources/META-INF/spring.factories中添加自动配置的元数据。 然后，创建MyAutoConfiguration类，该类需要@Configuration和@EnableConfigurationProperties注解。 第三步：创建配置属性类创建一个配置属性类，使用@ConfigurationProperties注解来绑定配置文件中的属性。 第四步：创建服务和控制器创建一个服务类和服务实现类，以及一个控制器来展示starter的功能。 第五步：发布Starter将starter发布到Maven仓库，无论是私有的还是共有的，如Maven Central。 第六步：使用starter在主应用的pom.xml中添加依赖，然后在application.properties或者application.yml中配置属性。 Spring Boot 注解Spring Boot 提供了丰富的注解，用于简化配置和开发过程。以下是一些常用的Spring Boot注解及其用途： 1.@SpringBootApplication 用于标记主应用程序类，标识一个Spring Boot应用程序的入口点，同时启用自动配置和组件扫描。 2.@Controller 标识控制器，处理HTTP请求。 3.@RestController 结合@Controller和@ResponseBody，返回RESTful风格的数据。 4.@Service 标识服务类，用于标记业务逻辑层。 5.@Repository 标识数据访问组件。 6.@Component 通用Spring组件注解，表示一个受Spring容器管理的组件。 7.@Autowired 用于自动装配的注解。 8.@Value 用于标记注入配置属性值。 9.@RequestMapping 用于映射HTTP请求路径到Controller的处理方法。 10.@GetMapping、@PostMapping、@PutMapping、@DeleteMapping 简化@RequestMapping的GET、POST、PUT、DELETE请求。 11.@Configuration 用于标记一个类为配置类，其中定义的Bean会被Spring容器管理。通常与@Bean注解配合使用。 Spring Boot 事务在Spring Boot中，开启事务管理非常简单，主要通过以下几个步骤来实现： 声明式事务启用事务管理Spring Boot默认已经启用了事务管理，但你需要确保在你的Spring Boot应用中引入了spring-boot-starter-data-jpa或spring-boot-starter-jdbc等依赖，这些依赖会自动配置事务管理器。 使用@EnableTransactionManagement注解（可选）在Spring Boot中，通常不需要显式地使用@EnableTransactionManagement注解，因为Spring Boot的自动配置已经启用了事务管理。但如果你需要更细粒度的控制，可以在配置类上使用该注解。 使用@Transactional注解在需要开启事务的方法或类上使用@Transactional注解。Spring会自动为这些方法或类开启事务管理。 配置事务管理器（可选）Spring Boot会根据你的数据源自动配置一个事务管理器（如DataSourceTransactionManager）。如果你需要自定义事务管理器，可以在配置类中手动配置。 事务传播行为和隔离级别你可以通过@Transactional注解的属性来配置事务的传播行为和隔离级别。 编程式事务在Spring Boot中，除了使用声明式事务（通过@Transactional注解），你还可以使用编程式事务来更细粒度地控制事务。编程式事务允许你在代码中手动开始、提交或回滚事务。以下是如何在Spring Boot中开启编程式事务的步骤： 注入PlatformTransactionManager首先，你需要注入PlatformTransactionManager，这是Spring管理事务的核心接口。Spring Boot会根据你的数据源自动配置一个默认的事务管理器（如DataSourceTransactionManager）。 使用TransactionTemplateTransactionTemplate是Spring提供的一个简化编程式事务的工具类。它封装了事务的开始、提交和回滚操作，使代码更加简洁。 "},{"title":"Spring-基础（下）","date":"2024-09-30T03:48:28.000Z","url":"/2024/09/30/Spring-%E5%9F%BA%E7%A1%80%EF%BC%88%E4%B8%8B%EF%BC%89/","tags":[["Bean","/tags/Bean/"]],"categories":[["编程语言","/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"],["Java","/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Java/"],["Spring","/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Java/Spring/"]],"content":"Spring设计Spring 如何解决循环依赖什么是循环依赖？循环依赖（Circular Dependency）是指两个或多个类之间互相依赖，形成一个闭环。例如，类 A 依赖类 B，而类 B 又依赖类 A，从而形成依赖闭环。循环依赖在软件设计中是一个常见的问题，尤其是在使用依赖注入（Dependency Injection, DI）框架时。 循环依赖的三种情况在 Spring 中，循环依赖问题可以分为以下三种情况： 使用构造参数传递依赖构成的循环依赖问题：两个类通过构造器注入形成循环依赖。 使用 setter 方法传递依赖且是原型模式下构成的循环依赖问题：两个类通过 setter 方法注入形成循环依赖，并且 Bean 的作用域是原型（Prototype）。 使用 setter 方法传递依赖且是单例模式下构成的循环依赖问题：两个类通过 setter 方法注入形成循环依赖，并且 Bean 的作用域是单例（Singleton）。 Spring 如何解决循环依赖在 Spring 中，只有第三种情况（单例模式下使用 setter 方法构成的循环依赖）被解决了，其他两种情况在遇到循环依赖问题时，Spring 仍然会抛出相应的异常。 Spring 通过三级缓存（Three-Level Cache）来解决单例模式下使用 setter 方法构成的循环依赖问题。具体步骤如下： 实例化 Bean：Spring 在实例化 Bean 时，会先创建一个空的 Bean 对象，并将其放入一级缓存（singletonObjects）中。 属性赋值：当 Spring 发现存在循环依赖时，会先将当前 Bean 暴露给后续的依赖 Bean，从而解决循环依赖问题。这一步通过提前暴露 Bean 来解决循环依赖。 Bean 初始化：完成属性赋值后，Spring 将 Bean 实例化，并放入二级缓存（earlySingletonObjects）中。 依赖注入：Spring 继续对 Bean 进行依赖注入，如果发现循环注入，会将二级缓存中的 Bean 对象取出，完成初始化的 Bean 实例。 三级缓存策略详解在 Spring 中，三级缓存策略是解决单例模式下使用 setter 方法构成的循环依赖问题的核心机制。三级缓存采用的都是 Map 类型的缓存数据结构，用于存储不同阶段的 Bean 实例。以下是对三级缓存策略的详细解释： 一级缓存（singletonObjects）一级缓存 使用 Map 存放完全初始化好的单例 Bean，也就是开箱即用的 Bean 实例。一级缓存存放在 DefaultSingletonBeanRegistry 中的 singletonObjects 属性中。 数据结构：Map&lt;String, Object&gt;，其中 key 是 Bean 的名称，value 是完全初始化好的 Bean 实例。 作用：存放已经完全初始化好的单例 Bean，这些 Bean 可以直接使用。 二级缓存（earlySingletonObjects）二级缓存 使用 Map 存放已经实例化但还未完全初始化的 Bean。这些 Bean 可能还没有进行属性注入等操作。二级缓存存放在 DefaultSingletonBeanRegistry 中的 earlySingletonObjects 属性中。 数据结构：Map&lt;String, Object&gt;，其中 key 是 Bean 的名称，value 是已经实例化但还未完全初始化的 Bean 实例。 作用：存放提前暴露的 Bean，这些 Bean 已经实例化但还未完全初始化，用于解决循环依赖问题。 三级缓存（singletonFactories）三级缓存 同样是一个 Map 类型的缓存，存储的是 ObjectFactory 对象，这些对象可以生成早期 Bean 的引用。当一个 Bean 正在创建过程中，如果被其他 Bean 依赖，那么这个正在创建的 Bean 就会通过这个 ObjectFactory 来创建一个早期引用，从而解决循环依赖问题。三级缓存存放在 DefaultSingletonBeanRegistry 中的 singletonFactories 属性中。 数据结构：Map&lt;String, ObjectFactory&lt;?&gt;&gt;，其中 key 是 Bean 的名称，value 是 ObjectFactory 对象，用于生成早期 Bean 的引用。 作用：存放 Bean 工厂，用于创建提前暴露的 Bean，解决循环依赖问题。 三级缓存策略的工作流程 实例化 Bean：Spring 在实例化 Bean 时，会先创建一个空的 Bean 对象，并将其放入三级缓存（singletonFactories）中。 提前暴露 Bean：当 Spring 发现存在循环依赖时，会先将当前 Bean 暴露给后续的依赖 Bean，从而解决循环依赖问题。这一步通过将 Bean 工厂放入三级缓存中来实现。 属性赋值：完成属性赋值后，Spring 将 Bean 实例化，并放入二级缓存（earlySingletonObjects）中。 依赖注入：Spring 继续对 Bean 进行依赖注入，如果发现循环注入，会将二级缓存中的 Bean 对象取出，完成初始化的 Bean 实例。 完全初始化：当 Bean 完全初始化后，Spring 将其放入一级缓存（singletonObjects）中，并从二级缓存和三级缓存中移除。 Spring 设计模式Spring 框架是一个高度模块化和可扩展的框架，它广泛使用了多种设计模式来实现其核心功能。以下是 Spring 中常用的一些设计模式及其应用场景： 1. 工厂模式（Factory Pattern）工厂模式 是一种创建型设计模式，用于创建对象而不指定具体的类。Spring 使用工厂模式来创建和管理 Bean 对象。 BeanFactory：Spring 的核心接口之一，用于创建和管理 Bean 实例。BeanFactory 提供了基本的 Bean 创建和获取功能。 ApplicationContext：ApplicationContext 是 BeanFactory 的子接口，提供了更高级的功能，如国际化、事件发布等。 2. 代理模式（Proxy Pattern）代理模式 是一种结构型设计模式，用于为其他对象提供一个代理以控制对这个对象的访问。Spring AOP 通过使用反射机制和动态代理来实现切面编程。 JDK Proxy：适用于被代理对象实现了接口的情况。 CGLIB：适用于被代理对象没有实现接口的情况。 3. 单例模式（Singleton Pattern）单例模式 是一种创建型设计模式，确保一个类只有一个实例，并提供一个全局访问点。Spring 中默认的 Bean 都是单例的。 单例 Bean：Spring 容器中的 Bean 默认是单例的，即在整个应用中只有一个实例。 4. 模板方法模式（Template Method Pattern）模板方法模式 是一种行为型设计模式，定义了一个算法的骨架，并允许子类在不改变算法结构的情况下重新定义算法的某些步骤。Spring 中的 JdbcTemplate 和 HibernateTemplate 等就是模板方法模式的典型应用。 JdbcTemplate：提供了数据库操作的模板方法，子类可以通过实现回调接口来定义具体的操作。 5. 装饰器模式（Decorator Pattern）装饰器模式 是一种结构型设计模式，允许动态地向对象添加功能。Spring 中的 DataSource 实现类（如 DataSourceTransactionManager）就是装饰器模式的典型应用。 6. 观察者模式（Observer Pattern）观察者模式 是一种行为型设计模式，定义了对象之间的一对多依赖关系，当一个对象状态发生改变时，所有依赖它的对象都会收到通知并自动更新。Spring 事件驱动模型就是一个典型的观察者模式。 ApplicationEvent：Spring 中的事件类，用于定义事件。 ApplicationListener：Spring 中的监听器接口，用于监听事件。 7. 适配器模式（Adapter Pattern）适配器模式 是一种结构型设计模式，用于将一个类的接口转换成客户端所期望的另一个接口。Spring AOP 的增强和通知使用了适配器模式，Spring MVC 中的控制器层也使用了适配器模式。 AdvisorAdapter：Spring AOP 中的适配器接口，用于将通知适配为增强。 HandlerAdapter：Spring MVC 中的适配器接口，用于将控制器适配为处理器。 Spring 常用注解Spring 框架提供了丰富的注解（Annotation）来简化配置和开发过程。以下是一些常用的 Spring 注解及其作用： 1. @Autowired 注解@Autowired 注解主要用于自动装配（Dependency Injection）Bean。当 Spring 容器中存在与注入属性类型匹配的 Bean 时，它会自动将 Bean 注入到属性中，类似于 new 对象一样。 2. @Component 注解@Component 注解用于将一个类标记为 Spring 中的 Bean。当一个类被 @Component 标记后，Spring 会将该类实例化为一个 Bean，并将其存放到 Bean 容器中。 3. @Configuration 注解@Configuration 注解用于将一个类标记为 Spring 的配置类。配置类可以包含 @Bean 注解的方法，用于定义和配置 Bean，作为全局配置。 4. @Bean 注解@Bean 注解用于标记一个方法，将该方法作为 Spring 的 Bean 工厂方法。当一个方法被 @Bean 注解标记时，Spring 会将该方法的返回值作为一个 Bean，并将其添加到 Spring 容器中。如果自定义配置会经常用到该注解。 5. @Service 注解@Service 注解用于将一个类标记为服务层的组件。它是 @Component 注解的特例，用于标记服务层的 Bean，一般用于标记服务层的实现类。 6. @Repository 注解@Repository 注解通常用于标记一个类作为数据访问层的组件。它也是 @Component 注解的特例，用于标记数据访问层的组件，该注解开发过程中很容易忘记而导致无法访问数据库。 7. @Controller 注解@Controller 注解通常用于标记一个类作为控制层的组件。它也是 @Component 注解的特例，用于标记控制层的 Bean。 总结Spring 框架提供了丰富的注解来简化配置和开发过程。通过合理使用这些注解，可以提高代码的可读性、可维护性和可扩展性。以下是这些注解的简要总结： 注解 作用 @Autowired 自动装配 Bean @Component 将类标记为 Spring Bean @Configuration 将类标记为 Spring 配置类 @Bean 将方法标记为 Spring Bean 工厂方法 @Service 将类标记为服务层组件 @Repository 将类标记为数据访问层组件 @Controller 将类标记为控制层组件 Spring 扩展机制Spring框架提供了丰富的扩展机制，使得开发者可以根据自己的需求定制和扩展Spring的功能。以下是一些常用的扩展点及其详细介绍： 1. BeanFactoryPostProcessorBeanFactoryPostProcessor允许在Spring容器实例化Bean之前修改Bean的定义。开发者可以通过实现该接口，在Bean实例化之前对Bean定义进行自定义处理。 2. BeanPostProcessorBeanPostProcessor允许在Bean实例化、配置以及初始化的前后对其进行额外的处理。开发者可以通过实现该接口，在Bean生命周期的关键点插入自定义逻辑。 3. PropertySourcePropertySource用于定义不同的属性源，如文件、数据库等，以便在Spring应用中使用。开发者可以通过自定义PropertySource来加载和使用外部属性。 4. Spring MVC中的HandlerInterceptorHandlerInterceptor用于拦截处理请求，可以在请求处理前、处理中和处理后执行特定逻辑。开发者可以通过实现该接口，在请求处理的不同阶段插入自定义逻辑。 5. Spring MVC中的ControllerAdviceControllerAdvice用于全局处理控制器的异常、数据绑定和校验。开发者可以通过实现该接口，在控制器处理请求时插入全局逻辑。 6. Spring Boot的自动配置Spring Boot提供了自动配置机制，开发者可以通过创建配置类，实现对框架和第三方库的自动配置。 7. 自定义注解Spring支持自定义注解，开发者可以通过创建自定义注解来实现特定的功能。 事务管理Spring事务失效场景分析在Spring Boot应用中，事务管理是确保数据一致性和完整性的关键机制。Spring通过其事务管理模块，特别是@Transactional注解，来实现事务操作。然而，事务失效的情况时有发生，这通常是由于配置不当或代码实现中的细微问题所致。以下是一些可能导致Spring事务失效的典型场景及其深入分析： 1. 未捕获的异常场景描述： 当一个异常未被捕获，并且该异常未被处理或传播至事务边界之外时，事务会失效。 深入分析： 在Spring中，默认情况下，事务会在遇到未捕获的异常时自动回滚。然而，如果异常被捕获但未重新抛出，或者异常被捕获后通过某种方式被“吞噬”，事务管理器将无法感知到异常的发生，从而导致事务无法回滚。 解决方案： 确保所有可能引发异常的代码路径都被正确处理，并在必要时重新抛出异常，以便事务管理器能够检测到异常并触发回滚操作。 2. 未受检异常场景描述： 默认情况下，Spring会对未受检异常（如RuntimeException及其子类）进行回滚，此时事务失效。 深入分析： 未受检异常通常表示程序逻辑中的错误或不可恢复的情况。Spring默认将这些异常视为事务失败的信号，并触发回滚操作。然而，如果开发者未意识到这一点，可能会在代码中无意间抛出未受检异常，导致事务失效。 解决方案： 在编写代码时，应尽量避免抛出未受检异常，或者在必要时通过@Transactional注解的rollbackFor属性显式指定哪些异常应触发回滚。 3. 事务属性传递不当场景描述： 当事务内存在嵌套事务且传播了一定的属性时，若传播的属性配置不当，可能导致事务失效。 深入分析： Spring提供了多种事务传播行为（如REQUIRED、REQUIRES_NEW、NESTED等），这些行为决定了事务如何在方法调用链中传播。如果传播行为配置不当，可能会导致事务边界不明确，从而引发事务失效。 解决方案： 仔细选择和配置事务传播行为，确保每个方法调用链中的事务边界清晰且符合业务逻辑需求。 4. 多数据源配置不当场景描述： 当事务操作涉及多个数据源时，若配置文件不当可能导致事务失效。 深入分析： 在多数据源场景下，Spring需要明确指定每个事务操作所涉及的数据源。如果配置不当，可能会导致事务管理器无法正确识别和处理事务，从而引发事务失效。 解决方案： 确保多数据源配置正确，并在必要时使用@Transactional注解的value属性显式指定事务管理器。 5. 事务调用外部方法场景描述： 当事务内调用其他方法，且其他方法未使用@Transactional标记，可能导致事务失效。 深入分析： 在Spring中，事务是通过代理机制实现的。如果一个事务方法调用了另一个未标记为事务的方法，Spring的事务代理将无法拦截该调用，从而导致事务失效。 解决方案： 确保所有需要事务支持的方法都使用@Transactional注解进行标记，或者通过AOP（面向切面编程）机制显式配置事务拦截。 6. 非公有方法场景描述： 如果@Transactional标记在私有方法或其他非公有方法上，事务也会失效。 深入分析： Spring的事务管理依赖于代理机制，而代理机制通常只能拦截公有方法的调用。因此，如果@Transactional注解被应用于非公有方法（如私有方法、受保护方法或包级私有方法），Spring将无法创建事务代理，从而导致事务失效。 解决方案： 将@Transactional注解应用于公有方法，或者通过AOP机制显式配置事务拦截。 Spring事务中调用this是否生效？在Spring事务管理中，调用this是否生效是一个常见且重要的技术问题。为了深入理解这一问题，我们需要从Spring事务的实现机制入手。 Spring事务的实现机制Spring事务管理的核心机制是通过AOP（面向切面编程）实现的。具体来说，Spring使用代理模式来拦截被@Transactional注解标记的方法，并在方法执行前后插入事务管理逻辑。 调用this是否生效？结论： 在Spring事务中，调用this是不生效的。 原因分析 代理对象与目标对象分离： 在Spring中，事务管理是通过代理对象实现的。代理对象与目标对象（即实际的业务逻辑类）是分离的。 当一个方法被@Transactional注解标记时，Spring会创建一个代理对象来拦截该方法的调用。 this引用指向目标对象： 在目标对象的方法内部，this引用指向的是目标对象本身，而不是代理对象。 因此，当在目标对象的方法内部调用this引用的其他方法时，实际上是直接调用了目标对象的方法，绕过了代理对象的事务管理逻辑。 示例代码 在上面的示例中，methodA被@Transactional注解标记，因此Spring会为其创建一个代理对象。然而，当methodA内部调用this.methodB()时，实际上是直接调用了目标对象的methodB，绕过了代理对象的事务管理逻辑，导致methodB的事务管理不生效。 解决方案为了避免上述问题，可以采用以下几种解决方案： 注入代理对象：通过依赖注入的方式获取代理对象，而不是直接使用this引用。 使用AOP切面：通过AOP切面显式配置事务拦截逻辑。 在Spring事务管理中，调用this是不生效的，因为this引用指向的是目标对象，而不是代理对象。为了避免事务失效，可以通过注入代理对象或使用AOP切面来确保事务管理逻辑的正确执行。 BeanSpring Bean的生命周期Spring框架的核心之一是其强大的依赖注入（DI）和控制反转（IoC）机制，而Bean的生命周期管理则是这一机制的重要组成部分。理解Spring Bean的生命周期对于掌握Spring框架的工作原理和优化应用性能至关重要。以下是Spring Bean生命周期的详细步骤： 实例化Bean Spring容器启动时，首先会查找并加载需要被管理的Bean定义。然后，Spring容器会根据Bean定义创建Bean实例。实例化过程通常涉及调用Bean的构造函数。 属性注入 Bean实例化之后，Spring容器会根据Bean定义中的配置，将依赖的Bean引用和属性值注入到Bean实例中。这一过程通常通过调用Bean的setter方法或直接设置字段值来完成。 实现BeanNameAware接口 如果Bean实现了BeanNameAware接口，Spring容器会在属性注入完成后，调用setBeanName(String name)方法，将Bean的名称（通常是Bean的id）传递给Bean。 实现BeanFactoryAware接口 如果Bean实现了BeanFactoryAware接口，Spring容器会在BeanNameAware阶段之后，调用setBeanFactory(BeanFactory beanFactory)方法，将BeanFactory实例传递给Bean。 实现ApplicationContextAware接口 如果Bean实现了ApplicationContextAware接口，Spring容器会在BeanFactoryAware阶段之后，调用setApplicationContext(ApplicationContext applicationContext)方法，将ApplicationContext实例传递给Bean。 前置处理器（BeanPostProcessor） 如果Bean实现了BeanPostProcessor接口，Spring容器会在初始化之前调用postProcessBeforeInitialization(Object bean, String beanName)方法。这一阶段允许开发者在Bean初始化之前对其进行自定义处理。 初始化Bean 在BeanPostProcessor前置处理之后，Spring容器会进行Bean的初始化。 实现InitializingBean接口：如果Bean实现了InitializingBean接口，Spring容器会调用afterPropertiesSet()方法。 自定义初始化方法：如果Bean定义中通过init-method属性指定了初始化方法，Spring容器会调用该方法。 后置处理器（BeanPostProcessor） 在Bean初始化之后，Spring容器会调用BeanPostProcessor的postProcessAfterInitialization(Object bean, String beanName)方法。这一阶段允许开发者在Bean初始化之后对其进行自定义处理。 Bean的使用 此时，Bean已经完全初始化并准备好被使用。Bean将在应用上下文中驻留，直至应用上下文被销毁。 Bean的销毁 当应用上下文被销毁时，Spring容器会进行Bean的销毁处理。 实现DisposableBean接口：如果Bean实现了DisposableBean接口，Spring容器会调用destroy()方法。 自定义销毁方法：如果Bean定义中通过destroy-method属性指定了销毁方法，Spring容器会调用该方法。 Spring Bean的单例与多例模式在Spring框架中，Bean的实例化模式是一个重要的配置选项，它决定了Bean在应用中的创建和使用方式。Spring默认采用单例（Singleton）模式，但也可以根据需要配置为多例（Prototype）模式。以下是对这两种模式的详细解释及其生命周期的差异。 单例模式（Singleton）默认行为在Spring中，Bean默认是单例的。这意味着在整个应用上下文中，每个Bean定义只会创建一个实例，并将其缓存起来。当需要使用该Bean时，Spring容器会从缓存中取出该实例，而不是重新创建。 优点 提高性能：由于Bean实例只创建一次，减少了频繁创建和销毁对象的开销。 节省内存：单例Bean在整个应用中共享，减少了内存占用。 提高复用率：单例Bean可以在多个地方重复使用，减少了对象的创建和销毁次数。 多例模式（Prototype）配置方式要将Bean配置为多例模式，可以在Bean定义中设置scope属性为prototype。例如： 或者在Java配置中： 行为在多例模式下，每次请求该Bean时，Spring容器都会创建一个新的实例。这意味着每个请求都会得到一个独立的Bean实例。对于多例Bean，Spring容器只负责创建实例，并将实例交给使用者。Spring不会管理多例Bean的完整生命周期。 优点 隔离性：每个请求都得到一个独立的Bean实例，避免了状态共享的问题。 灵活性：适用于需要频繁创建和销毁对象的场景。 Spring Bean的作用域在Spring框架中，Bean的作用域（Scope）定义了其生命周期与可见性。不同的作用域决定了Spring容器如何管理这些Bean实例，包括它们的创建、销毁以及是否被多个用户共享。Spring提供了多种作用域，以满足不同的应用需求。 Singleton（单例）是Spring的默认作用域，在整个应用中只会创建一次Bean实例。Spring容器在整个生命周期中管理该Bean实例，并将其缓存起来，供多个用户共享。这种作用域适用于无状态的Bean，如服务层、DAO层等，以及需要全局共享的Bean。 Prototype（多例）作用域下，每次请求都会新建一个Bean实例。新的实例交由使用者后，容器将不再管理该实例的后续生命周期。这种作用域适用于有状态的Bean，如表单对象、对话框等，以及需要频繁创建和销毁的Bean。 Request（请求）作用域在每个HTTP请求时生成一个新的Bean实例，仅在Spring Web应用程序中有效，适用于需要在单个HTTP请求中保持状态的Bean。 Session（会话）作用域在Session范围内只会创建一个Bean实例，该Bean实例仅在会话范围内共享。这种作用域适用于需要在用户会话中保持状态的Bean，如用户购物车。 Application（应用）作用域在当前ServletContext中仅存在一个Bean实例，适用于需要在整个应用中共享的Bean，如全局配置对象。 WebSocket（WebSocket）作用域在WebSocket范围内仅存在一个Bean实例，适用于需要在WebSocket会话中保持状态的Bean。 Spring还允许开发者自定义作用域，通过实现Scope接口来自定义Bean的作用域。这种自定义作用域适用于需要特殊生命周期管理的Bean。 在Bean加载&#x2F;销毁前后增加自定义逻辑在Spring框架中，开发者可以通过多种方式在Bean加载和销毁前后增加自定义逻辑。这些方式包括使用生命周期回调接口、注解以及XML配置。以下是详细的方法介绍： 1. 使用init-method和destroy-method在XML配置中，可以通过init-method和destroy-method属性指定Bean的初始化和销毁方法。 XML配置示例 Bean类实现 2. 实现InitializingBean接口和DisposableBean接口Spring提供了两个生命周期回调接口：InitializingBean和DisposableBean。通过实现这两个接口，可以在Bean初始化和销毁时执行自定义逻辑。 Bean类实现 3. 使用@PostConstruct注解和@PreDestroy注解Spring支持使用JSR-250注解@PostConstruct和@PreDestroy来指定Bean的初始化和销毁方法。 Bean类实现 4. 使用@Bean注解的initMethod属性和destroyMethod属性在Java配置中，可以使用@Bean注解的initMethod和destroyMethod属性来指定Bean的初始化和销毁方法。 Java配置示例 Bean类实现 Bean注入与XML注入在Spring框架中，Bean的注入方式主要有两种：注解注入和XML注入。这两种方式各有优缺点，适用于不同的场景。以下是对这两种注入方式的详细解释及其底层执行步骤。 Bean注解注入注解注入是Spring中常用的一种依赖注入方式，通过在类和属性上使用特定的注解，Spring容器可以自动完成Bean的注册和依赖注入。执行步骤如下： 类路径扫描：当Spring容器启动时，它会进行类路径扫描，查找带有特定注解的类，如@Component、@Service、@Repository、@Controller等。这些注解标记的类会被Spring容器识别为候选Bean。 注册Bean定义：找到的类会被注册到BeanDefinitionRegistry中，Spring容器会为其生成Bean定义信息，包括类的全限定名、作用域、依赖关系等。 依赖注入：在对Bean进行实例化时，Spring容器会检查属性中是否存在@Autowired、@Inject或@Resource注解。如果有，Spring会根据注解的信息进行依赖注入。注入方式可以是构造函数注入、setter方法注入或字段注入。 XML注入XML注入是Spring早期常用的依赖注入方式，通过在XML配置文件中定义Bean及其依赖关系，Spring容器可以完成Bean的注册和依赖注入。执行步骤如下： Bean定义解析：Spring容器通过XmlBeanDefinitionReader类解析XML配置文件，读取其中的&lt;bean&gt;标签以获取Bean的定义信息。解析后的Bean信息包括类的全限定名、作用域、依赖关系、初始化和销毁方法等。 注册Bean定义：解析后的Bean信息将被注册到BeanDefinitionRegistry中，Spring容器会根据这些信息生成Bean定义。 实例化和依赖注入：当应用程序请求某个Bean时，Spring容器会根据已有的Bean定义，使用反射机制创建该Bean实例。然后根据Bean定义中的配置，通过构造函数、setter方法或字段声明注入等方式注入所需要的依赖Bean。 Spring MVC了解MVCMVC（Model-View-Controller）是一种经典的软件设计模式，广泛应用于Web开发和其他类型的应用程序中。MVC模式通过将应用程序的不同职责分离到三个独立的组件中，提高了代码的可维护性、可扩展性和可重用性。 Model（模型） 模型是应用程序的核心部分，负责处理业务逻辑和数据操作。模型可以分为两类： 数据承载Bean：这些是实体对象（如User、Product等），专门用于承载业务数据。它们通常对应数据库中的表结构，包含数据的属性和方法。 业务处理Bean：这些是服务层或数据访问层对象（如Service、Dao等），专门用于处理用户发起的请求。它们负责执行业务逻辑、数据验证、数据持久化等操作。 View（视图） 视图是用户界面，负责向用户展示数据和接收用户的输入。视图通常是HTML、JSP、Thymeleaf、React等前端技术实现的页面或组件。 Controller（控制器） 控制器是模型和视图之间的桥梁，负责处理用户请求并将其转发给相应的模型进行处理。控制器根据模型的计算结果，决定如何更新视图。 Spring MVC的处理流程Spring MVC是Spring框架中的一个重要模块，用于构建基于MVC模式的Web应用程序。Spring MVC的处理流程涵盖了从用户请求到最终响应的整个过程。以下是对Spring MVC处理流程的详细解释： 用户发送请求到前端控制器（DispatcherServlet）：用户通过浏览器或其他客户端发送HTTP请求到Spring MVC应用程序。请求首先被前端控制器DispatcherServlet接收。 DispatcherServlet调用处理器映射器（HandlerMapping）：DispatcherServlet接收到请求后，会调用处理器映射器HandlerMapping，以确定哪个处理器（Controller）应该处理该请求。 处理器映射器生成处理器执行链（HandlerExecutionChain）：HandlerMapping根据请求的URL找到具体的处理器（Controller），并生成一个处理器执行链HandlerExecutionChain。该执行链包括处理器对象和处理器拦截器（如果有配置）。 DispatcherServlet获取处理器适配器（HandlerAdapter）：DispatcherServlet根据处理器（Controller）获取相应的处理器适配器HandlerAdapter。处理器适配器负责执行处理器（Controller）的方法。 处理器适配器执行处理器（Controller）：HandlerAdapter执行处理器（Controller）的方法，进行一系列处理操作，如数据封装、参数解析等。 处理器执行完成返回ModelAndView：处理器（Controller）执行完成后，返回一个ModelAndView对象。ModelAndView包含视图名称和模型数据。 HandlerAdapter将ModelAndView返回给DispatcherServlet：HandlerAdapter将处理器（Controller）返回的ModelAndView对象传递给DispatcherServlet。 DispatcherServlet调用视图解析器（ViewResolver）：DispatcherServlet接收到ModelAndView后，调用视图解析器ViewResolver，根据视图名称解析出具体的视图对象。 ViewResolver解析视图并返回给DispatcherServlet：ViewResolver解析视图名称，找到对应的视图对象（如JSP、Thymeleaf等），并将其返回给DispatcherServlet。 DispatcherServlet对视图进行渲染：DispatcherServlet将模型数据传递给视图对象，并调用视图对象的渲染方法，生成最终的HTML或其他格式的响应内容。 DispatcherServlet响应用户：DispatcherServlet将渲染后的响应内容返回给用户，完成整个请求处理流程。 HandlerMapping与HandlerAdapter在Spring MVC框架中，HandlerMapping和HandlerAdapter是两个关键组件，它们协同工作以处理用户请求并调用相应的控制器方法。以下是对这两个组件的详细解释及其工作流程。 HandlerMappingHandlerMapping的主要作用是将HTTP请求映射到相应的控制器（Controller）方法。它根据请求的URL、HTTP方法、请求参数等信息，确定哪个控制器方法应该处理该请求。 工作流程： 接收请求：DispatcherServlet接收到HTTP请求。 调用HandlerMapping：DispatcherServlet调用HandlerMapping，请求其查找处理该请求的控制器方法。 查找处理器：HandlerMapping根据请求的URL、HTTP方法等信息，查找并返回一个HandlerExecutionChain对象。该对象包含处理器（Controller）和拦截器（如果有配置）。 返回HandlerExecutionChain：HandlerMapping将HandlerExecutionChain返回给DispatcherServlet。 HandlerAdapterHandlerAdapter的主要作用是调用处理器（Controller）方法来处理请求。它负责解析请求参数、调用控制器方法、处理返回值等操作。 工作流程： 接收HandlerExecutionChain：DispatcherServlet接收到HandlerMapping返回的HandlerExecutionChain。 获取HandlerAdapter：DispatcherServlet根据处理器（Controller）的类型，获取相应的HandlerAdapter。 调用处理器方法：HandlerAdapter调用处理器（Controller）的方法，进行请求处理。 处理返回值：HandlerAdapter处理处理器方法的返回值，生成ModelAndView对象。 返回ModelAndView：HandlerAdapter将ModelAndView返回给DispatcherServlet。 HandlerMapping和HandlerAdapter是Spring MVC框架中的两个关键组件，它们协同工作以处理用户请求并调用相应的控制器方法。HandlerMapping负责将请求映射到控制器方法，而HandlerAdapter负责调用控制器方法并处理返回值。"},{"title":"Spring-基础（上）","date":"2024-09-30T03:48:27.000Z","url":"/2024/09/30/Spring-%E5%9F%BA%E7%A1%80%EF%BC%88%E4%B8%8A%EF%BC%89/","tags":[["IoC","/tags/IoC/"],["AOP","/tags/AOP/"]],"categories":[["编程语言","/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"],["Java","/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Java/"],["Spring","/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Java/Spring/"]],"content":"理解Spring框架Spring框架作为Java企业级应用开发的核心组件，其核心特性涵盖了多个关键领域，为开发者提供了强大的工具和抽象层，以简化复杂的企业级应用开发。以下Spring框架几个核心特性： 1.控制反转（IoC）容器 Spring的核心之一是其控制反转（Inversion of Control, IoC）容器。IoC容器通过反转对象的创建和管理职责，使得开发者能够专注于业务逻辑的实现，而非对象的生命周期管理。具体来说，开发者只需定义bean及其依赖关系，Spring容器会自动负责这些对象的创建、组装和管理。 依赖注入（Dependency Injection, DI）：IoC容器通过依赖注入机制，将对象之间的依赖关系从代码中解耦，使得对象的创建和依赖关系的管理更加灵活和可配置。Spring支持多种依赖注入方式，包括构造器注入、Setter注入和字段注入。 Bean生命周期管理：Spring容器不仅负责bean的创建，还管理其生命周期，包括初始化和销毁阶段。开发者可以通过实现特定的接口或使用注解来定制bean的生命周期行为。 2.面向切面编程（AOP） 面向切面编程（Aspect-Oriented Programming, AOP）是Spring框架的另一大核心特性。AOP允许开发者将横切关注点（如事务管理、日志记录、安全性等）模块化，从而提高代码的模块化程度和可维护性。 切面（Aspect）：切面是对横切关注点的模块化封装，通常包括通知（Advice）和切点（Pointcut）。通知定义了在切点处执行的行为，而切点则定义了在何处应用这些行为。 连接点（Join Point）：连接点是程序执行过程中的特定点，如方法调用、异常抛出等。Spring AOP支持在方法调用和异常抛出处应用切面。 代理机制：Spring AOP通过代理机制实现切面的应用。Spring支持两种代理方式：基于JDK动态代理和基于CGLIB的代理。前者适用于接口代理，后者适用于类代理。 3. 事务管理 Spring框架提供了一致且灵活的事务管理机制，使得开发者能够以声明式或编程式的方式管理事务。 声明式事务管理：通过使用@Transactional注解或XML配置，开发者可以声明事务边界和事务属性，Spring会自动管理事务的开始、提交和回滚。 编程式事务管理：对于需要更细粒度控制的事务场景，Spring提供了TransactionTemplate和PlatformTransactionManager等API，允许开发者以编程方式管理事务。 事务传播行为：Spring支持多种事务传播行为（如REQUIRED、REQUIRES_NEW、NESTED等），使得开发者能够灵活控制事务的传播和隔离级别。 4. Spring MVC框架 Spring MVC是基于Servlet API构建的Web框架，采用了模型-视图-控制器（Model-View-Controller, MVC）架构模式，为开发者提供了一种结构化的方式来构建Web应用。 模型（Model）：模型层负责处理业务逻辑和数据访问，通常由服务层和数据访问层组成。 视图（View）：视图层负责展示数据，通常由JSP、Thymeleaf、FreeMarker等模板引擎实现。 控制器（Controller）：控制器层负责处理用户请求，调用模型层处理业务逻辑，并将结果传递给视图层进行展示。Spring MVC通过@Controller和@RequestMapping等注解，简化了控制器的开发。IoC与AOP IoC控制反转（IoC）控制反转（Inversion of Control, IoC）是Spring框架的核心设计原则之一，它通过反转对象的创建和管理职责，使得开发者能够专注于业务逻辑的实现，而非对象的生命周期管理。依赖注入（Dependency Injection, DI）是IoC的一种具体实现方式。 在传统的开发模式中，对象的创建和管理通常由开发者手动完成，使用new关键字来实例化对象。这种方式会导致代码中各个对象之间的耦合度较高，难以维护和扩展。 而在使用IoC思想的开发中，对象的创建和管理职责被反转给IoC容器，开发者只需定义bean及其依赖关系，Spring容器会自动负责这些对象的创建、组装和管理。 IoC的核心概念1. 控制反转（Inversion of Control）所谓控制，就是对象的创建、初始化、销毁等生命周期管理。在传统的开发模式中，这些控制权由开发者掌握，而在IoC模式中，这些控制权被反转给IoC容器。 创建对象：原来是new一个对象，现在是由Spring容器创建。 初始化对象：原来是使用构造器或者setter方法给依赖赋值，现在由Spring自动注入。 销毁对象：原来是通过给对象赋null值销毁，现在由Spring容器管理生命周期进行销毁。 所谓反转，其实就是反转的控制权，对象的生命周期已经由Spring容器管理来进行控制，开发者由对象的控制者，变成了IoC的被动控制者。 2. 依赖注入（Dependency Injection, DI）依赖注入是IoC的一种实现方式，通过依赖注入，对象之间的依赖关系从代码中解耦，使得对象的创建和依赖关系的管理更加灵活和可配置。Spring支持多种依赖注入方式，包括构造器注入、Setter注入和字段注入。 构造器注入：通过构造器参数注入依赖。 Setter注入：通过Setter方法注入依赖。 字段注入：通过字段注解注入依赖。 IoC容器的优势 降低耦合度：对象之间的依赖关系通过配置文件或注解进行管理，减少了代码中的硬编码依赖。 提高可测试性：通过依赖注入，可以方便地使用Mock对象进行单元测试。 增强可维护性：对象的创建和管理由容器负责，开发者只需关注业务逻辑的实现。 IoC容器的实现Spring框架通过IoC容器来管理bean的生命周期和依赖关系。Spring IoC容器的主要实现包括： 1. BeanFactory BeanFactory是Spring IoC容器的基本实现，提供了最基本的IoC功能。BeanFactory是一个接口，定义了获取bean、检查bean类型、检查bean作用域等方法。 2. ApplicationContext ApplicationContext是BeanFactory的子接口，提供了更高级的功能，如国际化支持、事件发布、资源加载等。ApplicationContext是Spring应用上下文的核心接口，通常在企业级应用中使用。 示例以下是一个简单的IoC示例，展示了如何使用Spring IoC容器管理bean及其依赖关系。 定义服务类 定义数据访问类 配置Spring上下文 使用IoC容器 控制反转（IoC）是Spring框架的核心设计原则之一，通过反转对象的创建和管理职责，使得开发者能够专注于业务逻辑的实现。依赖注入（DI）是IoC的一种具体实现方式，通过依赖注入，对象之间的依赖关系从代码中解耦，使得对象的创建和依赖关系的管理更加灵活和可配置。Spring IoC容器通过BeanFactory和ApplicationContext实现bean的生命周期管理，提供了强大的工具和抽象层，以简化复杂的企业级应用开发。深入理解IoC的原理和应用，能够帮助开发者更好地利用Spring框架，提升代码的质量和开发效率。 依赖倒置、依赖注入、控制反转控制反转（Inversion of Control, IoC）控制反转是一种设计原则，它将程序的执行流程控制权从开发者手中转移到了框架或容器中。传统上，开发者通过编写代码来控制程序的执行流程，而在使用框架后，框架接管了这一职责。这种“反转”意味着开发者不再直接控制程序的执行顺序，而是通过配置或声明的方式让框架来管理。 依赖注入（Dependency Injection, DI）依赖注入是一种实现控制反转的具体技术。它通过将依赖对象的创建和管理从类内部转移到外部，从而实现类之间的解耦。依赖注入主要有三种方式： 构造函数注入：通过类的构造函数传递依赖对象。 Setter方法注入：通过类的Setter方法传递依赖对象。 字段注入：通过字段注解直接注入依赖对象。 依赖注入的核心思想是：类不应该负责创建和管理自己的依赖，而是由外部容器或框架来负责。 依赖倒置原则（Dependency Inversion Principle, DIP）依赖倒置原则是面向对象设计中的一个重要原则，它指导我们如何设计模块之间的依赖关系。具体来说，依赖倒置原则包含两个关键点： 高层模块不应该依赖于低层模块：传统的设计中，高层模块通常直接依赖于低层模块的具体实现。依赖倒置原则要求高层模块和低层模块都应该依赖于抽象接口或抽象类，而不是具体的实现。 抽象不应该依赖于细节，细节应该依赖于抽象：这意味着接口或抽象类的设计应该独立于具体的实现细节，而具体的实现类应该依赖于这些抽象。 依赖倒置原则通过引入抽象层，使得系统更加灵活、可扩展，并且降低了模块之间的耦合度。 Spring IoC 的设计与实现在深入探讨如何自行实现 Spring IoC（Inversion of Control，控制反转）容器时，我们需要关注以下几个关键方面，以确保设计的科学性和专业性： Bean 生命周期管理Bean 的生命周期管理是 IoC 容器设计的核心。为了实现这一功能，可以采用以下策略： 工厂模式：通过工厂模式来创建和管理 Bean 实例，确保 Bean 的创建过程与业务逻辑解耦。工厂模式可以进一步细分为简单工厂、工厂方法和抽象工厂，根据具体需求选择合适的模式。 单例模式：对于需要全局共享的 Bean，可以采用单例模式来确保系统中只有一个实例存在。单例模式可以通过双重检查锁定（Double-Checked Locking）或静态内部类等方式实现，以保证线程安全。 生命周期回调：除了基本的创建和销毁，还可以引入生命周期回调机制，如 @PostConstruct 和 @PreDestroy 注解，以支持 Bean 在初始化和销毁时的自定义逻辑。 依赖注入（Dependency Injection）依赖注入是 Spring IoC 的核心特性之一，其实现需要考虑以下几个方面： 注入方式：支持多种注入方式，包括字段注入（Field Injection）、构造器注入（Constructor Injection）和 setter 注入（Setter Injection）。构造器注入通常被认为是最佳实践，因为它可以确保 Bean 在创建时所有依赖都已满足。 反射机制：利用 Java 的反射机制来动态地解析和注入依赖。反射机制允许在运行时获取类的字段、方法和构造器信息，从而实现依赖的自动注入。 配置元数据：依赖注入的实现依赖于配置元数据，这些元数据可以通过 XML 配置文件、注解（如 @Autowired、@Inject）或 Java 配置类（如 @Configuration）来提供。 Bean 的作用域管理Bean 的作用域决定了 Bean 实例的生命周期和可见性。常见的 Bean 作用域包括： 单例（Singleton）：在整个应用中只存在一个 Bean 实例。 原型（Prototype）：每次请求时都会创建一个新的 Bean 实例。 会话（Session）：在 Web 应用中，每个会话对应一个 Bean 实例。 请求（Request）：在 Web 应用中，每个请求对应一个 Bean 实例。 为了支持多种作用域，可以使用 Map 或其他数据结构来存储不同作用域的 Bean 实例。例如，可以使用 ConcurrentHashMap 来存储单例 Bean，使用 ThreadLocal 来存储线程作用域的 Bean。 异常处理在 Bean 管理和依赖注入过程中，可能会遇到各种异常情况，如依赖注入失败、Bean 未找到等。为了确保系统的健壮性，需要定义特定的异常类型，并使用 try-catch 机制进行处理。 自定义异常：定义如 BeanNotFoundException、DependencyInjectionException 等自定义异常，以便在发生错误时能够提供更详细的错误信息。 异常传播：在异常处理过程中，考虑异常的传播机制，确保异常能够正确地传递到调用者，以便进行适当的处理。 面向切面编程（AOP）支持AOP（Aspect-Oriented Programming）是 Spring 框架的另一个重要特性，它允许在不修改原有代码的情况下，通过切面（Aspect）来增强功能。 动态代理：使用 Java 的动态代理机制来实现 AOP。动态代理可以在运行时生成代理类，从而在不修改原有类的情况下，插入额外的逻辑（如日志记录、事务管理等）。 切面编程：定义切面（Aspect）、切点（Pointcut）和通知（Advice），通过这些元素来实现横切关注点的分离。常见的通知类型包括前置通知（Before Advice）、后置通知（After Advice）、环绕通知（Around Advice）等。 配置文件加载配置文件的加载是 IoC 容器启动的关键步骤之一，它决定了容器如何初始化和管理 Bean。 配置文件格式：支持多种配置文件格式，如 XML、注解（如 @ComponentScan、@Bean）和 Java 配置类（如 @Configuration）。每种配置方式都有其优缺点，可以根据具体需求选择合适的配置方式。 配置解析：配置文件的解析是加载过程中的关键步骤。可以使用 DOM 解析器（如 DocumentBuilder）来解析 XML 配置文件，使用反射机制来解析注解配置，使用 Java 反射来解析 Java 配置类。 配置合并：在复杂的应用中，可能需要从多个配置文件中加载 Bean 信息。为了确保配置的一致性和完整性，可以实现配置的合并机制，将多个配置文件中的信息合并为一个统一的配置对象。 通过以上几个方面的深入设计和实现，可以构建一个功能完备、性能优越的 Spring IoC 容器，满足复杂应用场景的需求。 AOP面向切面编程（AOP）面向切面编程（Aspect-Oriented Programming, AOP）是Spring框架的另一大核心特性，它允许开发者将横切关注点（如事务管理、日志记录、安全性等）模块化，从而提高代码的模块化程度和可维护性。AOP的核心思想是将核心业务逻辑与周边业务逻辑分离，并通过切面将它们编织在一起。 AOP的核心概念 1. 切面（Aspect）切面是对横切关注点的模块化封装，通常包括通知（Advice）和切点（Pointcut）。切面定义了在哪些连接点（Join Point）上应用哪些通知。 2. 连接点（Join Point）连接点是程序执行过程中的一个特定点，例如方法调用、异常抛出等。在Spring AOP中，连接点仅支持方法级别的连接点。 3. 通知（Advice）通知定义了在切点处执行的行为。Spring AOP支持多种类型的通知，包括： 前置通知（Before Advice）：在目标方法执行前执行。 后置通知（After Advice）：在目标方法执行后执行，无论方法是否成功完成。 返回通知（After Returning Advice）：在目标方法成功执行后执行。 异常通知（After Throwing Advice）：在目标方法抛出异常后执行。 环绕通知（Around Advice）：在目标方法执行前后执行，可以控制方法的执行流程。 4. 切点（Pointcut）切点用于匹配连接点，定义了在哪些连接点上应用通知。切点通常通过表达式来匹配特定的连接点。 5. 引介（Introduction）引介允许一个切面声明被通知对象未被实现的额外接口。通过引介，可以为一个对象代理多个目标类。 6. 织入（Weaving）织入是将切面应用到目标对象的过程。在织入过程中，切面中的通知逻辑会被插入到目标方法上，使得通知逻辑在方法调用时得到执行。 7. AOP代理（AOP Proxy）AOP代理是在AOP框架中实现切面协议的对象。Spring AOP支持两种代理方式： JDK动态代理：适用于代理实现了接口的对象。Spring会使用JDK的Proxy类生成代理对象。 CGLIB动态代理：适用于代理没有实现接口的对象。Spring会使用CGLIB生成一个被代理对象的子类来进行代理。 8. 目标对象（Target Object）目标对象是被代理的对象，即切面逻辑将要应用的对象。 AOP的应用场景AOP能够将那些与业务无关、却为业务进行服务的通用公共功能封装起来，以便减少系统的代码量，使得系统更加模块化、降低系统耦合度，有利于未来系统的扩展与维护。常见的应用场景包括： 事务管理：通过AOP实现声明式事务管理，简化事务控制代码。 日志记录：通过AOP实现日志记录，避免在业务代码中嵌入日志逻辑。 安全性检查：通过AOP实现权限验证，确保只有授权用户才能访问特定资源。 性能监控：通过AOP实现性能监控，记录方法的执行时间和调用次数。 AOP的实现机制Spring AOP通过代理机制实现切面的应用。具体来说，Spring AOP会在运行时生成代理对象，并将切面逻辑织入到目标方法中。 JDK动态代理JDK动态代理适用于代理实现了接口的对象。Spring会使用JDK的Proxy类生成代理对象。JDK动态代理的优点是性能较高，但要求目标对象必须实现至少一个接口。 CGLIB动态代理CGLIB动态代理适用于代理没有实现接口的对象。Spring会使用CGLIB生成一个被代理对象的子类来进行代理。CGLIB动态代理的优点是不要求目标对象实现接口，但性能略低于JDK动态代理。 示例以下是一个简单的AOP示例，展示了如何使用Spring AOP实现日志记录功能。 1. 定义切面 注释解释 **@Aspect**：将 LoggingAspect 类标记为一个切面类。 **@Component**：将 LoggingAspect 类标记为一个Spring组件，使其可以被Spring容器管理。 方法解释 **@Pointcut(&quot;execution(* com.example.service.*.*(..))&quot;)**：定义一个切入点 serviceMethods，匹配 com.example.service 包下所有类的所有方法。 execution(* com.example.service.*.*(..))： *：匹配任意返回类型。 com.example.service.*.*：匹配 com.example.service 包下的所有类和所有方法。 (..)：匹配任意数量和类型的参数。 **@Before(&quot;serviceMethods()&quot;)**：定义一个前置通知 logBefore，在 serviceMethods 切入点匹配的方法执行前执行。 JoinPoint joinPoint：JoinPoint 对象包含被通知方法的详细信息，如方法签名、参数等。 joinPoint.getSignature().getName()：获取被通知方法的名称。 **@AfterReturning(pointcut = &quot;serviceMethods()&quot;, returning = &quot;result&quot;)**：定义一个返回通知 logAfterReturning，在 serviceMethods 切入点匹配的方法成功返回后执行。 returning = &quot;result&quot;：指定返回值的参数名称为 result。 Object result：接收方法的返回值。 2. 定义服务类 注释解释 **@Service**：将 UserService 类标记为一个Spring服务组件，使其可以被Spring容器管理。 方法解释 **public String saveUser(User user)**：定义一个服务方法 saveUser，接收一个 User 对象作为参数，并返回一个字符串。 3. 配置Spring上下文 注释解释 **@Configuration**：将 AppConfig 类标记为一个Spring配置类。 **@ComponentScan(&quot;com.example&quot;)**：启用组件扫描，扫描 com.example 包及其子包中的Spring组件。 **@EnableAspectJAutoProxy**：启用Spring AOP的自动代理功能，支持基于AspectJ的切面。 为何要有Spring AOPSpring AOP（Aspect-Oriented Programming，面向切面编程）的设计初衷确实是为了补充和增强面向对象编程（OOP）的不足，而不是作为一种独立的编程范式来替代现有的开发模式。AOP 的核心思想是将横切关注点（Cross-Cutting Concerns）从业务逻辑中分离出来，从而提高代码的模块化、可维护性和可重用性。 Spring AOP 原理：动态代理技术的应用Spring AOP（Aspect-Oriented Programming，面向切面编程）的核心原理是基于动态代理技术。动态代理允许在程序运行时生成代理对象，从而在不修改原有代码的情况下，插入额外的逻辑（如日志记录、事务管理等）。Spring AOP 主要使用了两种动态代理技术：JDK Proxy 和 CGLIB。 JDK ProxyJDK Proxy 是 Java 标准库提供的一种基于接口的动态代理实现方式，适用于被代理对象实现了接口的情况。JDK Proxy 的工作原理如下： 接口实现：JDK Proxy 要求被代理对象必须实现一个或多个接口。代理对象会实现相同的接口，并在运行时生成具体的实现类。 InvocationHandler：JDK Proxy 通过 InvocationHandler 接口来定义代理对象的行为。InvocationHandler 接口包含一个 invoke 方法，该方法会在代理对象的每个方法调用时被触发。 生成代理对象：通过 Proxy.newProxyInstance 方法，可以在运行时生成代理对象。该方法需要传入类加载器、接口数组和 InvocationHandler 实例。 示例代码 CGLIBCGLIB（Code Generation Library）是一种基于字节码生成的动态代理技术，适用于被代理对象没有实现接口的情况。CGLIB 的工作原理如下： 字节码生成：CGLIB 通过生成被代理类的子类来实现代理。生成的子类会覆盖被代理类的所有非 final 方法，并在方法调用前后插入额外的逻辑。 MethodInterceptor：CGLIB 通过 MethodInterceptor 接口来定义代理对象的行为。MethodInterceptor 接口包含一个 intercept 方法，该方法会在代理对象的每个方法调用时被触发。 生成代理对象：通过 Enhancer 类，可以在运行时生成代理对象。Enhancer 类需要传入被代理类的类型和 MethodInterceptor 实例。 示例代码 Spring AOP 的选择策略Spring AOP 在选择使用 JDK Proxy 还是 CGLIB 时，遵循以下策略： JDK Proxy：如果被代理对象实现了接口，Spring AOP 默认使用 JDK Proxy。这是因为 JDK Proxy 是 Java 标准库的一部分，具有更好的兼容性和性能。 CGLIB：如果被代理对象没有实现接口，或者在配置中显式指定了使用 CGLIB，Spring AOP 会使用 CGLIB。CGLIB 适用于需要代理具体类的情况，但需要注意的是，CGLIB 生成的代理类是目标类的子类，因此目标类不能是 final 的。 动态代理与静态代理的区别代理模式是一种常用的设计模式，其目的是为其他类提供一个代理来控制对某个对象的访问，从而将两个类的关系解耦。代理类和实现类通常需要实现相同的接口，最终调用的方法是委托类的方法。代理模式可以分为静态代理和动态代理两种类型，它们在实现方式和应用场景上存在显著差异。 静态代理静态代理是指在代码编译时就已经确定好了被代理对象的代理方式。静态代理通常由程序员或特定工具手动创建，代理类和被代理类之间的关系在编译时就已经固定。 编译时确定：静态代理在编译时就已经确定了代理类和被代理类的关系，代理类和被代理类都需要实现相同的接口。 单一性：静态代理通常只代理一个具体的类，每个代理类都需要为每个被代理类单独编写。 代码冗余：由于每个代理类都需要为每个被代理类单独编写，静态代理可能会导致代码冗余，尤其是在需要代理多个类时。 动态代理动态代理是指在程序运行期间，通过反射机制动态生成的代理方式。动态代理的对象通常会有多个实现类，代理类和被代理类之间的关系在运行时才确定。 运行时生成：动态代理在运行时通过反射机制动态生成代理类，代理类和被代理类之间的关系在运行时才确定。 灵活性：动态代理可以代理多个类，甚至可以代理没有实现接口的类（如使用 CGLIB）。 减少代码冗余：由于动态代理在运行时生成代理类，可以减少代码冗余，尤其是在需要代理多个类时。 示例代码（JDK Proxy） 区别总结 特性 静态代理 动态代理 生成时机 编译时 运行时 代理对象数量 通常只代理一个类 可以代理多个类 代码冗余 较高，每个代理类都需要单独编写 较低，动态生成代理类 实现方式 手动编写代理类 通过反射机制动态生成代理类 适用场景 代理对象较少，且关系固定 代理对象较多，且关系灵活 AOP 实现常见注解在 Spring AOP 中，注解是定义切面（Aspect）和通知（Advice）的重要方式。通过注解，可以方便地指定切点（Pointcut）、通知类型以及通知的执行时机。以下是 Spring AOP 中常见的注解及其作用： 1. @Aspect @Aspect 注解用于定义一个切面类。切面类中包含了切点和通知的定义，Spring AOP 会根据这些定义在运行时生成代理对象。 @Pointcut @Pointcut 注解用于定义切点，即指定哪些连接点（Join Point）会被应用通知。切点表达式可以使用通配符、逻辑运算符等来匹配方法。 @Before @Before 注解用于定义前置通知，即在目标方法执行之前执行的通知。前置通知通常用于在方法执行前进行一些准备工作，如日志记录、参数校验等。 @After @After 注解用于定义后置通知，即在目标方法执行之后（无论是否抛出异常）执行的通知。后置通知通常用于在方法执行后进行一些清理工作，如资源释放、日志记录等。 @Around @Around 注解用于定义环绕通知，即在目标方法执行前后都执行的通知。环绕通知可以完全控制目标方法的执行，包括是否执行目标方法、如何执行目标方法等。 @AfterReturning @AfterReturning 注解用于定义返回后通知，即在目标方法正常返回结果后执行的通知。返回后通知可以访问目标方法的返回值。 @AfterThrowing @AfterThrowing 注解用于定义异常通知，即在目标方法抛出异常后执行的通知。异常通知可以访问抛出的异常对象。 @Advice @Advice 注解是一个通用的通知类型注解，用于定义通知的类型。通常情况下，Spring AOP 提供了更具体的通知类型注解（如 @Before、@After 等），因此 @Advice 注解较少直接使用。 通过使用这些注解，可以方便地在 Spring AOP 中定义切面和通知，实现横切关注点的分离。以下是这些注解的简要总结： 注解 作用 @Aspect 定义切面类 @Pointcut 定义切点，指定连接点 @Before 前置通知，在目标方法执行前执行 @After 后置通知，在目标方法执行后（无论是否异常）执行 @Around 环绕通知，在目标方法执行前后都执行 @AfterReturning 返回后通知，在目标方法正常返回后执行 @AfterThrowing 异常通知，在目标方法抛出异常后执行 @Advice 通用通知类型，较少直接使用 反射的特性及其应用场景特性反射（Reflection）是 Java 语言提供的一种强大的机制，允许程序在运行时检查和操作类、方法、字段等结构信息。反射的主要特性包括： 运行时类信息访问：反射可以在运行时获取类的所有结构信息，包括类名、包名、父类、接口、属性、方法、构造器等。通过反射，可以动态地获取和操作这些信息。 动态对象创建：反射允许在运行时动态地创建对象实例，即使不知道具体的类名。通过 Class.forName() 方法可以加载类，并通过 newInstance() 方法创建对象实例。 方法调用：反射可以调用类的所有方法，包括私有方法。通过 Method 类的 invoke() 方法，可以在运行时调用任意方法。 访问和修改字段值：反射可以访问和修改类的字段值，包括私有字段。通过 Field 类的 get() 和 set() 方法，可以在运行时获取和设置字段的值。 应用场景反射在许多框架和库中得到了广泛应用，以下是一些常见的应用场景： 1. Spring 框架中的依赖注入（DI）和控制反转（IoC）Spring 框架通过使用反射机制来实现其核心特性：依赖注入（Dependency Injection, DI）和控制反转（Inversion of Control, IoC）。 依赖注入：在 Spring 中，开发者可以通过配置 XML 文件或基于注解的方式声明组件之间的依赖关系。当应用启动时，Spring 容器会扫描这些配置文件和注解，然后利用反射机制来实例化 Bean 对象，并根据配置文件自动装配到依赖中。 控制反转：Spring 通过反射机制实现控制反转，将对象的创建和依赖关系的管理交给容器，而不是由开发者手动管理。 2. 动态代理在需要对现有方法调用进行拦截、日志记录、权限控制或事务管理等应用场景中，反射结合动态代理技术被广泛应用。 动态代理：动态代理允许在运行时生成代理对象，从而在不修改原有代码的情况下，插入额外的逻辑。动态代理通常结合反射机制来实现。 Spring AOP：Spring AOP 允许开发者定义切面（Aspect），将切面逻辑插入到原有的业务逻辑中进行增强，而不需要修改原有的代码。Spring AOP 通过动态代理和反射机制实现。 "},{"title":"Redis-场景理解","date":"2024-09-27T00:54:37.000Z","url":"/2024/09/27/Redis-%E5%9C%BA%E6%99%AF%E7%90%86%E8%A7%A3/","categories":[["数据库&缓存","/categories/%E6%95%B0%E6%8D%AE%E5%BA%93-%E7%BC%93%E5%AD%98/"],["Redis","/categories/%E6%95%B0%E6%8D%AE%E5%BA%93-%E7%BC%93%E5%AD%98/Redis/"]],"content":"Redis 和 MySQL为什么使用RedisRedis 具备高性能和高并发两大特性。 1. 高性能 Redis 以其卓越的性能著称，主要得益于Redis 将数据存储在内存中，而 MySQL 则主要依赖磁盘存储。内存的读写速度远高于磁盘，因此 Redis 能够显著提升数据访问速度。 2. 高并发 Redis 采用单线程模型，避免了多线程竞争带来的锁和上下文切换开销。这种设计使得 Redis 在处理高并发请求时表现出色，其 QPS（每秒查询次数）轻松突破 10 万。此外，Redis 还可以通过部署 Redis 切片集群进一步增加整个系统的吞吐量。 高并发情况等下，Redis+MySQL单点能有多大并发量？ 若命中Redis缓存，4C8G内存配置 ，单点Redis能够达到10wQPS。 若未命中Redis缓存，4C8G内存配置，单点MySQL仅能达到5k左右QPS。 如何保证Redis和MySQL数据缓存一致性问题在分布式系统中，缓存和数据库之间的数据一致性是一个常见的问题。为了保证数据的一致性，通常采用旁路缓存策略，即先更新数据库，再删除缓存。 缓存通过牺牲强一致性来实现高性能，也就是CAP理论中的AP模式。所以，要保持数据的强一致性，就不适合使用缓存。但是，我们可以通过一些缓存方案优化来保证最终一致性。 消息队列方案为了保证缓存删除操作的可靠性，可以引入消息队列，由消费者来完成缓存删除操作。 生产者：在写数据时，将删除缓存的操作发送到消息队列中。 消费者：消费者从消息队列中获取消息，执行缓存删除操作。 如果应用删除缓存失败，可以从消息队列中重新获取消息，再次尝试删除缓存。这就是消息重试机制。 重试删除缓存机制总体可用，但可能造成业务代码入侵（业务代码入侵（Business Code Invasion）是指在业务逻辑代码中嵌入了与业务逻辑无关的代码，导致业务代码变得复杂、难以维护，并且增加了系统的耦合度。）。 订阅MySQL binlog，再操作缓存该策略的第一步是更新数据库，当数据库更新成功，会将旧的值存入 binlog 中。于是我们可以通过订阅 binlog 日志，拿到具体要删除的记录，再执行缓存删除。 可以使用开源工具如 Canal 来订阅 MySQL binlog。订阅 MySQL binlog，获取更新操作的记录，以下是示例代码。 本地缓存与 Redis 缓存：性能与应用场景的对比在现代应用开发中，缓存是提升系统性能和响应速度的重要手段。本地缓存和分布式缓存（如 Redis）是两种常见的缓存策略，各自具有独特的优势和适用场景。本文将深入探讨本地缓存和 Redis 缓存的性能特点，并通过对比帮助读者理解它们在不同场景下的应用。 本地缓存本地缓存是指将数据存储在本地程序或服务器上，通常使用内存作为存储介质。本地缓存通过利用内存的高速读写特性，显著提升数据访问速度。 优势 访问速度快：由于数据存储在本地内存中，访问速度极快，适合需要高频访问的数据。 减轻网络压力：本地缓存减少了对外部数据源的依赖，从而减轻了网络带宽的压力。 不足 可扩展性有限：本地缓存通常局限于单个服务器或进程，难以应对大规模分布式系统的需求。 分布式缓存（Redis）分布式缓存是指将数据存储在多个分布式节点上，通过协同工作提升高性能的数据访问服务。Redis 是一种常见的分布式缓存解决方案，通常采用集群的方式进行部署，通过多台服务器分担数据压力。 优势 可扩展性强：可以根据业务需求动态增加或减少集群节点，灵活应对数据量的变化。 数据高一致性：Redis 采用主从同步复制机制，确保数据在多个节点之间保持一致性。 易于维护：分布式缓存通常采用自动化管理方式，降低维护成本，提高运维效率。 不足 访问相对较慢：相比于本地缓存，分布式缓存需要通过网络访问数据，访问速度相对较慢。 网络开销大：分布式缓存依赖网络通信，网络延迟和带宽限制可能影响性能。 应用场景对比本地缓存适用场景 高频访问数据：适合存储频繁访问的热数据，如用户会话、配置信息等。 单机应用：适用于单机或单进程的应用场景，数据量较小且不需要分布式扩展。 Redis 缓存适用场景 大规模分布式系统：适合需要处理海量数据和高并发请求的分布式系统。 数据一致性要求高：适用于需要确保数据一致性的场景，如电商平台的商品库存管理。 动态扩展需求：适用于需要根据业务需求动态调整缓存规模的场景。 Redis 应用场景Redis 是一种基于内存的高性能数据库，凭借其快速的读写速度和丰富的数据结构，广泛应用于各种场景中。本文将详细介绍 Redis 在不同应用场景中的具体用途，并通过实例帮助读者更好地理解其优势。 缓存：缓存是 Redis 最常见的应用场景之一。通过将热门数据存储在内存中，Redis 可以显著提高系统的访问速度，减轻后端数据库的压力。 计数器：Redis 的单线程模式和操作的原子性使其非常适合用于实现计数器和统计功能。常见的应用包括页面访问量统计、用户行为统计等。（常用数据结构String、HyperLogLog） 排行榜：Redis 中的有序集合（Sorted Set，Zset）能够实现对数据的自动排序，非常适合用于排行榜、热门文章等需要排序的应用场景。 分布式锁：在分布式系统中，为了避免多个进程同时操作同一资源，可以使用 Redis 实现分布式锁。常见的应用包括资源访问控制、任务调度等。 消息队列：Redis 的发布和订阅功能（Pub&#x2F;Sub）使其可以作为一个轻量级的消息队列系统。常见的应用包括异步任务处理、事件通知等。（常用数据结构List、Stream） Redis 实现消息队列使用Pub&#x2F;Sub模式Redis 的 Pub&#x2F;Sub 模式是一种基于发布者&#x2F;订阅者的模式。任何客户端都可以订阅一个或多个频道，发布者可以向特定频道发布消息，所有订阅了该频道的订阅者都会收到消息。发布者和订阅者完全解耦，并且支持模式匹配。但是这种方式并不支持持久化，也就是说当发布者将消息发布后，若此时无订阅者，消息就会丢失。 示例： 发布者（Publisher） 订阅者（Subscriber） 使用List使用 List 实现消息队列是一种简单且高效的方式。生产者使用 LPUSH 命令将消息添加到 List 的队尾，消费者使用 BLPOP 或 BRPOP 命令阻塞地从队首取出消息进行消费（先进先出，FIFO）。这种方式可以结合Redis的过期时间特性实现消息的TTL，通过Redis事务可以保证操作的原子性，但需要客户端自己实现消息确认、消息重试机制。 生产者（Producer） 消费者（Consumer） 使用 Stream（Redis 5.0 后）Redis Stream 是 Redis 5.0 引入的一种新的数据结构，专门用于实现消息队列。Stream 提供了更强大的功能，如消息持久化、消费者组、消息确认等。 生产者（Producer） 消费者（Consumer） Redis 实现分布式锁详解在分布式系统中，为了避免多个进程同时操作同一资源，分布式锁是一种常用的解决方案。Redis 提供了多种实现分布式锁的方式，本文将详细介绍基于 SET 命令的争抢锁机制和 RedLock 算法，并通过代码示例帮助读者更好地理解其应用。 Redis 分布式锁实现原理分布式锁是分布式并发状态下的一种机制，用于控制一个资源在一个时间内，只有一个应用能对其进行使用。 Redis本身可以被多个客户端进行访问，就像一个共享存储，可以用来保存分布式锁。Redis 的 SET 命令参数 NX 表示只有在键不存在时才设置，具有互斥性，非常适合用来构建分布式锁： 若key存在，证明被加过锁了，所以此时可以认为加锁失败。 若key不存在，证明未被加锁，可以认为加锁成功。 基于Redis节点实现分布式锁，对于加锁条件，我们需要满足三个条件： 原子性：加锁操作涉及多个操作（读取锁变量、检查锁变量、设置锁变量），需要保证这些操作的原子性。 过期时间：锁变量需要设置过期时间，避免客户端获得锁后挂掉，锁一直不释放造成死锁。 唯一性：锁变量的值需要能区分是哪个客户端设置的锁，避免在释放锁时造成误释放操作。 基于 SET 命令的争抢锁机制Redis 提供了 SET 命令的扩展参数，可以用于实现分布式锁。通过 SET resource_name lock_value NX PX milliseconds 命令，客户端可以尝试获取锁。其中： NX：表示只有当键值不存在时才设置。 PX milliseconds：指定锁的过期时间（毫秒）。 如果设置成功，则认为当前客户端获得了锁。当客户端完成操作后，需要删除锁，这里涉及两个以上的操作（判断锁是否属于自己、删除锁），因此可以使用 Lua 脚本来保证 Redis 命令的原子性。 示例代码： 注意事项 锁的过期时间：设置合理的锁过期时间，避免锁长时间占用资源。 锁的唯一性：确保锁的值是唯一的，通常使用 UUID 或其他唯一标识符。 Lua 脚本：使用 Lua 脚本保证释放锁操作的原子性。 RedLock 算法RedLock 算法是 Redis 官方推荐的分布式锁实现方式，适用于需要高可用性和容错性的场景。RedLock 算法通过在多个独立的 Redis 实例上获取锁，并确保大多数实例（超过半数）成功获取锁，来实现分布式锁。 算法步骤 获取当前时间：记录当前时间戳。 尝试获取锁：在每个 Redis 实例上尝试获取锁，使用相同的键和随机值。 计算获取锁的时间：计算从开始获取锁到所有实例返回结果的时间。 判断锁是否获取成功：如果大多数实例（超过半数）成功获取锁，并且获取锁的时间小于锁的有效期，则认为锁获取成功。 释放锁：在所有实例上释放锁。 代码示例： 注意事项 多数原则：确保大多数实例（超过半数）成功获取锁。 时间同步：各个 Redis 实例的时间需要同步，避免时间差异导致锁失效。 故障处理：处理 Redis 实例故障的情况，确保锁的可靠性。 Redis KeyRedis 大 Key 问题在 Redis 中，大 Key 问题指的是一个键（Key）对应的值（Value）过大，导致 Redis 处理起来缓慢、内存不足、影响主从同步延迟等问题。 大地多大算大Key？这是没有标准的，通常认为字符串类型的key对应的value值空间占用超过了1M，或者集合中key对应的元素个数超过了1w，我们就认为该key是大key。 大 Key 问题的缺点 内存占用较高：大 Key 会占用大量的内存，导致 Redis 可用内存减少。Redis 是一个内存数据库，内存是其主要资源。如果内存被大 Key 占用过多，可能会导致内存不足，触发内存淘汰策略，影响其他键的访问。 降低性能：当对大 Key 进行处理时，会花费更多的 CPU 时间，导致整体性能下降，甚至会阻塞其他客户端的请求。大 Key 的读取、写入、删除等操作都会消耗更多的 CPU 资源，影响 Redis 的响应速度。 网络拥塞：大 Key 在网络传输时会占用大量带宽，可能导致网络拥塞。特别是在高并发场景下，大量请求传输大 Key 会导致网络资源被耗尽，影响其他请求的传输。假设有一个大 Key image:12345，对应的值是一个 1MB 的图片数据。如果有 1000 个请求同时传输这个大 Key，会占用 1000MB 的网络带宽，导致网络拥塞。 主从复制延迟：大 Key 在主从复制时需要传输大量数据，可能导致主从复制延迟，影响数据一致性。特别是在主从节点之间网络带宽有限的情况下，大 Key 的传输会占用大量带宽，导致复制延迟。 数据倾斜：一个大 Key 会造成单个切片节点使用了很大一部分内存，导致内存使用率远超其他切片节点。这种数据倾斜会导致集群中某些节点负载过重，影响整体性能。 如何解决大 Key 问题 大Key拆分：将数万成员的大 Key 拆分为更小的分散的 Key，可以有效减少单个键的内存占用，提高 Redis 的处理效率。。 内存清理：将大 Key 转移到其他存储介质（如文件系统、数据库等），然后释放 Redis 中的 Key，避免占用内存空间。（要使用异步删除） 内存阈值监控：持续监控 Redis 的内存使用率，当发现内存用量到达阈值时或内存使用率突然大幅提升时，对内存进行相应的处理，比如删除不需要的 Key。。 定期删除：定时对过期的 Key 进行删除，避免持续堆积而产生大 Key。 热Key什么是热key热 Key 是指那些被频繁访问的键（Key），其请求频率远高于其他键。热 Key 问题会导致 Redis 的性能瓶颈，影响整体系统的响应速度。 QPS 请求集中在特定 Key：假设 Redis 有 10,000 的 QPS（每秒查询次数），而某个 Key 被请求的频率达到 7,000 QPS。 带宽使用率集中在特定的 Key：某个 Key 的传输数据量占用了大量网络带宽。 CPU 使用时间集中在特定的 Key：某个 Key 的处理占用了大量 CPU 时间。 热 Key 的影响 性能瓶颈：热 Key 会导致 Redis 的性能瓶颈，影响整体系统的响应速度。 资源浪费：热 Key 会占用大量 CPU、内存和网络资源，导致其他请求的资源不足。 如何解决热key 负载均衡：由于 Redis 切片集群中，Key 的迁移粒度问题，无法将热 Key 迁移到其他节点分散单点压力。此时可以将热 Key 复制多几份，重新命名后装配到其他节点，并将热 Key 的请求分散到这些分散的节点中，以此降低单点压力。 缓存预热：在系统启动时，提前加载热 Key 的数据到缓存中，避免系统启动后瞬间的高并发请求导致热 Key 问题。 三大缓存问题详解在分布式系统中，缓存是提升系统性能的重要手段。然而，缓存也会带来一些问题，如缓存雪崩、缓存击穿和缓存穿透。 缓存雪崩缓存雪崩是指，在高并发场景下，同一时间内大量 Key 过期，或者 Redis 节点故障，导致大量的数据请求冲向数据库服务器，数据库可能会因无法承受大量数据请求而宕机。 对于大量key同时过期造成的缓存雪崩，我们可以设置以下方案解决： 均匀key过期时间：对于同一时间大量 Key 过期而产生的缓存雪崩，可以设置随机的过期时间，避免大量 Key 在同一时间失效。通过在基础过期时间上增加一个随机值，可以有效分散 Key 的过期时间，避免集中失效。 不设置 Key 过期时间：若业务场景可能长期需要该 Key，那么可以不设置过期时间，待业务活动过期后手动将 Key 删除。这种方式适用于那些长期有效的数据，避免频繁的缓存重建。 互斥锁：当业务线程发现该 Key 不在缓存中，就设置一个互斥锁，保证同一时间只有一个线程在处理缓存，避免在失效期间大量线程同一时间读数据库写缓存。通过互斥锁，可以有效控制缓存重建的并发度，减少数据库压力。 缓存击穿缓存击穿是指，在高并发场景下，某个热点 Key 在缓存中过期，导致大量请求直接访问数据库，导致数据库压力骤增，甚至宕机。 对于缓存击穿，我们也可以使用应对缓存雪崩中采取的两个方案： 互斥锁：使用互斥锁，保证同一时间只有一个线程访问数据库，其他线程等待缓存更新。通过互斥锁，可以有效控制缓存重建的并发度，减少数据库压力。 热点数据永不过期：对于热点数据，可以设置永不过期，或者设置较长的过期时间。这种方式适用于那些长期有效的数据，避免频繁的缓存重建。 后台异步更新：保持热点 Key 持续在线，由后台异步更新缓存。或者在 Key 即将过期时通知后台线程，重新设置过期时间。这种方式可以避免缓存过期瞬间的大量请求冲击数据库。 缓存穿透缓存穿透是指，在高并发场景下，请求的数据在缓存和数据库中都不存在，导致每次请求都直接访问数据库，导致数据库压力骤增，甚至宕机。 对于缓存穿透，我们可以采取以下方案： 限制非法请求：当有恶意的请求故意查询一条不存在的数据，大量的恶意请求也会导致缓存穿透问题。由此我们需要判断请求参数是否合理，过滤掉非法的数据请求。通过参数校验和请求过滤，可以有效减少非法请求对数据库的冲击。 缓存空值或默认值：当我们发现环境中存在缓存穿透现象时，可以为不存在的数据设置为空值或默认值，当缓存中存在有值就不需要向数据库发起大量的请求了。通过缓存空值或默认值，可以避免大量请求直接访问数据库。 布隆过滤器：我们可以在写入数据库时，使用布隆过滤器做标记，然后再请求到来时先判断缓存中是否存在该数据，若不存在则通过布隆过滤器快速判断要请求的数据是否存在。若判断存在，则数据可能存在，可以进一步向数据库查询；若判断不存在，则一定不存在，直接返回。通过布隆过滤器，可以快速过滤掉不存在的数据请求，减少数据库压力，Redis本身也实现了布隆过滤器。 布隆过滤器原理布隆过滤器是一种空间效率很高的概率型数据结构，用于判断一个元素是否在一个集合中。它由“初始值都为0的位图数组”和“n个哈希函数”两部分组成。布隆过滤器通过哈希计算来判断数据是否存在，具有高效的查询速度和较低的空间占用，但存在一定的误判率。当我们在写入数据库的时候，会在布隆过滤器中设置标记，证明该数据在数据库中存在，这样下次查询的时候直接先通过布隆过滤器就能判断出该数据在数据库中是否存在而不需要进一步查询数据库。 布隆过滤器会通过3个操作完成标记： 哈希计算：使用n个哈希函数对数据进行哈希计算，得到n个哈希值。 取模操作：将n个哈希值分别对位图数组的长度取模，得到每个哈希值在位图数组中相对应的位置。 设置标记：将每个哈希值在位图数组中相应的位置设置为1。 举个例子，假设有一个长度为5的位图数组、哈希函数有2个的布隆过滤器。 将数据x写入数据库后，会对数据x进行哈希计算，得到n个哈希值；再将得到的哈希值取模，也就得到了一堆数字结果，对应布隆过滤器中位图数组的位置；将这些位置设为1.下次要判断x是否存在于数据库中时，只需要对x进行哈希计算，查看对应位图数组上相应的位置是不是全都为1，如果全都是1，则认为数据可能存在于数据库中，可以继续下一步查询；否则，认为数据一定不存在。 布隆过滤器通过哈希计算来判断数据是否存在，必然存在哈希冲突，可能会有两个不同的数据计算出同样的哈希值，造成误判。具体来说： 误判情况：布隆过滤器认为数据存在，但实际上数据可能不存在。这种情况称为“假阳性”（False Positive）。 正确情况：布隆过滤器认为数据不存在，则数据一定不存在。这种情况称为“真阴性”（True Negative）。 所以，布隆过滤器认为该数据存在，则其可能存在；若认为数据不存在，则一定不存在。 Redis 应用设计如何设计秒杀场景处理高并发以及超卖现象？秒杀场景是一种典型的高并发场景，通常涉及大量用户在短时间内对有限数量的商品进行抢购。为了应对高并发和避免超卖现象，需要从数据库层面、分布式锁、分段锁以及 Redis 和异步队列等多个方面进行设计和优化。 数据库层面 查询商品库存时加排他锁 在查询商品库存时，可以使用数据库的排他锁（FOR UPDATE）来保证数据的一致性。 在事务中，线程 A 通过该语句给 id 为 ? 的数据行上了一个行级的排他锁。此时在事务期间，其他线程对该行的 UPDATE 和 DELETE 操作都将被阻塞，直到事务提交或发生回滚释放锁。 更新数据库减库存时进行库存限制 在更新数据库减库存时，可以通过条件判断来避免超卖现象。 这种通过数据库加锁来解决的方案，性能不是很好，在高并发的情况下可能会因为获取不到数据库的连接或超时等待报错。 利用分布式锁分布式锁可以保证在同一时间内只有一个客户端能获取到锁，获得锁的线程才能进行接下来的业务逻辑，而其他客户端获取不到锁只能无限循环尝试获取锁。 可以使用 Redis 的 SETNX 命令来实现分布式锁。 在高并发状态下，分布式锁只能进行串行化处理，效率很低。比如大量用户对同一个热门商品下单，此时只能一个个处理下单操作，效率很慢。 利用分布式锁 + 分段锁把数据分成很多段，每一段加上一个单独的锁，细粒度化，使得线程在对一段数据进行修改时，其他线程可以继续对剩下部分进行加锁操作。 假设商品库存分为多个段，每个段使用独立的锁。 通过分段锁，可以提高并发处理能力，减少锁的竞争，提升系统的吞吐量。 利用 Redis 的 INCR、DECR 的原子性 + 异步队列 系统初始化时加载库存到 Redis 在系统初始化时，将商品的库存数量加载到 Redis 中。 接收到秒杀请求时预减库存 接收到秒杀请求时，在 Redis 中进行预减库存（利用 Redis DECR 的原子性），当 Redis 的库存不足时直接返回秒杀失败，否则继续进行第三步。 3, 将请求放入异步队列 将请求放入异步队列中，返回正在排队中。 服务端异步队列请求出队 服务端异步队列请求出队（可以出队的情况根据业务来判定，比如判断是否已秒杀过，防重复秒杀），出队的请求可以生成秒杀订单，减少数据库存。 客户端轮询查看秒杀结果 用户在客户端申请完秒杀后，进行轮询，查看是否秒杀成功，秒杀成功则进入秒杀订单详情，否则秒杀失败。 由于使用了异步队列写入数据库，可能存在数据不一致问题，其次引用多个组件，复杂度比较高。"},{"title":"Redis-集群","date":"2024-09-27T00:54:36.000Z","url":"/2024/09/27/Redis-%E9%9B%86%E7%BE%A4/","tags":[["集群","/tags/%E9%9B%86%E7%BE%A4/"]],"categories":[["数据库&缓存","/categories/%E6%95%B0%E6%8D%AE%E5%BA%93-%E7%BC%93%E5%AD%98/"],["Redis","/categories/%E6%95%B0%E6%8D%AE%E5%BA%93-%E7%BC%93%E5%AD%98/Redis/"]],"content":"Redis主从同步机制详解完全同步在Redis的主从复制（Replication）机制中，完全同步（Full Synchronization）是一个关键过程，它确保从节点（Replica）能够获取主节点（Master）的完整数据集。完全同步通常发生在以下几种情况： 初次同步：当一个从节点首次连接到主节点时，它需要获取主节点的完整数据集。这是因为在初次连接时，从节点没有任何数据，因此需要进行一次完全同步。 从节点数据丢失：如果从节点由于系统崩溃、故障断电等原因导致数据丢失，它将无法继续提供服务。此时，从节点会向主节点发起完全同步请求，以恢复数据。 数据差异过大：在某些情况下，从节点可能长时间未与主节点进行同步，导致两者之间的数据差异过大。当差异超出预设的阈值时，从节点会主动发起完全同步请求，以确保数据的一致性。 完全同步的三阶段主从服务器之间的完全同步过程可以分为三个主要阶段： 建立连接与协商同步：主节点和从节点之间首先建立网络连接。从节点发送PSYNC命令（在Redis 2.8及以上版本中使用），请求与主节点进行同步。主节点响应FULLRESYNC命令，表示将进行完全同步，并提供一个唯一的同步ID（Replication ID）和当前的偏移量（Offset）。 主节点发送完全同步数据：主节点接收到从节点的同步请求后，会生成一个RDB快照文件。这个快照文件包含了主节点当前的所有数据。主节点将生成的RDB文件发送给从节点。 主节点发送新写命令：在RDB文件生成和传输期间，主节点会将所有新的写操作命令记录到一个称为replication backlog buffer的缓冲区中。当RDB文件传输完成后，主节点会将replication backlog buffer中的所有写操作命令发送给从节点。从节点接收到这些命令后，会依次执行这些命令，从而与主节点的数据保持一致。 实现过程详解这里参考一张小林哥的图： 主节点发送SYNC命令：在Redis 2.8之前的版本中，主节点会发送SYNC命令来启动同步过程。而在Redis 2.8及以上版本中，主节点会发送PSYNC命令，该命令支持部分重同步（Partial Resynchronization），但在初次同步时，仍然会执行完全同步。 生成RDB文件：主节点接收到从节点的同步请求后，会调用BGSAVE命令生成一个RDB快照文件。这个过程是异步的，主节点会在后台生成快照，同时继续处理客户端的请求。RDB文件生成完成后，主节点会将文件发送给从节点。 传输RDB文件：主节点通过网络将生成的RDB文件传输给从节点。传输过程中，主节点会继续记录新的写操作命令到replication backlog buffer中。从节点接收到RDB文件后，会将其加载到内存中，并应用其中的数据。 主节点记录写操作：在RDB文件生成和传输期间，主节点会将所有新的写操作命令记录到replication backlog buffer中。这个缓冲区的大小是有限的，通常为1MB，因此在高写入负载下，缓冲区可能会被填满。 传输新写命令：当RDB文件传输完成后，主节点会将replication backlog buffer中的所有写操作命令发送给从节点。从节点接收到这些命令后，会依次执行这些命令，从而与主节点的数据保持一致。 增量同步在Redis的主从复制机制中，增量同步（Partial Resynchronization）是一种高效的同步方式，它允许从节点（Replica）在网络恢复后，仅同步自上次同步以来主节点（Master）新增的数据，而不需要进行完整的完全同步（Full Synchronization）。增量同步基于PSYNC命令，并依赖于运行ID（run ID）和复制偏移量（offset）来实现。 增量同步的步骤还是借用小林哥的图： 增量同步的过程主要包括以下三个步骤： 从节点恢复网络并发送PSYNC命令：当从节点恢复网络连接后，它会向主节点发送PSYNC命令，请求进行增量同步。此时，PSYNC命令中的offset参数不再是-1，而是从节点上次同步时的复制偏移量。 主节点响应CONTINUE命令：主节点接收到从节点的PSYNC命令后，会检查从节点提供的复制偏移量是否在repl_backlog_buffer缓冲区中。如果存在，主节点会响应CONTINUE命令，表示接下来将进行增量同步。 主节点发送增量数据：主节点将从节点断线期间收到的所有写操作命令发送给从节点。从节点接收到这些命令后，会依次执行这些命令，从而与主节点的数据保持一致。 增量数据的来源主节点如何知道从节点缺少的是哪些增量数据呢？这主要依赖于两个关键组件： repl_backlog_buffer缓冲区：这是一个环形缓冲区，用于存储主节点近期传播的写操作命令。当从节点断连后，主节点可以通过这个缓冲区找到从节点缺失的数据。 **replication offset**：这是一个标记，用于记录主从节点各自的同步进度。主节点使用master_repl_offset来记录自己写到的位置，从节点使用slave_repl_offset来记录自己读到的位置。 repl_backlog_buffer缓冲区的写入时机在主节点传播命令时，它会将写操作命令发送给从节点的同时，也会将这些命令写入到repl_backlog_buffer缓冲区中。因此，repl_backlog_buffer缓冲区中存放了近期传播的写操作命令。 增量同步的判断条件当从节点断连后重新发起同步请求时，它会将自己的slave_repl_offset发送给主节点。主节点会根据master_repl_offset比较二者之间的数据差距，并判断是否可以进行增量同步。具体判断条件如下： 增量同步：如果从节点索要读取的数据还在repl_backlog_buffer缓冲区中（即主从节点的偏移量之差没有超过缓冲区的长度，可以抽象为没有被“套圈”），则采用增量同步方式。 完全同步：如果从节点索要的数据已经不在repl_backlog_buffer缓冲区中，说明落后数据太大，中间已有写操作缺失。为保证数据一致性，需要进行完全同步。 repl_backlog_buffer缓冲区的大小与调整repl_backlog_buffer缓冲区的默认大小是1MB，并且由于它是一个环形缓冲区，当缓冲区写满后，主节点继续写入的话，就会覆盖之前的数据。因此，当主节点的写入速度远超于从节点的读取速度时，缓冲区的数据很快就会被覆盖。 为了避免在网络恢复时频繁地使用完全同步的方式，我们应该调整repl_backlog_buffer缓冲区的大小，尽可能地大一些，以减少从节点要读取的数据被覆盖的概率，从而使得主节点能够更多地采用增量同步的方式。 扩展：Redis集群和主从同步能保证数据一致性吗？在分布式系统中，数据一致性是一个关键问题。Redis作为一个高性能的内存数据库，其主从复制和集群模式在设计上遵循了CAP理论中的AP模型，即保证高可用性（Availability）和分区容错性（Partition Tolerance），而牺牲了强一致性（Consistency）。也就是说，在网络分区的情况下，Redis能够保证服务的可用性，但可能会出现部分节点间数据不一致的情况。 Redis 哨兵机制原理在Redis的主从架构中，主节点（Master）负责处理所有的写操作，而从节点（Replica）则负责处理读操作。这种读写分离的架构在大多数情况下能够提供良好的性能和扩展性。然而，当主节点发生故障时，整个系统将无法处理写请求，从而导致服务中断。为了解决这个问题，Redis在2.8版本之后引入了哨兵机制（Sentinel），用于实现主从节点的故障转移。 哨兵机制的作用哨兵机制的主要作用是实现主从节点的故障转移，确保在主节点发生故障时，系统能够自动选举出一个新的主节点，并通知其他从节点和客户端更新配置，从而保证服务的连续性和高可用性。 哨兵节点的角色哨兵节点是一个运行在特殊状态下的Redis进程，它充当观察者的角色，主要负责监控主从节点的状态。哨兵节点通过以下三个主要动作来实现故障转移： 观察（Monitoring）： 哨兵节点会定期向主节点和从节点发送心跳检测（PING）命令，以确认它们的状态。 如果主节点在一定时间内没有响应，哨兵节点会认为主节点发生了故障。 选举（Election）： 当哨兵节点检测到主节点故障时，它会与其他哨兵节点进行协商，选举出一个新的主节点。 选举过程遵循Raft算法或类似的分布式一致性算法，确保选举结果的一致性和可靠性。 通知（Notification）： 一旦新的主节点被选举出来，哨兵节点会通知其他从节点更新配置，指向新的主节点。 同时，哨兵节点还会通知客户端新的主节点的信息，以便客户端能够继续发送写请求。 哨兵机制算法流程当Redis集群的主节点发生故障时，Sentinel机制将启动故障转移流程，从剩余的从节点中选举出一个新的主节点。这个过程主要分为四个步骤：故障节点主观下线、故障节点客观下线、Sentinel集群选举Leader、Sentinel Leader决定新主节点。 故障节点主观下线Sentinel集群中的每一个Sentinel节点会定时对Redis节点发送心跳检测包（PING），以检测节点是否正常运行。如果在down-after-milliseconds时间内，Redis节点没有回复Sentinel节点的心跳包，该Sentinel节点就会认为该节点主观下线（Subjectively Down, SDOWN）。 故障节点客观下线当一个Sentinel节点认为某个Redis节点主观下线时，它无法单独证明该节点确实下线了。因此，Sentinel节点会询问其他Sentinel节点，共同判断该节点是否客观下线（Objectively Down, ODOWN）。 如果Sentinel集群中超过quorum数量的节点认为该Redis节点下线了，则该Redis节点客观下线。 若客观下线的是从节点，则检测到此结束，不会进行下一步了；若该节点是主节点，则需要进行接下来的故障转移。 Sentinel集群选举Leader在决定新的主节点之前，Sentinel集群需要先选举出一个Sentinel Leader，代表Sentinel集群进行决策。每个Sentinel节点都有机会成为Leader。 每个Sentinel节点够可以变成Leader，在判定主节点主观下线后，节点会向Sentinel其他节点发送请求，将自己选举为Leader。被请求的节点如果没有为其他Sentinel节点投过票，则发起请求的节点票数+1，否则不增加票数。 如果一个Sentinel节点获得的票数达到Leader的最低票数（max(quorum, Sentinel集群节点数/2 + 1)），则该节点变成leader，否则重新选举。 Sentinel Leader决定新主节点Sentinel集群选举出Leader后，由Leader决定哪个从节点成为新的主节点。选择新主节点的过程遵循以下优先级： 过滤故障节点：首先，过滤掉已经下线的从节点。 选择优先级最高的从节点：选择slave-priority值最大的从节点作为新的主节点。如果存在多个从节点具有相同的优先级，则继续下一步。 选择复制偏移量最大的从节点：选择slave_repl_offset值最大的从节点作为新的主节点。slave_repl_offset表示从节点与主节点的数据同步进度。如果存在多个从节点具有相同的复制偏移量，则继续下一步。 选择runid最小的从节点：选择runid最小的从节点作为新的主节点。runid是Redis节点的唯一标识符。 Redis 切片集群详解随着数据量的增长，单个 Redis 节点的存储容量和性能可能无法满足需求。为了解决这一问题，Redis 提供了切片集群（Redis Cluster）方案。通过将数据分布在多个服务器上，Redis Cluster 不仅降低了单点故障的风险，还显著提升了读写性能。本文将深入探讨 Redis Cluster 的工作原理、优点和缺点，并通过实例帮助读者更好地理解。 Redis Cluster 的工作原理哈希槽（Hash Slots）Redis Cluster 采用哈希槽的方式来管理数据和节点之间的映射关系。一个 Redis Cluster 包含 16384 个哈希槽，这些哈希槽类似于数据分区。每个键值对（key-value pair）都会根据其 key 映射到一个特定的哈希槽中。具体步骤如下： CRC16 哈希算法：首先，Redis 使用 CRC16 算法对键值对的 key 进行计算，得到一个 16 位的值。 哈希槽映射：然后，将这个 16 位的值对 16384 取模，得到一个 0 到 16383 之间的余数。这个余数即为该键值对对应的哈希槽编号。 哈希槽与节点的映射在 Redis Cluster 中，哈希槽需要映射到具体的 Redis 节点上。有两种常见的映射方式： 平均分配：当使用 cluster create 命令创建集群时，Redis 会自动将 16384 个哈希槽平均分配到各个节点中。例如，如果集群中有 5 个节点，每个节点将分配到 16384 &#x2F; 5 ≈ 3276 个哈希槽。 手动分配：在某些情况下，可能需要手动分配哈希槽。可以通过 cluster meet 命令手动建立节点之间的连接，然后使用 cluster addslots 命令为每个节点分配指定的哈希槽数量。例如，可以手动将哈希槽 0 到 5000 分配给节点 A，将 5001 到 10000 分配给节点 B，以此类推。 Redis Cluster 的优缺点优点1. 高可用性：Redis Cluster 通过主从复制（Master-Slave Replication）机制实现了高可用性。每个节点都可以配置一个或多个从节点，主节点负责处理写请求，从节点负责处理读请求。当主节点发生故障时，从节点可以自动接管主节点的角色，确保服务的连续性。 2. 高性能：Redis Cluster 采用数据分片机制，将数据分散到多个节点上，从而降低了单个节点的负载压力。这种分布式架构显著提升了系统的读写性能和吞吐量。 3. 高扩展性：Redis Cluster 支持动态扩展，可以根据需求增加或减少节点。此外，集群模式还可以将某些节点设置为代理节点（Proxy Nodes），自动转发请求，增加了系统的灵活性和可定制性。 缺点1. 部署和同步复杂：Redis Cluster 的部署和维护相对复杂。特别是在大规模集群中，节点之间的同步和数据一致性管理需要特别注意。 2.集群同步问题：在 Redis Cluster 中，节点之间的数据同步是一个关键问题。如果同步不及时或出现错误，可能会导致数据丢失或不一致。 3.数据分片限制：虽然 Redis Cluster 通过数据分片提升了性能，但在某些情况下，数据分片可能会带来一些限制。例如，某些复杂的查询操作可能需要跨多个节点进行，增加了系统的复杂性。"},{"title":"Redis-缓存淘汰与过期删除","date":"2024-09-27T00:54:17.000Z","url":"/2024/09/27/Redis-%E7%BC%93%E5%AD%98%E6%B7%98%E6%B1%B0%E4%B8%8E%E8%BF%87%E6%9C%9F%E5%88%A0%E9%99%A4/","tags":[["策略","/tags/%E7%AD%96%E7%95%A5/"]],"categories":[["数据库&缓存","/categories/%E6%95%B0%E6%8D%AE%E5%BA%93-%E7%BC%93%E5%AD%98/"],["Redis","/categories/%E6%95%B0%E6%8D%AE%E5%BA%93-%E7%BC%93%E5%AD%98/Redis/"]],"content":"过期删除策略和内存淘汰策略有什么区别？ 过期删除策略是将已过期的键值进行删除，Redis采用的删除策略是惰性删除和定时删除。 内存淘汰策略是在内存满了的时候，redis触发内存淘汰策略，来淘汰一些不必要的内存资源，以腾出空间来保存新的内容。 Redis内存淘汰策略在32位系统中，Redis的maxmemory默认值为3GB，这是因为32位系统最高支持4GB内存，而系统本身需要一定的内存资源来运行。为了避免因内存不足而导致Redis崩溃，设置maxmemory为3GB是一个合理的默认值。 Redis提供了8种内存淘汰策略，这些策略可以根据是否进行数据淘汰分为两类： 1. 不进行数据淘汰 noeviction（Redis 3.0之后默认使用的策略）：当运行内存达到最大内存时，不会淘汰任何数据。如果有新的数据插入，Redis会返回错误。但对于普通的查询或删除操作，Redis可以正常运行。 2. 进行数据淘汰 针对“进行数据淘汰”这一类策略，又可以继续分为“在设置了过期时间的数据中淘汰”和“在所有数据范围内淘汰”两类。 “在设置了过期时间的数据中淘汰”： volatile-random：随机淘汰设置了过期时间的数据。 volatile-ttl：优先淘汰过期时间最早的数据。 volatile-lru（Redis 3.0之前默认使用策略）：淘汰所有设置了过期时间的数据中，最久未使用的键值。 volatile-lfu：淘汰所有设置了过期时间的数据中，最少使用的数据。 “在所有数据范围中进行淘汰”： allkeys-random：随机淘汰任意键值 allkey-lru：淘汰整个键值中最久未使用的键值 allkeys-lfu：淘汰整个键值中最少使用的键值 Redis过期删除策略Redis使用惰性删除和定期删除相结合的过期删除策略，以在CPU使用时间和避免内存空间浪费之间取得平衡。 惰性删除Redis的惰性删除策略由db.c文件中的expireIfNeeded函数实现。惰性删除的核心思想是：在访问或修改key之前，先检查key是否过期，如果过期则删除该key。 以下是expireIfNeeded函数源码： 检查key是否过期：在访问或修改key之前，调用expireIfNeeded函数检查key是否过期。 删除过期key：如果key过期，则根据lazyfree_lazy_expire参数配置，选择异步删除（dbAsyncDelete）或同步删除（dbSyncDelete）。 返回结果：如果key过期并被删除，返回null给客户端；如果key未过期，则正常返回键值对给客户端。 定期删除Redis的定期删除策略是每隔一段时间从内存中随机抽取一定数量的key进行检查，并删除其中过期的key。定期删除的目的是避免内存中积累过多的过期key，从而浪费内存空间。 定期删除的配置 间隔检查时间：默认是1秒检查10次，可以通过redis.conf文件进行配置。 随机抽查数量：在源码中，定期删除的实现在expire.c文件下的activeExpireCycle函数中，其中随机抽查的数量由ACTIVE_EXPIRE_CYCLE_LOOKUPS_PER_LOOP定义，数值是20。 定期删除的流程 随机抽取key：从过期字典中随机抽取20个key。 检查并删除过期key：检查这些key是否已过期，并删除已过期的key。 循环检查：如果本轮已过期的key超过5个，则继续抽取20个key再次进行检查删除，直到不满足该条件，退出。 Redis缓存为什么不过期直接删在Redis中，过期key的删除策略是惰性删除和定期删除相结合的方式。然而，在内存不紧张但CPU紧张的情况下，Redis并不会立即删除过期的key，而是选择延迟删除。这种设计主要是为了在CPU资源紧张的情况下，优先保证业务性能，避免因频繁删除过期key而占用过多的CPU时间。"},{"title":"Redis-事务与日志","date":"2024-09-27T00:53:42.000Z","url":"/2024/09/27/Redis-%E4%BA%8B%E5%8A%A1%E4%B8%8E%E6%97%A5%E5%BF%97/","tags":[["事务","/tags/%E4%BA%8B%E5%8A%A1/"],["日志","/tags/%E6%97%A5%E5%BF%97/"]],"categories":[["数据库&缓存","/categories/%E6%95%B0%E6%8D%AE%E5%BA%93-%E7%BC%93%E5%AD%98/"],["Redis","/categories/%E6%95%B0%E6%8D%AE%E5%BA%93-%E7%BC%93%E5%AD%98/Redis/"]],"content":"事务如何实现Redis原子性Redis在执行单条命令时具有原子性，因为Redis采用单线程模型，所有的命令都在一个主线程中顺序执行，不存在多线程竞争问题。然而，如果需要执行多条命令并保持原子性，Redis提供了Lua脚本功能，可以将多条Redis命令组合成一个整体执行，从而保证操作的原子性。 假设我们有一个分布式系统，多个进程需要访问一个共享资源，我们可以使用以下Lua脚本来实现分布式锁： 在Redis中执行该Lua脚本的命令如下： EVAL：Redis的命令，用于执行Lua脚本。 &quot;local lockKey = KEYS[1]; local lockValue = ARGV[1]; local lockTimeout = tonumber(ARGV[2]); local result = redis.call(&#39;SET&#39;, lockKey, lockValue, &#39;NX&#39;, &#39;EX&#39;, lockTimeout); if result then return 1 else return 0 end&quot;：Lua脚本内容。 1：表示脚本中有一个键（lockKey）。 lockKey、lockValue、lockTimeout：传递给Lua脚本的参数。 Redis事务除了使用Lua脚本，Redis事务也可以保证Redis的原子性。Redis事务通过MULTI、EXEC、DISCARD和WATCH命令来实现。事务可以将多个命令打包成一个整体执行，从而保证这些命令在执行过程中不会被其他命令打断，保证操作的原子性。 Redis事务的命令 **MULTI**：标记一个事务块的开始。 **EXEC**：执行事务块中的所有命令。 **DISCARD**：取消事务，放弃执行事务块中的所有命令。 **WATCH**：监视一个或多个键，如果在事务执行之前这些键被其他命令修改，事务将被中断。 Redis事务的执行流程 开启事务：使用MULTI命令开启一个事务。 添加命令：在事务块中添加多个Redis命令。 执行事务：使用EXEC命令执行事务块中的所有命令。 取消事务（可选）：如果需要取消事务，可以使用DISCARD命令。 假设我们需要执行以下两条命令，并确保它们具有原子性： 将键key1的值设置为value1。 将键key2的值设置为value2。 我们可以使用Redis事务来实现： Redis事务在执行过程中，如果某个命令执行失败，Redis不会进行事务回滚。也就是说，即使某个命令执行失败，事务块中的其他命令仍然会继续执行。 日志Redis的持久化Redis是一个高性能的内存数据库，所有的读写操作都在内存中进行。然而，内存中的数据在系统重启后会丢失，为了确保数据在重启后能够恢复，Redis提供了持久化机制，将数据存储到磁盘中。Redis的持久化主要通过两种机制实现：AOF（Append-Only File）日志和RDB（Redis Database）快照。 Redis的持久化主要通过两种机制： AOF日志：每执行一条操作命令，就把该命令以追加的方式写入日志文件中。 RDB快照：将某一刻的内存数据，以二进制的方式写入磁盘中。 AOF日志实现AOF日志是一种记录Redis操作命令的持久化方式。每当Redis执行一条写操作命令时，该命令会被追加到AOF日志文件中。当Redis重启时，可以通过读取AOF日志文件并逐行执行命令来恢复数据。 Redis提供了三种AOF日志回写硬盘的策略： Always：每执行一条命令后，立即将该命令写入磁盘日志文件中。这种策略保证了数据的实时持久化，但会对性能产生较大影响。 Everysec：每秒将AOF日志文件的内核缓冲区中的数据写入磁盘日志文件。这种策略在性能和数据安全性之间取得了平衡。 No：将命令写入AOF日志的内核缓冲区，由操作系统决定何时将日志写入磁盘日志文件。这种策略性能最高，但数据安全性较低。 RDB快照实现因为AOF日志记录的是命令操作，并非实际的数据。当AOF日志巨大时，Redis在启动中执行一次全量的命令操作，势必造成Redis恢复操作缓慢。为了解决这个问题，Redis增加了RDB快照。 RDB快照是一种记录Redis内存数据状态的持久化方式。RDB快照将某一时刻的内存数据以二进制格式写入磁盘文件中。当Redis重启时，可以通过加载RDB快照文件来快速恢复数据。 Redis提供了两条命令来生成RDB快照文件： save：在主线程中生成RDB快照文件。由于是在主线程中执行，如果快照文件较大，可能会阻塞主线程，影响Redis的性能。 bgsave：创建一个子线程来生成RDB快照文件。这种方式避免了主线程的阻塞，提高了Redis的性能。 "},{"title":"Redis-数据结构","date":"2024-09-27T00:53:09.000Z","url":"/2024/09/27/Redis-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%9E%8B/","tags":[["数据结构","/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"],["线程模型","/tags/%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%9E%8B/"]],"categories":[["数据库&缓存","/categories/%E6%95%B0%E6%8D%AE%E5%BA%93-%E7%BC%93%E5%AD%98/"],["Redis","/categories/%E6%95%B0%E6%8D%AE%E5%BA%93-%E7%BC%93%E5%AD%98/Redis/"]],"content":" 数据结构Redis底层数据结构Redis是一种高性能的非关系型数据库（NoSQL），提供了多种数据类型以满足不同的应用需求。常见的数据类型包括String、List、Hash、Set和Zset。每种数据类型在Redis内部都有特定的底层数据结构来支持其功能和性能特性。 数据类型与底层结构 数据类型 底层结构 存储的值 读写能力 String 简单动态字符串（SDS） 字符串、整数或浮点数 支持原子性的读写操作，适用于计数器、缓存等场景。 List 双向链表或压缩列表（ziplist） 字符串元素的列表 支持高效的插入和删除操作，适用于消息队列、任务队列等。 Hash 哈希表或压缩列表（ziplist） 字段-值对 支持快速的查找、插入和删除操作，适用于存储对象属性。 Set 哈希表或整数集合（intset） 无序、唯一的字符串集合 支持高效的集合运算（交集、并集、差集），适用于标签系统、好友关系等。 Zset 跳表或压缩列表（ziplist） 有序、唯一的字符串集合，每个元素关联一个分数 支持按分数排序的查找、插入和删除操作，适用于排行榜、范围查询等。 而在后续的版本更新中，又增加了新的四种数据结构支持：BitMap（2.2）、HyperLogLog（2.8）、GEO（3.2）、Stream（5.0） redis数据结构常用的场景分别如下： String：不仅存储字符串数据，还维护了字符串的长度和可用空间。适用于存储对象、简单计数器、分布式锁、session等。例如，可以使用INCR命令实现一个简单的计数器，用于统计网站的访问量。 List：使用双向链表来存储数据。适用于消息队列、任务队列等。例如，可以使用LPUSH和RPOP命令实现一个简单的消息队列，用于处理异步任务。 Hash：使用哈希表来存储数据。适用于存储对象属性，如购物车。例如，可以使用HSET和HGET命令存储用户的购物车信息。 Set：高效地进行集合运算（交集、并集、差集）。适用于标签系统、好友关系等。例如，可以使用SINTER命令计算两个用户之间的共同好友。 Zset：使用跳表来存储数据，这样可以高效地进行按分数排序。适用于排行榜、范围查询等。例如，可以使用ZADD和ZRANGE命令实现一个热度榜，用于展示热门文章。 在后续的版本更新中，Redis增加了四种新的数据结构： BitMap（2.2）：用于存放二值计算，如用户签到等。 HyperLogLog（2.8）：用于海量基数统计，比如统计网站的独立访客数。 GEO（3.2）：常用于存放地理位置信息，比如高德地图、滴滴打车。 Stream（5.0）：常用于做详细队列，与List不同的是，Stream会自动生成全局唯一ID，支持消费组形式消费数据。 Zset实现基础了解Zset（有序集合）是Redis中一种非常重要的数据类型，它能够存储有序的字符串集合，并且每个元素都关联一个分数（score），通过分数可以对元素进行排序。Zset的底层实现主要依赖于两种数据结构：跳表（Skip List）和压缩列表（ziplist）。在Redis 7.0及之后的版本中，压缩列表已被弃用，取而代之的是listpack。 在Redis7.0版本之前，Zset数据结构为： 若有序集合的元素小于128，且元素的数据大小小于64字节时，Redis会采用压缩列表作为底层数据结构。 若有序集合不满足以上条件，则采用跳表作为数据结构。 如何使用Zset以某文章热度为例，以下介绍在Redis中如何使用Zset。 使用ZADD添加文章 ZADD命令用于向有序集合中添加一个或多个元素。每个元素都关联一个分数（score），用于排序。 在这个例子中，我们向名为article_hotness的有序集合中添加了三篇文章，初始热度为0。 使用ZINCRBY增加文章热度 ZINCRBY命令用于增加有序集合中某个元素的分数（热度）。 在这个例子中，我们分别增加了三篇文章的热度，article_id_1增加了10，article_id_2增加了20，article_id_3增加了30。 使用ZRANGE和WITHSCORES获取热度前三的文章 ZRANGE命令用于获取有序集合中指定范围内的元素。由于Zset默认是按升序排列的，因此我们需要获取热度最高的三篇文章时，可以使用反转范围来获取。WITHSCORES选项用于同时返回元素的分数。 在这个例子中，我们使用ZREVRANGE命令来获取热度前三的文章及其热度值。 使用ZRANGEBYSCORE找出热度大于500的文章 ZRANGEBYSCORE命令用于获取有序集合中分数在指定范围内的元素。 在这个例子中，我们获取了热度大于500的所有文章及其热度值。 跳表实现链表在查询数据时，需要一个个元素遍历，时间复杂度是O(N)的，查询效率贼低，所以就有了跳表。跳表是在链表的基础上改进的，实现了一种“多层”的有序链表结构，以便于快速定位数据位置。 以上图中头节点有L0~L2三个头指针，分别指向不同层级的节点，每个层级的节点都通过指针连接起来。 L0层有5个节点：1、2、3、4、5 L1层有3个节点：2、3、4 L2层有1个节点：3 跳表的核心思想是通过增加多级索引来加速查找过程。跳表的每一层都是一个有序链表，高层级的节点数量较少，低层级的节点数量较多。通过这种方式，跳表可以在O(log n)的时间复杂度内完成查找操作。 跳表是如何工作的呢？举个例子，假设我们在链表中需要查找33这个数据节点，一个个元素遍历到该节点需要查找6次(1-&gt;5-&gt;11-&gt;20-&gt;27-&gt;33)，加了一层索引后，优化到需要4次(1-&gt;11-&gt;27-x-&gt;50转往下一层节点找27-&gt;33)，以此类推。查找流程示意图如下。 这个查找的过程在链表中跳跃，最后定位到元素，当数据量巨大时，查询的时间复杂度就来到了O(logn)。 那么跳表的节点如何实现多层级的？跳表的节点结构包含以下几个关键部分： 元素值（ele）：存储节点的值，通常是一个字符串（sds类型）。 分数（score）：存储节点的分数，用于排序，通常是一个双精度浮点数（double类型）。 后向指针（backward）：指向前一个节点，方便从跳表的尾节点开始访问，倒序查找时方便。 层级数组（level[]）：包含多个层级的信息，每个层级包含两个信息： 前向节点指针（forward）：指向当前层级的下一个节点。 跨度（span）：表示当前节点到下一个节点之间的跨度，用于计算节点的排名。 以下是跳表节点的C语言数据结构示例： 跟我的刚开始想象不同的是，在跳表中，跨度（Span）并不是固定的步长，而是表示当前节点到下一个节点之间的“距离”。跨度可以是1，也可以是2，不必与上一个节点同层级的跨度一致。跨度的主要作用是帮助计算节点的排名（rank），而不是用于遍历操作。遍历操作只需要通过链表的前向指针（forward）来实现。在这里继续引用小林哥的模拟图： Redis跳表在创建节点时，随机生成每个节点的层数，并没有严格维持相邻两层的节点数量比例为2:1的情况。具体的做法是，跳表在创建节点时，会生成一个范围是[0, 1]的随机数，并根据这个随机数来决定节点的层数。如果随机数小于0.25（选取0.25基于概率和性能考虑），则增加一层，然后生成下一个随机数，直到随机数大于0.25结束。最后，层数越高，概率越低，最高不会超过64层。 Redis 为啥使用跳表而不是B+树？Redis选择跳表（Skip List）而不是B+树（B+ Tree）作为有序集合（Zset）的底层数据结构，主要是基于以下几个方面的考虑：内存占用、对范围查找的支持、实现难易程度。 内存占用更少 B+树：每个节点通常包含两个指针（至少），一个指向左子节点，一个指向右子节点。此外，B+树的叶子节点还需要存储数据，这会占用更多的内存。 跳表：跳表的节点包含一个前向指针和一个跨度（span），平均每个节点包含约1.33个指针（概率期望值，p &#x3D; 0.25）。由于跳表的层数是随机生成的，高层级的节点数量较少，因此总体内存占用较少。 范围查询更简单 B+树：B+树的范围查询需要从根节点开始遍历，找到范围的起始节点，然后沿着叶子节点链表遍历到范围的结束节点。这个过程相对复杂，尤其是在范围较大时。 跳表：跳表的范围查询非常简单。只需要从最高层级开始，逐级向下查找，直到找到范围的起始节点，然后沿着链表遍历到范围的结束节点。由于跳表的层级结构，范围查询的效率非常高。 算法实现难度更简单 B+树：B+树的实现相对复杂，需要维护平衡性，插入和删除操作需要进行复杂的旋转和分裂操作，以保持树的平衡。 跳表：跳表的实现相对简单，插入和删除操作只需要更新指针，不需要进行复杂的平衡操作。跳表的层数是随机生成的，不需要严格维持平衡性，因此实现难度较低。 压缩列表实现压缩列表（ziplist）是Redis为优化内存使用而设计的一种紧凑的顺序存储结构，类似于数组。它通过一系列精心设计的字段来高效地存储和访问数据，特别适用于存储少量数据。 主要字段压缩列表包含以下几个关键字段： zlbytes：记录当前压缩列表总共占用的字节数。这个字段帮助快速计算列表的总大小，无需遍历整个列表。 zltail：记录最后一个节点相对于头节点的偏移量。通过这个字段，可以快速定位到最后一个节点，而不需要从头遍历整个列表。 zllen：记录当前压缩列表中节点的数量。这个字段帮助快速获取列表的长度。 zlend：表示压缩列表的结束位置，通常值为0xff（即十进制的255）。这个字段用于标识列表的结束，类似于C语言中的空字符（’\\0’）。 查找元素在压缩列表中，查找第一个和最后一个元素非常高效，时间复杂度为O(1)。具体来说： 查找第一个元素：直接从列表头开始，时间复杂度为O(1)。 查找最后一个元素：通过zltail字段可以直接计算出最后一个节点的位置，时间复杂度也为O(1)。 然而，查找其他元素则需要遍历列表，时间复杂度为O(n)，其中n是列表中节点的数量。因此，压缩列表并不适合存储大量数据，更适合用于存储少量、频繁访问的数据。 节点结构压缩列表中的每个节点包含以下三个部分： prevlen：记录前一个节点的长度。这个字段使得从后向前遍历列表成为可能，因为可以通过prevlen快速定位到前一个节点。 encoding：记录当前节点实际数据的类型和长度。Redis支持两种主要的数据类型：字符串和整数。encoding字段根据数据类型和大小动态调整，以节省内存。 data：记录当前节点的实际数据。根据encoding字段的不同，data部分可以是字符串或整数。 插入数据当向压缩列表插入数据时，Redis会根据插入数据的类型和大小动态调整prevlen和encoding字段的空间占用。例如： 如果插入的是一个较小的整数，encoding字段可能会使用较少的字节来表示这个整数。 如果插入的是一个较长的字符串，encoding字段可能会使用更多的字节来表示字符串的长度。 这种根据数据类型和大小进行动态空间分配的设计思想，正是Redis为了节省内存而采用的核心策略。 连锁更新问题压缩列表的缺点是会发生“连锁更新”问题，因为连锁更新一旦发生，就会导致压缩列表多次重新分配分配，从而影响直接压缩列表的访问性能。 为什么会发生连锁更新问题？因为当插入或删除节点时，如果前一个节点的长度发生变化，可能会导致后续节点的prevlen字段需要更新，从而引发连锁更新。 在压缩列表中，prevlen字段的长度是动态的，根据前一个节点的长度来决定。例如，如果前一个节点的长度小于254字节，prevlen字段占用1字节；如果大于等于254字节，prevlen字段占用5字节。 Listpack实现尽管quicklist通过控制quicklistnode中元素的大小和数量来缓解压缩列表（ziplist）的性能问题，但它并未完全解决压缩列表中存在的“连锁更新”问题。为了进一步优化，Redis在5.0版本中引入了一个新的数据结构——listpack。 Listpack的特点listpack最大的特点是每个节点不再包含前一个节点的长度信息。这一设计从根本上消除了“连锁更新”问题，从而提高了数据结构的稳定性和性能。 Listpack的头部信息listpack的头部包含两个关键数据： listpack总字节数：记录整个listpack结构占用的总字节数。这个字段帮助快速计算listpack的大小，无需遍历整个结构。 listpack元素数量：记录listpack中包含的元素数量。这个字段帮助快速获取listpack的长度。 Listpack节点的结构listpack中的每个节点包含以下三个部分： encoding：定义该元素的编码类型。encoding字段根据数据类型和大小动态调整，以节省内存。例如，如果数据是一个小整数，encoding字段可能会使用较少的字节来表示这个整数。 data：实际存放的数据。根据encoding字段的不同，data部分可以是字符串或整数。 len：encoding和data的总长度。这个字段记录了当前节点的总字节数，帮助快速计算节点的长度。 假设我们有一个listpack，其中存储了三个节点： 第一个节点存储了一个整数123。 第二个节点存储了一个字符串&quot;hello&quot;。 第三个节点存储了一个整数456。 在这种情况下，listpack的头部会记录整个listpack的总字节数和元素数量。每个节点的encoding字段会根据数据类型（整数或字符串）和数据大小动态调整，而len字段会记录当前节点的总字节数。 例如： 第一个节点的encoding可能是0x01（表示一个小整数），data是123，len可能是2字节。 第二个节点的encoding可能是0x02（表示一个字符串），data是&quot;hello&quot;，len可能是7字节。 第三个节点的encoding可能是0x01（表示一个小整数），data是456，len可能是2字节。 通过这种设计，listpack在存储数据时更加紧凑和高效，同时避免了压缩列表中“连锁更新”的问题（因为已经不会影响其他节点长度字段的变化），从而提高了整体性能和稳定性。 Hash表扩容在Redis中，Hash表的扩容（rehash）是一个关键操作，用于处理Hash表在数据量增加时可能出现的性能问题。然而，传统的rehash过程可能会导致性能瓶颈，特别是在Hash表中数据量非常大的情况下。为了解决这个问题，Redis采用了渐进式rehash机制。 传统rehash的问题在传统的rehash过程中，需要使用两个Hash表： Hash表1：当前正在使用的Hash表。 Hash表2：新建的Hash表，空间大小通常是Hash表1的两倍。 传统rehash的步骤如下： 分配空间：为Hash表2分配空间。 数据迁移：将Hash表1中的所有数据重新分配到Hash表2中。 释放空间：数据迁移完成后，释放Hash表1的空间，并将Hash表2设置为当前使用的Hash表。 这种一次性完成数据迁移的方式存在以下问题： 性能影响：如果Hash表1中的数据量非常大，数据迁移过程需要大量复制操作，可能导致Redis阻塞，影响性能。 阻塞风险：在数据迁移期间，Redis无法处理其他请求，可能导致服务中断。 渐进式rehash为了避免上述问题，Redis采用了渐进式rehash机制。渐进式rehash的核心思想是将数据迁移过程分散到多次操作中，而不是一次性完成。 渐进式rehash的步骤 分配空间：为Hash表2分配空间。 逐步迁移：在rehash期间，每次对Hash表进行增删改查操作时，Redis除了执行这些操作，还会顺序地将索引位置上的所有key-value迁移到Hash表2中。 完成迁移：随着处理客户端发起的Hash表操作越来越多，最终某个时间点会将Hash表1中的所有key-value迁移到Hash表2中，完成rehash操作。 渐进式rehash的优势 避免阻塞：通过将数据迁移分散到多次操作中，避免了在rehash过程中Redis的阻塞，提高了系统的可用性。 平滑过渡：渐进式rehash使得Hash表的扩容过程更加平滑，减少了性能波动。 渐进式rehash期间的Hash表操作在渐进式rehash进行期间，Redis会同时维护两个Hash表（Hash表1和Hash表2）。因此，Hash表的删除、查找、更新等操作会在两个Hash表中进行： 查找操作：先在Hash表1中查找，如果没找到，再在Hash表2中查找。 新增操作：新增的key-value会被保存到Hash表2中，而Hash表1不再进行任何添加操作。 删除和更新操作：同样会在两个Hash表中进行查找和操作。 随着渐进式rehash的进行，Hash表1的key-value数量会逐渐减少，最终变为空表。当所有数据都迁移到Hash表2后，Hash表1会被释放，Hash表2成为当前使用的Hash表。 假设我们有一个Hash表1，其中包含100万个key-value对。当Hash表1需要扩容时，Redis会执行以下步骤： 分配空间：为Hash表2分配空间，大小为Hash表1的两倍。 逐步迁移：在每次对Hash表进行操作时，Redis会逐步将Hash表1中的数据迁移到Hash表2中。例如，每次操作时迁移1000个key-value对。 完成迁移：随着操作的进行，最终所有数据都会迁移到Hash表2中。 通过这种方式，Redis避免了在rehash过程中可能出现的性能瓶颈和阻塞问题，确保了系统的稳定性和性能。 String存储在Redis中，String类型的数据是通过SDS（Simple Dynamic String）数据结构来存储的。SDS是Redis自己实现的一种字符串表示方式，相较于C语言中的字符数组（char[]），SDS提供了更多的功能和优势。 SDS的结构SDS的结构中包含以下几个成员变量： len：记录了字符串的实际长度。这个字段使得获取字符串长度的时间复杂度为O(1)，因为可以直接从len属性读取，而不需要像C语言中的strlen函数那样遍历整个字符数组。 alloc：分配给字符串的空间数组长度。这个字段记录了当前SDS结构中为字符数组分配的总空间大小，用于管理内存分配和释放。 flags：用来表示不同类型的SDS。SDS有多种类型，flags字段用于区分这些类型，以便在不同情况下进行不同的处理。 **buf[]**：字符数组，用来保存实际的字符串数据。这个字段存储了字符串的内容。 SDS的优势相较于C语言的字符数组，SDS具备以下优势： O(1)的获取长度时间复杂度： 在C语言中，获取字符串长度需要调用strlen函数，该函数需要遍历整个字符数组，时间复杂度为O(n)。 在SDS中，字符串的长度直接存储在len字段中，获取长度的时间复杂度为O(1)，极大地提高了性能。 二进制安全： C语言的字符串以空字符（’\\0’）作为字符串的结束标志，这使得C语言字符串不能存储包含空字符的二进制数据。 SDS使用len字段来表示字符串的长度，因此不需要以空字符作为结束标志，可以安全地存储任意二进制数据。 避免缓冲区溢出： 在C语言中，如果字符串操作不当，可能会导致缓冲区溢出，即写入的数据超出了分配的内存空间，导致程序崩溃或安全漏洞。 SDS通过alloc字段记录分配的内存空间大小，并在字符串操作时检查是否超出分配的空间，从而避免了缓冲区溢出的问题。 示例假设我们有一个字符串&quot;hello&quot;，在C语言中，它通常表示为： 在SDS中，这个字符串的表示方式如下： 在这个例子中： len字段的值为5，表示字符串&quot;hello&quot;的长度。 alloc字段的值为10，表示为字符数组分配了10个字节的内存空间。 flags字段的值为0，表示这是一个基本的SDS类型。 buf[]字段存储了字符串&quot;hello&quot;的实际内容。 通过这种方式，SDS不仅提供了高效的性能，还解决了C语言字符串的一些常见问题，如缓冲区溢出和二进制不安全等。 线程模型Redis为什么快？ Redis以其极高的性能而闻名，官方基准测试结果显示，单线程的Redis吞吐量可以达到每秒10万次操作（100,000 ops&#x2F;s）。Redis之所以能够实现如此高的性能，主要有以下几个原因： 内存操作 Redis的大部分操作都是在内存中完成的。内存的访问速度远远快于磁盘I&#x2F;O，因此数据操作的性能瓶颈通常不在于CPU，而在于数据的I&#x2F;O操作。Redis基于内存操作，将性能瓶颈从磁盘I&#x2F;O转移到了内存和网络传输上。此外，Redis还采用了高性能的数据结构，如哈希表、跳表等，进一步提升了操作效率。 单线程模型 Redis采用单线程模型来处理网络I&#x2F;O和请求数据。单线程模型有以下几个优势： 避免线程竞争：多线程程序中，线程间的竞争和同步开销较大。单线程模型避免了线程间的竞争问题，减少了线程切换的开销。 简化设计：单线程模型简化了程序设计，避免了复杂的线程同步和锁机制，降低了出错的概率。 I&#x2F;O多路复用机制 Redis采用I&#x2F;O多路复用机制来处理大量的客户端socket请求。I&#x2F;O多路复用机制允许一个线程同时处理多个I&#x2F;O流，具体来说： 内核监听：在Redis单线程的情况下，I&#x2F;O多路复用机制允许内核同时监听多个socket上的连接请求和数据请求。 请求处理：一旦有请求到达，内核会将请求交给Redis线程处理，从而实现了一个Redis线程处理多个I&#x2F;O流的效果。 高效的数据结构 Redis内部使用了多种高效的数据结构，如哈希表、跳表、压缩列表等。这些数据结构在内存中操作时，能够提供高效的插入、删除和查找操作，进一步提升了Redis的性能。 Redis对多线程的使用Redis的单线程模型指的是“接收客户端请求 -&gt; 解析客户端请求 -&gt; 进行数据操作 -&gt; 返回数据给客户端”这个过程由一个主线程完成。 虽然Redis在处理客户端请求时采用单线程模型，但这并不意味着Redis程序本身是单线程的。实际上，Redis在启动时会启动多个后台线程（BIO，Background I&#x2F;O）来处理一些耗时的任务，从而避免这些任务占用主线程的资源，影响Redis的性能。 在Redis2.6，后台会启动线程分别完成关闭文件和AOF刷盘任务； 在Redis4.0版本后，新增了一个线程用于异步释放内存操作，也就是lazyfree。例如，执行unlink key &#x2F; flushdb async &#x2F; flushall async等命令，异步释放内存，这样的好处是不占用主线程。 将这些“关闭文件”、“AOF算盘”、“释放空间”任务交由创建的独立线程完成，能够极大地提升Redis的处理效率，因为这些操作都是极为耗时的，若由主线程完成可能会造成阻塞，同时也没法处理其他socket请求了，严重影响了Redis的性能。 虽然Redis的主要工作（网络I&#x2F;O和执行命令）一直是单线程模型，但在Redis 6.0版本也引入了多个线程来处理网络I&#x2F;O请求。这是因为随着网络硬件性能的提升，Redis的性能瓶颈有时候会出现在处理网络I&#x2F;O上。 多线程网络I&#x2F;O的优势 提升网络I&#x2F;O并行度：通过引入多线程处理网络I&#x2F;O请求，Redis能够更高效地处理大量的并发连接和数据传输，从而提升整体的性能。 不影响命令执行：尽管引入了多线程处理网络I&#x2F;O，但对于执行命令，Redis仍然采用单线程模型。这种设计确保了命令执行的顺序性和一致性，避免了多线程带来的复杂性和潜在的竞争问题。 Redis如何实现IO多路复用Redis采用单线程模型来执行命令，这意味着所有的任务都按照顺序执行。然而，由于输入输出（I&#x2F;O）操作是阻塞的，如果一个文件的I&#x2F;O操作阻塞，整个进程将无法为其他客户端提供服务。为了解决这个问题，Redis采用了I&#x2F;O多路复用技术。 I&#x2F;O多路复用的概念I&#x2F;O多路复用（I&#x2F;O Multiplexing）是一种允许单个线程同时监视多个文件描述符（如socket）的技术。通过这种技术，单个线程可以检查多个socket的I&#x2F;O就绪状态，从而在单个线程中处理多个I&#x2F;O流。 Redis中的I&#x2F;O多路复用在Redis中，I&#x2F;O多路复用主要用于处理多个客户端连接的网络I&#x2F;O操作。Redis使用了一种称为epoll的机制来实现I&#x2F;O多路复用。epoll是Linux系统中的一种高效的I&#x2F;O多路复用技术，能够显著提高Redis在高并发环境下的性能。其模型参考一张网络来源图： 监听多个socket：Redis主线程会监听多个客户端连接的socket。每个socket代表一个客户端连接。 事件通知：当某个socket上有数据到达（如客户端发送请求），epoll机制会通知Redis主线程。 处理事件：Redis主线程接收到事件通知后，会处理该socket上的请求，执行相应的命令，并将结果返回给客户端。epoll机制使用非阻塞I&#x2F;O操作。当某个文件描述符上的I&#x2F;O操作无法立即完成时，I&#x2F;O多路复用机制会立即返回，并继续监听其他文件描述符上的事件。 继续监听：处理完一个事件后，Redis主线程继续监听其他socket，等待下一个事件的到来。 假设我们有一个Redis服务器，它需要处理多个客户端的请求。在传统的阻塞I&#x2F;O模型中，每个客户端连接都需要一个独立的线程来处理，这会导致线程数量过多，资源消耗大。而在Redis的I&#x2F;O多路复用模型中，所有客户端连接的socket都由一个主线程监听和处理。 例如，当客户端A发送一个请求时，epoll机制会通知Redis主线程处理该请求；同时，客户端B的请求也会被epoll监听到，并交给Redis主线程处理。通过这种方式，Redis能够高效地处理大量的并发请求，而不会因为线程切换和竞争导致性能下降。 Redis通过采用I&#x2F;O多路复用技术，实现了在单个线程中高效处理多个客户端连接的请求。这种设计使得Redis能够在高并发环境下提供极高的性能，同时确保系统的稳定性和响应速度。通过epoll机制，Redis能够监听多个socket，并在事件发生时及时处理，避免了传统阻塞I&#x2F;O模型中的性能瓶颈。 Redis网络模型Redis在6.0版本之前，采用的是单Reactor单线程模型。这种模型虽然简单，但在高并发环境下存在一些性能瓶颈。为了进一步提升性能，Redis在6.0版本引入了多线程处理网络I&#x2F;O，但命令的执行仍然保持单线程模式。 单Reactor单线程模型在Redis 6.0之前，Redis采用的是单Reactor单线程模型。缺点： 无法充分利用多核CPU：单线程模型无法充分利用多核CPU的计算能力，限制了Redis在高并发环境下的性能。 业务处理延时：在进行业务处理时，无法执行其他连接的事件。如果业务处理时间较长，会造成较大的延时，影响系统的响应速度。 Redis 6.0的多线程网络I&#x2F;O为了解决单Reactor单线程模型的性能瓶颈，Redis在6.0版本引入了多线程处理网络I&#x2F;O。具体来说： 多线程处理网络I&#x2F;O：Redis 6.0将网络I&#x2F;O操作从主线程中分离出来，使用多个线程来处理网络I&#x2F;O请求，从而提高网络I&#x2F;O的并行度和处理效率。 单线程执行命令：尽管网络I&#x2F;O采用了多线程处理，但对于命令的执行，Redis仍然保持单线程模式。这种设计确保了命令执行的顺序性和一致性，避免了多线程带来的复杂性和潜在的竞争问题。 优点 提升网络I&#x2F;O并行度：通过多线程处理网络I&#x2F;O，Redis能够更高效地处理大量的并发连接和数据传输，从而提升整体的性能。 不影响命令执行：尽管引入了多线程处理网络I&#x2F;O，但对于命令的执行，Redis仍然采用单线程模型。这种设计确保了命令执行的顺序性和一致性，避免了多线程带来的复杂性和潜在的竞争问题。 假设我们有一个Redis服务器，它需要处理大量的客户端请求。在Redis 6.0之前，所有的网络I&#x2F;O和命令执行都在一个主线程中进行。如果某个客户端的请求处理时间较长，会导致主线程阻塞，无法处理其他客户端的请求。 在Redis 6.0中，网络I&#x2F;O操作被分离出来，由多个线程处理。例如，当客户端A发送一个请求时，网络I&#x2F;O线程会处理该请求的读取和写入操作；同时，客户端B的请求也会被其他网络I&#x2F;O线程处理。这样，即使某个客户端的请求处理时间较长，也不会影响其他客户端的请求处理。 Redis在6.0版本之前采用单Reactor单线程模型，虽然简单，但在高并发环境下存在性能瓶颈。为了进一步提升性能，Redis在6.0版本引入了多线程处理网络I&#x2F;O，但命令的执行仍然保持单线程模式。这种设计使得Redis能够在高并发环境下提供极高的性能，同时确保系统的稳定性和响应速度。"},{"title":"DDD架构设计","date":"2024-09-25T00:19:37.000Z","url":"/2024/09/25/DDD%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/","tags":[["DDD","/tags/DDD/"]],"categories":[["架构","/categories/%E6%9E%B6%E6%9E%84/"]],"content":"领域驱动设计（DDD）概述什么是领域驱动设计（DDD）？领域驱动设计（Domain-Driven Design，简称DDD）是一种软件设计方法论，旨在通过将业务领域模型与软件实现紧密结合，来指导复杂软件系统的开发。DDD的核心在于“领域”（Domain），即业务领域，并通过一系列关键概念如界限上下文、实体、值对象、聚合、仓储和领域服务来实现对复杂业务需求的有效管理。 DDD的两大设计阶段DDD将软件设计过程分为两个主要阶段：战略设计和战术设计。 战略设计战略设计主要目标是应对复杂的业务需求，通过抽象和分治的设计过程，将业务领域拆分为多个独立的界限上下文（Bounded Context），每个界限上下文对应一个微服务或子系统。战略设计的成功在于能否确保每个界限上下文具有明确的职责，避免职责交叉和功能重叠。 战术设计战术设计主要目标是基于面向对象思想，运用领域模型来实现业务逻辑。通过设计一个能够准确表达业务领域的概念模型，并运用实体、聚合和领域服务来承载业务逻辑，战术设计旨在降低系统的复杂度，提升代码的可读性和可维护性。 总结 领域驱动设计（DDD）通过战略设计和战术设计两个阶段，帮助开发团队在复杂业务需求的背景下，构建出清晰、可维护且能够准确表达业务需求的软件系统。战略设计通过抽象和分治策略，将复杂的业务领域拆分为多个独立的界限上下文，确保每个界限上下文具有明确的职责。战术设计则通过领域模型、实体、聚合和领域服务的合理运用，实现业务逻辑的清晰表达和高效维护。通过DDD，开发团队可以在开发前期投入更多精力进行设计，规划出更加合理且可持续更新迭代的工程设计。 DDD的概念什么是充血模型？实体、值对象、聚合对象都有什么区别？把他们搞懂”为什么需要“，才能更好地进行设计。 充血模型充血模型是一种设计模式，它将对象的属性和行为逻辑聚合到一个类中。与传统的贫血模型（Anemic Model）不同，充血模型强调对象不仅包含数据（属性），还包含操作这些数据的行为（方法）。这种设计模式的优势在于： 内聚性：对象的属性和行为紧密结合，使得对象更加内聚，减少了重复代码的编写。 封装性：对象的行为被封装在类内部，外部调用者只需通过接口与对象交互，而不需要了解内部实现细节。 可维护性：由于行为和数据紧密结合，修改和扩展对象的行为变得更加容易，系统的可维护性得到提升。 充血模型不仅适用于类的设计，还可以应用于包结构设计。例如，在设计一个模块时，可以将相关的类和接口组织在一起，形成一个内聚的包结构。 领域模型领域模型是对特定业务领域内业务规则、策略以及业务流程的抽象和封装。通过领域模型，可以将复杂的业务逻辑分解为多个独立的界限上下文（Bounded Context），每个界限上下文都有其独立的领域模型。领域模型的设计手段包括： 领域对象：包括实体（Entity）、值对象（Value Object）和聚合（Aggregate）。实体具有唯一标识，值对象通过属性值来区分，聚合是一组相关实体和值对象的集合。 领域服务：用于封装那些不适合放在实体或值对象中的业务逻辑。 仓储（Repository）：用于管理聚合的持久化操作，提供了一种抽象，使得业务逻辑与数据访问层分离。 工厂（Factory）：用于创建复杂的领域对象。 端口适配器（Port Adapter）：用于定义与外部系统交互的接口标准，确保领域模型只关注业务实现，而不直接依赖外部系统。 领域模型与贫血模型的对比在传统的贫血模型中，业务逻辑通常被平铺在Service层，导致Service层变得扁平化和复杂化。贫血模型的主要问题在于： 职责分离不明确：Service层承担了过多的业务逻辑，导致职责不明确，代码难以维护。 对象行为缺失：对象仅包含数据，缺乏行为，导致对象之间的交互复杂，系统难以扩展。 在充血模型和领域模型的指导下，系统设计发生了显著变化： 职责分离：业务逻辑被分配到领域对象和领域服务中，Service层仅负责协调和调用领域对象。 对象行为丰富：对象不仅包含数据，还包含操作这些数据的行为，使得对象更加内聚和可维护。 防腐层：通过端口适配器，领域模型与外部系统解耦，确保领域模型只关注业务实现，而不直接依赖外部系统。 领域模型的优势 业务逻辑清晰：通过领域模型，业务逻辑被清晰地表达和封装，使得系统更加易于理解和维护。 可扩展性：领域模型通过职责分离和对象行为的丰富化，使得系统更加易于扩展和修改。 防腐设计：通过端口适配器，领域模型与外部系统解耦，确保领域模型只关注业务实现，而不直接依赖外部系统。 "},{"title":"Python算竞教程","date":"2024-09-20T00:08:08.000Z","url":"/2024/09/20/%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8Python%E5%8F%82%E5%8A%A0%E7%AE%97%E7%AB%9E/","categories":[["编程语言","/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"],["Python","/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Python/"]],"content":" 注 本文转载自：如何用Python参加算法竞赛 - Mxrurush - 博客园 (cnblogs.com) 如何用Python参加算法竞赛前言本文适合有一定c++基础且初步了解Python，并想开发自己第二竞赛用语言的人群阅读。 本文仅介绍Python3，更低版本Python请自行了解。 Python的优点在于在应对代码编写简单的题目时，在无电子板子的赛场环境可以一定缩短codeing时间。但在面对代码编写要求较高、时间限制较紧的情况，并**无法取代c++**。因此c++仍然是打算法竞赛的第一选择。 Python的适用场合有如下几种： 代码简单的，如一些思维题、构造题等 字符串处理，Python提供的字符串处理函数比c++丰富许多。 对拍器和数据生成器 注一： python与其他语言不同的一点在于，同样的算法，用标准库的永远比自己写的速度快。因为标准库算法大部分是用C语言写的，python由于语言限制永远到达不了C的速度，也即标准库的速度。 注二： python的官方中文文档比起一些别的语言已经算非常好了，如果看别人代码或者题解有不懂的函数或容器，可以直接搜官方文档的对应内容。本文对于一些内容也不会讲太细，可以直接搜官方文档看 注三： python语言并不适合递归算法，因为其递归深度，语言自身就有限制，就算去除限制，其也会开辟大量空间。蓝桥杯也会依据语言出题，python组用递归算法的题很少很少。所以平时应多注意迭代算法的积累，以及递归算法转迭代算法的方式 Python基本数据类型python的基本数据类型有六种，数值、字符串、列表、元组、字典、集合，常用的有int，str，bool，float，list，tuple，dict，set int（整数）没有长度限制，大数字乘法复杂度O(nlogn)O(nlogn)（补：因为当int达到高精度时，内部会使用FFT算法加速多项式乘法），非常方便。 float（浮点数）大概注意一下精度就行，[2.2250738585072014e−308,1.7976931348623157e+308][2.2250738585072014e−308,1.7976931348623157e+308] bool（布尔）有True，False两个值（注意大小写） list（列表）最常用的数据类型之一，可当成C++中数组。 由于python中没有C++的栈，该结构可作栈使用 还可以append添加元素，pop删除尾部最后一个元素（O(1)），删除中间元素（最坏O(n)），count计数（O(n)），index定位元素（O(n)），并且重载了加法（即同维数组连接） 加法示例 tuple（元组）和list差不多，初始化用括号 支持list的很多操作，唯独不能对一个tuple自身进行修改 所以 dict 因为要求 key 值不可变，当想对插入一个 （list，int）键值对时，必须将 list 转为 tuple str（字符串）和 C++ 中字符串类似，但是无法修改其中字符，因此经常用如下方法转换为一个list再进行操作。 重载了加法，加法即是字符串连接 同时也有count，index，find等函数 多了一个C++没有，很好用的 split split 默认以不可见字符进行分割，也可传入固定字符，以固定字符进行分割字符串，将子串存入list中 dict（字典）相当于C++的map容器，但是其内部是哈希表实现的，无序，大部分操作都是 O(1)O(1) 的 需要注意的是，其通过下标访问一个不存在的key时，会报异常，这点可以用后文的defaultdict解决 set（集合）set是一个数学意义集合（不可重，无序）的程序实现（内部由哈希表实现）。支持各种集合操作。 该类型重载了位运算，可以灵活的求集合交，并，补 其可迭代，故也可以 这样遍历 类型转换类型可以函数化，并互相转换 如最常用的 int，str 转换 还有 list 与 set 互相转换以实现去重操作 Python基础语法本部分，我将直接列出c++基础语法，并给出在Python上的等价替代。 主函数体c++main函数基础结构： Python主函数并不是必要的，完全直接在空文件编写代码，如： 在Python中可以直接写为： 当然，如果实在不习惯，想要和c++风格更加类似，可以按如下写法： 第一行if __name__ == &quot;__main__&quot;:的意思：字面上，这是一个if判断，而__name__是一个内置的特殊变量，当我们希望将一个python模块（就是写好的py文件）导入其他python模块时，就只会执行if __name__ == &quot;__main__&quot;:的语句，比如： print(123)就不会被执行。 但对于算法竞赛来说，一般不需要多模块操作，该写法只是为了更好的向c++代码风格靠拢。 运算符python中新添 ** 乘方运算符 无自增 ++ 运算符，无自减运算符 – 条件连接符 python 中均以英文表示条件连接，可读性好些 python C and &amp;&amp; or || not ! 基础语句循环： 需要注意的是，for i in range(n):实际上是对range生成的对象遍历，可以简单理解为对一个[0,1,2…,n−3,n−2,n−1][0,1,2…,n−3,n−2,n−1]的列表遍历，因此我们在循环中修改ii并不会改变之后的循环。比如： 并不会让循环按照0→2→4⋅⋅⋅0→2→4···的顺序进行。 可见，Python中的for循环不如c++中的灵活，因此while的使用频率大大提高了。 关于range函数： 三个参数分别代表，起点，终点和步长 range返回的区间是左闭右开的，也就是[start,end)[start,end) 第1和第3个参数可以缺省。 给几个使用实例 分支： 和c++差别不大，给个实例： 可以发现区别只在于Python将else if合并为了elif。 但因为引入了in这个关键字，有了一些更加方便的用法 函数Python中函数定义方法很简单： Python允许函数定义出现在函数内部 Output： 1 2 Python允许函数返回多个值 Output: 11 12 Python中函数内部如果想修改外部数字变量，需要使用nonlocal或者global关键字 如果将global t注释掉程序会报错。 如果想要使用的变量不是被定义在全局区，而是某个函数体内部则要使用nonlocal关键字 “头文件”Python除内置库外，有一些功能需要手动导入模块，有如下几种方法 第一种方法和后两种调用时有所区别 第一种： 后两种： 可见区别就是使用时是否要明确库名，一般在算法竞赛中为了代码简洁，推荐使用后者，但如果要使用from math import *的方法，将存在一定变量名冲突的风险。 因此，更推荐部分导入。 “宏定义”Python中没有宏定义，但有替代可以缩短一定码量。如下： 我们定义一个及其鬼畜的函数abcdefgasdas(x)并在之后给其“取别名”为func，调用func就等价调用了abcdefgasdas从而在某些要调用内置函数时，起一个更短的名字，降低码量。 附：之所以可以这样是因为python之中，一切皆对象，故可以一切皆变量（包括函数） 输入输出输入 Python中的读入和C++还是有很大不同的，需要一定时间适应。 Python读入时都是调用input()其将返回标准输入中的一行数据（不包括末尾的\\n），其返回的类型统一为字符串，因此还要对其进行变量类型转换。 在算法竞赛中，读入一行数字一般分为可数的几个整数，和一个很长的数组两种形式，我举例说明如何读入： Input 5 1 3 2 4 2 5 3 2 1 2 3 4 5 字符串读入方法就很简单了 读入优化 Python中的真读入优化需要码量巨大，在正式比赛中并不常用，但仍然可以使用如下方法提高一定的读入效率。 将其放在Python文件头部即可。可以提高一定效率，但没有c++那般明显。 PS：使用该方法行末的\\n将不会被忽略，在读入字符串数据时尤其要注意 输出 使用print()进行输出 将输出数据类型转换为字符串，并且将所有中间输出全部加入到此字符串中，最后一次性输出，有时可以提高一定效率，但并不明显。 文件读写由于前几年蓝桥杯 C++ 组有需要文件读写的情况，所以在此稍微讲解常用用法，具体可见标准库 r 以只读方式打开文件。文件的指针将会放在文件的开头。 w+ 打开一个文件用于读写。如果该文件已存在则打开文件，并从开头开始编辑，即原有内容会被删除。如果该文件不存在，创建新文件。 Python库和函数介绍一些常用的库和函数，着重和C++的STL对比。 简单函数 数学函数 math 库中的 sort自定义排序，Python不如C++灵活。首先它只可以对整个序列排序，而无法对部分序列排序，其次自定义方法不如C++的lamda表达式方便。 当然，很多时候我们只是想让它根据列表的某一维度排序，这时也可以用python的lambda表达式，代码量少很多。 sort是没有返回值的原地排序，如果我们希望获取到这个排序后列表，且不想改变原来的列表时，可以用sorted函数。自定义 map （映射）通过一个函数，对可迭代对象的所有值对象进行修改（创建副本，非原地修改） collections这个库里常用的有deque，defaultdict，Counter dequedeque对标c++中的双端队列，可以快速在头尾弹出和加入元素。速度比普通队列快，因此在需要队列的场合，统一使用deque defaultdict即当键值不存在时，有默认返回值的 dict，其余操作差不多 由于defaultdict对于key下标运算返回的是value的引用，若不存在则只能创建一个对象再返回，因此通过下标判断存在与否的方式不推荐，建议使用 in 来判断是否存在 用下标运算来插入与修改 Counter调用Counter函数计数，返回一个 defaultdict(int) PS：dict、set和其子类都是用的hash实现，而不是c++中的红黑树，因此没有自动排序功能，目前没有太好的替代。 如果是非标准库的话，有Sorted Container，比较好用。让我们祝福它早日进标准库 heapq（优先队列）Python中其实有优先队列，但是速度没有heapq快，因此用heapq代替。 heapq提供函数对一个list进行原地的小根堆的维护。 heapq并没有提供方便的重载为大根堆的方法，如果想使用大根堆，一般的技巧是加入值取负值，弹出后再恢复。 基础操作差不多这么多，还有一些其他功能可自行了解。 zip、enumerate函数这两个函数，都是使得枚举进一步简单化的函数。 zip函数可以同时访问不同list的同偏移量的元素 Output： 1 52 43 34 25 1 enumerate则是在访问list中元素时，同时给出元素的下标，下标默认从0开始。 Output: 0 11 22 33 44 5 itertools这个库里的大多函数方法，都是返回一个可迭代对象，因此若要变成list还需list()转换 permutations、combinationspermutations，combinations分别是返回一个可迭代对象（一般是list）的所有排列和组合。使用时需要导入itertools模块 用法如下： Output: (1, 2, 3)(1, 3, 2)(2, 1, 3)(2, 3, 1)(3, 1, 2)(3, 2, 1)(1, 2)(1, 3)(2, 3) accumulate（累计） pairwise（成对遍历） functoolsreduce （聚合）其位于functools库里面 对于可迭代对象进行使用，将可迭代对象里的所有值对象，两两聚合，最后返回一个值对象 Python小技巧交换没有swap函数，但可以这么写，也很方便 列表（其实可以是任何可以迭代对象）解析式创建列表时，可以用如下方法简化代码 列表解析式中中括号中返回的是一个可迭代对象，这个在很多函数中都是可接受的数据类型。结合上面说的“聚合函数”，就可以这样写 多维数组很可惜，python自身没有天然支持固定长度的多维数组（即如C++的int a[5][5][5];这样的），需要numpy才能很好的使用 但是仍然可以创建，方式如下 这是创建了一个 4 * 2 的 二维数组 有人可能疑惑，为什么不能这样创 这是后果 第一列全部被修改 最外层的乘4，相当于只是创建了四个引用，引用的都是一个[0] * 2 所以不行 三目表达式和c++中的三目表达式?:类似，Python中也有何其类似的语法。 快速创建一个字典"},{"title":"MySQL-性能调优","date":"2024-09-19T21:20:00.000Z","url":"/2024/09/20/MySQL-%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98/","tags":[["索引","/tags/%E7%B4%A2%E5%BC%95/"],["SQL调优","/tags/SQL%E8%B0%83%E4%BC%98/"]],"categories":[["数据库&缓存","/categories/%E6%95%B0%E6%8D%AE%E5%BA%93-%E7%BC%93%E5%AD%98/"],["MySQL","/categories/%E6%95%B0%E6%8D%AE%E5%BA%93-%E7%BC%93%E5%AD%98/MySQL/"]],"content":"在MySQL性能调优中，EXPLAIN命令是关键工具，用于分析查询执行计划。本文将介绍如何通过EXPLAIN识别性能瓶颈，并提供优化策略，包括索引创建、查询语句优化、避免文件排序和临时表的使用，以及缓存技术的应用。此外，还将探讨FORCE INDEX命令的使用，以强制使用指定索引。对于高并发场景，主从同步和分库分表策略同样重要，以确保系统稳定性和性能。通过这些方法，可以显著提升MySQL数据库的查询效率和整体性能。 性能调优EXPLAINEXPLAIN命令是MySQL中用于分析和优化查询性能的重要工具。通过EXPLAIN，我们可以查看一条SELECT语句的执行计划，了解查询的执行过程，例如是否使用了索引、是否实现了索引覆盖等。 以下是一条全表扫描查询语句的EXPLAIN结果示例： 执行计划参数 type：表示扫描数据的类型，下面会详细讲解。 possible_keys：表示可能用到的索引。 key：表示实际用到的索引，如果为null，则表示没有用到索引。 rows：表示扫描的记录行数。 扫描类型（type）type表示扫描数据时采用的方式，从性能上由低到高排列如下： ALL：全表扫描，性能最差，应尽量避免。全表扫描意味着数据库引擎需要读取表中的每一行数据，开销巨大，尤其是在大数据量的情况下。 INDEX：全索引表扫描，虽然扫描的是索引表，不需要对数据进行排序，但开销依旧很大。全索引扫描意味着数据库引擎需要读取索引中的每一行数据，尽管索引通常比数据表小，但仍然是一个昂贵的操作。 RANGE：采用了索引范围扫描，只需查找指定范围的索引。尽量让查询达到RANGE级别以上，越往上的级别索引作用越明显、效率越高。范围扫描通常用于WHERE子句中的范围条件（如&gt;、&lt;、BETWEEN等）。 REF（非唯一索引查询）：采用了非唯一索引或唯一索引的非唯一索引前缀，返回数据是多条的。虽然有的表会存在相同的索引，但一般这种索引重复记录条数不多，且在磁盘中已经按顺序排列，查询的范围会小很多。 EQ_REF（唯一索引查询）：使用主键索引或唯一索引产生的查询，通常用于多表连接查询。例如，使用学生ID查询学生信息和学科成绩信息，两表的stu_id是相同的。可以采用小表驱动大表进行多表查询。 CONST：表示使用了主键或唯一索引与常量进行比较查询，一般结果只有一条或采用了唯一索引扫描。与EQ_REF不同的地方是，CONST与常量进行比较，效率会快很多，EQ_REF通常用于多表级联查询。 Extra显示结果Extra显示的结果有几个重要的参考指标： Using filesort：采用了GROUP BY操作，但无法利用索引进行排序。应尽量避免。文件排序意味着数据库引擎需要将数据加载到内存中进行排序，这是一个昂贵的操作，尤其是在大数据量的情况下。 Using temporary：使用了临时表保存中间查询数据，常见于排序GROUP BY查询和分组GROUP BY查询。使用临时表意味着数据库引擎需要额外的内存和磁盘空间来存储中间结果，这会增加查询的开销。 Using index：所需要的数据直接通过扫描索引即可获得，不需要查询表中的数据或进行回表操作，也就是索引覆盖。索引覆盖意味着查询所需的所有数据都包含在索引中，因此不需要回表，这可以显著提高查询性能。 深入分析全表扫描（ALL）全表扫描是最低效的扫描方式，通常发生在没有索引或查询条件无法利用索引的情况下。为了避免全表扫描，可以考虑以下优化措施： 创建合适的索引：为查询条件中的字段创建索引，尤其是高频查询的字段。 优化查询条件：确保查询条件能够利用索引，避免使用函数操作或模糊查询（如LIKE &#39;%keyword&#39;）。 索引覆盖（Using index）索引覆盖是一种高效的查询方式，通过合理设计索引，可以使查询所需的所有数据都包含在索引中，从而避免回表操作。实现索引覆盖的关键在于： 选择合适的索引字段：确保查询所需的所有字段都包含在索引中。 避免不必要的字段：如果查询只需要部分字段，可以考虑创建覆盖索引，只包含这些字段。 文件排序（Using filesort）文件排序是一种昂贵的操作，通常发生在ORDER BY或GROUP BY操作无法利用索引的情况下。为了避免文件排序，可以考虑以下优化措施： 创建排序索引：为ORDER BY或GROUP BY的字段创建索引，确保排序操作可以利用索引。 优化查询语句：尽量减少排序操作，或者将排序操作放在应用程序层进行。 通过合理使用EXPLAIN命令，可以深入了解查询的执行计划，从而进行针对性的性能调优，提高查询效率。 查询优化查询优化是提升数据库性能的关键步骤。通过分析查询语句、创建或优化索引、减少不必要的数据查询、优化数据库结构以及使用缓存技术，可以显著提高查询效率。 1. 分析查询语句使用EXPLAIN命令分析查询语句的执行计划，了解查询的执行过程。通过查看扫描类型（type）、采用的索引（key）、扫描的记录行数（rows）等信息，判断查询是否走了索引，是否存在全表扫描等问题。 2. 创建或优化索引根据查询条件创建适用的索引，以提高查询效率。索引的选择应考虑以下因素： 高频查询字段：为经常出现在查询条件中的字段创建索引。 区分度高的字段：选择区分度高的字段作为索引的前缀，以提高索引的选择性。 联合索引：合理设计联合索引，遵循最左匹配原则，确保查询条件能够充分利用索引。 3. 查询优化只查询需要的数据，避免使用SELECT *，尽量能够命中索引，避免索引失效情况。具体措施包括： 选择性查询：只查询必要的字段，避免查询不需要的数据。 避免函数操作：对索引字段进行函数操作（如LOWER(column)）会导致索引失效，应尽量避免。 避免模糊查询：使用通配符开头的模糊查询（如LIKE &#39;%keyword&#39;）通常会导致索引失效，应尽量避免。 4. 优化数据库避免单表数据量过大，可以使用数据库集群和分表机制来优化数据库结构。具体措施包括： 分表分库：将大表拆分为多个小表，或者将数据分布到多个数据库中，以减少单表数据量。 数据库集群：使用数据库集群技术，将数据分布到多个节点上，提高数据库的并发处理能力。 5. 使用缓存技术缓存读写要比磁盘I&#x2F;O速度快得多，可以将数据写入缓存层（如Redis），以减少数据库的读写压力。具体措施包括： 缓存热点数据：将高频访问的数据缓存到Redis等缓存系统中，减少数据库的读取次数。 缓存查询结果：将复杂的查询结果缓存起来，避免重复计算，提高查询效率。 示例假设有一个订单表orders，包含字段order_id、customer_id、order_date等。以下是一些优化措施： 创建索引：为order_id和customer_id创建索引，提高查询效率。 查询优化：避免使用SELECT *，只查询必要的字段，如SELECT order_id, customer_id FROM orders WHERE order_id = 123。 分表分库：根据order_date字段将订单表拆分为多个小表，或者将数据分布到多个数据库中。 使用缓存：将高频查询的订单数据缓存到Redis中，减少数据库的读取次数。 扩展如果在执行查询计划时发现并没有使用正确的索引，可以使用FORCE INDEX命令，强制使用指定索引来优化查询。FORCE INDEX命令可以显式地告诉MySQL使用特定的索引，而不依赖于MySQL的查询优化器选择。 FORCE INDEX命令的语法如下： 示例 假设有一个订单表orders，包含字段order_id、customer_id、order_date等，并且有一个联合索引idx_customer_order基于customer_id和order_date。 未使用正确索引的查询 如果MySQL的查询优化器没有选择使用idx_customer_order索引，而是选择了全表扫描，可以通过FORCE INDEX命令强制使用该索引： 使用FORCE INDEX的查询 注意事项 索引选择：虽然FORCE INDEX可以强制使用指定索引，但并不总是最佳选择。在某些情况下，MySQL的查询优化器可能会选择更优的执行计划。因此，使用FORCE INDEX时应谨慎，最好结合EXPLAIN分析结果进行判断。 性能影响：强制使用索引可能会带来性能提升，但也可能导致性能下降。例如，如果强制使用的索引不是最优的，可能会增加查询的开销。 临时解决方案：FORCE INDEX通常作为临时解决方案，用于调试和优化查询。长期来看，应通过优化索引设计和查询语句来提高查询性能。 进一步优化 除了使用FORCE INDEX，还可以通过以下方式进一步优化查询： 索引覆盖：确保查询所需的所有字段都包含在索引中，避免回表操作。 查询重写：重写查询语句，使其更符合索引的使用规则，例如避免函数操作和模糊查询。 数据库分区：根据查询条件对数据库进行分区，减少查询的数据量。 通过合理使用FORCE INDEX命令，并结合其他优化措施，可以显著提高查询性能，减少数据库的I&#x2F;O操作，提升系统的整体性能。 架构优化主从同步【键盘都敲冒烟啦！！！】 分库分表【键盘都敲冒烟啦！！！】"},{"title":"MySQL日志可以用来干啥？","date":"2024-09-17T06:21:45.000Z","url":"/2024/09/17/MySQL%E6%97%A5%E5%BF%97%E5%8F%AF%E4%BB%A5%E7%94%A8%E6%9D%A5%E5%B9%B2%E5%95%A5%EF%BC%9F/","categories":[["数据库&缓存","/categories/%E6%95%B0%E6%8D%AE%E5%BA%93-%E7%BC%93%E5%AD%98/"],["MySQL","/categories/%E6%95%B0%E6%8D%AE%E5%BA%93-%E7%BC%93%E5%AD%98/MySQL/"]],"content":"了解MySQL的童靴们都知道，MySQL有好几种日志——undo log（回滚日志）、redo log（重做日志）还有binlog（归档日志），为啥需要这么多日志？这些日志分别都是干啥用的？在进一步探讨这么些问题之前，我们需要先了解一下一条SQL语句的执行过程。 笔者作为一名初学小白，时常感到好奇：当执行了 SQL 语句对数据记录进行修改时，如果突然遭遇系统关机、服务器卡死等故障，这段记录修改该如何是好？ 小伙伴们可能会不假思索地回答：“通过事务回滚恢复到执行增删改之前的状态！” 没错，这确实是 MySQL 保障数据安全的重要机制之一。即使我们没有显式地开启事务和提交事务，MySQL 也会隐式地启动事务执行“增删改”语句，并在执行完后自动提交事务（MySQL 默认开启了 autocommit 参数）。 但你是否想过，MySQL 是如何实现这种“时光倒流”般的神奇操作的呢？这就要归功于 MySQL 的“时光机”—— undolog、redolog 和 binlog。它们就像数据库的“守护天使”，默默地记录着数据的每一次变化，在关键时刻挺身而出，保障数据的安全性和一致性。 undolog、redolog 和 binlog 是 MySQL 保障数据安全的三大利器，它们各司其职，共同构建了 MySQL 强大的数据保护机制： undolog ：负责事务的原子性和 MVCC，确保数据的一致性。 redolog ：负责事务的持久性，确保数据不会因故障而丢失。 binlog ：负责数据的备份和主从复制，确保数据的可靠性和高可用性。 接下来，我们来进一步探讨这三种日志如何实现数据库神操作。 Undo Log 是干啥的在前言我们提到，MySQL 会隐式开启事务执行“增删改”语句，当操作过程中发生崩溃时，事务会进行回滚。那么，回滚操作中旧的数据要从哪里来呢？ 想象一下，如果在执行“增删改”操作之前，我们将要操作的数据记录做一个备份，那么当我们想恢复到执行操作之前的状态时，只要对照备份的信息就可以了。 当然，每次执行操作都要进行备份会很麻烦，但我们可以根据需求进行相应的操作记录。例如： 执行删除操作之前，记录要删除的记录信息，若想恢复，我们再把记录插回去； 执行新增操作之前，记下新增记录的ID，撤销新增只需要把对应ID记录删除即可； 执行修改操作之前，记录修改前的数据，撤销修改时只需将数据恢复到修改前的状态。 这种记录操作前数据的方式，正是 MySQL 中 Undo Log （回滚日志）的核心思想。Undo Log 记录了事务执行过程中对数据的修改操作，用于在事务回滚时撤销这些修改，将数据恢复到事务开始前的状态，它保证了事务的ACID特性中的原子性。 undo log 是一种用于撤销回退的日志。在事务没提交之前，MySQL 会先记录更新前的数据到 undo log 日志文件里面，当事务回滚时，可以利用 undo log 来进行回滚。如下图: 每当 InnoD8 引擎对一条记录进行操作(修改、删除、新增)时，要把回滚时需要的信息都记录到 undo log 里，发生回滚时，就读取undo log日志记录的数据，执行相反的操作来完成数据恢复。 需要注意的是，不同的操作，因需求不同，其undo log格式也不同，此处仅以更新操作的日志为例。每条记录的每一次更新操作产生的 Undo Log 格式中，都包含一个 roll_pointer 指针和一个 trx_id 事务 ID： trx_id 事务 ID：用于标识该记录是被哪个事务修改的，帮助系统追踪事务的执行顺序。 roll_pointer 指针：将这些 Undo Log 串成一个链表，这个链表就被称为版本链。版本链记录了该记录的所有历史版本，使得系统可以在需要时回滚到任意一个历史状态。 版本链的结构如下图所示： 另外，Undo Log 通过 ReadView + Undo Log 实现 MVCC（多版本并发控制）。 对于「读提交」和「可重复读」隔离级别的事务： 「读提交」：每次 SELECT 生成新的 Read View，可能导致同一事务中多次读取同一条数据时结果不一致。 「可重复读」：事务启动时生成 Read View，并在整个事务期间使用，确保读取的数据一致。 这两个隔离级别通过「事务的 Read View 里的字段」和「记录中的隐藏列（trx_id 和 roll_pointer）」进行比对，如果不满足可见性条件，就会顺着 Undo Log 版本链找到满足其可见性的记录，实现 MVCC。 因此，Undo Log 的两大作用是： 实现事务回滚，保障事务的原子性：在事务处理过程中，如果出现错误或用户执行 ROLLBACK 语句，MySQL 可以利用 Undo Log 中的历史数据将数据恢复到事务开始之前的状态。 实现 MVCC（多版本并发控制）的关键因素之一：MVCC 通过 ReadView + Undo Log 实现。Undo Log 为每条记录保存多份历史数据，MySQL 在执行快照读（普通 SELECT 语句）时，会根据事务的 Read View 里的信息，顺着 Undo Log 的版本链找到满足其可见性的记录。 Buffer Poll是干啥的【更新中。。。】"},{"title":"MySQL-事务与日志","date":"2024-09-14T21:20:03.000Z","url":"/2024/09/15/MySQL-%E4%BA%8B%E5%8A%A1%E4%B8%8E%E6%97%A5%E5%BF%97/","tags":[["事务","/tags/%E4%BA%8B%E5%8A%A1/"],["日志","/tags/%E6%97%A5%E5%BF%97/"],["锁","/tags/%E9%94%81/"]],"categories":[["数据库&缓存","/categories/%E6%95%B0%E6%8D%AE%E5%BA%93-%E7%BC%93%E5%AD%98/"],["MySQL","/categories/%E6%95%B0%E6%8D%AE%E5%BA%93-%E7%BC%93%E5%AD%98/MySQL/"]],"content":"这篇文章好像丢失了喔。。。T _ T "},{"title":"MySQL-索引与查询","date":"2024-09-14T21:20:01.000Z","url":"/2024/09/15/MySQL-%E7%B4%A2%E5%BC%95%E4%B8%8E%E6%9F%A5%E8%AF%A2/","tags":[["索引","/tags/%E7%B4%A2%E5%BC%95/"],["查询","/tags/%E6%9F%A5%E8%AF%A2/"]],"categories":[["数据库&缓存","/categories/%E6%95%B0%E6%8D%AE%E5%BA%93-%E7%BC%93%E5%AD%98/"],["MySQL","/categories/%E6%95%B0%E6%8D%AE%E5%BA%93-%E7%BC%93%E5%AD%98/MySQL/"]],"content":"在数据库管理中，索引是提升查询性能的关键工具。本文将深入探讨MySQL中的索引类型，从数据结构、物理存储、字段特性和字段个数等多个维度进行详细分类和解析。 索引分类详解与深入探讨MySQL中索引的分类可以从多个维度进行划分，包括数据结构、物理存储、字段特性和字段个数等。以下是对这些分类的详细解释和示例代码。 数据结构分类B+Tree索引结构特点与应用场景：B+Tree索引是一种平衡多路搜索树，所有数据存储在叶子节点，非叶子节点仅存储索引键值。这种结构保证了高效的查找、插入和删除操作，适用于范围查询、排序操作和频繁的插入、删除操作。B+Tree索引在大多数数据库系统中被广泛使用，因其平衡性和高效性。 Hash索引结构特点与应用场景：Hash索引通过哈希函数将索引键值映射到存储位置，实现快速查找。哈希索引的查找时间复杂度为O(1)，适用于等值查询，如用户登录验证、唯一性检查等场景。但由于不支持范围查询和排序，应用场景较为有限。 Full-text索引结构特点与应用场景：Full-text索引专门用于全文搜索，支持对文本内容进行分词、词干提取和倒排索引等操作，实现高效的全文检索。适用于需要进行文本分析和搜索的应用场景，如搜索引擎、文档管理系统等。 物理存储分类聚簇索引（主键索引）结构特点与应用场景：聚簇索引将数据行与索引结构存储在一起，主键索引即为聚簇索引。聚簇索引决定了数据在磁盘上的物理存储顺序，数据行的物理顺序与索引顺序一致，适用于频繁访问的数据，如用户表的主键索引。聚簇索引能够提高数据访问的局部性，减少磁盘I&#x2F;O操作。 二级索引（辅助索引）结构特点与应用场景：二级索引存储索引键值和指向数据行的指针，不直接存储数据行。二级索引适用于非主键字段的查询，可以加速查询操作，如用户表中的邮箱字段索引。二级索引可以提高查询效率，但会增加额外的存储空间和维护成本。 字段特性分类主键索引结构特点与应用场景：主键索引是唯一标识表中每一行的索引，具有唯一性和非空性。主键索引通常是聚簇索引，适用于需要唯一标识每一行的场景，如用户ID、订单ID等。主键索引能够确保数据的唯一性和完整性。 示例代码 唯一索引结构特点与应用场景：唯一索引确保索引字段的值唯一，但不要求非空。唯一索引适用于需要确保数据唯一性的场景，如用户表中的邮箱字段。唯一索引可以防止重复数据的插入。 示例代码 普通索引结构特点与应用场景：普通索引是最基本的索引类型，不具有唯一性约束，适用于加速查询操作。普通索引可以提高查询效率，但不会影响数据的唯一性，如用户表中的姓名字段。 示例代码 前缀索引结构特点与应用场景：前缀索引是对字段的前缀部分创建的索引，适用于长字段或文本字段的索引。前缀索引可以减少索引存储空间和提高查询效率，如用户表中的地址字段。 示例代码 字段个数分类单列索引结构特点与应用场景：单列索引是基于单个字段创建的索引，适用于单字段查询场景。单列索引可以提高单字段查询的效率，如用户表中的姓名字段。 联合索引结构特点与应用场景：联合索引是基于多个字段创建的索引，适用于多字段查询场景。联合索引可以提高多字段查询的效率，但需要注意索引字段的顺序和查询条件的匹配，遵循最左匹配原则，如用户表中的姓名和年龄字段。 聚簇索引与非聚簇索引 数据存储 聚簇索引的数据行按照键值顺序存储，索引的叶子节点包含了实际的数据行。这意味着数据行的物理存储顺序与索引顺序一致，数据行的位置由聚簇索引决定。 非聚簇索引的叶子节点存放的是索引键值和指向数据行的指针，而不是完整的数据行。这意味着非聚簇索引不直接影响数据行的物理存储顺序。 索引与数据关系 通过聚簇索引查找数据时，直接返回叶子节点中的完整数据行，无需额外的查找操作。 通过非聚簇索引查找数据时，首先查找到叶子节点，获取存放的聚簇索引数据，再通过聚簇索引查表获取完整数据行。这个通过非聚簇索引获取聚簇索引数据并回溯查表的过程称为回表。 唯一性 聚簇索引通常由主键构成，因此一个表只能有一个聚簇索引。聚簇索引决定了数据行的物理存储顺序，具有唯一性。 一个表可以有多个非聚簇索引，因为它们不直接影响数据行的物理存储顺序。非聚簇索引可以基于多个字段创建，具有较高的灵活性。 效率 聚簇索引直接返回叶子节点中的完整数据行，无需额外的查找操作，因此在查找效率上通常优于非聚簇索引。 非聚簇索引可能需要进行回表操作，即通过非聚簇索引获取聚簇索引数据，再通过聚簇索引查表获取完整数据行。回表操作会增加额外的I&#x2F;O开销，因此在查找效率上通常低于聚簇索引。 索引选择：自增ID vs UUID在选择主键索引时，自增ID和UUID是两种常见的选项。以下是对这两种选择的详细分析，特别是从索引性能和存储效率的角度进行探讨。 自增ID优点 顺序存储：自增ID是顺序生成的，因此数据行在磁盘上的存储顺序与索引顺序一致。这使得B+树的叶子节点更加紧凑，减少了内存碎片。 高效插入：由于自增ID的顺序性，新插入的数据行总是添加到B+树的末尾，减少了B+树的调整操作，提高了插入效率。 减少IO操作：顺序存储的数据行更容易被缓存，减少了磁盘I&#x2F;O操作，提高了查询效率。 缺点 可预测性：自增ID的可预测性可能带来安全风险，尤其是在分布式系统中，容易暴露业务信息。 分布式系统中的问题：在分布式系统中，自增ID的生成和管理可能变得复杂，需要额外的机制来保证全局唯一性。 UUID优点 全局唯一性：UUID由系统算法生成，保证了全局唯一性，适用于分布式系统中的数据唯一标识。 安全性：UUID的随机性使得其难以预测，提高了数据的安全性。 缺点 乱序存储：UUID的随机性导致数据行在磁盘上的存储顺序是乱序的，使得B+树的叶子节点变得稀疏，增加了内存碎片。 插入效率低：由于UUID的乱序性，新插入的数据行可能需要频繁调整B+树的结构，降低了插入效率。 增加IO操作：稀疏的数据分布导致查询时可能需要多次提取数据页，增加了磁盘I&#x2F;O操作，降低了查询效率。 选择建议自增ID 适用场景：适用于单机或集中式数据库系统，特别是需要高效插入和查询的场景。 示例：用户表、订单表等。 UUID 适用场景：适用于分布式系统，特别是需要全局唯一性和安全性的场景。 示例：分布式系统中的用户标识、订单标识等。 优化建议自增ID优化 使用自增ID作为主键：在单机或集中式数据库系统中，使用自增ID作为主键，可以提高插入和查询效率。 分布式系统中的自增ID：在分布式系统中，可以使用分布式ID生成器（如Snowflake算法）来生成全局唯一的自增ID。 UUID优化 使用UUID作为辅助索引：在需要全局唯一性的场景中，可以使用UUID作为辅助索引，而不是主键。 UUID的顺序化处理：在生成UUID时，可以考虑使用顺序UUID（如UUID v1），以减少B+树的稀疏性。 最左匹配原则最左匹配原则是联合索引的核心特性之一，它规定了在查询中如何利用联合索引。具体来说，最左匹配原则要求查询条件必须从联合索引的最左边的字段开始匹配，才能有效利用该索引。 详细解释联合索引在物理存储特性分类上归于聚簇索引或非聚簇索引，具体取决于数据库的实现。对于非聚簇索引，存储的数据通常是对应记录的主键或其他唯一标识符，因此可能需要执行回表操作来获取完整的数据。 假设我们有一个联合索引，基于字段A、B和C创建。在往联合索引表新增索引数据时，首先会根据字段A进行排序，然后在A的基础上根据字段B进行排序，依此类推。总结来说，字段B、C是全局无序的，仅相对于上一个索引字段局部有序。 完全匹配：查询条件包含所有索引字段，如WHERE A = &#39;value1&#39; AND B = &#39;value2&#39; AND C = &#39;value3&#39;。这种情况下，查询可以直接利用联合索引进行快速查找。 部分匹配：查询条件包含部分索引字段，但必须从最左边的字段开始，如WHERE A = &#39;value1&#39; AND B = &#39;value2&#39;。这种情况下，查询可以利用索引的前两个字段进行查找。 单字段匹配：查询条件只包含最左边的字段，如WHERE A = &#39;value1&#39;。这种情况下，查询可以利用索引的第一个字段进行查找。 无法利用索引的情况以下几种查询条件无法利用联合索引： 跳过字段：查询条件跳过了最左边的字段，如WHERE B = &#39;value2&#39; AND C = &#39;value3&#39;。这种情况下，查询无法利用联合索引，因为索引的构建顺序是从字段A开始的。 范围查询：在联合索引中，范围查询（如&gt;、&lt;、BETWEEN等）可能会导致后续字段的索引失效。例如，如果查询条件是WHERE A &gt; &#39;value1&#39; AND B = &#39;value2&#39;，那么字段B的索引可能无法被有效利用，因为数据库引擎需要扫描所有满足 A &gt; &#39;value1&#39; 的记录。 函数操作：对索引字段进行函数操作（如LOWER(column)）会导致索引失效，因为数据库无法直接使用索引进行比较。 在实际应用中，理解和遵循最左匹配原则对于优化查询性能至关重要。通过合理设计和使用联合索引，可以显著提高查询效率，减少数据库的I&#x2F;O操作。例如，在设计联合索引时，应优先选择区分度高的字段作为索引的前缀，以确保索引的高效利用。 总之，最左匹配原则是联合索引的核心，理解并遵循这一原则可以帮助我们更好地设计和优化数据库索引，从而提升系统的整体性能。 索引失效 不满足最左匹配原则：联合索引（Composite Index）是按照索引字段的顺序进行排序的。如果查询条件不从最左边的索引字段开始匹配，数据库优化器无法利用索引的有序性，导致索引失效。 使用函数或计算公式：在查询条件中对索引字段使用函数或计算公式会导致索引失效，因为数据库无法直接利用索引的有序性。 类型转换：查询条件中的数据类型与索引字段的数据类型不匹配，导致隐式类型转换，索引可能失效。隐式类型转换本质上也是一种函数操作。 使用 OR 条件：在某些数据库中，使用 OR 条件可能会导致索引失效，因为数据库优化器可能无法同时利用多个索引。 范围查询：范围查询（如 &gt;、&lt;、BETWEEN）可能会导致索引失效，尤其是当范围查询在联合索引的中间字段时。 索引下推索引下推（Index Condition Pushdown, ICP）的核心思想是在索引扫描阶段就应用部分查询条件，从而减少从表中读取数据的次数。为了在不读取数据的情况下知道条件是否符合，ICP 利用了索引的结构和特性。 索引的结构索引通常是按照索引字段的顺序存储的，并且每个索引条目通常包含索引字段的值和指向对应数据行的指针（如主键或行标识符）。对于复合索引，索引条目会按照索引字段的顺序进行排序。 ICP 的工作原理 索引扫描： 数据库引擎首先使用索引查找满足索引条件的记录。例如，对于复合索引 (customer_id, order_date)，引擎会查找所有 customer_id = 123 的记录。 应用部分查询条件： 在索引扫描阶段，数据库引擎会应用部分查询条件（非索引条件）。例如，对于查询 WHERE customer_id = 123 AND order_date &gt; &#39;2023-01-01&#39;，引擎会在索引扫描阶段就应用 order_date &gt; &#39;2023-01-01&#39; 的条件。 过滤索引条目： 由于索引是按照索引字段的顺序存储的，引擎可以在索引扫描阶段直接比较 order_date 的值，而不需要回表读取完整的数据行。如果 order_date 不满足条件，引擎可以直接跳过该索引条目，从而减少回表操作。 示例假设有一个表 orders，其中有一个复合索引 (customer_id, order_date)，并且执行以下查询： 没有 ICP 的情况： 使用索引查找所有 customer_id = 123 的记录。 根据这些记录的主键回表读取完整的数据行。 在读取完整数据行后，应用 order_date &gt; &#39;2023-01-01&#39; 的条件来过滤数据。 启用 ICP 的情况： 在索引扫描阶段，数据库引擎查找所有 customer_id = 123 的记录。 在查找过程中，引擎直接比较 order_date 的值，如果 order_date 不满足 order_date &gt; &#39;2023-01-01&#39; 的条件，引擎可以直接跳过该索引条目。 只有满足 customer_id = 123 且 order_date &gt; &#39;2023-01-01&#39; 的记录才会被回表读取。 总结通过在索引扫描阶段就应用部分查询条件，ICP 可以减少从表中读取数据的次数，从而提高查询性能。ICP 利用了索引的结构和特性，在索引扫描阶段直接比较索引字段的值，从而在不读取数据的情况下知道条件是否符合。这种优化技术特别适用于复合索引和范围查询，能够显著减少不必要的回表操作。 索引下推和最左匹配原则最左匹配原则只能按照从左到右一个个索引的匹配顺序进行索引查询，若只实现了部分索引查询，剩下的索引条件则全部失效，最后会扫描并查找所有符合部分索引的查询； 而索引下推则在扫描索引阶段应用所有索引条件，无需满足最左匹配原则，若不满足索引条件则直接扫描下一条索引记录。 区别 匹配顺序： 最左匹配原则要求查询条件从最左边的索引字段开始匹配，确保索引能够被有效利用。 索引下推（ICP）则允许在索引扫描阶段就应用部分查询条件，无需满足最左匹配原则。 应用阶段： 最左匹配原则主要关注查询条件的匹配顺序，确保查询条件从最左边的索引字段开始匹配。 索引下推（ICP）则关注在索引扫描阶段就应用部分查询条件，减少回表操作。 联系 联合索引的利用：最左匹配原则和 ICP 都依赖于联合索引的结构。最左匹配原则要求查询条件从最左边的索引字段开始匹配，而 ICP 则利用联合索引的有序性在索引扫描阶段应用部分查询条件。 提高查询性能：最左匹配原则和 ICP 都可以提高查询性能。最左匹配原则通过确保查询条件从最左边的索引字段开始匹配，使得数据库能够有效利用索引的有序性。ICP 则通过在索引扫描阶段就应用部分查询条件，减少回表操作，从而提高查询性能。 回表与覆盖索引回表根据索引的物理存储特性，索引可以分为聚簇索引和非聚簇索引。 聚簇索引：在B+树中存放的是一条完整的记录行，即索引和记录是放在一起的。因此，通过聚簇索引可以直接获取到完整的记录数据。 非聚簇索引：存放的是索引值和对应记录的聚簇索引地址。当通过非聚簇索引查找记录时，只能拿到指向对应记录的索引地址，然后需要根据这个地址再次查找聚簇索引，最终返回数据表中的完整记录。这个从非聚簇索引查找到聚簇索引后再次返回数据表进行查询的过程称为回表。 覆盖索引在使用非聚簇索引时，如果查询所需的所有数据都包含在非聚簇索引的记录中，那么就不需要进行回表操作，直接返回结果。这种情况称为覆盖索引。 覆盖索引的优势 减少I&#x2F;O操作：由于不需要回表，减少了额外的磁盘I&#x2F;O操作，提高了查询效率。 简化查询过程：查询可以直接从索引中获取所需数据，简化了查询过程。 实现覆盖索引的条件 查询字段包含在索引中：查询所需的所有字段都必须是索引的一部分。 避免回表：确保查询结果可以直接从索引中获取，而不需要额外的回表操作。 示例假设有一个表orders，包含字段order_id、customer_id和order_date，并且有一个联合索引(order_id, customer_id)。 非覆盖索引查询：SELECT * FROM orders WHERE order_id = 123。由于查询需要所有字段，而索引只包含order_id和customer_id，因此需要回表。 覆盖索引查询：SELECT order_id, customer_id FROM orders WHERE order_id = 123。由于查询的字段都包含在索引中，因此不需要回表，直接从索引中返回结果。 "},{"title":"MySQL-SQL基础","date":"2024-09-14T21:20:00.000Z","url":"/2024/09/15/MySQL-SQL%E5%9F%BA%E7%A1%80/","tags":[["MySQL基础","/tags/MySQL%E5%9F%BA%E7%A1%80/"]],"categories":[["数据库&缓存","/categories/%E6%95%B0%E6%8D%AE%E5%BA%93-%E7%BC%93%E5%AD%98/"],["MySQL","/categories/%E6%95%B0%E6%8D%AE%E5%BA%93-%E7%BC%93%E5%AD%98/MySQL/"]],"content":"在数据库管理中，SQL（Structured Query Language）是操作关系型数据库的核心工具。本文将深入探讨MySQL中的SQL基础知识，从数据库类型选择、设计范式、连接查询、数据插入、字符串类型、外键约束、关键字使用、内置函数、查询执行顺序、请求执行过程到存储引擎等多个方面进行详细解析。 SQL与NoSQL数据库概述SQL数据库SQL（Structured Query Language）代表关系型数据库管理系统（RDBMS），常见的代表包括SQL Server、Oracle、MySQL和PostgreSQL。关系型数据库以结构化方式存储数据，数据逻辑通过二维表（即行和列）来表示。每一列代表数据的属性，每一行则代表一个数据实体。 NoSQL数据库NoSQL（Not Only SQL）代表非关系型数据库，主要代表有MongoDB和Redis。NoSQL数据库不使用传统的二维表结构，而是采用如JSON文档、键值对、列族、图等多种数据模型来存储数据。 选择数据库的考量因素ACID与BASE关系型数据库通常支持ACID特性（原子性、一致性、隔离性、持久性），确保数据的强一致性和事务的完整性。而NoSQL数据库通常采用BASE模型（基本可用性、软状态、最终一致性），提供更高的灵活性和可扩展性，但可能在一致性方面有所妥协。 选择数据库时需根据具体应用场景来决定。例如，银行系统需要严格遵守ACID特性以防止资金重复使用，而社交软件则可以容忍一定程度的延迟和数据不一致。 扩展性NoSQL数据库由于其非关系型数据结构，数据之间通常不存在强关联，因此更容易实现水平扩展。例如，Redis提供了主从复制、哨兵模式和切片集群等扩展机制。 相比之下，SQL数据库中的数据可能存在复杂的关联关系，扩展时需要解决分布式事务等复杂问题。 数据库设计三大范式第一范式（1NF）第一范式要求数据库表中的每一列都必须是不可再分的原子项。这意味着每一列中的数据项必须是单一的、不可分割的值。 举例说明假设有一张表存储用户信息，其中包含“联系方式”列，该列包含电话和电子邮件。为了满足1NF，应将“联系方式”拆分为“电话”和“电子邮件”两列。 不满足1NF的表结构 用户ID 用户名 联系方式 1 张三 123-4567,&#122;&#104;&#97;&#110;&#x67;&#x73;&#x61;&#110;&#x40;&#x65;&#x78;&#97;&#109;&#112;&#108;&#101;&#x2e;&#x63;&#x6f;&#109; 2 李四 890-1234,&#108;&#105;&#x73;&#105;&#x40;&#x65;&#120;&#97;&#109;&#112;&#x6c;&#101;&#x2e;&#99;&#111;&#x6d; 满足1NF的表结构 用户ID 用户名 电话 电子邮件 1 张三 123-4567 &#x7a;&#x68;&#x61;&#110;&#x67;&#115;&#97;&#110;&#x40;&#x65;&#120;&#x61;&#x6d;&#112;&#x6c;&#x65;&#x2e;&#x63;&#111;&#109; 2 李四 890-1234 &#108;&#x69;&#x73;&#105;&#x40;&#x65;&#x78;&#x61;&#109;&#112;&#108;&#101;&#x2e;&#x63;&#111;&#109; 第二范式（2NF）第二范式在满足1NF的基础上，要求非主属性必须完全依赖于候选码（即主键）。换句话说，非主属性不能部分依赖于主键的一部分。 举例说明假设有一张订单表，主键为“订单ID”和“产品ID”。如果表中有一列“产品名称”，它只依赖于“产品ID”，而不依赖于“订单ID”，则该表不满足2NF。应将“产品名称”移到另一张产品表中。 不满足2NF的表结构 订单ID 产品ID 产品名称 数量 1 101 苹果 5 2 102 香蕉 3 3 101 苹果 2 满足2NF的表结构订单表 订单ID 产品ID 数量 1 101 5 2 102 3 3 101 2 产品表 产品ID 产品名称 101 苹果 102 香蕉 第三范式（3NF）第三范式在满足2NF的基础上，要求非主属性不依赖于其他的非主属性（即消除传递依赖）。 举例说明假设有一张员工表，包含“员工ID”、“员工姓名”、“部门ID”和“部门名称”。如果“部门名称”依赖于“部门ID”，而“部门ID”依赖于“员工ID”，则存在传递依赖，不满足3NF。应将“部门名称”移到另一张部门表中。 不满足3NF的表结构 员工ID 员工姓名 部门ID 部门名称 1 张三 D01 研发部 2 李四 D02 销售部 3 王五 D01 研发部 满足3NF的表结构员工表 员工ID 员工姓名 部门ID 1 张三 D01 2 李四 D02 3 王五 D01 部门表 部门ID 部门名称 D01 研发部 D02 销售部 数据库连接查询在数据库查询中，连接（Join）操作用于将两个或多个表中的数据组合在一起。常见的连接类型包括内连接、左外连接、右外连接和全外连接。以下是每种连接类型的详细说明及其SQL语法示例。 1. 内连接（Inner Join）内连接返回两个表中具有匹配关系的行。只有当两个表中的记录在连接条件上匹配时，才会返回结果。 示例解释 假设有两个表：Orders（订单表）和Customers（客户表），我们希望查询所有有订单的客户信息。 2. 左外连接（Left Outer Join）左外连接返回左表中的所有行，即使右表中没有匹配的行。对于右表中没有匹配的行，结果集中对应的数据为NULL。 示例解释 假设我们希望查询所有客户及其订单信息，包括那些没有订单的客户。 3. 右外连接（Right Outer Join）右外连接与左外连接相似，返回右表中的所有行，即使左表中没有匹配的行。对于左表中没有匹配的行，结果集中对应的数据为NULL。 示例解释 假设我们希望查询所有订单及其对应的客户信息，包括那些没有客户的订单。 4. 全外连接（Full Outer Join）全外连接返回两个表中的所有行，包括那些在另一个表中没有匹配的行。对于没有匹配的行，结果集中对应的数据为NULL。 示例解释 假设我们希望查询所有客户和订单的信息，包括那些没有订单的客户和没有客户的订单。 MySQL如何避免插入重复数据在MySQL中，有多种方法可以避免插入重复数据。以下是三种常见的方法及其详细说明。 方式一：使用UNIQUE约束UNIQUE约束用于确保表中某一列或一组列的值是唯一的。如果在插入数据时违反了UNIQUE约束，MySQL将拒绝插入该数据。 创建表时添加UNIQUE约束 如果尝试插入重复的email，MySQL将返回错误。 方式二：使用 INSERT ... ON DUPLICATE KEY UPDATEINSERT ... ON DUPLICATE KEY UPDATE语句在插入数据时，如果遇到重复键值（如UNIQUE约束或PRIMARY KEY），可以选择更新原有记录为新插入的记录。 插入或更新数据 如果product_id为1的记录已经存在，则更新其product_name和price字段。 方式三：使用 INSERT IGNOREINSERT IGNORE语句在插入数据时，如果遇到重复键值（如UNIQUE约束或PRIMARY KEY），将忽略该插入操作，不会抛出错误。 如果customer_id为1的记录已经存在，则忽略该插入操作，不会抛出错误。 MySQL中的字符串类型在MySQL中，字符串类型用于存储文本数据。常见的字符串类型包括CHAR、VARCHAR和TEXT。每种类型都有其特定的用途和存储特性。 CHARCHAR是一种固定长度的字符串类型。在定义时需要指定长度，存储时会在末尾填充空格以达到指定的长度。 特点 固定长度：无论实际存储的字符串长度如何，都会占用指定长度的存储空间。 存储效率：对于长度固定的字符串（如国家代码、性别等），CHAR类型可以提高存储效率。 VARCHARVARCHAR是一种可变长度的字符串类型。在定义时需要指定最大长度，存储时根据实际长度占用存储空间。 特点 可变长度：实际存储的字符串长度决定了占用的存储空间，节省存储空间。 灵活性：适用于长度不固定的字符串（如用户名、地址等）。 TEXTTEXT用于存储超长文本数据。TEXT类型有多种子类型，包括TEXT、MEDIUMTEXT和LONGTEXT，分别用于存储不同大小的文本。 特点 大容量存储：适用于存储大段文本（如文章内容、日志等）。 存储限制： TEXT：最大存储65,535字节（约64KB）。 MEDIUMTEXT：最大存储16,777,215字节（约16MB）。 LONGTEXT：最大存储4,294,967,295字节（约4GB）。 **CHAR**：适用于固定长度的字符串，存储效率高。 **VARCHAR**：适用于长度不固定的字符串，节省存储空间。 **TEXT**：适用于存储超长文本，有多种子类型满足不同存储需求。 根据具体需求选择合适的字符串类型，可以优化数据库的存储和查询性能。 外键约束外键约束（Foreign Key Constraint）是关系型数据库中用于维护表与表之间关系的一种机制。它确保数据的完整性和一致性，防止在关联表中插入无效数据。 作用 维护数据完整性：外键约束确保在子表中插入或更新的记录在父表中存在对应的记录。如果父表中不存在对应的记录，数据库将拒绝插入或更新操作。 防止无效数据：外键约束防止在子表中插入或更新无效数据，从而保持数据的正确性和一致性。 级联操作：外键约束可以配置级联操作，如级联删除（CASCADE DELETE）或级联更新（CASCADE UPDATE），以确保在父表中的记录被删除或更新时，子表中的相关记录也相应地被删除或更新。 假设有两个表：Orders（订单表）和Customers（客户表），我们希望在Orders表中定义一个外键约束，确保每个订单都关联到一个有效的客户。 MySQL关键字：IN 和 EXISTS在MySQL中，IN和EXISTS是两个常用的关键字，用于在查询中进行条件判断。它们各自有不同的用途和特点。 IN 关键字IN关键字用于检查左边的表达式是否存在于右边的列表或子查询中。如果存在，则返回true，否则返回false。 假设我们有一个Orders表，我们希望查询所有订单ID为1、2或3的订单。 或者使用子查询： EXISTS 关键字EXISTS关键字用于检查子查询是否至少返回一行数据。它不关心子查询返回的具体数据，只关注是否有返回数据。如果有返回数据，则返回true，否则返回false。 假设我们有一个Customers表和一个Orders表，我们希望查询所有有订单的客户。 区别与适用场景IN 适用场景 简单列表匹配：当需要检查某个值是否存在于一个固定的列表中时，IN非常适用。 子查询结果匹配：当需要检查某个值是否存在于子查询的结果集中时，IN也很适用。 EXISTS 适用场景 存在性检查：当只需要检查是否存在满足条件的记录，而不关心具体返回的数据时，EXISTS非常适用。 性能优化：在某些情况下，EXISTS的性能可能优于IN，特别是在子查询返回大量数据时。 MySQL基本函数MySQL提供了丰富的内置函数，用于处理字符串、数值、日期和聚合数据。以下是一些常用的MySQL函数及其说明。 字符串函数CONCAT(str1, str2, ...)连接多个字符串，返回拼接结果。 LENGTH(str)返回字符串的长度（字符数）。 SUBSTRING(str, start, length)从指定位置开始，截取指定长度的字符串。 REPLACE(str, from_str, to_str)将字符串中的指定字符替换为另一个字符。 数值函数ABS(num)返回数值的绝对值。 POWER(num, n)返回数值的n次幂。 日期函数NOW()返回当前日期和时间。 CURDATE()返回当前日期。 聚合函数COUNT(column)计算指定列中的非NULL值的个数。 SUM(column)计算指定列的总和。 AVG(column)计算指定列的平均值。 MAX(column)返回指定列的最大值。 MIN(column)返回指定列的最小值。 SQL查询执行顺序所有的查询语句都是从FROM开始执行，在执行过程中，每个步骤都会生成一个虚拟表，这个虚拟表将作为下一个执行步骤的输入，最后一个步骤产生的虚拟表即为输出结果。执行顺序如下： sql查询语句执行顺序注释： SQL请求执行过程详解 连接管理 连接器：客户端通过连接器与MySQL服务器建立连接。连接器负责验证客户端的身份和权限，并维护连接状态。 查询缓存 缓存查询：在MySQL 5.7及之前版本中，查询缓存功能默认关闭，而在MySQL 8.0中已被移除。如果查询缓存功能开启且命中缓存，服务器将直接返回缓存结果，从而提高查询效率。 语法解析 解析器：解析器负责对SQL语句进行词法和语法分析。词法分析确保SQL语句中的关键词和标识符正确无误，语法分析则验证SQL语句的结构是否符合语法规则。解析完成后，生成一棵语法树（AST）。 预处理 预处理阶段：预处理器对语法树进行进一步处理，检查表和字段是否存在，并验证SQL语句的语义正确性。此阶段还会处理SQL语句中的占位符，确保查询的完整性和一致性。 查询优化 优化器：优化器是SQL执行过程中的核心组件，负责选择最优的执行计划。优化器会评估多种可能的执行路径，并根据成本模型选择查询成本最小的执行计划。优化过程包括但不限于索引选择、表连接顺序优化、子查询优化等。 执行引擎 执行阶段：执行引擎根据优化器生成的执行计划，从存储引擎中读取数据。执行过程中，数据可能被缓存以提高后续查询的效率。最终，执行引擎将结果集返回给客户端。 MySQL存储引擎InnoDB 默认引擎：InnoDB是MySQL的默认存储引擎，适用于高并发场景。 事务支持：提供ACID（原子性、一致性、隔离性、持久性）事务特性，确保数据的一致性和完整性。 锁机制：支持行级锁，减少锁冲突，提高并发性能。 外键约束：支持外键约束，确保表之间的数据完整性。 MyISAM 存储优化：MyISAM具有较低的存储和内存消耗，适用于大量读操作的场景。 性能特点：不支持事务，没有行级锁和外键约束，因此在高并发写操作场景下性能较差。 适用场景：适合读密集型应用，如数据仓库、日志记录等。 Memory 内存存储：Memory引擎将数据存储在内存中，适用于需要快速读取的场景。 性能优势：由于数据存储在内存中，读取速度极快，适合临时数据存储和高频读取操作。 数据持久性：不支持事务、行级锁和外键索引。数据在服务器重启或崩溃时会丢失，因此不适合需要持久化的数据存储。 通过选择合适的存储引擎，可以根据应用的具体需求优化数据库性能和数据管理策略。InnoDB适用于需要高并发和事务支持的场景，MyISAM适合读密集型应用，而Memory引擎则适用于需要快速读取的临时数据存储。 数据文件在MySQL中，我们可以创建一个测试数据库test_db和一张测试表test_order。在数据库的存储路径下，可以看到以下三个文件： db.opt：该文件记录了当前数据库的默认字符集和校验规则。 test_order.frm：此文件存储了表的结构信息，包括字段定义、索引等，主要用于描述表的结构。 test_order.idb：所有的元数据和实际数据都存储在这个文件中，包括表的数据、索引等。 联合索引联合索引是由多个字段共同组成的索引。例如，索引可以基于字段A、B和C创建。联合索引的构建遵循最左匹配原则，即首先按照联合索引中的第一个字段进行分组排序，然后在此基础上按第二个字段分组排序，依此类推。 最左匹配原则最左匹配原则意味着查询必须从联合索引的最左边的字段开始匹配。例如，如果联合索引是基于字段A、B和C创建的，那么查询条件中必须包含字段A，才能利用该索引。如果查询条件只包含字段B和C，则无法利用该联合索引，因为往后的索引是全局无序的，而只是相对上一个字段局部有序。 索引区分度的重要性在构建联合索引时，优先选择区分度高的字段作为前缀。区分度的计算公式为：区分度 = (不同值的数量) / (总记录数)。区分度越高，索引的选择性越好，查询效率也越高。例如，使用性别作为联合索引的首个字段，由于其区分度极低（接近于0），即使通过索引找到了结果，由于是非聚簇索引，仍需执行回表操作，增加IO次数，因此不建议使用。 索引失效的情况从索引的物理存储特性来看，以下行为可能导致索引失效： 模糊查询：使用通配符开头的模糊查询（如LIKE &#39;%keyword&#39;）通常会导致索引失效，因为数据库无法利用索引来快速定位匹配的记录。 范围查询：在联合索引中，范围查询（如&gt;、&lt;、BETWEEN等）可能会导致后续字段的索引失效。例如，如果查询条件是A &gt; 10 AND B = 5，那么字段B的索引可能无法被有效利用。 函数操作：对索引字段进行函数操作（如LOWER(column)）会导致索引失效，因为数据库无法直接使用索引进行比较。 通过合理设计和使用联合索引，可以显著提高查询性能，减少数据库的I&#x2F;O操作。"},{"title":"Java并发编程-线程池篇","date":"2024-09-10T00:08:10.000Z","url":"/2024/09/10/Java%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B-%E7%BA%BF%E7%A8%8B%E6%B1%A0%E7%AF%87/","tags":[["线程池","/tags/%E7%BA%BF%E7%A8%8B%E6%B1%A0/"]],"categories":[["编程语言","/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"],["Java","/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Java/"],["并发编程","/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Java/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"]],"content":"Java 提供了强大的并发编程工具，其中线程池（ThreadPool）是管理和复用线程的核心机制。本文将深入探讨 Java 线程池的工作原理、核心组件、创建参数及其在实际应用中的使用场景。 线程池原理线程池是为了减少频繁创建和销毁线程带来的损耗，通过复用线程来提高系统的性能和稳定性。线程池的工作原理如下： 线程池的组成部分线程池主要由以下几个部分组成： 核心线程池：线程池中保持活跃的线程数量，即使这些线程处于空闲状态也不会被销毁。 线程池容量：线程池中允许的最大线程数量。 等待任务队列：当线程池中的线程都在执行任务时，新提交的任务会被放入等待任务队列中。 线程池的创建参数详解在 Java 中，ThreadPoolExecutor 是创建线程池的主要类。它提供了多个构造函数，其中最常用的是包含七个可选参数的构造函数。这些参数用于配置线程池的行为和特性。 以下是 ThreadPoolExecutor 构造函数的七个可选参数及其详细说明： 1. corePoolSize 类型：int 描述：核心线程池大小，即线程池中保持活跃的线程数量。即使这些线程处于空闲状态也不会被销毁。 默认值：无默认值，必须指定。 2. maximumPoolSize 类型：int 描述：线程池中允许的最大线程数量。当等待任务队列已满且核心线程池已满时，线程池会创建新的线程，直到达到最大线程数量。 默认值：无默认值，必须指定。 3. keepAliveTime 类型：long 描述：线程空闲时间，即当线程池中的线程数量超过核心线程池大小时，空闲线程在等待新任务的时间超过 keepAliveTime 后会被销毁。 默认值：无默认值，必须指定。 4. unit 类型：TimeUnit 描述：keepAliveTime 的时间单位，如秒、毫秒等。 默认值：无默认值，必须指定。 5. workQueue 类型：BlockingQueue&lt;Runnable&gt; 描述：等待任务队列，用于存放等待执行的任务。当线程池中的线程都在执行任务时，新提交的任务会被放入等待任务队列中。 默认值：无默认值，必须指定。 6. threadFactory 类型：ThreadFactory 描述：线程工厂，用于创建新的线程。可以通过自定义线程工厂来设置线程的名称、优先级等属性。 默认值：Executors.defaultThreadFactory()，使用默认的线程工厂。 7. handler 类型：RejectedExecutionHandler 描述：拒绝策略，当线程池容量已满且等待任务队列已满时，线程池会拒绝新提交的任务，并根据拒绝策略处理该任务。 默认值：AbortPolicy，直接抛出 RejectedExecutionException 异常。 以下是一个使用 ThreadPoolExecutor 创建线程池的示例代码： 线程池的工作流程工作流程如下图所示： 提交任务：当一个任务被提交到线程池时，线程池会首先检查核心线程池是否已满。 核心线程池是否已满： 如果核心线程池未满，线程池会创建一个新的线程来执行任务。 如果核心线程池已满，线程池会检查等待任务队列是否已满。 等待任务队列是否已满： 如果等待任务队列未满，线程池会将任务放入等待任务队列中。 如果等待任务队列已满，线程池会检查线程池容量是否已满。 线程池容量是否已满： 如果线程池容量未满，线程池会创建一个新的线程来执行任务。 如果线程池容量已满，线程池会拒绝任务，并根据拒绝策略处理该任务。 线程池的拒绝策略当线程池容量已满且等待任务队列已满时，线程池会拒绝新提交的任务。Java 提供了以下几种预置拒绝策略： AbortPolicy：默认策略，直接抛出 RejectedExecutionException 异常。 CallerRunsPolicy：由提交任务的线程执行该任务。 DiscardPolicy：直接丢弃任务，不抛出异常。 DiscardOldestPolicy：丢弃等待队列中最旧的任务，然后尝试重新提交当前任务。 其他线程池参数设置在设置线程池参数时，需要根据具体的应用场景和任务类型来调整线程池的核心线程数、最大线程数、等待任务队列和拒绝策略等参数。以下是一些常见的线程池参数设置建议。 CPU 密集型任务：对于 CPU 密集型任务，线程池的核心线程数可以设置为 CPU 核数加 1。这样可以确保线程池中的线程数量与 CPU 核心数量相匹配，避免过多的线程竞争 CPU 资源。 IO 密集型任务：对于 IO 密集型任务，线程池的核心线程数可以设置为 CPU 核数的两倍。这样可以确保线程池中有足够的线程来处理 IO 操作，避免线程等待 IO 操作完成时阻塞。 核心线程数可以设置为 0 吗？可以。将核心线程数设置为 0 时，线程池在初始状态下不会创建任何线程。当有任务提交时，任务会先进入等待任务队列。当等待任务队列已满时，线程池才会创建新的线程来执行任务。 线程池的种类在 Java 中，java.util.concurrent 包提供了多种线程池的实现，每种线程池都有其特定的用途和特点。以下是常见的几种线程池及其特点： ScheduledThreadPool ScheduledThreadPool 是一种可以设置定期执行任务的线程池。它允许你安排任务在给定的延迟后执行，或者定期重复执行。 特点 定期执行任务：可以设置任务在给定的延迟后执行，或者定期重复执行。 核心线程数固定：核心线程数和最大线程数相同。 FixedThreadPool FixedThreadPool 是一种核心线程数和最大线程数相同的线程池。它适用于需要固定数量线程来处理任务的场景。 特点 固定线程数：核心线程数和最大线程数相同。 等待任务队列：使用 LinkedBlockingQueue，容量为 Integer.MAX_VALUE。 CachedThreadPool CachedThreadPool 是一种可以成为缓存线程池的线程池。它的任务等待队列为 SynchronousQueue，容量为 0，仅做任务流转，效率很高。它的特点在于线程数可以一直增加，甚至达到 Integer.MAX_VALUE（即 2^31-1）。 特点 动态线程数：线程数可以一直增加，直到达到 Integer.MAX_VALUE。 等待任务队列：使用 SynchronousQueue，容量为 0，仅做任务流转。 SingleThreadExecutor SingleThreadExecutor 是一种只有一个线程的线程池。它适用于需要顺序执行任务的场景。 特点 单线程：只有一个线程，任务按顺序执行。 等待任务队列：使用 LinkedBlockingQueue，容量为 Integer.MAX_VALUE。 SingleThreadScheduledExecutor SingleThreadScheduledExecutor 是一种只有一个线程的线程池，可以设置定期执行任务。 特点 单线程：只有一个线程，任务按顺序执行。 定期执行任务：可以设置任务在给定的延迟后执行，或者定期重复执行。 shutdown 和 shutdownNow 方法详解在 Java 中，ThreadPoolExecutor 提供了两种关闭线程池的方法：shutdown 和 shutdownNow。这两种方法用于优雅地关闭线程池，但它们的行为有所不同。 shutdown 方法shutdown 方法用于优雅地关闭线程池。它会将状态置为SHUTDOWN，拒绝新提交的任务，但会等待当前正在执行的任务和已经在等待队列中的任务完成后再关闭线程池。 以下是 ThreadPoolExecutor 类中 shutdown 方法的源码： 关键步骤 获取锁：获取线程池的主锁 mainLock。 检查权限：调用 checkShutdownAccess() 方法检查是否有权限关闭线程池。 更新状态：调用 advanceRunState(SHUTDOWN) 方法将线程池的状态更新为 SHUTDOWN。 中断空闲线程：调用 interruptIdleWorkers() 方法中断所有空闲的线程。 调用钩子方法：调用 onShutdown() 方法，这是一个钩子方法，用于在关闭线程池时执行一些自定义操作。 释放锁：释放线程池的主锁 mainLock。 尝试终止：调用 tryTerminate() 方法尝试终止线程池。 shutdownNow 方法shutdownNow 方法用于立即关闭线程池。它会立即将线程池的状态设置为 STOP，并尝试中断所有正在执行的任务，同时返回等待队列中尚未执行的任务列表。 shutdownNow 试图通过调用 Thread.interrupt() 方法来终止线程。然而，这种方法的效果有限，如果线程中没有使用 sleep、wait、condition、定时锁等阻塞操作，interrupt() 方法可能无法中断当前的线程。因此，shutdownNow 并不保证线程池能够立即退出，它可能需要等待所有正在执行的任务完成才能真正退出。 以下是 ThreadPoolExecutor 类中 shutdownNow 方法的源码： 关键步骤 获取锁：获取线程池的主锁 mainLock。 检查权限：调用 checkShutdownAccess() 方法检查是否有权限关闭线程池。 更新状态：调用 advanceRunState(STOP) 方法将线程池的状态更新为 STOP。 中断所有线程：调用 interruptWorkers() 方法中断所有线程，包括正在执行任务的线程。 清空等待队列：调用 drainQueue() 方法清空等待队列，并返回尚未执行的任务列表。 释放锁：释放线程池的主锁 mainLock。 尝试终止：调用 tryTerminate() 方法尝试终止线程池。 提交到线程池的任务可以撤回？是的，当向线程池提交任务时，会得到一个 Future 对象。这个 Future 对象提供了几种方法来管理任务的执行，包括取消任务。取消任务的主要方法是 Future 接口中的 cancel(boolean mayInterruptIfRunning) 方法。这个方法尝试取消执行的任务。参数 mayInterruptIfRunning 指示是否允许中断正在执行的任务。 Future 接口Future 接口表示一个异步计算的结果。它提供了以下几个主要方法： **cancel(boolean mayInterruptIfRunning)**：尝试取消任务的执行。 **isCancelled()**：判断任务是否已被取消。 **isDone()**：判断任务是否已完成（包括正常完成、异常完成或被取消）。 **get()**：获取任务的执行结果，如果任务尚未完成，则阻塞等待。 **get(long timeout, TimeUnit unit)**：在指定时间内获取任务的执行结果，如果任务尚未完成，则阻塞等待。 多线程场景示例：按照顺序打印奇偶数在多线程编程中，实现按照顺序打印奇偶数是一个常见的场景。可以通过使用 synchronized 关键字、Lock 接口或 Semaphore 等同步机制来实现线程间的协作。 方法一：使用 synchronized 关键字实现思路 使用 synchronized 关键字同步两个线程的执行。 通过一个共享的变量来控制打印奇数和偶数的顺序。 输出结果 方法二：使用 Lock 接口和 Condition实现思路 使用 ReentrantLock 来实现线程间的同步。 使用 Condition 来控制线程的等待和唤醒。 示例代码 输出结果 方法三：使用 Semaphore实现思路 使用两个 Semaphore 来控制线程的执行顺序。 一个 Semaphore 用于控制奇数线程的执行，另一个 Semaphore 用于控制偶数线程的执行。 示例代码 输出结果 "},{"title":"Java并发编程-并发安全篇","date":"2024-09-10T00:08:09.000Z","url":"/2024/09/10/Java%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B-%E5%B9%B6%E5%8F%91%E5%AE%89%E5%85%A8%E7%AF%87/","tags":[["并发安全","/tags/%E5%B9%B6%E5%8F%91%E5%AE%89%E5%85%A8/"]],"categories":[["编程语言","/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"],["Java","/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Java/"],["并发编程","/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Java/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"]],"content":"Java提供了多种机制来保证线程安全，包括内置锁、显式锁、原子类、线程局部变量和并发集合等。本文将深入探讨Java中的并发安全机制，涵盖线程同步、锁机制、原子操作、线程局部变量以及并发集合等内容。 如何保证多线程安全在 Java 中，保证多线程安全主要有以下几种方式： 1.synchronized 关键字 使用 synchronized 关键字来同步代码块或方法，确保同一时刻只有一个线程能访问这些代码。 优点：简单易用，适用于简单的同步需求。 缺点：可能会导致性能问题，特别是在高并发场景下。可能会导致死锁。 2. volatile 关键字 使用 volatile 关键字，确保所有的线程都能看到该变量的最新值，而不是可能存储在本地寄存器中的副本。 优点：确保变量的可见性，适用于简单的状态标志。 缺点：不能保证复合操作的原子性，如 count++。 3. Lock 接口和 ReentrantLock 类 使用 Lock 接口和 ReentrantLock 类来实现更灵活的锁机制。 优点：提供更灵活的锁机制，支持可中断锁、公平锁等。 缺点：需要手动管理锁的获取和释放，容易出错。 4. 原子类 Java 并发库提供了原子类，这些类提供原子操作，可以用来更新基本数据类型而无需同步。 优点：提供原子操作，无需手动同步。 缺点：仅适用于基本数据类型的原子操作。 5. 线程局部变量 ThreadLocal 可以为每个线程创建独立的副本，这样每个副本都拥有自己的变量，消除竞争条件。 优点：每个线程拥有独立的变量副本，消除竞争条件。 缺点：可能会导致内存泄漏，特别是在线程池中使用时。 6. 并发集合 java.util.concurrent 包中提供了线程安全的集合，已实现线程安全逻辑。 优点：提供线程安全的集合操作，无需手动同步。 缺点：可能会导致性能问题，特别是在高并发场景下。 总结 synchronized 关键字：适用于简单的同步需求，但可能会导致性能问题和死锁。 volatile 关键字：确保变量的可见性，适用于简单的状态标志。 Lock 接口和 ReentrantLock 类：提供更灵活的锁机制，但需要手动管理锁的获取和释放。 原子类：提供原子操作，无需手动同步，但仅适用于基本数据类型的原子操作。 **线程局部变量 ThreadLocal**：每个线程拥有独立的变量副本，消除竞争条件，但可能会导致内存泄漏。 并发集合：提供线程安全的集合操作，无需手动同步，但可能会导致性能问题。 Java 中常用的锁及其使用场景在 Java 中，锁是用于管理多线程并发访问共享资源的关键机制。锁可以确保在任意给定时间内只有一个线程可以访问特定的资源，从而避免数据竞争和不一致性。Java 提供了多种锁机制，以下是常用的锁及其使用场景： 1. 内置锁 (synchronized) synchronized 关键字是 Java 内置的锁机制，可以用于方法或代码块。当一个线程进入 synchronized 代码块或方法时，它会获取关联对象的锁；当线程离开该代码块或方法时，锁会被释放。 优点：简单易用，适用于简单的同步需求。 缺点：可能会导致性能问题，特别是在高并发场景下。可能会导致死锁。 使用场景：适用于简单的同步需求，如单个对象的同步访问。 示例代码： 2. ReentrantLock java.util.concurrent.locks.ReentrantLock 是一个显式的锁类，提供了比 synchronized 更高级的功能，如可中断的锁等待、定时锁等待、公平锁选项等。 优点：提供更灵活的锁机制，支持可中断锁、公平锁等。 缺点：需要手动管理锁的获取和释放，容易出错。 使用场景：适用于需要更高级锁功能的场景，如可中断锁、公平锁等。 示例代码： 3. 读写锁 (ReadWriteLock) java.util.concurrent.locks.ReadWriteLock 接口定义了一种锁，允许多个读取者同时访问共享资源，但只允许一个写入者。 优点：适用于读取远多于写入的场景，提高并发性。 缺点：实现复杂，需要管理读锁和写锁的获取和释放。 使用场景：适用于读取操作远多于写入操作的场景，如缓存系统。 示例代码： 4. 乐观锁和悲观锁 **悲观锁 (Pessimistic Locking)**：在访问数据前就锁定资源，假设最坏的情况即数据很可能被其他线程修改。synchronized 和 ReentrantLock 都是悲观锁的例子。 **乐观锁 (Optimistic Locking)**：通常不锁定资源，而是在更新数据时检查数据是否已被其他线程修改。乐观锁常使用版本号或时间戳来实现。 优点：乐观锁适用于冲突较少的场景，减少锁的开销；悲观锁适用于冲突较多的场景，确保数据一致性。 缺点：乐观锁在冲突较多时性能较差；悲观锁在冲突较少时性能较差。 使用场景： 乐观锁适用于读多写少的场景，如版本控制系统。 悲观锁适用于写操作频繁的场景，如数据库事务。 示例代码： 5. 自旋锁 自旋锁是一种锁机制，线程在等待锁时会持续循环检查锁是否可用，而不是放弃 CPU 并阻塞。通常可以使用 CAS（Compare-And-Swap）来实现。 优点：在锁等待时间很短的情况下可以提高性能。 缺点：过度自旋会浪费 CPU 资源。 使用场景：适用于锁等待时间很短的场景，如轻量级同步。 示例代码： 总结 **内置锁 (synchronized)**：适用于简单的同步需求，但可能会导致性能问题和死锁。 **ReentrantLock**：提供更灵活的锁机制，但需要手动管理锁的获取和释放。 **读写锁 (ReadWriteLock)**：适用于读取操作远多于写入操作的场景，提高并发性。 乐观锁和悲观锁：乐观锁适用于冲突较少的场景，悲观锁适用于冲突较多的场景。 自旋锁：适用于锁等待时间很短的场景，但过度自旋会浪费 CPU 资源。 什么是可重入锁可重入锁（Reentrant Lock）是指同一个线程在获取了锁之后，可以再次重复获取该锁而不会造成死锁或其他问题。当一个线程持有锁时，如果再次尝试获取该锁，就会成功获取而不会被阻塞。 可重入锁的工作原理ReentrantLock 实现可重入锁的机制是基于线程持有锁的计数器。具体工作原理如下： 计数器初始化：当一个线程第一次获取锁时，计数器会加 1，表示该线程持有了锁。 重复获取锁：在此之后，如果同一个线程再次获取锁，计数器会再次加 1。每次线程成功获取锁时，都会将计数器加 1。 释放锁：当线程释放锁时，计数器会相应地减 1。只有当计数器减到 0 时，锁才会完全释放，其他线程才有机会获取锁。 避免死锁：这种计数器的设计使得同一个线程可以多次获取同一个锁，而不会造成死锁或其他问题。每次获取锁时计数器加 1；每次释放锁时，计数器减 1。只有当计数器减到 0 时，锁才会完全释放。 synchronized 和 ReentrantLock 的区别synchronized 工作原理synchronized 是 Java 提供的原子性内置锁，这种内置的并且使用者看不到的锁也被称为监视器锁。使用 synchronized 之后，会在编译之后在同步的代码块前后加上 monitorenter 和 monitorexit 字节码指令，它依赖操作系统底层互斥锁实现。它的作用主要就是实现原子性操作和解决共享变量的内存可见性问题。 工作原理： 执行 monitorenter 指令时会尝试获取对象锁，如果对象没有被锁定或者已经获得了锁，锁的计数器 +1。此时其他竞争锁的线程则会进入等待队列中。 执行 monitorexit 指令时则会把计数器 -1，当计数器值为 0 时锁释放，处于等待队列中的线程再继续竞争锁。 特点： synchronized 是排它锁，当一个线程获得锁之后，其他线程必须等待该线程释放锁后才能获得锁。 由于 Java 中的线程和操作系统原生线程是一一对应的，线程被阻塞或者唤醒时会从用户态切换到内核态，这种转换非常消耗性能。 从内存语义来说，加锁的过程会清除工作内存中的共享变量，再从主内存读取，而释放锁的过程则是将工作内存中的共享变量写回主内存。 ReentrantLock 工作原理ReentrantLock 的底层实现主要依赖于 AbstractQueuedSynchronizer (AQS) 这个抽象类。AQS 是一个提供了基本同步机制的框架，其中包括了队列、状态值等。 工作原理： ReentrantLock 在 AQS 的基础上通过内部类 Sync 来实现具体的锁操作。不同的 Sync 子类实现了公平锁和非公平锁的不同逻辑。 ReentrantLock 提供了更灵活的锁机制，支持可中断的锁等待、定时锁等待、公平锁选项等。 特点： 可见性：ReentrantLock 通过 volatile 变量来保证锁状态的可见性。 设置超时时间：ReentrantLock 支持在获取锁时设置超时时间，避免无限等待。 公平锁和非公平锁：ReentrantLock 提供了公平锁和非公平锁的选项，公平锁按照线程请求锁的顺序来分配锁，非公平锁不保证锁分配的顺序。 多个条件变量：ReentrantLock 支持多个条件变量，可以更细粒度地控制线程的等待和唤醒。 可重入性：ReentrantLock 支持可重入性，即同一个线程可以多次获取同一个锁。 区别synchronized 和 ReentrantLock 都是 Java 中提供的可重入锁，但它们在用法、获取和释放锁的方式、锁类型、响应中断以及底层实现等方面存在显著差异。 1.用法不同 **synchronized**：可以用来修饰普通方法、静态方法和代码块。 **ReentrantLock**：只能用在代码块中。 2.获取锁和释放锁方式不同 **synchronized**：会自动加锁和释放锁。当进入 synchronized 修饰的代码块之后会自动加锁，当离开 synchronized 的代码段之后会自动释放锁。 **ReentrantLock**：需要手动加锁和释放锁。通过 lock() 方法获取锁，通过 unlock() 方法释放锁。 3.锁类型不同 **synchronized**：属于非公平锁。 **ReentrantLock**：既可以是公平锁也可以是非公平锁。通过构造函数可以指定锁的类型。 4.响应中断不同 **ReentrantLock**：可以响应中断，解决死锁的问题。通过 lockInterruptibly() 方法可以实现可中断的锁等待。 **synchronized**：不能响应中断。 5.底层实现不同 **synchronized**：是 JVM 层面通过监视器（Monitor）实现的。在编译后的字节码中会生成 monitorenter 和 monitorexit 指令。 **ReentrantLock**：是基于 AQS（AbstractQueuedSynchronizer）实现的。AQS 是一个提供了基本同步机制的框架，其中包括了队列、状态值等。 总结 **synchronized**：适用于简单的同步需求，自动获取和释放锁，但可能导致性能问题和死锁。 **ReentrantLock**：提供更灵活的锁机制，支持可中断锁、公平锁、超时设置等，但需要手动管理锁的获取和释放。 synchronized 锁升级过程synchronized 锁在 Java 中的升级过程是一个逐步优化的过程，从无锁状态到偏向锁、轻量级锁，最终升级为重量级锁。这个过程旨在根据不同的竞争情况，动态调整锁的实现方式，以提高性能。 锁升级过程1. 无锁状态 描述：这是还没有开启偏向锁时的状态。JVM 启动后会有一个偏向延时，延迟一段时间后才会开启偏向锁。 特点：无锁状态下，对象的 Mark Word 中存储的是对象的哈希码和分代年龄等信息。 2. 偏向锁 描述：偏向锁开启后的锁状态。如果无线程拿到该锁，这个状态叫匿名偏向。当一个线程想要竞争该锁时，只需要拿线程 ID 和 Mark Word 中存储的线程 ID 比较，如果线程 ID 相同则直接获取锁（即锁偏向于这个线程），不需要进行 CAS 操作和将线程挂起。 特点：偏向锁减少了无竞争情况下的锁开销，适用于单线程访问的场景。 3. 轻量级锁 描述：在这个状态下，线程主要通过 CAS（Compare-And-Swap）操作实现。将对象的 Mark Word 存储到线程的虚拟栈上，然后将对象的 Mark Word 更新为指向线程栈中锁记录的指针。 特点：轻量级锁适用于竞争不激烈的场景，通过 CAS 操作避免了线程挂起和唤醒的开销。 4. 重量级锁 描述：当两个以上的线程获取锁时，轻量级锁就会升级为重量级锁。因为 CAS 操作如果没有成功的话，线程会自旋等待，进行 while 循环操作，非常消耗 CPU 资源。 特点：重量级锁通过操作系统底层的互斥锁实现，适用于高并发竞争场景。 锁升级的触发条件 无锁到偏向锁：JVM 启动后经过偏向延时，默认情况下偏向锁是开启的。 偏向锁到轻量级锁：当有其他线程尝试获取偏向锁时，偏向锁会升级为轻量级锁。 轻量级锁到重量级锁：当多个线程竞争同一个锁时，轻量级锁会升级为重量级锁。 synchronized 锁的升级过程是一个动态优化的过程，从无锁状态到偏向锁、轻量级锁，最终升级为重量级锁。这个过程根据不同的竞争情况，动态调整锁的实现方式，以提高性能。 总结 无锁状态：JVM 启动后经过偏向延时，默认情况下偏向锁是开启的。 偏向锁：减少了无竞争情况下的锁开销，适用于单线程访问的场景。 轻量级锁：通过 CAS 操作避免了线程挂起和唤醒的开销，适用于竞争不激烈的场景。 重量级锁：通过操作系统底层的互斥锁实现，适用于高并发竞争场景。 AQSAbstractQueuedSynchronizer（简称 AQS）是 Java 中的一个抽象类，是用于构建锁、同步器、协作工具类的工具类（框架）。AQS 提供了一个基于 FIFO 队列的阻塞锁和相关的同步器（如信号量、事件等）的框架，是 Java 并发包（java.util.concurrent）的基础。 AQS 的核心思想AQS 的核心思想是，如果当前请求的资源空闲，那么就将当前请求资源的线程设置为有效工作线程，将共享资源锁定；如果资源被占用，就需要一定的等待阻塞唤醒机制来保证锁的分配。这个机制主要用的是 CLH 队列变体实现的，将暂时获取不到锁的线程加入到队列中。 CLH 队列CLH（Craig, Landin, and Hagersten）队列是一种基于链表的自旋锁队列。AQS 使用 CLH 队列的变体来管理等待线程的队列。 AQS 的核心组成部分AQS 最核心的就是三大部分： 状态（State）： AQS 使用一个 volatile 的 int 类型的成员变量 state 来表示同步状态。state 的值可以表示锁的状态、信号量的计数等。 通过 getState()、setState() 和 compareAndSetState() 方法来操作 state 的值。 FIFO 队列： AQS 内置了一个 FIFO 队列来管理等待线程。当线程获取锁失败时，会被加入到这个队列中等待。 队列中的每个节点代表一个等待线程，节点之间通过 prev 和 next 指针连接。 获取&#x2F;释放操作（重写）： AQS 定义了获取和释放资源的方法，但具体的实现需要子类去重写。 子类需要实现 tryAcquire()、tryRelease()、tryAcquireShared()、tryReleaseShared() 等方法，来定义资源的获取和释放逻辑。 AQS 的工作原理 获取资源： 线程调用 acquire() 方法尝试获取资源。 如果 tryAcquire() 返回 true，表示获取成功，线程继续执行。 如果 tryAcquire() 返回 false，表示获取失败，线程会被加入到等待队列中，并进入阻塞状态。 释放资源： 线程调用 release() 方法释放资源。 如果 tryRelease() 返回 true，表示释放成功，AQS 会唤醒等待队列中的一个或多个线程，让它们重新竞争资源。 以下是一个简单的自定义锁的示例，展示了如何使用 AQS 实现一个独占锁： ThreadLocal 详解ThreadLocal 是 Java 中为了线程安全设置的一种机制，每个线程可以设置局部变量，也就是允许设置自己线程的一个数据副本，线程对副本的修改不会影响到线程间的资源共享和同步问题。 ThreadLocal 的作用 线程隔离：每个线程都有自己独立的 ThreadLocal 变量副本，线程之间的数据互不影响。 降低耦合度：在同一个线程的多个函数或组件之间，使用 ThreadLocal 可以减少参数的传递，降低代码之间的耦合度，使得模块清晰化。 性能优势：由于 ThreadLocal 避免了线程间的同步开销，所以大量线程并发执行时，相比传统的锁机制，它可以提供更好的性能。 ThreadLocal 的原理ThreadLocal 的实现依赖于 Thread 类中的一个 ThreadLocalMap 字段，这是一个存储 ThreadLocal 变量本身和对应值的映射。每个线程都有自己的 ThreadLocalMap 实例，用于存储该线程所持有的所有 ThreadLocal 变量的值。 核心操作 get() 方法： 当调用 ThreadLocal 的 get() 方法时，ThreadLocal 会检查当前线程的 ThreadLocalMap 中是否有与之关联的值。 如果有，则返回值；如果没有，会调用 initialValue() 方法初始化该值，然后将其放入 ThreadLocalMap 中并返回。 set() 方法： 当调用 set() 方法时，ThreadLocal 会将当前线程与给定的值关联起来，即向 ThreadLocalMap 中存入键值对，键为当前 ThreadLocal 对象本身，值为给定的值。 remove() 方法： 当调用 remove() 方法时，ThreadLocal 会从当前线程的 ThreadLocalMap 中移除与当前 ThreadLocal 对象关联的键值对。 可能存在的问题内存泄漏问题 原因：ThreadLocalMap 中的 Entry 对象持有对 ThreadLocal 对象的强引用，如果 ThreadLocal 对象没有被显式移除，即使线程结束，Entry 对象仍然存在，导致 ThreadLocal 对象无法被垃圾回收。 解决方法：在不再需要 ThreadLocal 变量时，显式调用 remove() 方法，确保 ThreadLocal 对象能够被及时回收。 以下是一个简单的示例代码，展示了 ThreadLocal 的使用： 乐观锁&#x2F;悲观锁乐观锁总是假设最好的情况，认为共享资源每次被访问的时候不会出现问题，线程可以不停地执行，无需加锁也无需等待，只是在提交修改的时候去验证对应的资源（也就是数据）是否被其它线程修改了（具体方法可以使用版本号机制或 CAS 算法），如果没有被修改，则更新资源；如果被修改，则重试操作。 悲观锁总是假设最坏的情况，认为共享资源每次被访问的时候就会出现问题(比如共享数据被修改)，所以每次在获取资源操作的时候都会上锁，这样其他线程想拿到这个资源就会阻塞直到锁被上一个持有者释放。也就是说，共享资源每次只给一个线程使用，其它线程阻塞，用完后再把资源转让给其它线程。 Java 实现乐观锁的方式在 Java 中，实现乐观锁的方式主要有以下几种： CAS（Compare-and-Swap）操作 CAS 是乐观锁的基础，Java 提供了原子类包（java.util.concurrent.atomic），包含各种原子变量类操作，这些类通过使用 CAS 操作方式，实现了线程安全的原子操作，可用来实现乐观锁。 以下是一个使用 AtomicInteger 实现乐观锁的示例代码： 2. 版本号控制 增加一个字段记录更新的版本，每次更新递增版本号。在更新时，同时比较版本号，如果一致则替换更新完成，若不一致则更新失败。 以下是一个使用版本号控制实现乐观锁的示例代码： 时间戳 使用时间戳记录更新时的时间，每次更新时比较时间戳，如果一致则替换更新完成，若不一致则更新失败。 以下是一个使用时间戳实现乐观锁的示例代码： CAS 的缺点CAS（Compare-and-Swap）操作是实现乐观锁的基础，但它也存在一些缺点，主要包括以下三个方面： ABA 问题 ABA 问题是指在 CAS 操作中，一个变量在操作过程中经历了从 A 到 B 再回到 A 的变化，而 CAS 操作只比较变量的当前值和预期值是否一致，无法检测到这种中间变化。 解决方案 版本号：在变量中增加一个版本号字段，每次更新时递增版本号，CAS 操作同时比较变量值和版本号。 时间戳：使用时间戳记录变量的更新时间，CAS 操作同时比较变量值和时间戳。 循环时间过长 若 CAS 无法更新成功，线程会一直自旋（循环），长时间占用 CPU 资源，带来无用的花销。这也就造成了不能所有锁都使用CAS。 解决方案 自旋次数限制：设置自旋次数上限，超过次数后放弃自旋，进入阻塞状态。 自旋时间限制：设置自旋时间上限，超过时间后放弃自旋，进入阻塞状态。 只能保证一个共享变量的原子性 CAS 操作只能保证单个共享变量的原子性，无法保证多个共享变量的原子性。 解决方案 锁机制：使用 synchronized 或 ReentrantLock 等锁机制，保证多个共享变量的原子性。 组合操作：将多个共享变量封装在一个对象中，使用 AtomicReference 进行 CAS 操作。 volatilevolatile 是 Java 中的一个关键字，主要用于修饰变量。它具有两个主要作用：保证变量对所有线程的可见性和禁止指令重排序优化。 保证变量对所有线程的可见性当一个变量被声明为 volatile 时，它会保证对这个变量的写操作会立即刷新到主存中，而对这个变量的读操作会直接从主存中读取，从而确保了多线程环境下对该变量访问的可见性。这意味着一个线程修改了 volatile 变量的值，其他线程能够立刻看到这个修改，不会受到各自线程工作内存的影响。 禁止指令重排序优化volatile 关键字在 Java 中主要通过内存屏障来禁止特定类型的指令重排序。内存屏障分为以下几种： 写-写（Write-Write）屏障： 在对 volatile 变量执行写操作之前，会插入一个写屏障。这确保了在该变量写操作之前的所有普通写操作都已完成，防止了这些写操作被移到 volatile 写操作之后。 读-写（Read-Write）屏障： 在对 volatile 变量执行读操作之后，会插入一个读屏障。它确保了对 volatile 变量的读操作之后的所有普通读操作都不会被提前到 volatile 读之前执行，保证了读取到的数据是最新的。 写-读（Write-Read）屏障： 这是最重要的一个屏障，它发生在 volatile 写之后和 volatile 读之前。这个屏障确保了 volatile 写操作之前的所有内存操作（包括写操作）都不会被重排序到 volatile 读之后，同时也确保了 volatile 读操作之后的所有内存操作（包括读操作）都不会被重排序到 volatile 写之前。 volatile 不能完全保证线程安全volatile 关键字在 Java 中主要用于保证变量对所有线程的可见性和禁止指令重排序优化。然而，volatile 并不能完全保证线程安全，因为它没有保证数据操作的原子性。在多线程环境下，进行复合操作（如自增、自减等，自增、自减包含读取、修改和写入三个步骤，可能会出现覆盖问题）时，volatile 无法保证操作的原子性，因此可能会导致线程安全问题。 保证线程安全的解决方案为了保证复合操作的线程安全，可以使用以下方法： synchronized 关键字：使用 synchronized 关键字来同步代码块或方法，确保同一时刻只有一个线程能访问这些代码。 Lock 接口和 ReentrantLock 类：使用 Lock 接口和 ReentrantLock 类来实现更灵活的锁机制，确保同一时刻只有一个线程能访问这些代码。 原子类：使用 java.util.concurrent.atomic 包中的原子类（如 AtomicInteger）来实现原子操作，确保操作的原子性。 指令重排的原理在执行程序时，为了提高性能，处理器和编译器往往会对指令进行重排优化。指令重排的目的是在不改变程序运行结果的前提下，优化指令的执行顺序，以提高处理器的执行效率。 指令重排的原则指令重排遵循以下两个原则： 不能改变程序的运行结果：指令重排不能改变单线程程序的运行结果。也就是说，无论指令如何重排，单线程程序的执行结果必须保持一致。 存在依赖关系的指令不能进行重排：如果两条指令之间存在数据依赖关系（即一条指令的执行结果会影响另一条指令的执行），那么这两条指令不能进行重排。 指令重排的类型指令重排可以分为以下几种类型： 编译器重排：编译器在生成机器码时，可能会对指令进行重排，以优化代码的执行顺序。 处理器重排：处理器在执行指令时，可能会对指令进行重排，以提高指令流水线的效率。 指令重排的示例以下是一个简单的示例代码，展示了指令重排的效果： 在这个示例中，t1 线程中的两条指令 a = 1 和 b = 2 之间没有数据依赖关系，因此编译器和处理器可能会对这两条指令进行重排。重排后的执行顺序可能是 b = 2 先执行，a = 1 后执行。 指令重排的影响指令重排在单线程环境下通常不会影响程序的运行结果，但在多线程环境下可能会导致不可预期的结果。例如，在上述示例中，如果 t2 线程在 t1 线程完成 a = 1 之前读取了 b 的值，那么 t2 线程可能会输出 x = 2, y = 0，这与预期的 x = 2, y = 1 不一致。 公平锁与非公平锁在多线程编程中，锁机制是保证线程安全的重要手段。根据线程获取锁的顺序，锁可以分为公平锁和非公平锁。 公平锁公平锁（Fair Lock）是指多个线程按照申请锁的顺序来获取锁，线程直接进入队列中排队，队列中的第一个线程才能获得锁。 流程 获取锁: 线程尝试获取锁，若锁已被占用，则将自身加入等待队列队尾，并进入休眠状态。 释放锁: 持有锁的线程释放锁后，会唤醒等待队列队首的线程，该线程尝试获取锁。 状态切换: 线程在运行和休眠状态之间切换，每次切换都需要进行用户态和内核态的转换，这种转换开销较大，导致公平锁执行速度较慢。 非公平锁非公平锁（Non-Fair Lock）是指多个线程加锁时直接尝试获取锁，能抢到锁的线程直接占有锁，抢不到才会到等待队列的队尾等待。 流程 获取锁: 线程尝试通过CAS操作直接获取锁，若成功则直接持有锁，无需进入等待队列。 竞争锁: 若CAS失败，线程才会进入等待队列，等待下次获取锁的机会。 效率提升: 非公平锁避免了线程频繁的休眠和唤醒操作，减少了用户态和内核态的切换开销，从而提高了程序执行效率。 对比公平锁与非公平锁的优缺点对比: 特性 公平锁 非公平锁 获取锁顺序 严格按照等待队列顺序 不保证顺序，可能出现“插队”现象 吞吐量 较低，频繁的线程切换开销大 较高，减少了线程切换开销 响应时间 较长，新线程需要等待 较短，新线程有机会立即获取锁 饥饿问题 不易发生 可能发生，某些线程可能长时间无法获取锁 适用场景 对公平性要求较高，例如银行排队系统 对性能要求较高，例如高并发场景 扩展 Synchronized 是不公平锁，ReentrantLock 默认情况下也是不公平锁，但可以通过构造函数参数指定为公平锁（在其获取锁的方法中，设置前置判断条件 !hasQueuedPredecessors()）。 "},{"title":"Java并发编程-多线程篇","date":"2024-09-10T00:08:08.000Z","url":"/2024/09/10/Java%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B-%E5%A4%9A%E7%BA%BF%E7%A8%8B%E7%AF%87/","tags":[["多线程","/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"]],"categories":[["编程语言","/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"],["Java","/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Java/"],["并发编程","/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Java/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"]],"content":"Java作为一门广泛使用的编程语言，提供了丰富的多线程编程接口和工具，使得开发者能够轻松地创建和管理线程。然而，多线程编程并非易事，它涉及到线程的创建、启动、关闭、同步等多个复杂问题。本文将深入探讨Java中的多线程编程，涵盖线程的基本概念、线程与操作系统的关系、线程的创建和管理方法。 Java中的多线程与操作系统中的多线程在探讨Java中的多线程与操作系统中的多线程之间的关系时，我们首先需要理解两者在底层实现上的联系。尽管Java语言本身提供了丰富的多线程编程接口，但其底层实现依赖于操作系统的线程机制。 Java语言通过java.lang.Thread类提供了多线程编程的支持。然而，Java虚拟机（JVM）在实现这些线程时，依赖于操作系统的线程机制。具体来说，JVM在大多数操作系统上使用POSIX线程（pthread）库来创建和管理线程。 在Linux系统中，JVM通过调用pthread_create函数来创建线程。pthread_create是POSIX线程库中的一个函数，用于在操作系统级别创建一个新的线程。因此，从底层实现的角度来看，Java中的线程实际上是操作系统线程的封装。 Java线程与操作系统线程之间的关系通常被称为“1对1线程模型”。在这种模型中，每个Java线程都直接映射到一个操作系统线程。这意味着： 资源管理：操作系统负责管理线程的资源分配，如CPU时间、内存等。 调度：操作系统的调度器负责决定哪个线程在何时执行。 上下文切换：线程的上下文切换由操作系统内核完成。 由于Java线程直接映射到操作系统线程，因此Java线程的行为和性能特征在很大程度上受到操作系统线程机制的影响。 使用多线程需要注意的问题在多线程编程中，确保线程安全是至关重要的。线程安全指的是在多线程环境下，程序能够正确地处理共享数据，避免数据竞争和不一致性问题。Java提供了多种机制来保证线程安全，主要包括原子性、可见性和有序性。 原子性 原子性是指一个操作要么全部执行，要么全部不执行，不存在中间状态。在多线程环境中，原子性确保了同一时间只有一个线程能够对共享数据进行操作，从而避免了数据竞争。 实现 java.util.concurrent.atomic包：提供了多种原子类（如AtomicInteger、AtomicLong等），这些类通过CAS（Compare-And-Swap）操作实现原子性。 synchronized关键字：通过监视器锁（monitor lock）确保方法或代码块在同一时间只能被一个线程执行。 可见性 可见性确保一个线程对数据的修改对其他线程是可见的。在多线程环境中，由于CPU缓存和编译器优化，可能会导致一个线程的修改对其他线程不可见。 实现 volatile关键字：确保变量的修改立即对所有线程可见，禁止CPU缓存和编译器优化。 synchronized关键字：在进入和退出同步块时，确保变量的可见性。 3. 有序性 有序性确保指令按照程序的顺序执行。在多线程环境中，由于编译器和CPU的指令重排序优化，可能会导致指令的执行顺序与程序代码的顺序不一致。 实现 volatile关键字：禁止指令重排序，确保变量的读写操作按顺序执行。 synchronized关键字：确保同步块内的代码按顺序执行。 使用了happens-before原则来确保有序性。 Java中保证数据一致性的科学方案在Java应用中，确保数据一致性是关键任务之一。以下是几种科学且专业的方案，旨在帮助读者理解并实施有效的数据一致性策略： 事务管理事务管理是保证数据一致性的基础手段。通过数据库事务，可以确保一系列数据操作要么全部成功提交，要么全部失败回滚。这一机制依赖于事务的ACID属性： 原子性（Atomicity）：事务中的所有操作要么全部完成，要么全部不完成，不存在部分执行的情况。 一致性（Consistency）：事务执行前后，数据库从一个一致状态转变到另一个一致状态。 隔离性（Isolation）：并发执行的事务之间相互隔离，一个事务的执行不会影响其他事务。 持久性（Durability）：一旦事务提交，其结果将永久保存在数据库中，即使系统发生故障。 锁机制锁机制是另一种重要的数据一致性保障手段。通过锁，可以实现对数据的互斥访问，确保同一时间只有一个事务能够对特定数据进行操作。常见的锁类型包括： 共享锁（Shared Lock）：允许多个事务同时读取同一数据，但阻止写操作。 排他锁（Exclusive Lock）：阻止其他事务读取或写入同一数据，确保数据修改的独占性。 版本控制版本控制是一种乐观的并发控制策略，通过记录数据的版本信息来保证数据一致性。具体实现方式如下： 乐观锁（Optimistic Locking）：在更新数据时，检查数据的版本号。如果版本号与预期一致，则允许更新并递增版本号；否则，拒绝更新操作。 这种策略适用于读多写少的场景，能够减少锁竞争，提高系统并发性能。 如何创建线程在 Java 中，创建线程主要有以下几种方式： 继承 Thread 类 通过继承 Thread 类并重写 run() 方法来创建线程。 优点：简单直接，易于理解和实现。 缺点：由于 Java 不支持多重继承，继承 Thread 类后无法再继承其他类。线程管理和复用性较差。 实现 Runnable 接口 通过实现 Runnable 接口并重写 run() 方法来创建线程。 优点：避免了单继承的限制，可以继承其他类。代码更加灵活，适用于需要实现多线程的场景。 缺点：编程稍微复杂，如果需要访问当前线程，必须使用Thread.currentThread()方法。 实现 Callable 和 FutureTask 通过实现 Callable 接口并使用 FutureTask 来创建线程。Callable 接口允许线程返回结果，并且可以抛出异常。要执行Callable任务，需将它包装进一个FutureTask，因为Thread类的构造器只接受Runnable参数，而FutureTask实现了Runnable接囗。 优点：允许线程返回结果，并且可以抛出异常。适用于需要获取线程执行结果的场景。 缺点：代码相对复杂，需要处理 FutureTask 和 Callable。 使用线程池（Executor） 通过使用 Executor 框架来创建和管理线程池。Executor 框架提供了多种线程池实现，如 FixedThreadPool、CachedThreadPool、SingleThreadExecutor 等。 优点：提高线程的复用性和管理性，减少线程创建和销毁的开销。适用于需要管理多个线程的场景。 缺点：代码相对复杂，需要理解线程池的概念和配置。 总结 继承 Thread 类：适用于简单的线程创建，但无法继承其他类。 实现 Runnable 接口：适用于需要实现多线程的场景，并且可以继承其他类。 **实现 Callable 和 FutureTask**：适用于需要返回结果或抛出异常的线程。 使用线程池（Executor）：适用于需要管理多个线程的场景，提高线程的复用性和管理性。 如何启动&#x2F;关闭线程？ 启动线程 启动线程通过 Thread 类的 start() 方法。 关闭线程 关闭线程主要有以下几种方法： 异常停止：通过抛出异常来停止线程。 优点：优雅地停止线程，避免资源泄漏。 缺点：需要在线程代码中处理异常。 在沉睡中停止：通过在 sleep() 方法中抛出 InterruptedException 来停止线程。 优点：适用于线程在沉睡中停止的场景。 缺点：需要在线程代码中处理异常。 stop() 暴力停止：使用 Thread 类的 stop() 方法来暴力停止线程。 优点：简单直接，易于使用。 缺点：不安全，可能导致资源泄漏或数据不一致。stop() 方法已被弃用，不推荐使用。 使用 return 停止：通过在 run() 方法中使用 return 语句来停止线程。 优点：优雅地停止线程，避免资源泄漏。适用于需要控制线程停止的场景。 缺点：需要在线程代码中添加停止标志。 调用 interrupt 如何让线程抛出异常在Java中，线程的中断机制是通过一个布尔属性来表示线程的中断状态。初始状态下，线程的中断状态为 false。当一个线程被其他线程调用 Thread.interrupt() 方法中断时，会根据线程当前的执行状态做出不同的响应。 中断机制的工作原理 中断状态的设置：当调用 Thread.interrupt() 方法时，目标线程的中断状态会被设置为 true。 响应中断： 如果目标线程当前正在执行低级别的可中断方法（如 Thread.sleep()、Thread.join() 或 Object.wait()），这些方法会检查线程的中断状态。 如果发现中断状态为 true，这些方法会立即解除阻塞，并抛出 InterruptedException 异常。 轮询中断状态： 如果目标线程当前没有执行可中断方法，Thread.interrupt() 方法仅会设置线程的中断状态为 true。 被中断的线程可以通过轮询中断状态（使用 Thread.currentThread().isInterrupted() 方法）来决定是否停止当前正在执行的任务。 示例代码 以下是一个示例，展示了如何通过 interrupt 方法让线程抛出 InterruptedException 异常： 关键点解析 可中断方法：Thread.sleep()、Thread.join() 和 Object.wait() 等方法是可中断的。当线程在这些方法中被中断时，会立即抛出 InterruptedException 异常。 中断状态的轮询：如果线程没有执行可中断方法，可以通过 Thread.currentThread().isInterrupted() 方法轮询中断状态，以决定是否停止当前任务。 重新设置中断状态：在捕获 InterruptedException 异常后，通常需要重新设置中断状态（使用 Thread.currentThread().interrupt()），以确保中断状态不会丢失。 通过调用 Thread.interrupt() 方法，可以设置线程的中断状态，并根据线程当前的执行状态做出不同的响应。如果线程正在执行可中断方法，会立即抛出 InterruptedException 异常；否则，线程可以通过轮询中断状态来决定是否停止当前任务。这种机制确保了线程能够优雅地响应中断请求，避免资源泄露和不一致状态。 Java 线程状态详解状态在Java中，线程的生命周期可以通过其状态来描述。线程的状态反映了线程当前的执行情况和行为。Java线程的状态由 Thread.State 枚举类定义，主要包括以下几种状态： NEW（新建） 描述：线程对象已经被创建，但尚未调用 start() 方法启动。 状态转换：从 NEW 状态调用 start() 方法后，线程进入 RUNNABLE 状态。 RUNNABLE（可运行） 描述：线程正在Java虚拟机中执行，但它可能正在等待操作系统的其他资源（如CPU时间片）。 状态转换： 从 NEW 状态调用 start() 方法后进入 RUNNABLE 状态。刚调用start()等待系统调度时是READY状态，当执行任务时为RUNNING状态。 从 BLOCKED、WAITING、TIMED_WAITING 状态恢复后进入 RUNNABLE 状态。 BLOCKED（阻塞） 描述：线程正在等待获取监视器锁（monitor lock）以进入同步代码块或方法。 状态转换： 当线程尝试进入同步代码块或方法但锁已被其他线程占用时，进入 BLOCKED 状态。 当获取到锁后，线程从 BLOCKED 状态进入 RUNNABLE 状态。 WAITING（等待） 描述：线程正在无限期地等待另一个线程执行特定操作（如 Object.wait()、Thread.join() 或 LockSupport.park()）。 状态转换： 通过调用 Object.wait()、Thread.join() 或 LockSupport.park() 方法进入 WAITING 状态。 当其他线程调用 Object.notify()、Object.notifyAll() 或 LockSupport.unpark() 方法时，线程从 WAITING 状态进入 RUNNABLE 状态。 TIMED_WAITING（计时等待） 描述：线程正在等待另一个线程执行特定操作，但有一个超时时间（如 Thread.sleep(long)、Object.wait(long)、Thread.join(long) 或 LockSupport.parkNanos(long)）。 状态转换： 通过调用 Thread.sleep(long)、Object.wait(long)、Thread.join(long) 或 LockSupport.parkNanos(long) 方法进入 TIMED_WAITING 状态。 当超时时间到达或被其他线程唤醒时，线程从 TIMED_WAITING 状态进入 RUNNABLE 状态。 TERMINATED（终止） 描述：线程已经执行完毕，run() 方法正常退出或抛出未捕获的异常。 状态转换： 当线程的 run() 方法执行完毕或抛出未捕获的异常时，线程进入 TERMINATED 状态。 notify 和 notifyAll 的区别在Java中，notify 和 notifyAll 都是用于唤醒等待在对象监视器上的线程，但它们的行为有所不同。 notify 功能：notify 方法会随机唤醒一个正在等待该对象监视器的线程。 特点：只唤醒一个线程，其他线程仍处于 WAITING 状态。如果其他线程没有被再次调用 notify 或 notifyAll，它们可能会一直等待，直到超时或被中断。 notifyAll 功能：notifyAll 方法会唤醒所有正在等待该对象监视器的线程。 特点：所有线程都会被唤醒，但只有一个线程能获得锁，其他线程会继续竞争锁。所有线程都会从 WAITING 状态进入 RUNNABLE 状态，开始竞争锁。 以下是一个示例代码，展示了 notify 和 notifyAll 的区别： 总结 **notify**：适用于只需要唤醒一个线程的场景，但需要注意其他线程可能会一直等待。 **notifyAll**：适用于需要唤醒所有线程的场景，确保所有线程都有机会竞争锁。 wait 和 sleep 的区别wait 和 sleep 都是用于线程的等待操作，但它们的行为和使用场景有所不同。 wait 所属类：Object 类的方法。 功能：使当前线程进入等待状态，直到被唤醒（通过 notify 或 notifyAll）或超时。 特点： 必须在同步代码块（synchronized）中调用。 调用 wait 方法会释放对象的监视器锁（monitor lock）。 线程进入 WAITING 或 TIMED_WAITING 状态。 sleep 所属类：Thread 类的方法。 功能：使当前线程暂停执行指定的时间。 特点： 可以在任何地方调用，不需要在同步代码块中。 调用 sleep 方法不会释放对象的监视器锁。 线程进入 TIMED_WAITING 状态。 以下是一个示例代码，展示了 wait 和 sleep 的区别： 总结 **wait**：适用于需要在同步代码块中等待并释放锁的场景，通常用于线程间的协调和通信。 **sleep**：适用于需要暂停线程执行一段时间的场景，不会释放锁，通常用于简单的延迟操作。 notify会唤醒哪个线程？查看源码注释： 大致的意思是： 唤醒一个正在等待该对象监视器的单个线程。如果有任何线程正在等待该对象，其中一个线程将被选择并唤醒。选择是任意的，并由实现自行决定。线程通过调用其中一个 wait 方法来等待对象的监视器。 也就是说，依赖于JVM的具体实现。JVM有很多实现，比较流行的就是hotspot，hotspot对notofy0的实现并不是我们以为的随机唤醒，而是“先进先出”的顺序唤醒。"},{"title":"Java集合-Set篇","date":"2024-09-09T05:14:03.000Z","url":"/2024/09/09/Java%E9%9B%86%E5%90%88-Set%E7%AF%87/","tags":[["Set","/tags/Set/"]],"categories":[["编程语言","/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"],["Java","/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Java/"],["集合","/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Java/%E9%9B%86%E5%90%88/"]],"content":"在Java集合框架中，Set是一种不包含重复元素的集合，具有唯一性、无序性和不可变性等特点。Set通过哈希表或红黑树实现元素的唯一性，常见的实现类包括HashSet、TreeSet和LinkedHashSet。HashSet基于哈希表，TreeSet基于红黑树，而LinkedHashSet结合了哈希表和双向链表，既能保证元素的唯一性，又能记录插入顺序。理解这些集合类型的特点和实现原理，有助于在实际编程中选择合适的集合类型，提高代码的效率和可维护性。 Set集合特点Set集合是一种不包含重复元素的集合，它具有以下特点： 唯一性：Set集合中的元素是唯一的，不允许有重复的元素。 无序性：Set集合中的元素没有特定的顺序，即元素的存储顺序与插入顺序无关。 不可变性：Set集合中的元素一旦插入，通常不能被修改（除非删除后重新插入）。 Set集合key无重复原理Set集合通过内部的数据结构来实现元素的唯一性。常见的实现方式包括使用哈希表（HashMap）或红黑树（TreeMap）等数据结构。以下是Set集合实现key无重复的基本原理： 哈希表（HashMap）实现在Java中，HashSet是基于HashMap实现的。HashSet内部维护了一个HashMap，其中元素作为HashMap的key，而HashMap的value是一个固定的虚拟对象（通常是一个常量对象）。 插入元素的过程： 计算哈希值：当向HashSet中插入一个元素时，首先会计算该元素的哈希值（通过hashCode()方法）。 确定存储位置：根据哈希值确定元素在哈希表中的存储位置。 检查重复：在存储位置上，通过equals()方法检查是否已经存在相同的元素。如果存在相同的元素，则不插入；否则，将元素插入到哈希表中。 红黑树（TreeMap）实现在Java中，TreeSet是基于TreeMap实现的。TreeSet内部维护了一个TreeMap，其中元素作为TreeMap的key，而TreeMap的value是一个固定的虚拟对象。 插入元素的过程： 比较元素：当向TreeSet中插入一个元素时，首先会通过元素的compareTo()方法（或Comparator）进行比较。 检查重复：如果比较结果表明元素已经存在（即compareTo()返回0），则不插入；否则，将元素插入到红黑树中。 总结 无论是基于哈希表还是红黑树，Set集合实现key无重复的核心原理都是通过比较元素的哈希值或直接比较元素本身来确保集合中的元素唯一。具体步骤如下： 计算哈希值或比较元素：根据元素的哈希值或直接比较元素。 检查重复：通过equals()方法或compareTo()方法检查是否已经存在相同的元素。 插入或拒绝：如果元素不存在，则插入；否则，拒绝插入。 有序的Set集合在Java中，TreeSet和LinkedHashSet是两种常见的Set集合实现，它们分别提供了有序性和记录插入顺序的功能。 TreeSetTreeSet是基于红黑树（Red-Black Tree）实现的，它保证了元素的自然顺序。红黑树是一种自平衡的二叉查找树，能够在插入和删除操作后自动调整树的结构，以保持树的平衡。 特点： 有序性：TreeSet中的元素按照自然顺序（或通过自定义的Comparator）进行排序。 唯一性：TreeSet中的元素是唯一的，不允许重复。 性能：插入、删除和查找操作的时间复杂度为O(log n)。 LinkedHashSetLinkedHashSet是基于哈希表和双向链表实现的，它保证了元素的插入顺序。哈希表用于快速查找元素，而双向链表用于维护元素的插入顺序。 特点： 插入顺序：LinkedHashSet中的元素按照插入顺序进行存储和遍历。 唯一性：LinkedHashSet中的元素是唯一的，不允许重复。 性能：插入、删除和查找操作的时间复杂度为O(1)。 记录插入顺序的集合通常指的是LinkedHashSet。LinkedHashSet通过维护一个双向链表来记录元素的插入顺序，因此它能够保证元素按照插入顺序进行存储和遍历。 以下是一个使用LinkedHashSet来记录插入顺序的代码示例： 由于LinkedHashSet不允许重复元素，因此插入重复元素不会改变集合的内容，插入顺序保持不变。 运行上述代码后，输出结果如下： 可以看到，LinkedHashSet成功地记录了元素的插入顺序，并且重复元素不会被插入。"},{"title":"Java集合-Map篇(上)","date":"2024-09-09T05:14:02.000Z","url":"/2024/09/09/Java%E9%9B%86%E5%90%88-Map%E7%AF%87(%E4%B8%8A)/","tags":[["Map","/tags/Map/"]],"categories":[["编程语言","/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"],["Java","/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Java/"],["集合","/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Java/%E9%9B%86%E5%90%88/"]],"content":"在Java集合框架中，Map接口提供了多种实现类，其中HashMap是最常用的键值对存储结构。HashMap的底层实现经历了多次优化，从Java 1.7及之前的数组+链表结构，到Java 1.8引入的红黑树优化，显著提高了查询性能。HashMap通过哈希算法将键值映射到数组槽位，解决哈希冲突的方法包括链表法、开放寻址法、再哈希法和哈希桶扩容。HashMap在多线程环境下存在数据丢失和死循环问题，可以通过Collections.synchronizedMap、Hashtable或ConcurrentHashMap实现线程安全。HashMap的核心操作包括put和get方法，依赖于哈希算法和数组结构。选择红黑树而非平衡二叉树是为了在保证查询性能的同时，减少插入和删除操作的开销。HashMap支持null作为键和值，但null作为键只能有一个。理解这些原理和实现细节，有助于在实际编程中选择合适的集合类型，提高代码的效率和可维护性。 HashMap 原理HashMap 是 Java 中常用的键值对存储结构，其底层实现经历了多次优化。在 Java 1.7 之前，HashMap 的存储结构为数组 + 链表，而在 Java 1.8 中引入了红黑树来优化链表过长导致的性能问题。 Java 1.7 及之前的 HashMap在Java 1.7 及之前的HashMap存储结构为数组 + 链表，通过哈希算法将元素的键值映射到数组中的槽位（bucket），如果多个键映射到同一个槽位上，它们就会使用链表连接在一起。 由此也就引发了一个问题：当哈希冲突严重时，链表会变得非常长，查询性能会下降到 O(n)，导致性能变差。 Java 1.8 的优化在Java 1.8 之后，对HashMap进行了优化，采用数组 + 链表 + 红黑树的数据结构：当链表长度大于 8 时，链表会转化为红黑树，查询性能提升到 O(log n)；当链表长度小于 6 时，红黑树会退化为链表。 关键点 哈希算法：HashMap 使用哈希算法将键值映射到数组的槽位，哈希算法的设计直接影响哈希冲突的概率和性能。 链表与红黑树的转换： 链表转红黑树： 当链表长度大于 8 时，链表会转化为红黑树。 红黑树转链表： 当红黑树节点数小于 6 时，红黑树会退化为链表。 红黑树的特性： 自平衡： 红黑树是一种自平衡的二叉查找树，能够在插入和删除操作后自动调整树的结构，保持树的高度平衡。 查询性能： 红黑树的查询、插入和删除操作的平均时间复杂度为 O(log n)。 以下是 Java 1.8 中 HashMap 的部分源码： Java 1.7 及之前： HashMap 使用数组 + 链表的结构，链表查询复杂度为 O(n)。 Java 1.8 及之后： 引入了红黑树，当链表长度大于 8 时转化为红黑树，查询复杂度提升到 O(log n)，当链表长度小于 6 时退化为链表。 这种优化显著提高了 HashMap 在哈希冲突严重时的查询性能，使其在实际应用中更加高效。 哈希冲突解决办法哈希冲突是指不同的键值通过哈希函数计算后，映射到同一个哈希桶（bucket）中。为了解决哈希冲突，常见的解决方法有以下几种： 1.链表法（Separate Chaining） 使用链表等数据结构存储冲突的键值，将它们连接在同一个桶里。 每个桶（bucket）维护一个链表，当发生哈希冲突时，将新元素插入到链表的尾部。 2. 开放寻址法（Open Addressing） 在哈希表中找一个可用的位置来存放冲突的键值，而不使用同一个链表进行存储。 常见的开放寻址法有线性探测、二次探测和双重哈希。 3. 再哈希法（Rehashing） 当哈希冲突时，使用另一个哈希函数进行二次哈希，直到找到一个可用的空槽。 再哈希函数的选择需要避免再次冲突。 4. 哈希桶扩容（Resize） 动态增加哈希桶的容量，重新分配键值对，即可减少哈希冲突。 当哈希表的负载因子（load factor）达到一定阈值时，进行扩容操作。 HashMap 线程安全吗？HashMap 是线程不安全的，在多线程情况下会出现以下问题： Java 1.7 及之前的问题在 Java 1.7 及之前，HashMap 的数据结构为数组 + 链表。在多线程环境下，多个线程同时进行扩容操作时，可能会导致链表形成环状结构（由于此前版本在扩容复制新链表时，采用的是头插法，在新的链表中指针的顺序会进行翻转），从而引发Entry 链死循环；当多个线程同时进行插入操作时，可能会导致数据丢失。 Java 1.8 及之后的问题在 Java 1.8 及之后，HashMap 采用了数组 + 链表 + 红黑树的数据结构，优化了之前版本的问题（采用了尾插的形式，不会导致环形链表进入死循环）。但在多线程背景下，put 方法仍然存在数据丢失的问题（例如，两个线程同时检测到某个索引位置为空，并同时插入新节点，导致其中一个线程插入的数据被覆盖。）。 线程安全的解决方案如果想要保证 HashMap 的线程安全，可以使用以下方式： 使用 Collections.synchronizedMap 方法进行加锁 底层实现： Collections.synchronizedMap 方法会返回一个包装了原始 HashMap 的同步视图。 其底层实现原理是为每个方法调用添加一个同步块（synchronized block），确保同一时刻只有一个线程可以访问该 Map。 缺点： 性能开销较大，因为每次方法调用都需要获取和释放锁。 迭代时需要手动同步，否则可能会抛出 ConcurrentModificationException。 ###使用 Hashtable 底层实现： Hashtable 是线程安全的 Map 实现，其所有方法都使用 synchronized 关键字进行同步。 使用 ConcurrentHashMap 底层实现： ConcurrentHashMap 是 java.util.concurrent 包中的一个线程安全 Map 实现。 采用分段锁（Segment）机制，将 Map 分成多个段（Segment），每个段独立加锁，从而提高并发性能。 总结 HashMap： 线程不安全，多线程环境下可能会出现死循环和数据丢失问题。 Collections.synchronizedMap： 简单易用，但性能开销较大。 Hashtable： 线程安全，但性能较差。 ConcurrentHashMap： 线程安全，性能较高，适用于高并发场景。 HashMap的“put”过程在多线程背景下，HashMap 的 put 方法可能会出现数据丢失或覆盖等问题。为了深入理解这些问题，我们来看看 put 方法的具体流程。 1.根据键计算哈希码获得索引： 使用键的哈希码计算出在数组中的索引位置。 计算公式：index = hash(key) &amp; (table.length - 1) 2.检查该索引位置是否为空：如果该索引位置为空，直接将新节点插入到该位置。 3.如果索引已存在，则对比键值是否相同：遍历该索引位置的链表或红黑树，查找是否存在相同的键，如果找到相同的键，则直接覆盖该位置的值，完成更新。 4.如果键值不同，则插入新节点：如果链表长度小于 8，将新节点插入到链表的尾部。如果链表长度大于等于 8，将链表转化为红黑树，并将新节点插入到红黑树中。 put(K key, V val)和get(K key)HashMap 是 Java 中常用的键值对存储结构，其核心操作包括 put(K key, V val) 和 get(K key) 方法。这两个方法分别用于存储对象和读取对象，其底层实现依赖于哈希算法和数组结构。 put(K key, V val) 方法： 计算哈希值： 使用传入的 key 计算哈希值。 计算公式：hash = hash(key) 计算数组索引： 使用哈希值计算出在数组中的索引位置。 计算公式：index = hash &amp; (table.length - 1) 检查索引位置： 如果该索引位置为空，直接将新节点插入到该位置。 如果该索引位置已存在节点，则遍历链表或红黑树，查找是否存在相同的键。 处理冲突： 如果找到相同的键，则直接覆盖该位置的值，完成更新。 如果键值不同，则插入新节点： 如果链表长度小于 8，将新节点插入到链表的尾部。 如果链表长度大于等于 8，将链表转化为红黑树，并将新节点插入到红黑树中。 检查负载因子： 如果插入后达到了 HashMap 设置的负载阈值（默认为 0.75），则需要扩容 100%。 扩容操作会创建一个新的数组，并将原数组中的元素重新分配到新数组中。 代码： get(K key) 方法 计算哈希值： 使用传入的 key 计算哈希值。 计算公式：hash = hash(key) 计算数组索引： 使用哈希值计算出在数组中的索引位置。 计算公式：index = hash &amp; (table.length - 1) 检查索引位置： 如果该索引位置为空，返回 null。 如果该索引位置已存在节点，则遍历链表或红黑树，查找是否存在相同的键。 处理哈希冲突： 如果节点是链表结构，遍历链表查找键值。 如果节点是红黑树结构，调用红黑树的查找方法。 返回值： 如果找到相同的键，返回对应的值。 如果未找到相同的键，返回 null。 代码： 为什么 HashMap 使用的是红黑树而不是其他？选择红黑树的主要原因是为了优化查询性能，因此选用了查询性能优秀的平衡树一类。 为什么不是平衡二叉树？平衡二叉树（如 AVL 树）追求一种“完美平衡”，即任何节点的子树高度差都不超过 1。这种严格的平衡性确保了查询操作的时间复杂度为 O(log n)，但在插入或删除数据时，很容易破坏这种平衡。为了保持平衡，树会进行频繁的旋转操作，从而消耗大量性能。 红黑树的优势红黑树是一种自平衡的二叉查找树，它通过引入颜色标记和一些规则来保持树的平衡。红黑树的平衡性要求相对较弱，不需要频繁维护树的平衡，从而减少了开销。 红黑树的特性 自平衡： 红黑树通过颜色标记和旋转操作来保持树的平衡，插入和删除操作的时间复杂度为 O(log n)。 弱平衡： 红黑树的平衡性要求相对较弱（整个树的最长路径不会超过最短路径的2倍），不需要频繁进行旋转操作，减少了维护平衡的开销。 查询性能： 红黑树的查询性能略逊于平衡二叉树，但仍然为 O(log n)，与平衡二叉树相差不大。 红黑树与平衡二叉树的对比 特性 红黑树 平衡二叉树（如 AVL 树） 平衡性要求 弱平衡 严格平衡 旋转操作 较少 频繁 插入&#x2F;删除性能 较好 较差 查询性能 O(log n) O(log n) 实现复杂度 中等 较高 为什么选择红黑树？综合考虑以下因素，选择红黑树更为合适： 查询性能： 红黑树的查询性能为 O(log n)，与平衡二叉树相差不大。 插入&#x2F;删除性能： 红黑树的插入和删除操作性能较好，因为不需要频繁进行旋转操作。 实现复杂度： 红黑树的实现复杂度适中，易于理解和实现。 总结 红黑树： 自平衡、弱平衡、查询性能为 O(log n)、插入&#x2F;删除性能较好、实现复杂度适中。 平衡二叉树： 严格平衡、查询性能为 O(log n)、插入&#x2F;删除性能较差、实现复杂度较高。 在 HashMap 中，选择红黑树是为了在保证查询性能的同时，减少插入和删除操作的开销，从而提高整体性能。 HashMap的key可以为null吗？答案是可以的。 hashMap中使用hash()方法来计算key的哈希值，当key为空时，直接令key的哈希值为0，不走key.hashcode()方法; HashMap虽然支持key和value为null，但是null作为key只能有一个，null作为value可以有多个。因为HashMap中，如果key值一样，那么会覆盖相同key值的value为最新，所以key为nul只能有一个。 HashCode.equals和hashMap.hashCode在 HashMap 中比较元素时，首先会通过 hashCode 进行比较，如果 hashCode 相同，再通过 equals 方法进行比较。因此，如果两个对象通过 equals 方法比较是相等的，那么它们的 hashCode 必须相等。然而，hashCode 相等的两个对象，equals 方法的比较结果不一定相等（例如，在发生哈希冲突的情况下）。 如果这些方法没有被正确地实现，可能会导致两个不同的 Key 产生相同的哈希码和 equals() 输出，从而导致 HashMap 认为它们是相同的，进而覆盖它们，而不是将它们存储到不同的地方。 如果在重写 equals 方法时没有同时重写 hashCode 方法，可能会导致 equals 方法返回 true，而 hashCode 方法返回不同的值。这种情况的后果是，在 HashMap 等类中可能会存储多个实际上相同的对象，从而导致数据覆盖的问题。这与 HashMap 中每个键必须是唯一的规范不符。 重写equals和hashCode方法应该保持以下原则： 如果 o1.equals(o2)，那么 o1.hashCode() == o2.hashCode() 总是为 true。 如果 o1.hashCode() == o2.hashCode()，并不意味着 o1.equals(o2) 会为 true。 "},{"title":"Java集合-Map篇(下)","date":"2024-09-09T05:14:02.000Z","url":"/2024/09/09/Java%E9%9B%86%E5%90%88-Map%E7%AF%87(%E4%B8%8B)/","tags":[["Map","/tags/Map/"]],"categories":[["编程语言","/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"],["Java","/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Java/"],["集合","/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Java/%E9%9B%86%E5%90%88/"]],"content":"在Java集合框架中，Map接口提供了多种实现类，其中HashMap和HashTable是最常用的键值对存储结构。HashMap通过哈希算法和数组+链表&#x2F;红黑树结构，实现了高效的查询和插入操作。HashTable通过同步方法实现了线程安全，但性能较差。ConcurrentHashMap在Java 1.7及之前版本采用分段锁技术，而在Java 1.8及之后版本通过数组+链表&#x2F;红黑树结构和volatile+CAS或synchronized机制，实现了更高的并发性能。ConcurrentHashMap综合运用了乐观锁和悲观锁，通过CAS操作实现无锁的初始化和空桶设置，通过synchronized关键字确保非空桶操作的线程安全。理解这些原理和实现细节，有助于在实际编程中选择合适的集合类型，提高代码的效率和可维护性。 HashMap的扩容机制简述HashMap默认的负载因子（load factor）是0.75。负载因子定义了HashMap在触发扩容之前，允许的元素数量与容量的比例。具体来说，当HashMap中的元素个数超过当前容量的75%时，就会触发扩容操作。 扩容操作分为两个主要步骤： 扩展哈希表的长度：HashMap会将当前的容量扩展为原来的两倍。例如，如果当前容量是16，扩容后容量将变为32。 重新分配数据：扩容后，HashMap需要将旧哈希表中的数据重新分配到新的哈希表中。由于新的容量是原来的两倍，元素在新哈希表中的位置可能会发生变化。 负载因子为何选择0.75？负载因子的选择是一个权衡性能和空间利用率的过程。负载因子为0.75是一个经验值，它在以下两个方面取得了平衡： 减少哈希冲突：当负载因子较大时（例如0.8或0.9），数组中的元素密度增加，导致哈希冲突的概率上升，从而降低查询和插入操作的效率。 避免频繁扩容：当负载因子较小时（例如0.5或0.6），虽然哈希冲突减少，但扩容的频率增加，导致空间利用率降低，且频繁的扩容操作也会带来额外的性能开销。 为什么是扩容2倍？扩容2倍，其实是一个非常巧妙的设计。在扩容过程中，HashMap并不需要重新计算每个元素的哈希值。这是因为HashMap的容量总是2的幂次（例如16、32、64等），这使得扩容后的新索引可以通过简单的位运算来确定。 具体来说，当容量从n扩展到2n时，新的索引位置可以通过以下方式计算： 如果元素的哈希值在高位新增的bit为0，则元素在新哈希表中的位置与原位置相同。 如果元素的哈希值在高位新增的bit为1，则元素在新哈希表中的位置为原位置加上旧容量（即原索引 + oldCap）。 如下图示，元素在重新计算hash之后，因为n变为2倍，那么n-1的mask范围在高位多1bit(红色)，因此新的index遵循上述规则计算： 扩展：为什么Hash计算时有一个右移16位操作？在Java的HashMap中，哈希值的计算并不仅仅依赖于对象的hashCode()方法，而是通过一个额外的位运算来进一步优化哈希值的分布。具体来说，HashMap在计算哈希值时，会进行一个右移16位的操作，然后将结果与原哈希值进行异或运算。这个操作的目的是为了减少哈希碰撞，提高HashMap的性能。 源码分析 我们来看一下HashMap中计算哈希值的源码： 在这段代码中，h是对象的原始哈希值，h &gt;&gt;&gt; 16表示将h右移16位。然后，将右移后的结果与原哈希值进行异或运算（^），得到最终的哈希值。 为什么需要右移16位？ 哈希值h是一个32位的整数。如果不进行任何处理，直接使用h作为哈希值，可能会导致哈希碰撞的概率增加。这是因为hashCode()方法返回的哈希值在低位可能会有较多的重复，尤其是在处理较小的数据集时。 通过将h右移16位，相当于将哈希值的高16位与低16位进行混合。这种混合操作可以有效地将高位信息引入到低位，从而减少哈希碰撞的可能性。具体来说： 右移16位：将哈希值的高16位移到低16位，这样低16位就包含了高16位的信息。 异或运算：通过异或运算，将高16位和低16位的信息进行混合，使得最终的哈希值在低位也包含了高位的信息。 通过右移16位并进行异或运算，HashMap能够更有效地利用哈希值的高位信息，减少哈希碰撞的概率。这种设计使得HashMap在处理大量数据时仍能保持较高的性能，确保键值对的快速查找和插入。 HashTable原理HashTable是一种基于哈希表的数据结构，用于存储键值对。其内部实现主要依赖于数组和链表的结合，以解决哈希冲突问题。 数据结构 数组：HashTable的主体是一个数组，数组的每个元素称为“桶”（bucket）。数组的大小通常是固定的，或者可以根据需要进行动态调整。 链表：当不同的键值对通过哈希函数计算得到的哈希值相同，即发生哈希冲突时，HashTable使用链表来存储这些键值对。每个桶中可以存储一个链表，链表中的每个节点包含一个键值对。 线程安全 HashTable的所有公共方法都使用了synchronized关键字进行修饰，这意味着每个方法在执行时都会获取对象级别的锁。这种设计确保了HashTable在多线程环境下的线程安全性，但同时也带来了性能上的开销，因为每次方法调用都会导致线程阻塞。 HashMap和HashTable的区别HashMap和HashTable都是Java中用于存储键值对的数据结构，但它们在实现和使用上有一些关键的区别。以下是它们的主要区别： 1. 线程安全性 HashMap：HashMap是线程不安全的。这意味着在多线程环境下，如果多个线程同时对同一个HashMap进行操作，可能会导致数据不一致或其他并发问题。 HashTable：HashTable是线程安全的。HashTable的所有公共方法都使用了synchronized关键字进行修饰，确保在多线程环境下操作的安全性。例如： 这意味着在同一时刻，只有一个线程可以执行HashTable的某个方法，从而避免了并发问题。 2. 性能 HashMap：由于HashMap不是线程安全的，因此在单线程环境下，HashMap的性能通常优于HashTable。HashMap不需要额外的同步开销，因此在读写操作上更快。 HashTable：由于HashTable的方法都使用了synchronized关键字，因此在多线程环境下，HashTable的性能可能会受到影响。每次方法调用都需要获取锁，这会增加额外的开销。 3. 允许null值 HashMap：HashMap允许键和值为null。也就是说，你可以将null作为键或值存储在HashMap中。 HashTable：HashTable不允许键或值为null。如果尝试将null作为键或值存储在HashTable中，会抛出NullPointerException。 4. 迭代器 HashMap：HashMap的迭代器是快速失败的（fail-fast）。如果在迭代过程中，HashMap的结构发生了变化（例如添加或删除元素），迭代器会抛出ConcurrentModificationException。 HashTable：HashTable的迭代器也是快速失败的，但它的迭代器实现方式与HashMap略有不同。 总结 HashMap和HashTable在实现和使用上有显著的区别。HashMap适用于单线程环境，性能更好，允许null键和值；而HashTable适用于多线程环境，线程安全，但不允许null键和值，性能相对较差。在现代Java编程中，推荐使用ConcurrentHashMap来替代HashTable，以获得更好的性能和扩展性。 ConcurrentHashMap原理ConcurrentHashMap是Java中用于并发环境下的高效键值对存储数据结构。它在Java 1.7及之前版本和Java 1.8及之后版本有不同的实现方式。以下是ConcurrentHashMap在不同版本中的实现原理及其优化的详细介绍。 Java 1.7及之前版本的实现在Java 1.7及之前版本中，ConcurrentHashMap采用了分段锁（Segment）技术来实现线程安全。其核心结构是数组+链表，具体分为以下几个部分： Segment数组：ConcurrentHashMap内部包含一个Segment数组，每个Segment相当于一个小的HashMap，并且是一个可重入锁（ReentrantLock）。 HashEntry数组：每个Segment内部包含一个HashEntry数组，HashEntry用于存储键值对数据。每个HashEntry是一个链表结构的元素。 分段锁技术： ConcurrentHashMap将数据分成多个段（Segment），每个段相当于一个小的HashMap，并且有自己的锁。 当一个线程访问某个段的数据时，只需要锁住该段，而不影响其他段的数据访问。这样就实现了并发访问，提高了并发性能。 缺点： 虽然分段锁技术提高了并发性能，但由于使用了链表结构，当链表过长时，访问速度会变慢，因为需要遍历链表。 Java 1.8及之后版本的实现在Java 1.8及之后版本中，ConcurrentHashMap进行了优化，采用了数组+链表&#x2F;红黑树的数据结构，并使用volatile+CAS或synchronized来实现线程安全。具体实现如下： 数组+链表&#x2F;红黑树：ConcurrentHashMap内部使用一个数组来存储数据，每个数组元素（桶）可以是一个链表或红黑树。当链表长度超过一定阈值时，链表会转换为红黑树，以提高查找效率。 volatile+CAS：用于实现无锁的并发操作，例如初始化容器或设置节点。 synchronized：用于在发生冲突时对桶的头节点加锁，确保线程安全。 添加元素的过程： 初始化容器：如果容器为空，使用volatile+CAS来初始化容器。 计算桶位置：根据存储的元素计算桶的位置。 CAS设置节点：如果计算结果为空，则利用CAS设置该节点。 synchronized加锁：如果桶不为空，则使用synchronized对桶的头节点加锁，然后遍历桶中的元素，并替换或新增节点到桶中。 转换为红黑树：最后判断是否需要将链表转换为红黑树，以提高查找效率。 优点： 锁粒度更小：通过只对桶的头节点加锁，锁的粒度相比分段锁更小，减少了锁的竞争，提高了并发性能。 红黑树优化：当链表过长时，转换为红黑树，提高了查找效率。 总结 ConcurrentHashMap在Java 1.8及之后版本中通过数组+链表&#x2F;红黑树的数据结构和volatile+CAS或synchronized的并发控制机制，实现了高效的并发访问。相比Java 1.7及之前版本的分段锁技术，Java 1.8及之后版本的ConcurrentHashMap在锁粒度和查找效率上都有显著提升，更适合高并发的场景。 一句话归纳：Java 1.8及之后版本的ConcurrentHashMap通过对桶的头节点加锁，锁的粒度更小，减少了锁的竞争，同时通过红黑树优化提高了查找效率，从而实现了更高的并发性能。 分段锁怎么加锁的？在 ConcurrentHashMap 中，将整个数据结构分为多个 Segment，每个 Segment 都类似于小的 HashMap，每个 Segment 都有自己的锁，不同 Segment 之间的操作互不影响，从而提高并发性能。 在 ConcurrentHashMap 中，对于插入、更新、删除等操作，需要先定位到具体的 Segment,然后再在该 Segment 上加锁，而不是像传统的 HashMap 一样对整个数据结构加锁。这样可以使得不同 Segment 之间的操作并行进行，提高了并发性能。 什么是可重入锁？可重入锁（Reentrant Lock）是一种同步机制，允许同一个线程多次获取同一个锁，而不会导致死锁。它是 Java 中 java.util.concurrent.locks.ReentrantLock 类的实现。 同一个线程可以多次获取同一个锁，而不会被自己阻塞。每次获取锁时，锁的计数器会递增；每次释放锁时，计数器会递减。只有当计数器归零时，锁才会完全释放。 JDK 1.7 ConcurrentHashMap中的分段锁是用了 ReentrantLock，是一个可重入的锁。 为什么使用了synchronized还要使用CAS？CAS是一种无锁的并发控制机制，它通过硬件级别的原子操作来实现线程安全。CAS操作包括三个参数：内存位置、预期值和更新值。CAS操作会先比较内存位置的当前值是否等于预期值，如果相等，则将内存位置的值更新为新值，并返回成功；否则，返回失败。CAS的主要作用是： 无锁操作：CAS操作不需要加锁，因此不会阻塞线程，减少了线程切换的开销。 原子性：CAS操作是原子的，可以确保在多线程环境下对共享变量的修改是安全的。 在ConcurrentHashMap中，CAS主要用于一些不需要加锁的简单操作，例如初始化容器、设置节点等。 综合原因 在ConcurrentHashMap中，synchronized和CAS结合使用的原因如下： 减少锁竞争：CAS操作是无锁的，可以在不加锁的情况下完成一些简单的操作，减少了锁的竞争，提高了并发性能。 优化初始化：在初始化ConcurrentHashMap时，使用CAS操作可以确保只有一个线程能够成功初始化容器，避免了多个线程同时初始化容器的问题。 提高并发性能：对于一些不需要遍历链表或红黑树的操作，使用CAS可以避免加锁，从而提高并发性能。例如，在添加元素时，如果桶为空，可以直接使用CAS操作设置节点，而不需要加锁。 细粒度锁控制：synchronized用于在发生哈希冲突时对桶的头节点加锁，确保线程安全地操作链表或红黑树。通过只对头节点加锁，锁的粒度更小，减少了锁的竞争，提高了并发性能。 ConcurrentHashMap使用了乐观锁还是悲观锁？ConcurrentHashMap在实现并发控制时，综合运用了乐观锁和悲观锁的机制。 容器初始化： ​ 当容器为空时，ConcurrentHashMap使用volatile关键字和CAS（Compare-And-Swap）操作进行初始化。volatile确保了变量的可见性，而CAS则是一种乐观锁机制，通过原子操作来确保初始化的线程安全性。 元素添加： 如果容器不为空，ConcurrentHashMap会根据元素的哈希值计算其在桶中的位置。 如果计算出的位置为空，则再次使用CAS操作来设置该节点，这是一种乐观锁的实现方式，通过原子操作来避免锁的开销。 如果计算出的位置不为空，ConcurrentHashMap会使用synchronized关键字对桶进行锁定，这是一种悲观锁的实现方式。锁定后，线程会遍历桶中的数据，并根据需要替换或新增节点。如果桶中的元素数量达到一定阈值，还会将链表结构转换为红黑树，以优化查找性能。 总结 ConcurrentHashMap在并发控制中灵活运用了乐观锁和悲观锁： 乐观锁：主要用于初始化和空桶位置的设置，通过CAS操作实现，减少了锁的开销。 悲观锁：用于非空桶的访问和修改，通过synchronized关键字实现，确保了操作的原子性和线程安全。 "},{"title":"Java集合-List篇","date":"2024-09-09T05:14:01.000Z","url":"/2024/09/09/Java%E9%9B%86%E5%90%88-List%E7%AF%87/","tags":[["List","/tags/List/"]],"categories":[["编程语言","/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"],["Java","/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Java/"],["集合","/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Java/%E9%9B%86%E5%90%88/"]],"content":"在Java集合框架中，List接口提供了多种实现类，如Vector、ArrayList和LinkedList，每种实现类都有其特定的特点和适用场景。Vector是线程安全的动态数组，适用于多线程环境；ArrayList是线程不安全的动态数组，适用于单线程环境，性能较高；LinkedList是双向链表，适用于频繁插入和删除元素的场景。ArrayList在多线程环境下存在数据不一致的问题，可以通过Collections.synchronizedList()、CopyOnWriteArrayList或手动同步来实现线程安全。CopyOnWriteArrayList通过写时复制机制和ReentrantLock保证线程安全，适用于读多写少的场景。理解这些集合类型的特点和实现原理，有助于在实际编程中选择合适的集合类型，提高代码的效率和可维护性。 List的实现List接口是Java中常用的集合接口之一，提供了多种实现类，以满足不同的需求。以下是List接口的三个主要实现类及其特点和适用场景。 1. VectorVector是一个线程安全的动态数组，实现了List接口。Vector的所有方法都是同步的，因此适用于多线程环境。 特点 线程安全：所有方法都使用synchronized关键字进行同步。 动态调整大小：可以根据需要动态调整大小。 存储结构：存储的是对象数组，当空间不足时会创建一个新的数组，并将原来的数组拷贝过去。 性能较低：由于同步机制，Vector的性能通常低于非线程安全的ArrayList。 适用场景 需要线程安全的场景。 对性能要求不高的场景。 2. ArrayListArrayList是一个线程不安全的动态数组，实现了List接口。ArrayList在性能上比Vector快很多，适用于单线程环境。 特点 线程不安全：没有同步机制，性能较高。 动态调整大小：可以根据需要动态调整大小。 存储结构：存储的是对象数组，当空间不足时会创建一个新的数组，并将原来的数组拷贝过去。 扩容机制：扩容时增加50%的容量。 适用场景 单线程环境。 对性能要求较高的场景。 3. LinkedListLinkedList是一个双向链表，实现了List接口。LinkedList也是线程不安全的，适用于需要频繁插入和删除元素的场景。 特点 线程不安全：没有同步机制，性能较高。 存储结构：使用链表结构，插入和删除元素效率高。 随机访问较慢：由于不是顺序存储，访问元素时需要遍历链表，效率较低。 适用场景 需要频繁插入和删除元素的场景。 对随机访问性能要求不高的场景。 示例代码 概括 Vector：线程安全，适用于多线程环境，但性能较低。 ArrayList：线程不安全，适用于单线程环境，性能较高，适合随机访问。 LinkedList：线程不安全，适用于频繁插入和删除元素的场景，但随机访问性能较低。 了解ArrayList为什么 ArrayList 不是线程安全的？在高并发添加数据的情况下，ArrayList 会暴露以下三个问题： 部分值为 null（此前我们没有插入过 null 值） 索引越界 数组的 size 大小与插入 add 情况不一致 原因分析ArrayList 的 add 方法源码如下： 可以看到，插入一个元素的操作分为三步： step1：判断当前数组空间是否足够插入一个元素，不够则调用 grow 方法扩容。 step2：在 size 索引位置设置值为新插入的元素。 step3：维护 size 值加 1。 问题根源1. 部分值为 null： 在高并发情况下，多个线程可能同时执行 elementData[size] = e;，导致某些线程覆盖了其他线程插入的值，也就是在同一个索引位置设置值，但最后不同的线程都会给size++，最终导致部分值为 null。 2. 索引越界： 线程1走到扩容那里发现当前size是9，数组容量是10不用扩容，cpu让出执行权，线程2也发现不用扩容，这时候数组的容量就是10，而线程1 set完之后size++，这时候线程2再进来size就是10，数组的大小只有10，而你要设置下标索引为10的就会越界(数组的下标索引从0开始): 3. 数组的 size 大小与插入 add 情况不一致： 由于 size++ 操作不是原子的，多个线程同时执行 size++ ，可能取得size值都是同一个(比如size为10，线程1将把size赋值为11，在线程1未完成赋值时线程二也在执行，此时获取到的size值还是10，最后执行了两次size++，实际上只有效一次size++)，会导致 size 值与实际插入的元素数量不一致。 如何将ArrayList变成线程安全的？ArrayList 是 Java 中常用的动态数组实现，但它并非线程安全。这意味着在多线程环境下，多个线程同时访问和修改 ArrayList 可能会导致数据不一致或其他并发问题。 使用 Collections.synchronizedList() 底层实现： Collections.synchronizedList() 方法会返回一个包装了原始 ArrayList 的同步视图。其底层实现原理是为每个方法调用添加一个同步块（synchronized block），确保同一时刻只有一个线程可以访问该列表。 使用 CopyOnWriteArrayList 底层实现： CopyOnWriteArrayList 是 java.util.concurrent 包中的一个线程安全列表实现。其核心思想是**写时复制 (Copy-On-Write)**：当列表发生修改时，会创建一个列表的副本，并在副本上进行修改，而原始列表保持不变。 手动同步 底层实现： 手动同步需要开发者显式地使用 synchronized 关键字来控制对 ArrayList 的访问。 ArrayList 的扩容机制当向 ArrayList 中新增元素时，如果下一个索引位置超出了当前数组的容量，则会触发扩容机制。扩容机制的具体步骤如下： 扩容步骤 计算新的容量：一般情况下，新的容量为原来容量的 1.5 倍。 计算公式：newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1) 创建新的数组：根据计算出的新容量，创建一个新的数组。 复制原有数组元素：将原有数组中的元素逐个复制到新的数组中。 更新引用：将 ArrayList 内部的数组引用更新为新的数组。 完成扩容：扩容完成后，可以继续插入新的元素。 代码示例 以下是 ArrayList 扩容机制的部分源码： 关键点 扩容因子： 通常为 1.5 倍，但具体实现可能会根据需求调整。 数组复制： 使用 Arrays.copyOf() 方法进行数组复制，效率较高。 内存开销： 扩容会导致内存占用增加，因此在初始化 ArrayList 时，合理设置初始容量可以减少扩容次数，提高性能。 线程安全的 List 如何实现线程安全的？以 CopyOnWriteArrayList 为例，其底层也是使用数组保存数据。CopyOnWriteArrayList 通过以下方式实现线程安全： 1. 使用 volatile 关键字修饰数组CopyOnWriteArrayList 使用 volatile 关键字修饰数组，确保线程对数组对象重新赋值后，其他线程可以感知到。 2. 写时复制 (Copy-On-Write) 机制CopyOnWriteArrayList 的核心思想是**写时复制 (Copy-On-Write)**：当列表发生修改时，会创建一个列表的副本，并在副本上进行修改，而原始列表保持不变。 关键方法： add 方法： setArray 方法： 3. 读操作无需加锁由于写操作是在副本上进行的，读操作可以直接访问原始数组，无需加锁，从而提高了读操作的性能。 4. 使用 ReentrantLock 保证写操作的线程安全在写操作（如 add、remove 等）时，CopyOnWriteArrayList 使用 ReentrantLock 保证同一时刻只有一个线程可以进行写操作，从而确保线程安全。 总结 CopyOnWriteArrayList 通过以下方式实现线程安全： 使用 volatile 关键字修饰数组，确保线程对数组对象重新赋值后，其他线程可以感知到。 采用写时复制 (Copy-On-Write) 机制，写操作在副本上进行，读操作无需加锁。 使用 ReentrantLock 保证写操作的线程安全。 这种设计使得 CopyOnWriteArrayList 在读多写少的场景下具有较高的性能，但在写操作频繁的场景下，由于需要频繁复制数组，性能会受到影响。 "},{"title":"Java集合-概念篇","date":"2024-09-09T05:14:00.000Z","url":"/2024/09/09/Java%E9%9B%86%E5%90%88-%E6%A6%82%E5%BF%B5%E7%AF%87/","categories":[["编程语言","/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"],["Java","/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Java/"],["集合","/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Java/%E9%9B%86%E5%90%88/"]],"content":"在Java编程中，集合（Collection）是一种用于存储和操作一组对象的核心数据结构。Java集合框架（Java Collections Framework, JCF）提供了丰富的集合类型，以满足不同的编程需求。 什么是集合？在计算机科学中，集合（Collection）是一种用于存储和操作一组对象的数据结构。集合框架提供了一系列接口和类，用于处理不同类型的集合。Java的集合框架（Java Collections Framework, JCF）是Java标准库的一部分，提供了丰富的集合类型，以满足不同的编程需求。 集合的分类1. List：List是一种有序集合，允许存储重复元素。List接口提供了精确控制每个元素插入位置的能力，并且可以通过索引访问指定元素。 实现类： ArrayList：基于动态数组实现，支持高效的随机访问，但在插入和删除元素时可能需要移动大量元素。 Vector：类似于ArrayList，但线程安全，适用于多线程环境。 Stack：继承自Vector，实现后进先出（LIFO）的数据结构。 2.Set：Set是一种不允许存储重复元素的集合，每个元素都是唯一的。Set接口不保证元素的顺序。 实现类： HashSet：基于哈希表实现，提供了平均时间复杂度为O(1)的插入、删除和查找操作。 TreeSet：基于红黑树实现，元素按自然顺序或自定义顺序排序。 LinkedHashSet：结合了HashSet和LinkedList的特性，既保证了元素的唯一性，又维护了插入顺序。 3. Map：Map是一种键值对（Key-Value）的集合，存储键和值之间的映射关系。Map中的键是无序且唯一的，而值则可以重复。Map接口没有继承Collection接口，但它是集合框架的一部分。 实现类： HashMap：基于哈希表实现，提供了平均时间复杂度为O(1)的插入、删除和查找操作。 TreeMap：基于红黑树实现，键按自然顺序或自定义顺序排序。 Hashtable：类似于HashMap，但线程安全，适用于多线程环境。 特点 动态大小：集合的大小是动态的，可以根据需要添加或删除元素，而数组的大小是固定的。 类型安全：集合通常只能存储对象，而不能直接存储基本数据类型。然而，Java提供了自动装箱（Autoboxing）机制，使得基本数据类型可以自动转换为对应的包装类，从而存储在集合中。 丰富的操作：集合框架提供了丰富的操作方法，如添加、删除、查找、排序等，使得开发者可以方便地对集合进行操作。 集合是Java中用于存储和操作一组对象的重要数据结构。通过使用集合框架，开发者可以灵活地处理不同类型的数据，提高代码的效率和可维护性。理解不同集合类型的特点和适用场景，有助于在实际编程中做出更合理的选择。 数组与集合的对比分析概述在计算机科学中，数组（Array）和集合（Collection）是两种常见的数据结构，它们在存储和操作数据方面有着显著的区别。理解这些区别对于编写高效、可维护的代码至关重要。 主要区别 长度特性：数组的长度在初始化时是固定的，无法动态调整。这意味着一旦数组被创建，其大小就无法改变。集合的长度是动态的，可以根据需要添加或删除元素。集合的实现通常基于动态数据结构，如链表或动态数组，允许在运行时调整大小。 数据类型：数组可以存储基本数据类型（如int、char、float等）以及对象（如String、Object等）。数组中的所有元素必须是相同的数据类型。集合通常只能存储对象，而不能直接存储基本数据类型。然而，Java等语言提供了自动装箱（Autoboxing）机制，使得基本数据类型可以自动转换为对应的包装类（如Integer、Character等），从而存储在集合中。 访问机制：数组中的元素通过索引直接访问，时间复杂度为O(1)。这意味着访问数组中的任意元素都非常高效。集合中的元素通常需要通过迭代器（Iterator）或其他访问方法来获取。访问集合中的元素的时间复杂度可能因集合的实现方式而异，通常为O(n)或O(log n)。 常见集合类型 ArrayList：基于动态数组实现的集合，支持随机访问，但在插入和删除元素时可能需要移动大量元素，导致性能下降。适用于需要频繁随机访问元素的场景。 Map：键值对（Key-Value）的集合，每个键唯一对应一个值。常见的实现包括HashMap和TreeMap。适用于需要通过键快速查找值的场景。 HashMap：基于哈希表实现的Map，提供了平均时间复杂度为O(1)的插入、删除和查找操作。适用于需要高效查找和插入操作的场景。 TreeMap：基于红黑树（Red-Black Tree）实现的Map，元素按自然顺序或自定义顺序排序。适用于需要有序访问键值对的场景。 PriorityQueue：基于堆（Heap）实现的优先队列，元素按优先级排序，支持高效的插入和删除操作。适用于需要按优先级处理元素的场景，如任务调度、事件处理等。 总结 数组和集合各有优缺点，选择合适的数据结构取决于具体的应用场景和需求。数组适用于需要固定大小且高效随机访问的场景，而集合则适用于需要动态调整大小和灵活操作的场景。理解这些区别有助于开发者在实际编程中做出更合理的选择，从而提高代码的性能和可维护性。 Java中线程安全的集合在多线程编程中，确保数据的一致性和线程安全是至关重要的。Java的java.util包中只有少数几个类是线程安全的，而大多数集合类是非线程安全的。为了满足高并发环境下的需求，Java提供了java.util.concurrent包，其中包含多种线程安全的集合类。 java.util包中的线程安全集合1. VectorVector是一个线程安全的动态数组，实现了List接口。Vector的所有方法都是同步的，因此适用于多线程环境。 线程安全：所有方法都使用synchronized关键字进行同步。 性能较低：由于同步机制，Vector的性能通常低于非线程安全的ArrayList。 2. HashtableHashtable是一个线程安全的哈希表，实现了Map接口。Hashtable的所有方法都是同步的，因此适用于多线程环境。 线程安全：所有方法都使用synchronized关键字进行同步。 性能较低：由于同步机制，Hashtable的性能通常低于非线程安全的HashMap。 java.util.concurrent包中的线程安全集合1. 并发Set并发Set是一种线程安全的集合，不允许存储重复元素。 ConcurrentSkipListSet：基于跳表（Skip List）实现的有序集合，适用于高并发环境下的插入、删除和查找操作。 CopyOnWriteArraySet：基于CopyOnWriteArrayList实现，适用于读多写少的场景，写操作会创建一个新的副本，读操作则直接访问当前副本。 2. 并发Map并发Map是一种线程安全的键值对集合，存储键和值之间的映射关系。 ConcurrentHashMap：它与HashTable的区别在于二者加锁的粒度不同。ConcurrentHashMap基于分段锁（Segmented Locking）实现的哈希表，提供了高效的并发访问能力，适用于高并发环境下的插入、删除和查找操作。 ConcurrentSkipListMap：基于跳表实现的有序映射，适用于高并发环境下的插入、删除和查找操作。 3. 并发Queue并发Queue是一种线程安全的队列，支持先进先出（FIFO）的数据结构。 ConcurrentLinkedQueue：基于链表实现的无界队列，适用于高并发环境下的插入和删除操作。 ArrayBlockingQueue：基于数组实现的有界阻塞队列，适用于生产者-消费者模型。 LinkedBlockingQueue：基于链表实现的有界阻塞队列，适用于生产者-消费者模型。 PriorityBlockingQueue：基于堆实现的无界阻塞队列，元素按优先级排序。 4. 并发List并发List是一种线程安全的列表，允许存储重复元素。 CopyOnWriteArrayList：基于CopyOnWrite机制实现，适用于读多写少的场景，写操作会创建一个新的副本，读操作则直接访问当前副本。 5. 并发Dequeue并发Dequeue是一种线程安全的双端队列，支持在队列的两端进行插入和删除操作。 ConcurrentLinkedDeque：基于链表实现的无界双端队列，适用于高并发环境下的插入和删除操作。 LinkedBlockingDeque：基于链表实现的有界阻塞双端队列，适用于生产者-消费者模型。 总结Java的java.util.concurrent包提供了多种线程安全的集合类，适用于不同的并发场景。这些集合类通过各种并发控制机制（如分段锁、跳表、CopyOnWrite机制等）确保了在多线程环境下的数据一致性和线程安全。理解这些集合类的特点和适用场景，有助于开发者在实际编程中选择合适的并发集合，从而提高系统的并发性能和可靠性。 Collection与Collections在Java集合框架中，Collections和Collection是两个关键的概念，它们在集合操作中扮演着不同的角色。理解它们的区别和联系对于掌握Java集合框架至关重要。 Collection接口Collection是Java集合框架中的一个基础接口，位于java.util包中。它是所有集合类的基础接口，定义了一系列通用的集合操作方法。 主要功能： 遍历：Collection接口提供了iterator()方法，用于遍历集合中的元素。 插入：Collection接口提供了add()和addAll()方法，用于向集合中插入元素。 删除：Collection接口提供了remove()和removeAll()方法，用于从集合中删除元素。 查询：Collection接口提供了contains()和containsAll()方法，用于查询集合中是否包含指定元素。 大小：Collection接口提供了size()方法，用于获取集合的大小。 Collection接口有许多实现类，如ArrayList、LinkedList、HashSet、TreeSet等，它们分别实现了不同的集合类型和特性。 Collections工具类Collections是Java提供的一个工具类，位于java.util包中。它提供了一系列静态方法，用于对集合进行各种操作，如排序、查找、替换、反转等。 主要功能： 排序：Collections.sort()方法可以对实现了List接口的集合进行排序。 查找：Collections.binarySearch()方法可以在有序集合中进行二分查找。 替换：Collections.replaceAll()方法可以替换集合中的所有指定元素。 反转：Collections.reverse()方法可以反转集合中元素的顺序。 同步：Collections.synchronizedCollection()方法可以将集合包装为线程安全的集合。 不可变集合：Collections.unmodifiableCollection()方法可以创建一个不可变的集合视图。 Collections工具类的方法可以对实现了Collection接口的类进行操作，如List和Set。 区别与联系区别 类型：Collections是一个工具类，而Collection是一个接口。 功能：Collections提供了一系列静态方法，用于对集合进行各种操作；而Collection定义了集合的基本操作方法。 使用方式：Collections的方法通常通过类名直接调用，如Collections.sort(list)；而Collection的方法需要通过集合对象调用，如list.add(element)。 联系 依赖关系：Collections工具类的方法通常作用于实现了Collection接口的集合对象。 共同目标：Collections和Collection都是为了方便开发者对集合进行操作和管理，提高代码的效率和可维护性。 集合遍历在Java中，集合遍历是常见的操作之一。不同的遍历方式适用于不同的场景，选择合适的遍历方式可以提高代码的可读性和性能。以下是几种常见的集合遍历方式及其示例代码片段。 1. 使用foreach循环foreach循环是Java中最简单和常用的遍历方式之一。它适用于遍历任何实现了Iterable接口的集合。 2. 使用Iterator迭代器Iterator是一种传统的遍历方式，适用于需要在遍历过程中修改集合的情况。 3. 使用Stream API（Java 8+）Stream API是Java 8引入的一种函数式编程风格，适用于对集合进行复杂的操作和转换。 "},{"title":"What is Java ?（四）","date":"2024-07-24T05:14:00.000Z","url":"/2024/07/24/What-is-Java-%EF%BC%88%E5%9B%9B%EF%BC%89/","tags":[["序列化","/tags/%E5%BA%8F%E5%88%97%E5%8C%96/"],["I/O","/tags/I-O/"],["其他","/tags/%E5%85%B6%E4%BB%96/"]],"categories":[["编程语言","/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"],["Java","/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Java/"],["基础","/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Java/%E5%9F%BA%E7%A1%80/"]],"content":"内容：序列化、I/O、其他 本篇博客是笔者作为初学者记录自己对Java一些基本概念的理解。内容参考了大量网络资源，篇幅很长，旨在作为个人学习笔记，供自己日后回顾和复习。 序列化怎么把一个对象从一个JVM转移到另一个JVM？ 使用序列化和反序列化：将对象序列化为字节流（objectoutputstream），发送到另一个JVM中再进行字节流反序列化（objectinputstream）。 使用消息传递机制：可以使用消息队列等方式，通过网络传输对象。常见的消息队列系统包括 RabbitMQ、Kafka 等。 远程调用（RPC）：使用远程调用框架（如 RMI、gRPC、Dubbo 等）进行跨 JVM 的对象调用。 使用数据共享：使用数据共享，如将对象所需的数据存入数据库或共享缓存中，能够让其他JVM访问得到。 序列化和反序列化有没有更好的设计？Java默认的序列化虽然方便，但也存在一些问题： 无法跨语言：Java序列化格式是Java特有的，它依赖于Java的内部数据结构和类型系统。因此，生成的序列化数据无法直接被其他编程语言（如Python、C++、JavaScript等）解析和使用。这意味着如果你需要在不同的编程语言之间共享数据，Java序列化机制就无法满足需求。为了实现跨语言的互操作性，通常需要使用更通用的序列化格式，如JSON、XML、Protocol Buffers、Avro等。 容易被攻击：Java序列化机制存在安全漏洞，尤其是在反序列化过程中。攻击者可以通过构造恶意的序列化数据，在反序列化时执行任意代码，从而导致安全问题。这种攻击被称为“反序列化漏洞”或“反序列化攻击”。为了防止这种攻击，开发者需要非常小心地处理反序列化过程，或者使用更安全的序列化机制，如JSON、Protocol Buffers等，这些机制通常不会引入类似的安全风险。 性能差：Java序列化机制在性能方面表现不佳，尤其是在处理大量数据时。主要原因包括： 序列化后的数据体积较大：Java序列化生成的数据通常比其他序列化格式（如Protocol Buffers）更大，这会导致更高的网络传输成本和存储成本。 序列化和反序列化过程较慢：Java序列化机制在处理复杂对象时，性能开销较大。尤其是在需要频繁进行序列化和反序列化操作的场景中，性能问题会更加明显。 更好的设计 为了解决上述问题，可以使用以下几种替代方案： 1. JSON 序列化JSON（JavaScript Object Notation）是一种轻量级的数据交换格式，易于阅读和编写，同时也易于解析和生成。许多编程语言都支持JSON序列化，因此可以实现跨语言的数据交换。 示例代码（使用 Jackson 库） 2. Protocol BuffersProtocol Buffers（ProtoBuf）是Google开发的一种轻量级、高效的序列化格式，支持多种编程语言，并且具有更好的性能和安全性。 示例代码（使用 Protocol Buffers） 首先，定义一个 .proto 文件： 然后，生成Java类并使用： 3. ThriftApache Thrift 是另一种高效的序列化框架，支持多种编程语言，并且具有良好的性能和扩展性。 示例代码（使用 Thrift） 首先，定义一个 .thrift 文件： 然后，生成Java类并使用： 为了解决Java默认序列化机制存在的问题，可以使用JSON、Protocol Buffers和Thrift等替代方案。这些方案具有更好的跨语言支持、更高的安全性和更好的性能，适用于不同的应用场景。 I&#x2F;OBIO、NIO、AIO：Java I&#x2F;O模型的演进在Java编程中，I&#x2F;O操作是不可或缺的一部分。随着技术的发展，Java提供了多种I&#x2F;O模型，以满足不同场景下的需求。本文将简要介绍三种主要的I&#x2F;O模型：BIO（Blocking I&#x2F;O）、NIO（Non-blocking I&#x2F;O）和AIO（Asynchronous I&#x2F;O）。 1. BIO（Blocking I&#x2F;O）BIO是Java传统的I&#x2F;O模型，基于java.io包实现。它通过字节流（Byte Stream）和字符流（Character Stream）来处理数据。BIO的核心特点是同步阻塞，即在进行I&#x2F;O操作时，线程会被阻塞，直到操作完成。这种模型的执行顺序是线性的，代码编写简单直观，但处理效率较低，扩展性有限。 优缺点： 代码简单，易于理解和维护；适用于简单的I&#x2F;O操作场景。 处理效率低，尤其是在高并发环境下，线程阻塞会导致资源浪费；扩展性差，难以应对大规模并发请求。 2. NIO（Non-blocking I&#x2F;O）NIO是Java 1.4引入的一种新型I&#x2F;O模型，旨在解决BIO在高并发环境下的性能瓶颈。NIO的核心思想是同步非阻塞，通过以下三大组件实现： 通道（Channel）：类似于流，但支持双向数据传输。 缓冲区（Buffer）：用于存储数据的容器，支持直接内存操作，提高数据处理效率。 多路复用器（Selector）：用于管理多个通道，实现非阻塞I&#x2F;O操作。 NIO通过Selector机制，允许单个线程管理多个通道，从而避免了线程阻塞，提高了系统的并发处理能力。 优缺点： 非阻塞I&#x2F;O操作，提高了系统的并发处理能力；适用于高并发、低延迟的网络应用。 代码复杂度增加，需要理解Channel、Buffer和Selector等概念；调试和维护相对困难。 3. AIO（Asynchronous I&#x2F;O）AIO是NIO的进一步演进，提供了异步非阻塞的I&#x2F;O操作方式。在AIO模型中，当发起I&#x2F;O操作后，线程不会被阻塞，而是继续执行其他任务，I&#x2F;O操作由后台线程处理完成后，通过回调机制通知主线程。 AIO的核心组件包括： 异步通道（Asynchronous Channel）：支持异步I&#x2F;O操作的通道。 CompletionHandler：用于处理I&#x2F;O操作完成后的回调。 优缺点： 异步非阻塞，进一步提高了系统的并发处理能力；适用于需要高并发、高吞吐量的应用场景。 实现复杂，需要处理回调和异步编程的复杂性；对开发者的技术要求较高。 总结 BIO、NIO和AIO代表了Java I&#x2F;O模型的不同阶段，各自适用于不同的应用场景。BIO简单易用，但处理效率低；NIO通过非阻塞机制提高了并发处理能力，但增加了代码复杂度；AIO则进一步通过异步机制提升了系统的吞吐量，但实现难度较大。选择合适的I&#x2F;O模型，需要根据具体的应用需求和技术栈来决定。 NIO原理详解NIO（Non-blocking I&#x2F;O）是Java 1.4引入的一种新型I&#x2F;O模型，旨在提高I&#x2F;O操作的效率和系统的并发处理能力。NIO的核心思想是同步非阻塞，通过以下三大组件实现： 1. 核心组件 Selector（选择器&#x2F;多路复用器）：Selector是NIO同步机制的核心。它负责轮询多个Channel，检查它们是否准备好进行I&#x2F;O操作（如读、写等）。Selector的引入避免了线程在等待I&#x2F;O操作时的阻塞，从而提高了系统的并发处理能力。 Channel（通道）：Channel类似于传统的流（Stream），但支持双向数据传输。与流不同的是，Channel可以直接与Buffer进行数据交换，无需线程等待。常见的Channel类型包括FileChannel、SocketChannel和ServerSocketChannel。 Buffer（缓冲区）：Buffer是用于存储数据的容器，支持直接内存操作，提高了数据处理的效率。Buffer有多种类型，如ByteBuffer、CharBuffer等，分别用于处理不同类型的数据。 2. 工作原理NIO的工作原理可以概括为以下几个步骤： 注册Channel到Selector：首先，将需要监听的Channel注册到Selector上，并指定感兴趣的事件（如连接、读、写等）。 Selector轮询：Selector会定期轮询所有注册的Channel，检查它们是否准备好进行I&#x2F;O操作。如果某个Channel准备好，Selector会返回一个SelectionKey，表示该Channel可以进行相应的I&#x2F;O操作。 处理I&#x2F;O操作：当Selector检测到某个Channel准备好进行I&#x2F;O操作时，应用程序可以通过SelectionKey获取对应的Channel，并进行读写操作。数据在Channel和Buffer之间进行传输，无需线程等待。 非阻塞机制：由于Selector的轮询机制，线程在等待I&#x2F;O操作时不会被阻塞，可以继续处理其他任务。这种非阻塞机制大大提高了系统的并发处理能力。 3. 事件驱动机制NIO采用了事件驱动机制，当某个I&#x2F;O事件（如连接、读、写等）发生时，Selector会立即触发相应的事件处理逻辑，无需线程不断监视。这种机制减少了线程的空闲等待时间，提高了系统的响应速度。 4. 线程通信在NIO中，线程间通过notify和wait机制进行通信，减少了线程切换的开销。当某个I&#x2F;O操作完成时，线程可以通过notify通知其他线程继续处理，避免了不必要的线程切换。 总结 NIO通过Selector、Channel和Buffer三大组件，实现了同步非阻塞的I&#x2F;O操作。Selector负责轮询Channel，避免了线程在等待I&#x2F;O操作时的阻塞；Channel和Buffer支持高效的数据传输，无需线程等待。NIO的事件驱动机制和线程通信优化，进一步提高了系统的并发处理能力和响应速度。NIO适用于高并发、低延迟的网络应用场景，但需要开发者理解其复杂的工作原理和组件间的协作关系。 其他代理模式和适配器模式有什么区别？代理模式（Proxy Pattern）和适配器模式（Adapter Pattern）是两种常见的设计模式，它们在软件设计中有着不同的用途和实现方式。以下是它们的主要区别： 1. 定义和目的代理模式 定义：代理模式为其他对象提供一个代理或占位符，以控制对这个对象的访问。 目的：主要用于控制对对象的访问，可以在不改变原始对象的情况下，增加额外的功能（如权限控制、延迟初始化、日志记录等）。 适配器模式 定义：适配器模式将一个类的接口转换成客户端所期望的另一个接口。 目的：主要用于解决接口不兼容的问题，使得原本由于接口不匹配而无法一起工作的类可以协同工作。 2. 结构和实现代理模式 结构：代理模式通常包含一个代理类和一个真实主题类。代理类和真实主题类实现相同的接口，代理类内部持有真实主题类的引用。 实现：代理类在调用真实主题类的方法前后，可以执行额外的操作（如权限检查、日志记录等）。 适配器模式 结构：适配器模式通常包含一个适配器类、一个目标接口和一个被适配者类。适配器类实现目标接口，并在内部持有被适配者类的引用。 实现：适配器类将目标接口的方法调用转换为被适配者类的方法调用。 3. 使用场景代理模式 场景：当需要控制对某个对象的访问时，可以使用代理模式。例如： 远程代理：控制对远程对象的访问。 虚拟代理：延迟加载对象，直到真正需要时才创建。 保护代理：控制对敏感对象的访问权限。 日志代理：在方法调用前后记录日志。 适配器模式 场景：当需要将一个类的接口转换为另一个接口，以便与现有代码兼容时，可以使用适配器模式。例如： 旧系统与新系统的接口不兼容。 第三方库的接口与现有代码不匹配。 需要复用已有的类，但其接口不符合需求。 总结 代理模式：主要用于控制对对象的访问，可以在不改变原始对象的情况下，增加额外的功能。 适配器模式：主要用于解决接口不兼容的问题，使得原本由于接口不匹配而无法一起工作的类可以协同工作。 集合多属性排序假如有一个学生数组，想要按照成绩降序、学号升序排序，如何实现？ 在Java中，可以使用Comparator接口来实现集合的多属性排序。以下是一个示例，展示了如何对学生数组按照成绩降序、学号升序进行排序。 示例代码 代码说明 Student类：定义了一个学生类，包含学号（id）、姓名（name）和成绩（score）三个属性。 Main类：包含主方法，用于创建学生数组并进行排序。 排序逻辑： 使用Arrays.sort方法对学生数组进行排序。 通过Comparator接口实现多属性排序： 首先按成绩降序排序（Double.compare(s2.getScore(), s1.getScore())）。 如果成绩相同，按学号升序排序（Integer.compare(s1.getId(), s2.getId())）。 输出结果：排序后的学生数组将按照成绩降序、学号升序的顺序输出。 输出示例 tips 理解Comparator接口的用法，特别是与Collections.sort()方法结合使用时，关键在于理解compare方法的返回值如何影响排序结果。 Comparator接口的compare方法 Comparator接口的compare方法定义如下： 这个方法的返回值决定了o1和o2的相对顺序： 如果返回负值，表示o1应该排在o2之前（即o1小于o2）。 如果返回0，表示o1和o2相等，顺序不变。 如果返回正值，表示o1应该排在o2之后（即o1大于o2）。 升序和降序的实现 为了实现升序或降序排序，你需要根据compare方法的返回值来调整对象的相对顺序。 升序排序 升序排序意味着较小的元素应该排在前面。因此，如果o1小于o2，compare方法应该返回负值。 降序排序 降序排序意味着较大的元素应该排在前面。因此，如果o1小于o2，compare方法应该返回正值。 native方法native方法是Java中的一种特殊方法，它使用native关键字进行声明，表示该方法的实现是由非Java代码（通常是C&#x2F;C++代码）提供的。native方法允许Java程序调用底层操作系统或其他语言编写的库，从而实现Java与本地代码的交互。 volatile 和 synchronized 的区别volatile 和 synchronized 是 Java 中用于处理并发问题的关键字，但它们的作用和使用场景有所不同。 1. volatile作用： 保证可见性： 当一个线程修改了 volatile 变量的值时，其他线程能够立即看到这个修改。 禁止指令重排序： volatile 变量的读写操作不会被 JVM 优化重排序，从而保证有序性。 适用场景： 单个变量的读写： volatile 适用于单个变量的读写操作，特别是当这个变量被多个线程共享时。 状态标志： 例如，用于控制线程是否继续运行的标志变量。 代码示例： 2. synchronized作用： 互斥访问： synchronized 关键字用于实现互斥访问，确保同一时刻只有一个线程可以执行被 synchronized 修饰的代码块或方法。 保证可见性： 进入 synchronized 代码块或方法时，会清空工作内存中的变量副本，从主内存中重新加载；退出时，会将工作内存中的变量值刷新到主内存。 适用场景： 多个变量的读写： synchronized 适用于多个变量的读写操作，特别是当这些变量需要保持一致性时。 复杂的同步逻辑： 例如，需要对多个操作进行同步的场景。 代码示例： 区别总结 特性 volatile synchronized 作用 保证可见性、禁止指令重排序 互斥访问、保证可见性 适用场景 单个变量的读写、状态标志 多个变量的读写、复杂的同步逻辑 性能 相对较高，因为不需要加锁 相对较低，因为需要加锁 使用范围 仅限于变量 可以用于方法、代码块 原子性 不能保证复合操作的原子性 可以保证复合操作的原子性 "},{"title":"What is Java ?（三）","date":"2024-07-23T05:14:00.000Z","url":"/2024/07/23/Java-is-What-%EF%BC%88%E4%B8%89%EF%BC%89/","tags":[["注解","/tags/%E6%B3%A8%E8%A7%A3/"],["异常","/tags/%E5%BC%82%E5%B8%B8/"],["Object","/tags/Object/"],["Java8新特性","/tags/Java8%E6%96%B0%E7%89%B9%E6%80%A7/"]],"categories":[["编程语言","/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"],["Java","/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Java/"],["基础","/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Java/%E5%9F%BA%E7%A1%80/"]],"content":"内容：注解、异常、Object、Java8新特性 本篇博客是笔者作为初学者记录自己对Java一些基本概念的理解。内容参考了大量网络资源，篇幅很长，旨在作为个人学习笔记，供自己日后回顾和复习。 注解在Java中，注解（Annotation）是一种元数据（metadata），它提供了关于程序代码的额外信息，但本身并不直接影响程序的执行。注解可以用于类、方法、字段、参数、局部变量等程序元素上，用于在编译时、运行时或部署时提供额外的信息。 注解本质是一个继承了Annotation的特殊接口，其具体实现类是Java运行时生成的动态代理类。我们通过反射获取注解时，返回的是Java运行时生成的动态代理对象。通过代理对象调用自定义注解的方法，会最终调用AnnotationlnvocationHandler的invoke方法。该方法会从memberValues这个Map中索引出对应的值。而memberValues的来源是Java常量池。 注解的原理 定义注解：注解是通过@interface关键字定义的。例如： 这个注解MyAnnotation有两个元素：value和count。value是必需的，而count有一个默认值1。 元注解：元注解是用于注解其他注解的注解。Java提供了几个内置的元注解，用于控制注解的行为： @Retention：指定注解的保留策略，即注解在什么阶段有效（源码、编译时、运行时）。 RetentionPolicy.SOURCE：注解仅在源码中保留，编译时丢弃。 RetentionPolicy.CLASS：注解在编译时保留，但运行时不可见。 RetentionPolicy.RUNTIME：注解在运行时保留，可以通过反射获取。 @Target：指定注解可以应用的目标类型（类、方法、字段等）。 ElementType.TYPE：类、接口、枚举。 ElementType.METHOD：方法。 ElementType.FIELD：字段。 ElementType.PARAMETER：方法参数。 ElementType.CONSTRUCTOR：构造函数。 ElementType.LOCAL_VARIABLE：局部变量。 ElementType.ANNOTATION_TYPE：注解类型。 ElementType.PACKAGE：包。 @Documented：指定注解是否包含在JavaDoc中。 @Inherited：指定注解是否可以被子类继承。 @Repeatable：指定注解是否可以重复应用在同一个元素上。 使用注解：注解可以应用在类、方法、字段等程序元素上。例如： 处理注解：注解本身并不做任何事情，它们需要通过某种方式被处理才能发挥作用。处理注解的方式主要有两种： 编译时处理：使用注解处理器（Annotation Processor）在编译时处理注解。例如，Lombok库使用注解处理器在编译时生成代码。 运行时处理：使用反射（Reflection）在运行时获取注解信息。例如： 这个方法通过反射检查类上是否存在MyAnnotation注解，并获取注解的值。 总结 注解的原理可以概括为以下几点： 定义注解：使用@interface关键字定义注解，并指定注解的元素。 元注解：使用元注解控制注解的行为，如保留策略、目标类型等。 使用注解：将注解应用在程序元素上。 处理注解：通过编译时处理或运行时反射来处理注解，使其发挥作用。 应用作用域在Java中，注解可以应用于多种程序元素，包括类、方法、字段（属性）、参数、局部变量等。注解的作用域（即注解可以应用的目标类型）由@Target元注解指定。以下是一些常见的注解作用域及其对应的ElementType枚举值： 1. 类注解可以应用于类、接口、枚举等类型定义上。对应的ElementType是TYPE。 使用示例： 2. 方法注解可以应用于方法定义上。对应的ElementType是METHOD。 使用示例： 3. 属性（字段）注解可以应用于字段（属性）定义上。对应的ElementType是FIELD。 使用示例： 其他作用域除了上述常见的类、方法和字段，注解还可以应用于其他程序元素： 参数：注解可以应用于方法参数上。对应的ElementType是PARAMETER。 使用示例： 构造函数：注解可以应用于构造函数上。对应的ElementType是CONSTRUCTOR。 使用示例： 局部变量：注解可以应用于局部变量上。对应的ElementType是LOCAL_VARIABLE。 使用示例： 注解类型：注解可以应用于其他注解类型上。对应的ElementType是ANNOTATION_TYPE。 使用示例： 包：注解可以应用于包声明上。对应的ElementType是PACKAGE。 使用示例： 异常啥是异常？Java异常主要基于两大类：Throwable类及其子类。Throwable的子类主要有两个重要的子类：Error和Exception，它们分别代表了不同类型的异常情况。 ErrorError表示运行环境错误，极难恢复，不能指望程序自己处理这些异常。比如系统崩溃、连接错误等。比如OutOfMemoryError内存不足错误、StackOverflowError栈溢出错误。通常程序不应该去捕获这些错误，因为它们表示系统级别的严重问题，程序无法自行恢复。 ExceptionException表示运行程序错误，根据发生时期又可以分为编译时异常和运行时异常。 编译时异常（Checked Exception）在代码编译时出现的异常，必须显式处理（捕获或声明抛出）。这些异常通常是程序外部的异常，比如文件不存在、无法找到类等。对于这些异常必须使用try-catch块捕获异常，或者在方法签名中使用throws关键字声明抛出异常。 运行时异常（Unchecked Exception）程序运行过程中出现的异常，通常由程序逻辑错误引起，不需要显式处理。 常见异常： NullPointerException：空指针异常。 IllegalArgumentException：非法参数异常。 ClassCastException：类转换异常。 IndexOutOfBoundsException：数组越界异常。 虽然运行时异常不需要显式处理，但建议在代码中进行适当的检查和处理，以提高程序的健壮性。 异常处理机制Java提供了异常处理机制，通过try-catch语句块来捕获和处理异常。以下是Java常见的异常处理方式： try块：包含可能抛出异常的代码。 catch块：捕获并处理异常。 throw语句：用于手动抛出异常。 finally块：无论是否发生异常，都会执行的代码块，通常用于资源清理。 示例代码 以下是一个完整的异常处理示例，展示了如何使用try-catch语句块、throw语句和finally块： 抛出异常为什么不用throws？如果说异常是未检查异常（Unchecked Exception）或已经在方法内部处理，就不需要再使用throws声明了。 Unchecked Exception：未检查异常，是继承自RuntimeException类或者Error类的异常，编译器不强制要求进行异常处理。因此对于这些异常，不需要在方法签名中使用throws来声明。 捕获和异常处理：另一种常见情况是已经在方法内部捕获了可能抛出的异常并在方法内部处理它们。 try-catch的执行顺序正常情况下会按顺序执行try块中的代码，当运行过程中出现异常则跳转到相应的catch异常捕获块，最后无论是否出现异常，总会执行finally块。 常见问题 以下这段代码最后会返回什么？ 答案是返回&#39;b&#39;。因为try的return语句先执行，压入返回栈中，而finally中的return方法后执行，也压入栈中，返回结果先弹出栈上方的元素，所以会返回&#39;b&#39;，也就是说finally中的return会覆盖try块的返回语句。 示例代码 以下是一个示例，展示了try-catch-finally块的执行顺序： 输出结果： 在这个示例中，try块中的return &#39;a&#39;语句先执行，但被finally块中的return &#39;b&#39;语句覆盖，因此最终返回值为&#39;b&#39;。 Object“&#x3D;&#x3D;”与“equals”有什么区别？对于字符串变量，==与equals方法是不同的。==判断的是两个对象的引用是否相同，即比较两个对象的内存首地址是否指向同一个对象，而equals则判断的是两个对象的值是否相同。 示例代码片段，对于字符串来说： 对于非字符串来说，若没有对equals方法重写，则==和equals是相同的，都是比较两个对象的内存首地址是否相同，即比较两个对象的引用是否指向同一个变量。 示例代码片段，对于非字符串对象： “equals”与“hashCode”equals方法用于比较两个对象是否相等，而hashCode方法返回对象的哈希码值。在Java中，如果两个对象通过equals方法比较相等，那么它们的hashCode值必须相同。反之，如果两个对象的hashCode值相同，它们不一定相等。 示例代码片段 StringBuilder和StringBuffer由于String类型是不可变的（immutable），每次对String进行修改操作时，都会创建一个新的String对象，这可能会导致性能问题。为了解决这个问题，Java提供了StringBuilder和StringBuffer类，它们是可变的（mutable），允许在原有对象上进行修改操作。 区别 线程安全： StringBuffer是线程安全的，适用于多线程环境。 StringBuilder不是线程安全的，适用于单线程环境，性能更高。 性能： 通常情况下，StringBuilder的性能优于StringBuffer，因为StringBuffer需要维护线程安全，会带来额外的开销。 String的性能通常是最差的，因为每次修改都会创建新的对象。 使用场景： 在单线程环境中，推荐使用StringBuilder以获得最佳性能。 在多线程环境中，如果需要线程安全，使用StringBuffer。 示例代码片段 Java 1.8 新特性Stream APIJava 8 引入了 Stream API，提供了一种更加高效的数据处理方式，特别是对于集合的操作如过滤、排序、映射等。使用 Stream 能够充分利用多核处理器的优势进行并行处理。 示例 以下是一个简单的示例，展示了如何使用 Stream API 对集合进行操作： 解释 创建列表： 使用 Arrays.asList 创建一个包含整数的列表。 使用 Stream API： numbers.stream()：创建一个顺序流。 filter(n -&gt; n % 2 == 0)：过滤出偶数。 map(n -&gt; n * n)：将每个偶数计算平方。 collect(Collectors.toList())：将结果收集到一个列表中。 使用并行流： numbers.parallelStream()：创建一个并行流，充分利用多核处理器的优势。 输出 总结 Stream API 提供了一种简洁、高效的方式来处理集合数据，支持顺序和并行处理，能够显著提高数据处理的性能。通过合理使用 Stream API，可以简化代码并提高程序的可读性和可维护性。 Stream流的并行API即 ParallelStream。并行流其实带着“分而治之”的思想，在处理源数据时，将数据分成多个子流，然后将处理结果汇总为一个流对象。底层逻辑是使用 Fork&#x2F;Join 框架来实现并行处理。 对CPU密集型的任务来说，并行流使用ForkJoinPool线程池，为每个CPU分配一个任务，这是非常有效率的，但是如果任务不是CPU密集的，而是I&#x2F;O密集的，并且任务数相对线程数比较大，那么直接用Parallelstream并不是很好的选择。 CompletableFutureCompletableFuture 是 Java 8 引入的一个类，用于支持异步编程和非阻塞操作。它实现了 Future 接口，并提供了更强大的功能，如组合多个异步任务、处理异常、以及在任务完成时执行回调等。 主要功能 异步执行任务：使用 CompletableFuture.supplyAsync 或 CompletableFuture.runAsync 方法来异步执行任务。 任务组合：使用 thenApply、thenAccept、thenRun 等方法来组合多个异步任务。 异常处理：使用 exceptionally 方法来处理异常。 任务完成时的回调：使用 whenComplete 方法在任务完成时执行回调。 示例 以下是一个简单的示例，展示了如何使用 CompletableFuture 进行异步编程： 解释 异步执行任务：CompletableFuture.supplyAsync(() -&gt; &#123; ... &#125;)：异步执行一个返回值为 String 的任务。 任务完成时的回调：future.thenAccept(result -&gt; &#123; ... &#125;)：在任务完成时执行回调，输出结果。 异常处理：future.exceptionally(ex -&gt; &#123; ... &#125;)：处理任务执行过程中可能抛出的异常。 等待任务完成：future.get()：等待任务完成并获取结果。 输出 再来一个简单的组合示例： "},{"title":"What is Java ?（二）","date":"2024-07-20T05:14:00.000Z","url":"/2024/07/20/What-is-Java-%EF%BC%88%E4%BA%8C%EF%BC%89/","tags":[["拷贝","/tags/%E6%8B%B7%E8%B4%9D/"],["泛型","/tags/%E6%B3%9B%E5%9E%8B/"],["对象","/tags/%E5%AF%B9%E8%B1%A1/"],["反射","/tags/%E5%8F%8D%E5%B0%84/"]],"categories":[["编程语言","/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"],["Java","/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Java/"],["基础","/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Java/%E5%9F%BA%E7%A1%80/"]],"content":"内容：拷贝、泛型、对象、反射 本篇博客是笔者作为初学者记录自己对Java一些基本概念的理解。内容参考了大量网络资源，篇幅很长，旨在作为个人学习笔记，供自己日后回顾和复习。 拷贝浅拷贝和深拷贝的区别浅拷贝（Shallow Copy）浅拷贝复制了一个对实例对象的引用，因此在内存中这两个对象指向的是同一个对象。换句话说，浅拷贝只复制了对象的引用，而不是对象本身。 示例代码 解释：original 和 copy 指向同一个对象，因此修改 copy 的值也会影响 original。 深拷贝（Deep Copy）深拷贝新建一个一模一样的实例对象，两个对象的引用指向的是不同的地址。换句话说，深拷贝复制了对象本身，而不是对象的引用。 示例代码 解释：original 和 copy 指向不同的对象，因此修改 copy 的值不会影响 original。 图示 实现深拷贝的方法常用的深拷贝方法有三种： 实现 Cloneable 接口的 clone 方法 使用序列化和反序列化 手写递归复制 1. 实现 Cloneable 接口的 clone 方法通过实现 Cloneable 接口并重写 clone 方法，可以实现深拷贝。需要注意的是，clone 方法默认是浅拷贝，因此需要手动处理对象的深拷贝。 示例代码 2. 使用序列化和反序列化通过将对象序列化为字节流，然后再反序列化为新的对象，可以实现深拷贝。这种方法适用于实现了 Serializable 接口的对象。 示例代码 3. 手写递归复制通过手写递归方法，逐层复制对象的每个字段，可以实现深拷贝。这种方法适用于任何对象，但需要手动处理每个字段的复制。 示例代码 总结 实现 Cloneable 接口的 clone 方法：适用于简单的对象，需要手动处理深拷贝。 使用序列化和反序列化：适用于实现了 Serializable 接口的对象，可以自动处理深拷贝。 手写递归复制：适用于任何对象，需要手动处理每个字段的复制。 泛型什么是泛型？泛型是 Java 语言中的一个重要特性，它允许类、接口和方法在定义时使用一个或多个类型参数，而这些参数在实际运行时才会指定具体的参数类型。泛型提供了一种在编译时进行类型检查的机制，从而提高代码的类型安全性和可读性。 为什么需要泛型？泛型的主要目的是提高代码的类型安全性和可读性，具体体现在以下几个方面： 适用于多种类型执行相同的代码： 泛型允许在定义类、接口和方法时使用类型参数，从而可以在不同的类型上执行相同的代码。 类型安全： 泛型在编译时进行类型检查，确保类型的一致性，避免运行时类型转换错误。 使用泛型可以减少强制类型转换的需求，提高代码的可读性和安全性。 示例代码 总结 泛型：允许在定义类、接口和方法时使用类型参数，提高代码的类型安全性和可读性。 类型安全：泛型在编译时进行类型检查，避免运行时类型转换错误。 减少强制类型转换：使用泛型可以减少强制类型转换的需求，提高代码的可读性和安全性。 通过这些特性，泛型在 Java 编程中提供了更强大的类型检查和代码复用能力，使得代码更加健壮和易于维护。 对象创建对象的方式 使用new关键字： 这是最常见和最直接的对象创建方式。通过调用类的构造函数来实例化对象。 示例： 使用clone方法： 通过调用对象的clone方法来创建对象的副本。需要注意的是，类必须实现Cloneable接口。 示例： 使用反序列化： 通过将对象序列化为字节流，然后再反序列化来创建对象。这通常用于对象的持久化存储和传输。 示例： 使用Class类的newInstance方法： 通过调用Class类的newInstance方法来创建对象。需要注意的是，该方法要求类具有无参构造函数。 示例： 使用Constructor的newInstance方法： 通过调用Constructor类的newInstance方法来创建对象。这种方式允许使用带参数的构造函数。 示例： new的对象什么时候回收？通过关键字new创建的对象，由Java的垃圾回收器（Garbage Collector, GC）负责回收。垃圾回收器的工作是在程序运行过程中自动进行的，它会周期性地检测不再被引用的对象，并将其回收以释放内存。 回收时机 Java对象的回收时机是由垃圾回收器根据一些算法来决定的，主要有以下几种情况： 引用计数法：当某个对象的引用计数为0时，表示该对象不再被引用，可以被回收。然而，Java并不采用引用计数法，因为它无法解决循环引用的问题。 可达性分析算法：从根对象（如方法区中的类静态属性、方法中的局部变量等）出发，通过对象之间的引用链进行遍历。如果存在一条引用链到达某个对象，则说明该对象是可达的；反之，不可达的对象将被回收。可达性分析算法是Java垃圾回收器主要采用的方法。 终结器（Finalizer）：如果对象重写了finalize()方法，垃圾回收器会在回收该对象之前调用finalize()方法。对象可以在finalize()方法中进行一些清理操作。然而，终结器机制的使用不被推荐，因为它的执行时间是不确定的，可能会导致不可预测的性能问题。 流程如下： 反射什么是反射？Java反射机制是指在运行状态中，任意一个类都能知道这个类中的所有方法和属性，并且任意对象都能调用这个类对象的属性和方法。这种动态获取的信息和调用对象方法的功能称为Java的反射机制。 反射机制如图所示： 动态性： 反射允许在运行时动态地获取类的完整结构信息，包括类名、父类、方法和属性等，并调用其方法（包括私有方法），而不需要在编译时确定。 示例：通过Class.forName()方法动态加载类，并使用getMethods()、getFields()等方法获取类的结构信息。 灵活性： 反射提供了灵活的编程方式，可以在运行时根据需要创建对象、调用方法和访问属性。 示例：使用反射API动态地创建对象实例，即使在编译时不知道具体的类名。这是通过Class类的newInstance()方法或Constructor对象的newInstance()方法实现的。 访问私有成员： 反射可以访问类的私有成员（如私有方法和私有属性），这在正常情况下是不允许的。 示例：通过Field类的setAccessible(true)方法绕过访问控制，使用get()和set()方法访问和修改私有字段的值。 反射常见应用场景 框架开发：许多框架（如Spring、Hibernate）使用反射来动态加载和配置类，实现依赖注入和AOP（面向切面编程）等功能。 序列化和反序列化：在对象的序列化和反序列化过程中，反射用于动态地访问和设置对象的属性。 动态代理：反射与动态代理结合使用，可以在运行时创建代理对象，实现方法的拦截和增强。 单元测试：单元测试框架（如JUnit）使用反射来动态地发现和执行测试方法。 插件化系统：反射用于动态加载和执行插件，使得系统具有扩展性和灵活性。 ORM框架：ORM（对象关系映射）框架使用反射来将数据库表映射到Java对象，并动态地生成SQL语句。 反射的优缺点优点 灵活性：反射提供了极大的灵活性，允许在运行时动态地操作类和对象。 扩展性：反射使得系统具有更好的扩展性，可以通过插件或配置文件动态加载和执行代码。 缺点 性能开销：反射操作通常比直接调用方法或访问属性要慢，因为它涉及到动态解析和安全检查。 安全风险：反射可以访问和修改类的私有成员，这可能会导致安全问题。 代码可读性：反射代码通常比直接调用方法或访问属性的代码更复杂，可读性较差。 "},{"title":"What is Java ?（一）","date":"2024-07-15T05:14:00.000Z","url":"/2024/07/15/What-is-Java-%EF%BC%88%E4%B8%80%EF%BC%89/","tags":[["Java基本概念","/tags/Java%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/"],["数据类型","/tags/%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/"],["面向对象","/tags/%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1/"]],"categories":[["编程语言","/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"],["Java","/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Java/"],["基础","/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Java/%E5%9F%BA%E7%A1%80/"]],"content":"内容：Java基本概念、数据类型、面向对象 本篇博客是笔者作为初学者记录自己对Java一些基本概念的理解。内容参考了大量网络资源，篇幅很长，旨在作为个人学习笔记，供自己日后回顾和复习。 概念Java的特点Java语言以其三大核心特点著称： 跨平台性：Java的口号“一次编译，处处运行”体现了其强大的跨平台能力。Java源代码经过编译后生成字节码文件（.class文件），这些字节码文件可以在任何安装了Java虚拟机（JVM）的平台上运行。需要注意的是，虽然Java语言本身是跨平台的，但JVM并非跨平台，因此在不同的操作系统上需要安装相应的JDK（Java Development Kit）。 面向对象：Java是一门严格遵循面向对象编程范式的语言。它将现实世界中的业务逻辑抽象为对象，并通过对象的属性和行为来描述这些逻辑，从而使得代码更贴近现实世界的模型，便于理解和维护。 自动内存管理：Java内置了垃圾回收机制，能够自动回收不再使用的内存资源，避免了开发者手动管理内存的繁琐工作。这一特性大大减少了内存泄漏和内存溢出等常见问题，提升了程序的稳定性和开发效率。 Java如何实现跨平台Java之所以能够实现跨平台运行，关键在于其核心组件——Java虚拟机（Java Virtual Machine，简称JVM）。JVM是Java Development Kit（JDK）中的一个重要组成部分，它负责将编译后的字节码文件解释并执行。 具体来说，Java源代码首先被编译成与平台无关的字节码文件（.class文件）。这些字节码文件随后被JVM解释执行。由于JVM在不同的操作系统上都有相应的实现版本，因此相同的字节码文件可以在安装了相应JVM的任何操作系统上运行。 这种机制使得Java具备了“一次编译，处处运行”的特性，极大地提高了代码的可移植性。开发者只需编写一次代码，并将其编译成字节码，就可以在多种平台上运行，而无需针对不同平台进行额外的编译工作。 Java与其他编程语言的区别与人类能够理解的自然语言不同，计算机只能理解由“0”和“1”组成的机器指令集。常见的编程语言如C&#x2F;C++、Java、Python、TypeScript等属于高级语言，这些语言编写的代码机器本身无法直接理解，需要经过特定的处理才能转化为机器指令。根据处理方式的不同，编程语言可以分为两大类： 编译型语言： 代表语言：C&#x2F;C++ 特点：源代码在运行前需要通过编译器编译成机器码，生成可执行文件。这种方式的优点是执行速度快，但缺点是可移植性较差，因为生成的机器码通常是针对特定平台的。 解释型语言： 代表语言：Python 特点：源代码在运行时由解释器逐行解释并执行。这种方式的优点是跨平台性好，但缺点是执行速度相对较慢。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Java结合了编译型和解释型语言的特点，采用了编译+解释+即时编译（Just-In-Time Compilation，JIT）的执行方式，JVM解释执行流程图如下： 编译阶段： Java源代码首先被编译成字节码文件（.class文件），这些字节码文件是与平台无关的中间代码。 解释阶段： 字节码文件在运行时由Java虚拟机（JVM）解释执行，JVM将字节码翻译成特定平台的机器指令。 需要注意的是，字节码文件在JVM中并不仅仅被解释执行，同时也会使用即时编译技术进行优化。 即时编译（JIT）： 即时编译技术允许JVM在运行时将频繁执行的字节码直接编译成机器码，从而提高执行效率。 在JVM中，使用程序计数器（Program Counter，PC）来跟踪当前执行的字节码指令。当某个字节码指令被执行到一定次数时，JVM会启用即时编译技术。 JIT编译器会监控字节码的执行频率，当发现某些代码块频繁执行时，会将这些代码块编译成机器码，并缓存起来，以便后续执行时直接使用机器码，从而提高执行速度。 这种混合执行方式使得Java既具备了编译型语言的高效性，又具备了解释型语言的跨平台性。开发者只需编写一次代码，并将其编译成字节码，就可以在安装了JVM的任何平台上运行，从而实现了“一次编译，处处运行”的特性。 总结来说，Java通过其独特的编译+解释执行方式，在保持高效性的同时，实现了高度的跨平台性，这是它与其他编程语言的主要区别之一。 JDK、JRE、JVMJDK、JRE和JVM是Java开发和运行环境中的三个核心组件，它们之间的关系如下： JDK（Java Development Kit）：JDK是Java开发工具包，包含了开发Java应用程序所需的所有工具和库。主要组件包括编译器（javac）、调试工具（jdb）、Java标准库和其他开发工具所需的库。JDK中包含了JRE，因此开发者可以在本地运行和测试他们编写的Java程序。 JRE（Java Runtime Environment）：JRE是Java程序运行时所需的最小环境，包括一组Java库和JVM。主要组件包括Java标准库和JVM，确保Java程序能够在任何安装了JRE的系统上运行。 JVM（Java Virtual Machine）：JVM是Java虚拟机，是Java程序运行的核心环境。主要功能包括字节码解释执行、内存管理（包括垃圾回收）、安全性和跨平台性。JVM使得Java程序能够在不同的操作系统上运行，实现了“一次编译，处处运行”的特性。 三者的关系 JDK包含JRE：JDK是开发工具包，包含了开发Java应用程序所需的所有工具和库，其中就包括JRE。 JRE包含JVM：JRE是运行Java程序所需的最小环境，包含了Java库和JVM。 简而言之，JDK是开发工具包，JRE是运行环境，JVM是执行引擎。JDK包含JRE，JRE包含JVM。 数据类型基本数据类型Java中有8种基本数据类型，主要分为3类： 数值型： 整型：byte、short、int、long 浮点型：float、double 字符型：char 布尔型：boolean 各个数据类型所占字节数和取值范围表示如下（一个字节占8个bit位）： 数据类型 字节数 默认值 取值范围 byte 1 0 -128 到 127（-2^7~2^7-1） short 2 0 -32,768 到 32,767（-2^15~2^15-1） int 4 0 -2,147,483,648 到 2,147,483,647（-2^31~2^31-1） long 8 0L -9,223,372,036,854,775,808 到 9,223,372,036,854,775,807（-2^63~2^63-1） float 4 0.0f 大约 ±3.4E+38（有效位数为6-7位） double 8 0.0d 大约 ±1.7E+308（有效位数为15位） char 2 ‘\\u0000’ 0 到 65,535（Unicode字符） boolean 1 false true 或 false 数据类型转换数据类型转换方式在Java中，数据类型转换主要有以下几种方式： 自动类型转换（隐式转换） 当目标类型的范围大于源类型时，Java会自动将源类型转换为目标类型，无需显式的类型转换。例如： 将 int 转换为 long 将 float 转换为 double 强制类型转换（显式转换） 当目标类型的范围小于源类型时，需要使用强制类型转换将源类型转换为目标类型。这可能导致数据丢失或溢出。语法为： 例如： 将 long 转换为 int 将 double 转换为 int 字符串转换 Java提供了将字符串表示的数据转换为其他类型数据的方法。例如： 将字符串转换为整型 int，可以使用 Integer.parseInt() 方法。 将字符串转换为浮点型 double，可以使用 Double.parseDouble() 方法。 数值之间的转换 Java提供了一些数值类型之间的转换方法，如将整型转换为字符型、将字符型转换为整型等。这些转换方式可以通过类型的包装类来实现，例如 Character 类、Integer 类等提供了相应的转换方法。 类型互转可能出现的问题 数据丢失 当将一个范围较大的数据类型转换为一个范围较小的数据类型时，可能会发生数据丢失。例如：将一个 long 类型的值转换为 int 类型时，如果 long 值超出了 int 类型的范围，转换结果将是截断后的低位部分，高位部分的数据将丢失。 数据溢出 与数据丢失相反，当将一个范围较小的数据类型转换为一个范围较大的数据类型时，可能会发生数据溢出。例如：将一个 int 类型的值转换为 long 类型时，转换结果会填充额外的高位空间，但原始数据仍然保持不变。 精度损失 在进行浮点数类型的转换时，可能会发生精度损失。例如：将一个单精度浮点数（float）转换为双精度浮点数（double）时，精度可能会损失。 类型不匹配导致的错误 在进行类型转换时，需要确保源类型和目标类型是兼容的。如果两者不兼容，可能会导致编译错误或运行时错误。 基本数据类型与包装类为何需要包装类？在Java中，包装类（Wrapper Classes）的存在有以下几个重要原因： 对象封装： 包装类将基本数据类型（如 int、char、boolean 等）封装成对象，使得这些基本数据类型可以像对象一样进行操作。例如，Integer 类不仅封装了 int 类型的数据，还提供了许多处理 int 数据的方法，如 parseInt()、valueOf() 等。 集合类的支持： Java中的集合类（如 ArrayList、HashMap 等）只能存储对象，不能直接存储基本数据类型。因此，如果需要将基本数据类型存储在集合中，必须将其包装成对应的包装类对象。例如，将 int 类型的数据存储在 ArrayList 中时，需要将其转换为 Integer 对象。 方法参数和返回值： 许多Java方法和API要求使用对象作为参数或返回值，而不是基本数据类型。例如，java.util.Collections 类中的许多方法都要求使用 List&lt;Integer&gt; 而不是 List&lt;int&gt;。 提供额外功能： 包装类提供了许多有用的方法来处理基本数据类型，如类型转换、字符串解析、比较等。例如，Integer 类提供了parseInt() 方法将字符串转换为 int，Double 类提供了 parseDouble() 方法将字符串转换为 double。 以下是包装类应用的示例代码： 包装类及其对应的基本数据类型： 包装类 对应的基本数据类型 Byte byte Short short Integer int Long long Float float Double double Character char Boolean boolean 通过使用包装类，Java开发者可以更方便地处理基本数据类型，并充分利用面向对象编程的优势。 基本数据类型与包装类的转换：装箱和拆箱在Java中，装箱（Boxing）和拆箱（Unboxing）是基本数据类型与其对应的包装类之间的自动转换过程。 装箱（Boxing）装箱是指将基本数据类型转换为其对应的包装类对象。Java编译器会自动完成这个过程，称为自动装箱。例如： 在这个例子中，int 类型的 num 被自动转换为 Integer 对象 wrappedNum。 拆箱（Unboxing）拆箱是指将包装类对象转换为其对应的基本数据类型。Java编译器也会自动完成这个过程，称为自动拆箱。例如： 在这个例子中，Integer 对象 wrappedNum 被自动转换为 int 类型的 num。 装箱和拆箱的应用场景 集合类：集合类（如 ArrayList、HashMap 等）只能存储对象，因此需要将基本数据类型装箱后才能存储在集合中。例如： 方法参数和返回值：许多方法要求使用对象作为参数或返回值，因此需要将基本数据类型装箱后传递给这些方法。例如： 通过装箱和拆箱，Java开发者可以更方便地在基本数据类型和包装类之间进行转换，从而充分利用面向对象编程的优势。 自动装拆箱的弊端虽然自动装箱（Autoboxing）和自动拆箱（Auto-unboxing）为Java开发者提供了便利，但它们也存在一些潜在的弊端和需要注意的问题： 性能开销：自动装箱和拆箱涉及到对象的创建和销毁，这会带来一定的性能开销。频繁的装箱和拆箱操作可能会导致性能下降，尤其是在循环或大量数据处理的情况下。 空指针异常：自动拆箱时，如果包装类对象为 null，会抛出 NullPointerException。例如： 代码可读性：过多的自动装箱和拆箱可能会降低代码的可读性，尤其是在复杂的表达式中。例如： 类型转换错误：自动装箱和拆箱可能会导致类型转换错误，尤其是在混合使用不同类型的包装类时。例如： 虽然自动装箱和拆箱为Java开发者提供了便利，但在使用时需要注意其潜在的性能开销、空指针异常、代码可读性和类型转换错误等问题。合理使用自动装箱和拆箱，可以提高代码的简洁性和可读性，但过度依赖可能会带来不必要的麻烦。 有了包装类，还留着基本数据类型干啥？在Java中，保留基本数据类型（Primitive Types）而不全部使用包装类（Wrapper Classes）有以下几个重要原因： 性能优势： 内存占用：基本数据类型直接存储在栈内存中，占用空间小，访问速度快。而包装类对象存储在堆内存中，占用空间较大，访问速度相对较慢。 操作效率：基本数据类型的操作（如算术运算、逻辑运算）直接在硬件层面上进行，效率更高。而包装类对象的操作需要通过方法调用，效率较低。 简化编程： 代码简洁性：基本数据类型的使用使得代码更加简洁明了，减少了不必要的对象创建和销毁。 避免空指针异常：基本数据类型没有 null 值，因此不会出现空指针异常。而包装类对象可能为 null，需要额外的空值检查。 语言设计的一致性： 历史兼容性：Java从一开始就设计了基本数据类型，许多现有的代码库和框架都依赖于基本数据类型。完全移除基本数据类型会破坏大量的现有代码。 语言特性：基本数据类型是Java语言的一部分，提供了语言设计的一致性和完整性。 基本数据类型在内存占用、操作效率和代码简洁性方面具有显著优势，因此在性能敏感的场景中，使用基本数据类型是更好的选择。而包装类则提供了对象封装、集合类支持和额外功能等优势，适用于需要对象操作和面向对象编程的场景。 Java通过保留基本数据类型和提供包装类，兼顾了性能和功能需求，使得开发者可以根据具体场景选择合适的数据类型，从而实现高效、灵活的编程。 面向对象面向对象编程简介面向对象编程（Object-Oriented Programming, OOP）是一种编程范式，通过构建对象（对象具有属性和行为）来表示现实世界中的实体及其行为。这种编程思想使得代码更易于理解和维护。 面向对象编程的核心特性包括： 封装（Encapsulation）：将对象的属性和行为结合在一起，隐藏内部实现细节，仅通过接口与外界交互。封装增强了代码的安全性和独立性，简化了编程复杂度。 继承（Inheritance）：子类可以继承父类的属性和方法，从而实现代码的复用。继承有助于构建层次化的类结构，减少重复代码。 多态（Polymorphism）：多态允许不同的类对象对同一消息做出不同的响应。多态分为两种类型： 编译时多态（静态多态），通过方法重载实现，即同一个方法名在不同参数下有不同的实现。 运行时多态（动态多态），通过方法重写实现，即子类重写父类的方法，在运行时根据对象类型调用相应的方法。（接口的实现也属于运行时多态。） 啥是多态？以上对多态的解释有点点抽象，我们可以进一步讲讲。 多态的体现多态（Polymorphism）是面向对象编程中的一个核心概念，它允许不同的对象对同一消息做出不同的响应。多态性使得代码更加灵活、可扩展和易于维护。多态性主要体现在以下几个方面： 1. 方法重载（Overloading）方法重载是指在同一个类中定义多个同名方法，但这些方法的参数列表不同（参数类型、数量或顺序不同）。编译器在编译时根据调用时提供的参数类型和数量来决定调用哪个方法。 示例： 在这个示例中，Calculator 类中有三个 add 方法，但它们的参数列表不同。编译器根据调用时提供的参数类型和数量来决定调用哪个方法。 2. 方法重写（Overriding）方法重写是指子类重新定义父类中已有的方法，以实现不同的操作逻辑。重写的方法需要加上 @Override 注解。在程序运行时，系统会根据引用对象的实际类型来调用具体版本的方法。 示例： 在这个示例中，Dog 和 Cat 类都重写了 Animal 类的 makeSound 方法。在运行时，根据实际对象类型调用相应的方法。 3. 接口实现（Interface Implementation）接口实现是指多个类可以实现同一个接口，并提供各自的方法实现。接口实现体现了多态性，因为不同的类可以对同一个接口方法提供不同的实现。 示例： 在这个示例中，Circle 和 Rectangle 类都实现了 Shape 接口，并提供了各自的 draw 方法实现。在运行时，根据实际对象类型调用相应的方法。 4. 上转型与下转型（Upcasting and Downcasting） 上转型（Upcasting）：将子类对象赋值给父类引用，称为上转型。上转型是安全的，因为子类对象包含了父类的所有属性和方法。 下转型（Downcasting）：将父类引用强制转换为子类引用，称为下转型。下转型需要谨慎使用，因为如果父类引用指向的对象不是子类类型，会导致运行时错误。 示例： 在这个示例中，myAnimal 是 Animal 类型的引用，但实际上指向 Dog 对象。通过上转型，可以调用 Dog 重写的 makeSound 方法。通过下转型，可以调用 Dog 特有的 fetch 方法。 多态能够用来干啥？多态（Polymorphism）是面向对象编程中的一个核心特性，它允许子类替换父类，并在实际代码运行过程中调用子类的方法实现。多态性需要编程语言提供特殊的语法机制来实现，比如继承、接口类等。多态可以提高代码的扩展性和复用性，是许多设计模式、设计原则和编程技巧的基础。 面向对象设计原则：SOLID原则面向对象设计中有常见的五大设计原则，简称SOLID原则。SOLID原则是一组指导原则，旨在帮助开发者创建更灵活、可维护和可扩展的软件系统。这些原则分别是：单一职责原则（SRP）、开闭原则（OCP）、里氏替换原则（LSP）、接口隔离原则（ISP）和依赖倒置原则（DIP）。 1. 单一职责原则（Single Responsibility Principle, SRP）定义：一个类应该只有一个引起它变化的原因，即一个类应该只负责一个职责。 简单示例： 不好的设计：一个类既负责计算工资，又负责保存员工信息。 好的设计：将计算工资和保存员工信息分别放在两个不同的类中。 2. 开闭原则（Open&#x2F;Closed Principle, OCP）定义：软件实体（类、模块、函数等）应该对扩展开放，对修改关闭。即在不修改现有代码的情况下，可以通过扩展来增加新功能。 简单示例： 不好的设计：每次增加新图形时，都需要修改计算面积的代码。 好的设计：通过定义一个抽象的图形接口，新增图形时只需实现该接口，而不需要修改现有代码。 3. 里氏替换原则（Liskov Substitution Principle, LSP）定义：子类应该能够替换所有其父类的引用，而不会影响程序的正确性。为了保证数据安全，子类的行为应该与父类一致或更严格。 简单示例： 不好的设计：鸟类可以飞，但企鹅不能飞，子类行为与父类不一致。 好的设计：将飞行的行为抽象出来，只有能飞的鸟类才实现该行为。 4. 接口隔离原则（Interface Segregation Principle, ISP）定义：客户端不应该依赖于它不需要的接口，即接口应该小而精、细粒度。 简单示例： 不好的设计：一个接口包含多个方法，但某些类只需要其中一部分方法。 好的设计：将接口拆分为多个小接口，每个接口只包含相关的方法。 5. 依赖倒置原则（Dependency Inversion Principle, DIP）定义：高层模块不应该依赖于低层模块，二者都应该依赖于抽象。抽象不应该依赖于细节，细节应该依赖于抽象。 简单示例： 不好的设计：高层模块直接依赖于低层模块的具体实现。例如，一个高层模块直接创建并使用低层模块的对象。 好的设计：通过依赖抽象接口，高层模块不直接依赖于低层模块的具体实现，而是通过接口注入的形式调用实现。例如，高层模块依赖于一个抽象接口，并通过构造函数或setter方法注入具体的实现类。 抽象类和普通类、抽象类和接口的区别抽象类与普通类的区别抽象类和普通类都可以被继承，但它们在功能和使用场景上存在显著差异： 实例化能力： 抽象类：无法被实例化，通常作为基类使用，用于定义子类的通用行为和属性。 普通类：可以被实例化，用于创建具体的对象。 方法实现： 抽象类：可以包含抽象方法（没有具体实现的方法），也可以包含具体实现的方法。抽象类不能使用 final 修饰符，因为 final 修饰符用于禁止该类被继承或方法被子类重写，这与抽象类的设计目的相冲突。 普通类：必须实现所有方法，不能包含抽象方法。 静态方法： 抽象类：允许包含静态方法，但静态方法无法访问抽象类的实例成员，因为抽象类无法实例化。 普通类：允许包含静态方法，静态方法可以访问类的实例成员。 抽象类与接口的区别抽象类和接口在设计目的和使用方式上有所不同： 设计目的： 抽象类：用于定义类的通用行为和属性，提供部分实现，子类可以继承并扩展这些行为。 接口：用于定义一组行为契约，实现类必须遵循这些契约，接口不提供任何实现。 构造方法： 抽象类：可以包含构造方法，用于初始化抽象类的成员变量。 接口：不能包含构造方法，因为接口不涉及实例化。 方法实现： 抽象类：可以包含具体实现的方法，子类可以选择性地覆盖这些方法。 接口：除了定义静态方法外，其他方法默认是抽象的，必须由实现类来实现。但从 Java 8 开始，接口可以包含默认方法（default 方法），这些方法可以有具体实现，并且实现类可以选择性地覆盖这些默认方法。但注意，静态方法不能被实现类覆盖。 继承与实现： 抽象类：一个类只能继承一个抽象类。 接口：一个类可以实现多个接口。 成员变量： 抽象类：可以包含成员变量，这些变量可以是静态的、非静态的、常量等。 接口：只能包含静态常量（默认是 public static final）且必须赋予初始值，不能包含非静态成员变量。 访问修饰符： 抽象类：方法和成员变量可以使用所有访问修饰符（public、protected、private）。 接口：所有方法默认是 public，不能使用其他访问修饰符。成员变量默认是 public static final。 静态了解了面向对象的多态特性，那么Java中的静态也一同了解一下吧~ 静态变量和静态方法在 Java 中，静态变量和静态方法与类本身关联，而不与类的实例化对象关联。它们在内存中独此一份，可以被类的所有实例化对象共享。 静态变量（类变量）静态变量是通过 static 关键字修饰的变量，属于类而不属于实例对象。静态变量在类被加载时初始化，只会分配一次内存。所有的实例对象都能共享该静态变量，也就是说，如果一个实例对象修改了该静态变量，其他实例对象调用该变量时也会看到修改后的值。静态变量可以通过类名访问，也可以通过实例对象访问（但推荐使用类名访问）。 静态方法静态方法也是通过 static 关键字修饰的方法，属于类而不属于实例对象。静态方法在类被加载时初始化，可以被类的所有实例化对象共享。静态方法可以通过类名直接调用，不需要创建类的实例对象。 总结 静态变量：属于类，所有实例对象共享，可以通过类名或实例对象访问（推荐使用类名）。 静态方法：属于类，可以通过类名直接调用，不需要创建实例对象。 静态内部类静态内部类是使用 static 关键字修饰的内部类。与静态变量和静态方法类似，静态内部类属于外部类本身，而不是外部类的实例对象。 静态内部类与非静态内部类的区别 访问方式：静态内部类可以通过外部类名直接访问，不需要创建外部类的实例对象；非静态内部类依赖于外部类的实例，需要通过外部类的实例对象来访问。 访问权限： 静态内部类：只能访问外部类的静态变量和静态方法。不能直接访问外部类的私有成员变量和方法，必须通过外部类的实例来访问（为什么呢？因为private 修饰符表示成员只能在声明它的类内部访问，即使是私有静态成员变量和方法，对于静态内部类来说也是不可见的）。 非静态内部类：可以访问外部类的实例变量和方法，包括私有成员变量和方法。 实例化方式：静态内部类可以独立实例化，不需要依赖外部类的实例；非静态内部类必须等待外部类实例化后，才能实例化自己的对象。 示例代码 编译器如何实现非静态内部类直接访问其外部类方法？非静态内部类可以直接访问外部类的实例变量和方法，包括私有成员。这是通过编译器在内部类中生成一个隐式的外部类引用实现的。 编译器生成的代码 编译器在生成非静态内部类的字节码时，会自动为内部类添加一个指向外部类实例的引用。这个引用通常命名为 this$0，用于访问外部类的实例成员。 编译器生成的字节码大致如下： 通过这种方式，非静态内部类可以直接访问外部类的实例成员，而不需要显式地传递外部类的实例。 在继承关系中，实例化子类时静态加载顺序在继承关系中，当一个父类与子类都存在静态变量、静态方法时，实例化子类时的加载顺序如下： 加载父类的静态代码块：父类的静态代码块（即静态变量、静态方法等）在首次使用到与父类相关的代码时加载，并且仅加载一次。 加载子类的静态代码块：子类的静态代码块（即静态变量、静态方法等）在首次使用到与子类相关的代码时加载，并且仅加载一次。 加载父类的构造函数：父类的构造函数在实例化子类时首先被调用。 加载子类的构造函数：子类的构造函数在父类的构造函数执行完毕后被调用。 示例代码 输出结果 解释 在首次使用到与父类相关的代码时（即实例化子类时），父类的静态代码块首先被加载并执行。接着，子类的静态代码块在首次使用到与子类相关的代码时（即实例化子类时）被加载并执行。然后，父类的构造函数在实例化子类时被调用。最后，子类的构造函数在父类的构造函数执行完毕后被调用。 总结 在继承关系中，实例化子类时的静态加载顺序是： 父类的静态代码块（仅在首次使用时加载） 子类的静态代码块（仅在首次使用时加载） 父类的构造函数 子类的构造函数 "},{"date":"2024-10-05T00:41:16.745Z","url":"/CSS/loading.css","categories":[["undefined",""]],"content":"/* loading.css */ #loading-overlay { display: none; position: fixed; top: 0; left: 0; width: 100%; height: 100%; background: rgba(0, 0, 0, 0.5); z-index: 9999; justify-content: center; align-items: center; pointer-events: none; /* 确保覆盖层不会阻止其他元素的交互 */ } #loading-spinner { border: 8px solid #f3f3f3; border-top: 8px solid #3498db; border-radius: 50%; width: 50px; height: 50px; animation: spin 2s linear infinite; } @keyframes spin { 0% { transform: rotate(0deg); } 100% { transform: rotate(360deg); } }"},{"date":"2024-09-28T11:46:22.016Z","url":"/CSS/custom.css","categories":[["undefined",""]],"content":"/* 对所有段落应用缩进，但不包括列表项 */ p:not(li p) { text-indent: 2em; } /* 自定义加粗字体的颜色 */ strong { color: rgb(0, 115, 255); /* 这里使用 RGB 色号，0, 0, 255 对应蓝色 */ }"},{"date":"2024-10-05T00:46:32.445Z","url":"/JS/loading.js","categories":[["undefined",""]],"content":"// loading.js document.addEventListener('DOMContentLoaded', function() { var links = document.querySelectorAll('a[href^=\"/\"]:not([href*=\"#\"]):not([target=\"_blank\"])'); links.forEach(function(link) { link.addEventListener('click', function(event) { event.preventDefault(); var url = this.href; showLoading(); setTimeout(function() { window.location.href = url; }, 500); // 延迟500毫秒以显示加载动画 }); }); // 处理带有片段标识符的链接 var fragmentLinks = document.querySelectorAll('a[href^=\"#\"]:not([target=\"_blank\"])'); fragmentLinks.forEach(function(link) { link.addEventListener('click', function(event) { event.preventDefault(); var targetId = this.getAttribute('href').substring(1); // 获取片段标识符 var targetElement = document.getElementById(targetId); if (targetElement) { targetElement.scrollIntoView({ behavior: 'smooth' }); } }); }); }); function showLoading() { var overlay = document.createElement('div'); overlay.id = 'loading-overlay'; overlay.innerHTML = ''; document.body.appendChild(overlay); overlay.style.display = 'flex'; }"}]