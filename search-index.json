[{"title":"Redis-场景理解","date":"2024-09-27T00:54:37.000Z","url":"/2024/09/27/Redis-%E5%9C%BA%E6%99%AF%E7%90%86%E8%A7%A3/","categories":[["Redis","/categories/Redis/"]],"content":"Redis 和 MySQL为什么使用RedisRedis 具备高性能和高并发两大特性。 1. 高性能 Redis 以其卓越的性能著称，主要得益于Redis 将数据存储在内存中，而 MySQL 则主要依赖磁盘存储。内存的读写速度远高于磁盘，因此 Redis 能够显著提升数据访问速度。 2. 高并发 Redis 采用单线程模型，避免了多线程竞争带来的锁和上下文切换开销。这种设计使得 Redis 在处理高并发请求时表现出色，其 QPS（每秒查询次数）轻松突破 10 万。此外，Redis 还可以通过部署 Redis 切片集群进一步增加整个系统的吞吐量。 高并发情况等下，Redis+MySQL单点能有多大并发量？ 若命中Redis缓存，4C8G内存配置 ，单点Redis能够达到10wQPS。 若未命中Redis缓存，4C8G内存配置，单点MySQL仅能达到5k左右QPS。 如何保证Redis和MySQL数据缓存一致性问题在分布式系统中，缓存和数据库之间的数据一致性是一个常见的问题。为了保证数据的一致性，通常采用旁路缓存策略，即先更新数据库，再删除缓存。 缓存通过牺牲强一致性来实现高性能，也就是CAP理论中的AP模式。所以，要保持数据的强一致性，就不适合使用缓存。但是，我们可以通过一些缓存方案优化来保证最终一致性。 消息队列方案为了保证缓存删除操作的可靠性，可以引入消息队列，由消费者来完成缓存删除操作。 生产者：在写数据时，将删除缓存的操作发送到消息队列中。 消费者：消费者从消息队列中获取消息，执行缓存删除操作。 如果应用删除缓存失败，可以从消息队列中重新获取消息，再次尝试删除缓存。这就是消息重试机制。 重试删除缓存机制总体可用，但可能造成业务代码入侵（业务代码入侵（Business Code Invasion）是指在业务逻辑代码中嵌入了与业务逻辑无关的代码，导致业务代码变得复杂、难以维护，并且增加了系统的耦合度。）。 订阅MySQL binlog，再操作缓存该策略的第一步是更新数据库，当数据库更新成功，会将旧的值存入 binlog 中。于是我们可以通过订阅 binlog 日志，拿到具体要删除的记录，再执行缓存删除。 可以使用开源工具如 Canal 来订阅 MySQL binlog。订阅 MySQL binlog，获取更新操作的记录，以下是示例代码。 本地缓存与 Redis 缓存：性能与应用场景的对比在现代应用开发中，缓存是提升系统性能和响应速度的重要手段。本地缓存和分布式缓存（如 Redis）是两种常见的缓存策略，各自具有独特的优势和适用场景。本文将深入探讨本地缓存和 Redis 缓存的性能特点，并通过对比帮助读者理解它们在不同场景下的应用。 本地缓存本地缓存是指将数据存储在本地程序或服务器上，通常使用内存作为存储介质。本地缓存通过利用内存的高速读写特性，显著提升数据访问速度。 优势 访问速度快：由于数据存储在本地内存中，访问速度极快，适合需要高频访问的数据。 减轻网络压力：本地缓存减少了对外部数据源的依赖，从而减轻了网络带宽的压力。 不足 可扩展性有限：本地缓存通常局限于单个服务器或进程，难以应对大规模分布式系统的需求。 分布式缓存（Redis）分布式缓存是指将数据存储在多个分布式节点上，通过协同工作提升高性能的数据访问服务。Redis 是一种常见的分布式缓存解决方案，通常采用集群的方式进行部署，通过多台服务器分担数据压力。 优势 可扩展性强：可以根据业务需求动态增加或减少集群节点，灵活应对数据量的变化。 数据高一致性：Redis 采用主从同步复制机制，确保数据在多个节点之间保持一致性。 易于维护：分布式缓存通常采用自动化管理方式，降低维护成本，提高运维效率。 不足 访问相对较慢：相比于本地缓存，分布式缓存需要通过网络访问数据，访问速度相对较慢。 网络开销大：分布式缓存依赖网络通信，网络延迟和带宽限制可能影响性能。 应用场景对比本地缓存适用场景 高频访问数据：适合存储频繁访问的热数据，如用户会话、配置信息等。 单机应用：适用于单机或单进程的应用场景，数据量较小且不需要分布式扩展。 Redis 缓存适用场景 大规模分布式系统：适合需要处理海量数据和高并发请求的分布式系统。 数据一致性要求高：适用于需要确保数据一致性的场景，如电商平台的商品库存管理。 动态扩展需求：适用于需要根据业务需求动态调整缓存规模的场景。 Redis 应用场景Redis 是一种基于内存的高性能数据库，凭借其快速的读写速度和丰富的数据结构，广泛应用于各种场景中。本文将详细介绍 Redis 在不同应用场景中的具体用途，并通过实例帮助读者更好地理解其优势。 缓存：缓存是 Redis 最常见的应用场景之一。通过将热门数据存储在内存中，Redis 可以显著提高系统的访问速度，减轻后端数据库的压力。 计数器：Redis 的单线程模式和操作的原子性使其非常适合用于实现计数器和统计功能。常见的应用包括页面访问量统计、用户行为统计等。（常用数据结构String、HyperLogLog） 排行榜：Redis 中的有序集合（Sorted Set，Zset）能够实现对数据的自动排序，非常适合用于排行榜、热门文章等需要排序的应用场景。 分布式锁：在分布式系统中，为了避免多个进程同时操作同一资源，可以使用 Redis 实现分布式锁。常见的应用包括资源访问控制、任务调度等。 消息队列：Redis 的发布和订阅功能（Pub&#x2F;Sub）使其可以作为一个轻量级的消息队列系统。常见的应用包括异步任务处理、事件通知等。（常用数据结构List、Stream） Redis 实现消息队列使用Pub&#x2F;Sub模式Redis 的 Pub&#x2F;Sub 模式是一种基于发布者&#x2F;订阅者的模式。任何客户端都可以订阅一个或多个频道，发布者可以向特定频道发布消息，所有订阅了该频道的订阅者都会收到消息。发布者和订阅者完全解耦，并且支持模式匹配。但是这种方式并不支持持久化，也就是说当发布者将消息发布后，若此时无订阅者，消息就会丢失。 示例： 发布者（Publisher） 订阅者（Subscriber） 使用List使用 List 实现消息队列是一种简单且高效的方式。生产者使用 LPUSH 命令将消息添加到 List 的队尾，消费者使用 BLPOP 或 BRPOP 命令阻塞地从队首取出消息进行消费（先进先出，FIFO）。这种方式可以结合Redis的过期时间特性实现消息的TTL，通过Redis事务可以保证操作的原子性，但需要客户端自己实现消息确认、消息重试机制。 生产者（Producer） 消费者（Consumer） 使用 Stream（Redis 5.0 后）Redis Stream 是 Redis 5.0 引入的一种新的数据结构，专门用于实现消息队列。Stream 提供了更强大的功能，如消息持久化、消费者组、消息确认等。 生产者（Producer） 消费者（Consumer） Redis 实现分布式锁详解在分布式系统中，为了避免多个进程同时操作同一资源，分布式锁是一种常用的解决方案。Redis 提供了多种实现分布式锁的方式，本文将详细介绍基于 SET 命令的争抢锁机制和 RedLock 算法，并通过代码示例帮助读者更好地理解其应用。 Redis 分布式锁实现原理分布式锁是分布式并发状态下的一种机制，用于控制一个资源在一个时间内，只有一个应用能对其进行使用。 Redis本身可以被多个客户端进行访问，就像一个共享存储，可以用来保存分布式锁。Redis 的 SET 命令参数 NX 表示只有在键不存在时才设置，具有互斥性，非常适合用来构建分布式锁： 若key存在，证明被加过锁了，所以此时可以认为加锁失败。 若key不存在，证明未被加锁，可以认为加锁成功。 基于Redis节点实现分布式锁，对于加锁条件，我们需要满足三个条件： 原子性：加锁操作涉及多个操作（读取锁变量、检查锁变量、设置锁变量），需要保证这些操作的原子性。 过期时间：锁变量需要设置过期时间，避免客户端获得锁后挂掉，锁一直不释放造成死锁。 唯一性：锁变量的值需要能区分是哪个客户端设置的锁，避免在释放锁时造成误释放操作。 基于 SET 命令的争抢锁机制Redis 提供了 SET 命令的扩展参数，可以用于实现分布式锁。通过 SET resource_name lock_value NX PX milliseconds 命令，客户端可以尝试获取锁。其中： NX：表示只有当键值不存在时才设置。 PX milliseconds：指定锁的过期时间（毫秒）。 如果设置成功，则认为当前客户端获得了锁。当客户端完成操作后，需要删除锁，这里涉及两个以上的操作（判断锁是否属于自己、删除锁），因此可以使用 Lua 脚本来保证 Redis 命令的原子性。 示例代码： 注意事项 锁的过期时间：设置合理的锁过期时间，避免锁长时间占用资源。 锁的唯一性：确保锁的值是唯一的，通常使用 UUID 或其他唯一标识符。 Lua 脚本：使用 Lua 脚本保证释放锁操作的原子性。 RedLock 算法RedLock 算法是 Redis 官方推荐的分布式锁实现方式，适用于需要高可用性和容错性的场景。RedLock 算法通过在多个独立的 Redis 实例上获取锁，并确保大多数实例（超过半数）成功获取锁，来实现分布式锁。 算法步骤 获取当前时间：记录当前时间戳。 尝试获取锁：在每个 Redis 实例上尝试获取锁，使用相同的键和随机值。 计算获取锁的时间：计算从开始获取锁到所有实例返回结果的时间。 判断锁是否获取成功：如果大多数实例（超过半数）成功获取锁，并且获取锁的时间小于锁的有效期，则认为锁获取成功。 释放锁：在所有实例上释放锁。 代码示例： 注意事项 多数原则：确保大多数实例（超过半数）成功获取锁。 时间同步：各个 Redis 实例的时间需要同步，避免时间差异导致锁失效。 故障处理：处理 Redis 实例故障的情况，确保锁的可靠性。 Redis KeyRedis 大 Key 问题在 Redis 中，大 Key 问题指的是一个键（Key）对应的值（Value）过大，导致 Redis 处理起来缓慢、内存不足、影响主从同步延迟等问题。 大地多大算大Key？这是没有标准的，通常认为字符串类型的key对应的value值空间占用超过了1M，或者集合中key对应的元素个数超过了1w，我们就认为该key是大key。 大 Key 问题的缺点 内存占用较高：大 Key 会占用大量的内存，导致 Redis 可用内存减少。Redis 是一个内存数据库，内存是其主要资源。如果内存被大 Key 占用过多，可能会导致内存不足，触发内存淘汰策略，影响其他键的访问。 降低性能：当对大 Key 进行处理时，会花费更多的 CPU 时间，导致整体性能下降，甚至会阻塞其他客户端的请求。大 Key 的读取、写入、删除等操作都会消耗更多的 CPU 资源，影响 Redis 的响应速度。 网络拥塞：大 Key 在网络传输时会占用大量带宽，可能导致网络拥塞。特别是在高并发场景下，大量请求传输大 Key 会导致网络资源被耗尽，影响其他请求的传输。假设有一个大 Key image:12345，对应的值是一个 1MB 的图片数据。如果有 1000 个请求同时传输这个大 Key，会占用 1000MB 的网络带宽，导致网络拥塞。 主从复制延迟：大 Key 在主从复制时需要传输大量数据，可能导致主从复制延迟，影响数据一致性。特别是在主从节点之间网络带宽有限的情况下，大 Key 的传输会占用大量带宽，导致复制延迟。 数据倾斜：一个大 Key 会造成单个切片节点使用了很大一部分内存，导致内存使用率远超其他切片节点。这种数据倾斜会导致集群中某些节点负载过重，影响整体性能。 如何解决大 Key 问题 大Key拆分：将数万成员的大 Key 拆分为更小的分散的 Key，可以有效减少单个键的内存占用，提高 Redis 的处理效率。。 内存清理：将大 Key 转移到其他存储介质（如文件系统、数据库等），然后释放 Redis 中的 Key，避免占用内存空间。（要使用异步删除） 内存阈值监控：持续监控 Redis 的内存使用率，当发现内存用量到达阈值时或内存使用率突然大幅提升时，对内存进行相应的处理，比如删除不需要的 Key。。 定期删除：定时对过期的 Key 进行删除，避免持续堆积而产生大 Key。 热Key什么是热key热 Key 是指那些被频繁访问的键（Key），其请求频率远高于其他键。热 Key 问题会导致 Redis 的性能瓶颈，影响整体系统的响应速度。 QPS 请求集中在特定 Key：假设 Redis 有 10,000 的 QPS（每秒查询次数），而某个 Key 被请求的频率达到 7,000 QPS。 带宽使用率集中在特定的 Key：某个 Key 的传输数据量占用了大量网络带宽。 CPU 使用时间集中在特定的 Key：某个 Key 的处理占用了大量 CPU 时间。 热 Key 的影响 性能瓶颈：热 Key 会导致 Redis 的性能瓶颈，影响整体系统的响应速度。 资源浪费：热 Key 会占用大量 CPU、内存和网络资源，导致其他请求的资源不足。 如何解决热key 负载均衡：由于 Redis 切片集群中，Key 的迁移粒度问题，无法将热 Key 迁移到其他节点分散单点压力。此时可以将热 Key 复制多几份，重新命名后装配到其他节点，并将热 Key 的请求分散到这些分散的节点中，以此降低单点压力。 缓存预热：在系统启动时，提前加载热 Key 的数据到缓存中，避免系统启动后瞬间的高并发请求导致热 Key 问题。 三大缓存问题详解在分布式系统中，缓存是提升系统性能的重要手段。然而，缓存也会带来一些问题，如缓存雪崩、缓存击穿和缓存穿透。 缓存雪崩缓存雪崩是指，在高并发场景下，同一时间内大量 Key 过期，或者 Redis 节点故障，导致大量的数据请求冲向数据库服务器，数据库可能会因无法承受大量数据请求而宕机。 对于大量key同时过期造成的缓存雪崩，我们可以设置以下方案解决： 均匀key过期时间：对于同一时间大量 Key 过期而产生的缓存雪崩，可以设置随机的过期时间，避免大量 Key 在同一时间失效。通过在基础过期时间上增加一个随机值，可以有效分散 Key 的过期时间，避免集中失效。 不设置 Key 过期时间：若业务场景可能长期需要该 Key，那么可以不设置过期时间，待业务活动过期后手动将 Key 删除。这种方式适用于那些长期有效的数据，避免频繁的缓存重建。 互斥锁：当业务线程发现该 Key 不在缓存中，就设置一个互斥锁，保证同一时间只有一个线程在处理缓存，避免在失效期间大量线程同一时间读数据库写缓存。通过互斥锁，可以有效控制缓存重建的并发度，减少数据库压力。 缓存击穿缓存击穿是指，在高并发场景下，某个热点 Key 在缓存中过期，导致大量请求直接访问数据库，导致数据库压力骤增，甚至宕机。 对于缓存击穿，我们也可以使用应对缓存雪崩中采取的两个方案： 互斥锁：使用互斥锁，保证同一时间只有一个线程访问数据库，其他线程等待缓存更新。通过互斥锁，可以有效控制缓存重建的并发度，减少数据库压力。 热点数据永不过期：对于热点数据，可以设置永不过期，或者设置较长的过期时间。这种方式适用于那些长期有效的数据，避免频繁的缓存重建。 后台异步更新：保持热点 Key 持续在线，由后台异步更新缓存。或者在 Key 即将过期时通知后台线程，重新设置过期时间。这种方式可以避免缓存过期瞬间的大量请求冲击数据库。 缓存穿透缓存穿透是指，在高并发场景下，请求的数据在缓存和数据库中都不存在，导致每次请求都直接访问数据库，导致数据库压力骤增，甚至宕机。 对于缓存穿透，我们可以采取以下方案： 限制非法请求：当有恶意的请求故意查询一条不存在的数据，大量的恶意请求也会导致缓存穿透问题。由此我们需要判断请求参数是否合理，过滤掉非法的数据请求。通过参数校验和请求过滤，可以有效减少非法请求对数据库的冲击。 缓存空值或默认值：当我们发现环境中存在缓存穿透现象时，可以为不存在的数据设置为空值或默认值，当缓存中存在有值就不需要向数据库发起大量的请求了。通过缓存空值或默认值，可以避免大量请求直接访问数据库。 布隆过滤器：我们可以在写入数据库时，使用布隆过滤器做标记，然后再请求到来时先判断缓存中是否存在该数据，若不存在则通过布隆过滤器快速判断要请求的数据是否存在。若判断存在，则数据可能存在，可以进一步向数据库查询；若判断不存在，则一定不存在，直接返回。通过布隆过滤器，可以快速过滤掉不存在的数据请求，减少数据库压力，Redis本身也实现了布隆过滤器。 布隆过滤器原理布隆过滤器是一种空间效率很高的概率型数据结构，用于判断一个元素是否在一个集合中。它由“初始值都为0的位图数组”和“n个哈希函数”两部分组成。布隆过滤器通过哈希计算来判断数据是否存在，具有高效的查询速度和较低的空间占用，但存在一定的误判率。当我们在写入数据库的时候，会在布隆过滤器中设置标记，证明该数据在数据库中存在，这样下次查询的时候直接先通过布隆过滤器就能判断出该数据在数据库中是否存在而不需要进一步查询数据库。 布隆过滤器会通过3个操作完成标记： 哈希计算：使用n个哈希函数对数据进行哈希计算，得到n个哈希值。 取模操作：将n个哈希值分别对位图数组的长度取模，得到每个哈希值在位图数组中相对应的位置。 设置标记：将每个哈希值在位图数组中相应的位置设置为1。 举个例子，假设有一个长度为5的位图数组、哈希函数有2个的布隆过滤器。 将数据x写入数据库后，会对数据x进行哈希计算，得到n个哈希值；再将得到的哈希值取模，也就得到了一堆数字结果，对应布隆过滤器中位图数组的位置；将这些位置设为1.下次要判断x是否存在于数据库中时，只需要对x进行哈希计算，查看对应位图数组上相应的位置是不是全都为1，如果全都是1，则认为数据可能存在于数据库中，可以继续下一步查询；否则，认为数据一定不存在。 布隆过滤器通过哈希计算来判断数据是否存在，必然存在哈希冲突，可能会有两个不同的数据计算出同样的哈希值，造成误判。具体来说： 误判情况：布隆过滤器认为数据存在，但实际上数据可能不存在。这种情况称为“假阳性”（False Positive）。 正确情况：布隆过滤器认为数据不存在，则数据一定不存在。这种情况称为“真阴性”（True Negative）。 所以，布隆过滤器认为该数据存在，则其可能存在；若认为数据不存在，则一定不存在。 Redis 应用设计如何设计秒杀场景处理高并发以及超卖现象？秒杀场景是一种典型的高并发场景，通常涉及大量用户在短时间内对有限数量的商品进行抢购。为了应对高并发和避免超卖现象，需要从数据库层面、分布式锁、分段锁以及 Redis 和异步队列等多个方面进行设计和优化。 数据库层面 查询商品库存时加排他锁 在查询商品库存时，可以使用数据库的排他锁（FOR UPDATE）来保证数据的一致性。 在事务中，线程 A 通过该语句给 id 为 ? 的数据行上了一个行级的排他锁。此时在事务期间，其他线程对该行的 UPDATE 和 DELETE 操作都将被阻塞，直到事务提交或发生回滚释放锁。 更新数据库减库存时进行库存限制 在更新数据库减库存时，可以通过条件判断来避免超卖现象。 这种通过数据库加锁来解决的方案，性能不是很好，在高并发的情况下可能会因为获取不到数据库的连接或超时等待报错。 利用分布式锁分布式锁可以保证在同一时间内只有一个客户端能获取到锁，获得锁的线程才能进行接下来的业务逻辑，而其他客户端获取不到锁只能无限循环尝试获取锁。 可以使用 Redis 的 SETNX 命令来实现分布式锁。 在高并发状态下，分布式锁只能进行串行化处理，效率很低。比如大量用户对同一个热门商品下单，此时只能一个个处理下单操作，效率很慢。 利用分布式锁 + 分段锁把数据分成很多段，每一段加上一个单独的锁，细粒度化，使得线程在对一段数据进行修改时，其他线程可以继续对剩下部分进行加锁操作。 假设商品库存分为多个段，每个段使用独立的锁。 通过分段锁，可以提高并发处理能力，减少锁的竞争，提升系统的吞吐量。 利用 Redis 的 INCR、DECR 的原子性 + 异步队列 系统初始化时加载库存到 Redis 在系统初始化时，将商品的库存数量加载到 Redis 中。 接收到秒杀请求时预减库存 接收到秒杀请求时，在 Redis 中进行预减库存（利用 Redis DECR 的原子性），当 Redis 的库存不足时直接返回秒杀失败，否则继续进行第三步。 3, 将请求放入异步队列 将请求放入异步队列中，返回正在排队中。 服务端异步队列请求出队 服务端异步队列请求出队（可以出队的情况根据业务来判定，比如判断是否已秒杀过，防重复秒杀），出队的请求可以生成秒杀订单，减少数据库存。 客户端轮询查看秒杀结果 用户在客户端申请完秒杀后，进行轮询，查看是否秒杀成功，秒杀成功则进入秒杀订单详情，否则秒杀失败。 由于使用了异步队列写入数据库，可能存在数据不一致问题，其次引用多个组件，复杂度比较高。"},{"title":"Redis-集群","date":"2024-09-27T00:54:36.000Z","url":"/2024/09/27/Redis-%E9%9B%86%E7%BE%A4/","tags":[["集群","/tags/%E9%9B%86%E7%BE%A4/"]],"categories":[["Redis","/categories/Redis/"]],"content":"Redis主从同步机制详解完全同步在Redis的主从复制（Replication）机制中，完全同步（Full Synchronization）是一个关键过程，它确保从节点（Replica）能够获取主节点（Master）的完整数据集。完全同步通常发生在以下几种情况： 初次同步：当一个从节点首次连接到主节点时，它需要获取主节点的完整数据集。这是因为在初次连接时，从节点没有任何数据，因此需要进行一次完全同步。 从节点数据丢失：如果从节点由于系统崩溃、故障断电等原因导致数据丢失，它将无法继续提供服务。此时，从节点会向主节点发起完全同步请求，以恢复数据。 数据差异过大：在某些情况下，从节点可能长时间未与主节点进行同步，导致两者之间的数据差异过大。当差异超出预设的阈值时，从节点会主动发起完全同步请求，以确保数据的一致性。 完全同步的三阶段主从服务器之间的完全同步过程可以分为三个主要阶段： 建立连接与协商同步：主节点和从节点之间首先建立网络连接。从节点发送PSYNC命令（在Redis 2.8及以上版本中使用），请求与主节点进行同步。主节点响应FULLRESYNC命令，表示将进行完全同步，并提供一个唯一的同步ID（Replication ID）和当前的偏移量（Offset）。 主节点发送完全同步数据：主节点接收到从节点的同步请求后，会生成一个RDB快照文件。这个快照文件包含了主节点当前的所有数据。主节点将生成的RDB文件发送给从节点。 主节点发送新写命令：在RDB文件生成和传输期间，主节点会将所有新的写操作命令记录到一个称为replication backlog buffer的缓冲区中。当RDB文件传输完成后，主节点会将replication backlog buffer中的所有写操作命令发送给从节点。从节点接收到这些命令后，会依次执行这些命令，从而与主节点的数据保持一致。 实现过程详解这里参考一张小林哥的图： 主节点发送SYNC命令：在Redis 2.8之前的版本中，主节点会发送SYNC命令来启动同步过程。而在Redis 2.8及以上版本中，主节点会发送PSYNC命令，该命令支持部分重同步（Partial Resynchronization），但在初次同步时，仍然会执行完全同步。 生成RDB文件：主节点接收到从节点的同步请求后，会调用BGSAVE命令生成一个RDB快照文件。这个过程是异步的，主节点会在后台生成快照，同时继续处理客户端的请求。RDB文件生成完成后，主节点会将文件发送给从节点。 传输RDB文件：主节点通过网络将生成的RDB文件传输给从节点。传输过程中，主节点会继续记录新的写操作命令到replication backlog buffer中。从节点接收到RDB文件后，会将其加载到内存中，并应用其中的数据。 主节点记录写操作：在RDB文件生成和传输期间，主节点会将所有新的写操作命令记录到replication backlog buffer中。这个缓冲区的大小是有限的，通常为1MB，因此在高写入负载下，缓冲区可能会被填满。 传输新写命令：当RDB文件传输完成后，主节点会将replication backlog buffer中的所有写操作命令发送给从节点。从节点接收到这些命令后，会依次执行这些命令，从而与主节点的数据保持一致。 增量同步在Redis的主从复制机制中，增量同步（Partial Resynchronization）是一种高效的同步方式，它允许从节点（Replica）在网络恢复后，仅同步自上次同步以来主节点（Master）新增的数据，而不需要进行完整的完全同步（Full Synchronization）。增量同步基于PSYNC命令，并依赖于运行ID（run ID）和复制偏移量（offset）来实现。 增量同步的步骤还是借用小林哥的图： 增量同步的过程主要包括以下三个步骤： 从节点恢复网络并发送PSYNC命令：当从节点恢复网络连接后，它会向主节点发送PSYNC命令，请求进行增量同步。此时，PSYNC命令中的offset参数不再是-1，而是从节点上次同步时的复制偏移量。 主节点响应CONTINUE命令：主节点接收到从节点的PSYNC命令后，会检查从节点提供的复制偏移量是否在repl_backlog_buffer缓冲区中。如果存在，主节点会响应CONTINUE命令，表示接下来将进行增量同步。 主节点发送增量数据：主节点将从节点断线期间收到的所有写操作命令发送给从节点。从节点接收到这些命令后，会依次执行这些命令，从而与主节点的数据保持一致。 增量数据的来源主节点如何知道从节点缺少的是哪些增量数据呢？这主要依赖于两个关键组件： repl_backlog_buffer缓冲区：这是一个环形缓冲区，用于存储主节点近期传播的写操作命令。当从节点断连后，主节点可以通过这个缓冲区找到从节点缺失的数据。 **replication offset**：这是一个标记，用于记录主从节点各自的同步进度。主节点使用master_repl_offset来记录自己写到的位置，从节点使用slave_repl_offset来记录自己读到的位置。 repl_backlog_buffer缓冲区的写入时机在主节点传播命令时，它会将写操作命令发送给从节点的同时，也会将这些命令写入到repl_backlog_buffer缓冲区中。因此，repl_backlog_buffer缓冲区中存放了近期传播的写操作命令。 增量同步的判断条件当从节点断连后重新发起同步请求时，它会将自己的slave_repl_offset发送给主节点。主节点会根据master_repl_offset比较二者之间的数据差距，并判断是否可以进行增量同步。具体判断条件如下： 增量同步：如果从节点索要读取的数据还在repl_backlog_buffer缓冲区中（即主从节点的偏移量之差没有超过缓冲区的长度，可以抽象为没有被“套圈”），则采用增量同步方式。 完全同步：如果从节点索要的数据已经不在repl_backlog_buffer缓冲区中，说明落后数据太大，中间已有写操作缺失。为保证数据一致性，需要进行完全同步。 repl_backlog_buffer缓冲区的大小与调整repl_backlog_buffer缓冲区的默认大小是1MB，并且由于它是一个环形缓冲区，当缓冲区写满后，主节点继续写入的话，就会覆盖之前的数据。因此，当主节点的写入速度远超于从节点的读取速度时，缓冲区的数据很快就会被覆盖。 为了避免在网络恢复时频繁地使用完全同步的方式，我们应该调整repl_backlog_buffer缓冲区的大小，尽可能地大一些，以减少从节点要读取的数据被覆盖的概率，从而使得主节点能够更多地采用增量同步的方式。 扩展：Redis集群和主从同步能保证数据一致性吗？在分布式系统中，数据一致性是一个关键问题。Redis作为一个高性能的内存数据库，其主从复制和集群模式在设计上遵循了CAP理论中的AP模型，即保证高可用性（Availability）和分区容错性（Partition Tolerance），而牺牲了强一致性（Consistency）。也就是说，在网络分区的情况下，Redis能够保证服务的可用性，但可能会出现部分节点间数据不一致的情况。 Redis 哨兵机制原理在Redis的主从架构中，主节点（Master）负责处理所有的写操作，而从节点（Replica）则负责处理读操作。这种读写分离的架构在大多数情况下能够提供良好的性能和扩展性。然而，当主节点发生故障时，整个系统将无法处理写请求，从而导致服务中断。为了解决这个问题，Redis在2.8版本之后引入了哨兵机制（Sentinel），用于实现主从节点的故障转移。 哨兵机制的作用哨兵机制的主要作用是实现主从节点的故障转移，确保在主节点发生故障时，系统能够自动选举出一个新的主节点，并通知其他从节点和客户端更新配置，从而保证服务的连续性和高可用性。 哨兵节点的角色哨兵节点是一个运行在特殊状态下的Redis进程，它充当观察者的角色，主要负责监控主从节点的状态。哨兵节点通过以下三个主要动作来实现故障转移： 观察（Monitoring）： 哨兵节点会定期向主节点和从节点发送心跳检测（PING）命令，以确认它们的状态。 如果主节点在一定时间内没有响应，哨兵节点会认为主节点发生了故障。 选举（Election）： 当哨兵节点检测到主节点故障时，它会与其他哨兵节点进行协商，选举出一个新的主节点。 选举过程遵循Raft算法或类似的分布式一致性算法，确保选举结果的一致性和可靠性。 通知（Notification）： 一旦新的主节点被选举出来，哨兵节点会通知其他从节点更新配置，指向新的主节点。 同时，哨兵节点还会通知客户端新的主节点的信息，以便客户端能够继续发送写请求。 哨兵机制算法流程当Redis集群的主节点发生故障时，Sentinel机制将启动故障转移流程，从剩余的从节点中选举出一个新的主节点。这个过程主要分为四个步骤：故障节点主观下线、故障节点客观下线、Sentinel集群选举Leader、Sentinel Leader决定新主节点。 故障节点主观下线Sentinel集群中的每一个Sentinel节点会定时对Redis节点发送心跳检测包（PING），以检测节点是否正常运行。如果在down-after-milliseconds时间内，Redis节点没有回复Sentinel节点的心跳包，该Sentinel节点就会认为该节点主观下线（Subjectively Down, SDOWN）。 故障节点客观下线当一个Sentinel节点认为某个Redis节点主观下线时，它无法单独证明该节点确实下线了。因此，Sentinel节点会询问其他Sentinel节点，共同判断该节点是否客观下线（Objectively Down, ODOWN）。 如果Sentinel集群中超过quorum数量的节点认为该Redis节点下线了，则该Redis节点客观下线。 若客观下线的是从节点，则检测到此结束，不会进行下一步了；若该节点是主节点，则需要进行接下来的故障转移。 Sentinel集群选举Leader在决定新的主节点之前，Sentinel集群需要先选举出一个Sentinel Leader，代表Sentinel集群进行决策。每个Sentinel节点都有机会成为Leader。 每个Sentinel节点够可以变成Leader，在判定主节点主观下线后，节点会向Sentinel其他节点发送请求，将自己选举为Leader。被请求的节点如果没有为其他Sentinel节点投过票，则发起请求的节点票数+1，否则不增加票数。 如果一个Sentinel节点获得的票数达到Leader的最低票数（max(quorum, Sentinel集群节点数/2 + 1)），则该节点变成leader，否则重新选举。 Sentinel Leader决定新主节点Sentinel集群选举出Leader后，由Leader决定哪个从节点成为新的主节点。选择新主节点的过程遵循以下优先级： 过滤故障节点：首先，过滤掉已经下线的从节点。 选择优先级最高的从节点：选择slave-priority值最大的从节点作为新的主节点。如果存在多个从节点具有相同的优先级，则继续下一步。 选择复制偏移量最大的从节点：选择slave_repl_offset值最大的从节点作为新的主节点。slave_repl_offset表示从节点与主节点的数据同步进度。如果存在多个从节点具有相同的复制偏移量，则继续下一步。 选择runid最小的从节点：选择runid最小的从节点作为新的主节点。runid是Redis节点的唯一标识符。 Redis 切片集群详解随着数据量的增长，单个 Redis 节点的存储容量和性能可能无法满足需求。为了解决这一问题，Redis 提供了切片集群（Redis Cluster）方案。通过将数据分布在多个服务器上，Redis Cluster 不仅降低了单点故障的风险，还显著提升了读写性能。本文将深入探讨 Redis Cluster 的工作原理、优点和缺点，并通过实例帮助读者更好地理解。 Redis Cluster 的工作原理哈希槽（Hash Slots）Redis Cluster 采用哈希槽的方式来管理数据和节点之间的映射关系。一个 Redis Cluster 包含 16384 个哈希槽，这些哈希槽类似于数据分区。每个键值对（key-value pair）都会根据其 key 映射到一个特定的哈希槽中。具体步骤如下： CRC16 哈希算法：首先，Redis 使用 CRC16 算法对键值对的 key 进行计算，得到一个 16 位的值。 哈希槽映射：然后，将这个 16 位的值对 16384 取模，得到一个 0 到 16383 之间的余数。这个余数即为该键值对对应的哈希槽编号。 哈希槽与节点的映射在 Redis Cluster 中，哈希槽需要映射到具体的 Redis 节点上。有两种常见的映射方式： 平均分配：当使用 cluster create 命令创建集群时，Redis 会自动将 16384 个哈希槽平均分配到各个节点中。例如，如果集群中有 5 个节点，每个节点将分配到 16384 &#x2F; 5 ≈ 3276 个哈希槽。 手动分配：在某些情况下，可能需要手动分配哈希槽。可以通过 cluster meet 命令手动建立节点之间的连接，然后使用 cluster addslots 命令为每个节点分配指定的哈希槽数量。例如，可以手动将哈希槽 0 到 5000 分配给节点 A，将 5001 到 10000 分配给节点 B，以此类推。 Redis Cluster 的优缺点优点1. 高可用性：Redis Cluster 通过主从复制（Master-Slave Replication）机制实现了高可用性。每个节点都可以配置一个或多个从节点，主节点负责处理写请求，从节点负责处理读请求。当主节点发生故障时，从节点可以自动接管主节点的角色，确保服务的连续性。 2. 高性能：Redis Cluster 采用数据分片机制，将数据分散到多个节点上，从而降低了单个节点的负载压力。这种分布式架构显著提升了系统的读写性能和吞吐量。 3. 高扩展性：Redis Cluster 支持动态扩展，可以根据需求增加或减少节点。此外，集群模式还可以将某些节点设置为代理节点（Proxy Nodes），自动转发请求，增加了系统的灵活性和可定制性。 缺点1. 部署和同步复杂：Redis Cluster 的部署和维护相对复杂。特别是在大规模集群中，节点之间的同步和数据一致性管理需要特别注意。 2.集群同步问题：在 Redis Cluster 中，节点之间的数据同步是一个关键问题。如果同步不及时或出现错误，可能会导致数据丢失或不一致。 3.数据分片限制：虽然 Redis Cluster 通过数据分片提升了性能，但在某些情况下，数据分片可能会带来一些限制。例如，某些复杂的查询操作可能需要跨多个节点进行，增加了系统的复杂性。"},{"title":"Redis-缓存淘汰与过期删除","date":"2024-09-27T00:54:17.000Z","url":"/2024/09/27/Redis-%E7%BC%93%E5%AD%98%E6%B7%98%E6%B1%B0%E4%B8%8E%E8%BF%87%E6%9C%9F%E5%88%A0%E9%99%A4/","tags":[["策略","/tags/%E7%AD%96%E7%95%A5/"]],"categories":[["Redis","/categories/Redis/"]],"content":"过期删除策略和内存淘汰策略有什么区别？ 过期删除策略是将已过期的键值进行删除，Redis采用的删除策略是惰性删除和定时删除。 内存淘汰策略是在内存满了的时候，redis触发内存淘汰策略，来淘汰一些不必要的内存资源，以腾出空间来保存新的内容。 Redis内存淘汰策略在32位系统中，Redis的maxmemory默认值为3GB，这是因为32位系统最高支持4GB内存，而系统本身需要一定的内存资源来运行。为了避免因内存不足而导致Redis崩溃，设置maxmemory为3GB是一个合理的默认值。 Redis提供了8种内存淘汰策略，这些策略可以根据是否进行数据淘汰分为两类： 1. 不进行数据淘汰 noeviction（Redis 3.0之后默认使用的策略）：当运行内存达到最大内存时，不会淘汰任何数据。如果有新的数据插入，Redis会返回错误。但对于普通的查询或删除操作，Redis可以正常运行。 2. 进行数据淘汰 针对“进行数据淘汰”这一类策略，又可以继续分为“在设置了过期时间的数据中淘汰”和“在所有数据范围内淘汰”两类。 “在设置了过期时间的数据中淘汰”： volatile-random：随机淘汰设置了过期时间的数据。 volatile-ttl：优先淘汰过期时间最早的数据。 volatile-lru（Redis 3.0之前默认使用策略）：淘汰所有设置了过期时间的数据中，最久未使用的键值。 volatile-lfu：淘汰所有设置了过期时间的数据中，最少使用的数据。 “在所有数据范围中进行淘汰”： allkeys-random：随机淘汰任意键值 allkey-lru：淘汰整个键值中最久未使用的键值 allkeys-lfu：淘汰整个键值中最少使用的键值 Redis过期删除策略Redis使用惰性删除和定期删除相结合的过期删除策略，以在CPU使用时间和避免内存空间浪费之间取得平衡。 惰性删除Redis的惰性删除策略由db.c文件中的expireIfNeeded函数实现。惰性删除的核心思想是：在访问或修改key之前，先检查key是否过期，如果过期则删除该key。 以下是expireIfNeeded函数源码： 检查key是否过期：在访问或修改key之前，调用expireIfNeeded函数检查key是否过期。 删除过期key：如果key过期，则根据lazyfree_lazy_expire参数配置，选择异步删除（dbAsyncDelete）或同步删除（dbSyncDelete）。 返回结果：如果key过期并被删除，返回null给客户端；如果key未过期，则正常返回键值对给客户端。 定期删除Redis的定期删除策略是每隔一段时间从内存中随机抽取一定数量的key进行检查，并删除其中过期的key。定期删除的目的是避免内存中积累过多的过期key，从而浪费内存空间。 定期删除的配置 间隔检查时间：默认是1秒检查10次，可以通过redis.conf文件进行配置。 随机抽查数量：在源码中，定期删除的实现在expire.c文件下的activeExpireCycle函数中，其中随机抽查的数量由ACTIVE_EXPIRE_CYCLE_LOOKUPS_PER_LOOP定义，数值是20。 定期删除的流程 随机抽取key：从过期字典中随机抽取20个key。 检查并删除过期key：检查这些key是否已过期，并删除已过期的key。 循环检查：如果本轮已过期的key超过5个，则继续抽取20个key再次进行检查删除，直到不满足该条件，退出。 Redis缓存为什么不过期直接删在Redis中，过期key的删除策略是惰性删除和定期删除相结合的方式。然而，在内存不紧张但CPU紧张的情况下，Redis并不会立即删除过期的key，而是选择延迟删除。这种设计主要是为了在CPU资源紧张的情况下，优先保证业务性能，避免因频繁删除过期key而占用过多的CPU时间。"},{"title":"Redis-事务与日志","date":"2024-09-27T00:53:42.000Z","url":"/2024/09/27/Redis-%E4%BA%8B%E5%8A%A1%E4%B8%8E%E6%97%A5%E5%BF%97/","tags":[["事务","/tags/%E4%BA%8B%E5%8A%A1/"],["日志","/tags/%E6%97%A5%E5%BF%97/"]],"categories":[["Redis","/categories/Redis/"]],"content":"事务如何实现Redis原子性Redis在执行单条命令时具有原子性，因为Redis采用单线程模型，所有的命令都在一个主线程中顺序执行，不存在多线程竞争问题。然而，如果需要执行多条命令并保持原子性，Redis提供了Lua脚本功能，可以将多条Redis命令组合成一个整体执行，从而保证操作的原子性。 假设我们有一个分布式系统，多个进程需要访问一个共享资源，我们可以使用以下Lua脚本来实现分布式锁： 在Redis中执行该Lua脚本的命令如下： EVAL：Redis的命令，用于执行Lua脚本。 &quot;local lockKey = KEYS[1]; local lockValue = ARGV[1]; local lockTimeout = tonumber(ARGV[2]); local result = redis.call(&#39;SET&#39;, lockKey, lockValue, &#39;NX&#39;, &#39;EX&#39;, lockTimeout); if result then return 1 else return 0 end&quot;：Lua脚本内容。 1：表示脚本中有一个键（lockKey）。 lockKey、lockValue、lockTimeout：传递给Lua脚本的参数。 Redis事务除了使用Lua脚本，Redis事务也可以保证Redis的原子性。Redis事务通过MULTI、EXEC、DISCARD和WATCH命令来实现。事务可以将多个命令打包成一个整体执行，从而保证这些命令在执行过程中不会被其他命令打断，保证操作的原子性。 Redis事务的命令 **MULTI**：标记一个事务块的开始。 **EXEC**：执行事务块中的所有命令。 **DISCARD**：取消事务，放弃执行事务块中的所有命令。 **WATCH**：监视一个或多个键，如果在事务执行之前这些键被其他命令修改，事务将被中断。 Redis事务的执行流程 开启事务：使用MULTI命令开启一个事务。 添加命令：在事务块中添加多个Redis命令。 执行事务：使用EXEC命令执行事务块中的所有命令。 取消事务（可选）：如果需要取消事务，可以使用DISCARD命令。 假设我们需要执行以下两条命令，并确保它们具有原子性： 将键key1的值设置为value1。 将键key2的值设置为value2。 我们可以使用Redis事务来实现： Redis事务在执行过程中，如果某个命令执行失败，Redis不会进行事务回滚。也就是说，即使某个命令执行失败，事务块中的其他命令仍然会继续执行。 日志Redis的持久化Redis是一个高性能的内存数据库，所有的读写操作都在内存中进行。然而，内存中的数据在系统重启后会丢失，为了确保数据在重启后能够恢复，Redis提供了持久化机制，将数据存储到磁盘中。Redis的持久化主要通过两种机制实现：AOF（Append-Only File）日志和RDB（Redis Database）快照。 Redis的持久化主要通过两种机制： AOF日志：每执行一条操作命令，就把该命令以追加的方式写入日志文件中。 RDB快照：将某一刻的内存数据，以二进制的方式写入磁盘中。 AOF日志实现AOF日志是一种记录Redis操作命令的持久化方式。每当Redis执行一条写操作命令时，该命令会被追加到AOF日志文件中。当Redis重启时，可以通过读取AOF日志文件并逐行执行命令来恢复数据。 Redis提供了三种AOF日志回写硬盘的策略： Always：每执行一条命令后，立即将该命令写入磁盘日志文件中。这种策略保证了数据的实时持久化，但会对性能产生较大影响。 Everysec：每秒将AOF日志文件的内核缓冲区中的数据写入磁盘日志文件。这种策略在性能和数据安全性之间取得了平衡。 No：将命令写入AOF日志的内核缓冲区，由操作系统决定何时将日志写入磁盘日志文件。这种策略性能最高，但数据安全性较低。 RDB快照实现因为AOF日志记录的是命令操作，并非实际的数据。当AOF日志巨大时，Redis在启动中执行一次全量的命令操作，势必造成Redis恢复操作缓慢。为了解决这个问题，Redis增加了RDB快照。 RDB快照是一种记录Redis内存数据状态的持久化方式。RDB快照将某一时刻的内存数据以二进制格式写入磁盘文件中。当Redis重启时，可以通过加载RDB快照文件来快速恢复数据。 Redis提供了两条命令来生成RDB快照文件： save：在主线程中生成RDB快照文件。由于是在主线程中执行，如果快照文件较大，可能会阻塞主线程，影响Redis的性能。 bgsave：创建一个子线程来生成RDB快照文件。这种方式避免了主线程的阻塞，提高了Redis的性能。 "},{"title":"Redis-数据结构","date":"2024-09-27T00:53:09.000Z","url":"/2024/09/27/Redis-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%9E%8B/","tags":[["数据结构","/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"],["线程模型","/tags/%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%9E%8B/"]],"categories":[["Redis","/categories/Redis/"]],"content":" 数据结构Redis底层数据结构Redis是一种高性能的非关系型数据库（NoSQL），提供了多种数据类型以满足不同的应用需求。常见的数据类型包括String、List、Hash、Set和Zset。每种数据类型在Redis内部都有特定的底层数据结构来支持其功能和性能特性。 数据类型与底层结构 数据类型 底层结构 存储的值 读写能力 String 简单动态字符串（SDS） 字符串、整数或浮点数 支持原子性的读写操作，适用于计数器、缓存等场景。 List 双向链表或压缩列表（ziplist） 字符串元素的列表 支持高效的插入和删除操作，适用于消息队列、任务队列等。 Hash 哈希表或压缩列表（ziplist） 字段-值对 支持快速的查找、插入和删除操作，适用于存储对象属性。 Set 哈希表或整数集合（intset） 无序、唯一的字符串集合 支持高效的集合运算（交集、并集、差集），适用于标签系统、好友关系等。 Zset 跳表或压缩列表（ziplist） 有序、唯一的字符串集合，每个元素关联一个分数 支持按分数排序的查找、插入和删除操作，适用于排行榜、范围查询等。 而在后续的版本更新中，又增加了新的四种数据结构支持：BitMap（2.2）、HyperLogLog（2.8）、GEO（3.2）、Stream（5.0） redis数据结构常用的场景分别如下： String：不仅存储字符串数据，还维护了字符串的长度和可用空间。适用于存储对象、简单计数器、分布式锁、session等。例如，可以使用INCR命令实现一个简单的计数器，用于统计网站的访问量。 List：使用双向链表来存储数据。适用于消息队列、任务队列等。例如，可以使用LPUSH和RPOP命令实现一个简单的消息队列，用于处理异步任务。 Hash：使用哈希表来存储数据。适用于存储对象属性，如购物车。例如，可以使用HSET和HGET命令存储用户的购物车信息。 Set：高效地进行集合运算（交集、并集、差集）。适用于标签系统、好友关系等。例如，可以使用SINTER命令计算两个用户之间的共同好友。 Zset：使用跳表来存储数据，这样可以高效地进行按分数排序。适用于排行榜、范围查询等。例如，可以使用ZADD和ZRANGE命令实现一个热度榜，用于展示热门文章。 在后续的版本更新中，Redis增加了四种新的数据结构： BitMap（2.2）：用于存放二值计算，如用户签到等。 HyperLogLog（2.8）：用于海量基数统计，比如统计网站的独立访客数。 GEO（3.2）：常用于存放地理位置信息，比如高德地图、滴滴打车。 Stream（5.0）：常用于做详细队列，与List不同的是，Stream会自动生成全局唯一ID，支持消费组形式消费数据。 Zset实现基础了解Zset（有序集合）是Redis中一种非常重要的数据类型，它能够存储有序的字符串集合，并且每个元素都关联一个分数（score），通过分数可以对元素进行排序。Zset的底层实现主要依赖于两种数据结构：跳表（Skip List）和压缩列表（ziplist）。在Redis 7.0及之后的版本中，压缩列表已被弃用，取而代之的是listpack。 在Redis7.0版本之前，Zset数据结构为： 若有序集合的元素小于128，且元素的数据大小小于64字节时，Redis会采用压缩列表作为底层数据结构。 若有序集合不满足以上条件，则采用跳表作为数据结构。 如何使用Zset以某文章热度为例，以下介绍在Redis中如何使用Zset。 使用ZADD添加文章 ZADD命令用于向有序集合中添加一个或多个元素。每个元素都关联一个分数（score），用于排序。 在这个例子中，我们向名为article_hotness的有序集合中添加了三篇文章，初始热度为0。 使用ZINCRBY增加文章热度 ZINCRBY命令用于增加有序集合中某个元素的分数（热度）。 在这个例子中，我们分别增加了三篇文章的热度，article_id_1增加了10，article_id_2增加了20，article_id_3增加了30。 使用ZRANGE和WITHSCORES获取热度前三的文章 ZRANGE命令用于获取有序集合中指定范围内的元素。由于Zset默认是按升序排列的，因此我们需要获取热度最高的三篇文章时，可以使用反转范围来获取。WITHSCORES选项用于同时返回元素的分数。 在这个例子中，我们使用ZREVRANGE命令来获取热度前三的文章及其热度值。 使用ZRANGEBYSCORE找出热度大于500的文章 ZRANGEBYSCORE命令用于获取有序集合中分数在指定范围内的元素。 在这个例子中，我们获取了热度大于500的所有文章及其热度值。 跳表实现链表在查询数据时，需要一个个元素遍历，时间复杂度是O(N)的，查询效率贼低，所以就有了跳表。跳表是在链表的基础上改进的，实现了一种“多层”的有序链表结构，以便于快速定位数据位置。 以上图中头节点有L0~L2三个头指针，分别指向不同层级的节点，每个层级的节点都通过指针连接起来。 L0层有5个节点：1、2、3、4、5 L1层有3个节点：2、3、4 L2层有1个节点：3 跳表的核心思想是通过增加多级索引来加速查找过程。跳表的每一层都是一个有序链表，高层级的节点数量较少，低层级的节点数量较多。通过这种方式，跳表可以在O(log n)的时间复杂度内完成查找操作。 跳表是如何工作的呢？举个例子，假设我们在链表中需要查找33这个数据节点，一个个元素遍历到该节点需要查找6次(1-&gt;5-&gt;11-&gt;20-&gt;27-&gt;33)，加了一层索引后，优化到需要4次(1-&gt;11-&gt;27-x-&gt;50转往下一层节点找27-&gt;33)，以此类推。查找流程示意图如下。 这个查找的过程在链表中跳跃，最后定位到元素，当数据量巨大时，查询的时间复杂度就来到了O(logn)。 那么跳表的节点如何实现多层级的？跳表的节点结构包含以下几个关键部分： 元素值（ele）：存储节点的值，通常是一个字符串（sds类型）。 分数（score）：存储节点的分数，用于排序，通常是一个双精度浮点数（double类型）。 后向指针（backward）：指向前一个节点，方便从跳表的尾节点开始访问，倒序查找时方便。 层级数组（level[]）：包含多个层级的信息，每个层级包含两个信息： 前向节点指针（forward）：指向当前层级的下一个节点。 跨度（span）：表示当前节点到下一个节点之间的跨度，用于计算节点的排名。 以下是跳表节点的C语言数据结构示例： 跟我的刚开始想象不同的是，在跳表中，跨度（Span）并不是固定的步长，而是表示当前节点到下一个节点之间的“距离”。跨度可以是1，也可以是2，不必与上一个节点同层级的跨度一致。跨度的主要作用是帮助计算节点的排名（rank），而不是用于遍历操作。遍历操作只需要通过链表的前向指针（forward）来实现。在这里继续引用小林哥的模拟图： Redis跳表在创建节点时，随机生成每个节点的层数，并没有严格维持相邻两层的节点数量比例为2:1的情况。具体的做法是，跳表在创建节点时，会生成一个范围是[0, 1]的随机数，并根据这个随机数来决定节点的层数。如果随机数小于0.25（选取0.25基于概率和性能考虑），则增加一层，然后生成下一个随机数，直到随机数大于0.25结束。最后，层数越高，概率越低，最高不会超过64层。 Redis 为啥使用跳表而不是B+树？Redis选择跳表（Skip List）而不是B+树（B+ Tree）作为有序集合（Zset）的底层数据结构，主要是基于以下几个方面的考虑：内存占用、对范围查找的支持、实现难易程度。 内存占用更少 B+树：每个节点通常包含两个指针（至少），一个指向左子节点，一个指向右子节点。此外，B+树的叶子节点还需要存储数据，这会占用更多的内存。 跳表：跳表的节点包含一个前向指针和一个跨度（span），平均每个节点包含约1.33个指针（概率期望值，p &#x3D; 0.25）。由于跳表的层数是随机生成的，高层级的节点数量较少，因此总体内存占用较少。 范围查询更简单 B+树：B+树的范围查询需要从根节点开始遍历，找到范围的起始节点，然后沿着叶子节点链表遍历到范围的结束节点。这个过程相对复杂，尤其是在范围较大时。 跳表：跳表的范围查询非常简单。只需要从最高层级开始，逐级向下查找，直到找到范围的起始节点，然后沿着链表遍历到范围的结束节点。由于跳表的层级结构，范围查询的效率非常高。 算法实现难度更简单 B+树：B+树的实现相对复杂，需要维护平衡性，插入和删除操作需要进行复杂的旋转和分裂操作，以保持树的平衡。 跳表：跳表的实现相对简单，插入和删除操作只需要更新指针，不需要进行复杂的平衡操作。跳表的层数是随机生成的，不需要严格维持平衡性，因此实现难度较低。 压缩列表实现压缩列表（ziplist）是Redis为优化内存使用而设计的一种紧凑的顺序存储结构，类似于数组。它通过一系列精心设计的字段来高效地存储和访问数据，特别适用于存储少量数据。 主要字段压缩列表包含以下几个关键字段： zlbytes：记录当前压缩列表总共占用的字节数。这个字段帮助快速计算列表的总大小，无需遍历整个列表。 zltail：记录最后一个节点相对于头节点的偏移量。通过这个字段，可以快速定位到最后一个节点，而不需要从头遍历整个列表。 zllen：记录当前压缩列表中节点的数量。这个字段帮助快速获取列表的长度。 zlend：表示压缩列表的结束位置，通常值为0xff（即十进制的255）。这个字段用于标识列表的结束，类似于C语言中的空字符（’\\0’）。 查找元素在压缩列表中，查找第一个和最后一个元素非常高效，时间复杂度为O(1)。具体来说： 查找第一个元素：直接从列表头开始，时间复杂度为O(1)。 查找最后一个元素：通过zltail字段可以直接计算出最后一个节点的位置，时间复杂度也为O(1)。 然而，查找其他元素则需要遍历列表，时间复杂度为O(n)，其中n是列表中节点的数量。因此，压缩列表并不适合存储大量数据，更适合用于存储少量、频繁访问的数据。 节点结构压缩列表中的每个节点包含以下三个部分： prevlen：记录前一个节点的长度。这个字段使得从后向前遍历列表成为可能，因为可以通过prevlen快速定位到前一个节点。 encoding：记录当前节点实际数据的类型和长度。Redis支持两种主要的数据类型：字符串和整数。encoding字段根据数据类型和大小动态调整，以节省内存。 data：记录当前节点的实际数据。根据encoding字段的不同，data部分可以是字符串或整数。 插入数据当向压缩列表插入数据时，Redis会根据插入数据的类型和大小动态调整prevlen和encoding字段的空间占用。例如： 如果插入的是一个较小的整数，encoding字段可能会使用较少的字节来表示这个整数。 如果插入的是一个较长的字符串，encoding字段可能会使用更多的字节来表示字符串的长度。 这种根据数据类型和大小进行动态空间分配的设计思想，正是Redis为了节省内存而采用的核心策略。 连锁更新问题压缩列表的缺点是会发生“连锁更新”问题，因为连锁更新一旦发生，就会导致压缩列表多次重新分配分配，从而影响直接压缩列表的访问性能。 为什么会发生连锁更新问题？因为当插入或删除节点时，如果前一个节点的长度发生变化，可能会导致后续节点的prevlen字段需要更新，从而引发连锁更新。 在压缩列表中，prevlen字段的长度是动态的，根据前一个节点的长度来决定。例如，如果前一个节点的长度小于254字节，prevlen字段占用1字节；如果大于等于254字节，prevlen字段占用5字节。 Listpack实现尽管quicklist通过控制quicklistnode中元素的大小和数量来缓解压缩列表（ziplist）的性能问题，但它并未完全解决压缩列表中存在的“连锁更新”问题。为了进一步优化，Redis在5.0版本中引入了一个新的数据结构——listpack。 Listpack的特点listpack最大的特点是每个节点不再包含前一个节点的长度信息。这一设计从根本上消除了“连锁更新”问题，从而提高了数据结构的稳定性和性能。 Listpack的头部信息listpack的头部包含两个关键数据： listpack总字节数：记录整个listpack结构占用的总字节数。这个字段帮助快速计算listpack的大小，无需遍历整个结构。 listpack元素数量：记录listpack中包含的元素数量。这个字段帮助快速获取listpack的长度。 Listpack节点的结构listpack中的每个节点包含以下三个部分： encoding：定义该元素的编码类型。encoding字段根据数据类型和大小动态调整，以节省内存。例如，如果数据是一个小整数，encoding字段可能会使用较少的字节来表示这个整数。 data：实际存放的数据。根据encoding字段的不同，data部分可以是字符串或整数。 len：encoding和data的总长度。这个字段记录了当前节点的总字节数，帮助快速计算节点的长度。 假设我们有一个listpack，其中存储了三个节点： 第一个节点存储了一个整数123。 第二个节点存储了一个字符串&quot;hello&quot;。 第三个节点存储了一个整数456。 在这种情况下，listpack的头部会记录整个listpack的总字节数和元素数量。每个节点的encoding字段会根据数据类型（整数或字符串）和数据大小动态调整，而len字段会记录当前节点的总字节数。 例如： 第一个节点的encoding可能是0x01（表示一个小整数），data是123，len可能是2字节。 第二个节点的encoding可能是0x02（表示一个字符串），data是&quot;hello&quot;，len可能是7字节。 第三个节点的encoding可能是0x01（表示一个小整数），data是456，len可能是2字节。 通过这种设计，listpack在存储数据时更加紧凑和高效，同时避免了压缩列表中“连锁更新”的问题（因为已经不会影响其他节点长度字段的变化），从而提高了整体性能和稳定性。 Hash表扩容在Redis中，Hash表的扩容（rehash）是一个关键操作，用于处理Hash表在数据量增加时可能出现的性能问题。然而，传统的rehash过程可能会导致性能瓶颈，特别是在Hash表中数据量非常大的情况下。为了解决这个问题，Redis采用了渐进式rehash机制。 传统rehash的问题在传统的rehash过程中，需要使用两个Hash表： Hash表1：当前正在使用的Hash表。 Hash表2：新建的Hash表，空间大小通常是Hash表1的两倍。 传统rehash的步骤如下： 分配空间：为Hash表2分配空间。 数据迁移：将Hash表1中的所有数据重新分配到Hash表2中。 释放空间：数据迁移完成后，释放Hash表1的空间，并将Hash表2设置为当前使用的Hash表。 这种一次性完成数据迁移的方式存在以下问题： 性能影响：如果Hash表1中的数据量非常大，数据迁移过程需要大量复制操作，可能导致Redis阻塞，影响性能。 阻塞风险：在数据迁移期间，Redis无法处理其他请求，可能导致服务中断。 渐进式rehash为了避免上述问题，Redis采用了渐进式rehash机制。渐进式rehash的核心思想是将数据迁移过程分散到多次操作中，而不是一次性完成。 渐进式rehash的步骤 分配空间：为Hash表2分配空间。 逐步迁移：在rehash期间，每次对Hash表进行增删改查操作时，Redis除了执行这些操作，还会顺序地将索引位置上的所有key-value迁移到Hash表2中。 完成迁移：随着处理客户端发起的Hash表操作越来越多，最终某个时间点会将Hash表1中的所有key-value迁移到Hash表2中，完成rehash操作。 渐进式rehash的优势 避免阻塞：通过将数据迁移分散到多次操作中，避免了在rehash过程中Redis的阻塞，提高了系统的可用性。 平滑过渡：渐进式rehash使得Hash表的扩容过程更加平滑，减少了性能波动。 渐进式rehash期间的Hash表操作在渐进式rehash进行期间，Redis会同时维护两个Hash表（Hash表1和Hash表2）。因此，Hash表的删除、查找、更新等操作会在两个Hash表中进行： 查找操作：先在Hash表1中查找，如果没找到，再在Hash表2中查找。 新增操作：新增的key-value会被保存到Hash表2中，而Hash表1不再进行任何添加操作。 删除和更新操作：同样会在两个Hash表中进行查找和操作。 随着渐进式rehash的进行，Hash表1的key-value数量会逐渐减少，最终变为空表。当所有数据都迁移到Hash表2后，Hash表1会被释放，Hash表2成为当前使用的Hash表。 假设我们有一个Hash表1，其中包含100万个key-value对。当Hash表1需要扩容时，Redis会执行以下步骤： 分配空间：为Hash表2分配空间，大小为Hash表1的两倍。 逐步迁移：在每次对Hash表进行操作时，Redis会逐步将Hash表1中的数据迁移到Hash表2中。例如，每次操作时迁移1000个key-value对。 完成迁移：随着操作的进行，最终所有数据都会迁移到Hash表2中。 通过这种方式，Redis避免了在rehash过程中可能出现的性能瓶颈和阻塞问题，确保了系统的稳定性和性能。 String存储在Redis中，String类型的数据是通过SDS（Simple Dynamic String）数据结构来存储的。SDS是Redis自己实现的一种字符串表示方式，相较于C语言中的字符数组（char[]），SDS提供了更多的功能和优势。 SDS的结构SDS的结构中包含以下几个成员变量： len：记录了字符串的实际长度。这个字段使得获取字符串长度的时间复杂度为O(1)，因为可以直接从len属性读取，而不需要像C语言中的strlen函数那样遍历整个字符数组。 alloc：分配给字符串的空间数组长度。这个字段记录了当前SDS结构中为字符数组分配的总空间大小，用于管理内存分配和释放。 flags：用来表示不同类型的SDS。SDS有多种类型，flags字段用于区分这些类型，以便在不同情况下进行不同的处理。 **buf[]**：字符数组，用来保存实际的字符串数据。这个字段存储了字符串的内容。 SDS的优势相较于C语言的字符数组，SDS具备以下优势： O(1)的获取长度时间复杂度： 在C语言中，获取字符串长度需要调用strlen函数，该函数需要遍历整个字符数组，时间复杂度为O(n)。 在SDS中，字符串的长度直接存储在len字段中，获取长度的时间复杂度为O(1)，极大地提高了性能。 二进制安全： C语言的字符串以空字符（’\\0’）作为字符串的结束标志，这使得C语言字符串不能存储包含空字符的二进制数据。 SDS使用len字段来表示字符串的长度，因此不需要以空字符作为结束标志，可以安全地存储任意二进制数据。 避免缓冲区溢出： 在C语言中，如果字符串操作不当，可能会导致缓冲区溢出，即写入的数据超出了分配的内存空间，导致程序崩溃或安全漏洞。 SDS通过alloc字段记录分配的内存空间大小，并在字符串操作时检查是否超出分配的空间，从而避免了缓冲区溢出的问题。 示例假设我们有一个字符串&quot;hello&quot;，在C语言中，它通常表示为： 在SDS中，这个字符串的表示方式如下： 在这个例子中： len字段的值为5，表示字符串&quot;hello&quot;的长度。 alloc字段的值为10，表示为字符数组分配了10个字节的内存空间。 flags字段的值为0，表示这是一个基本的SDS类型。 buf[]字段存储了字符串&quot;hello&quot;的实际内容。 通过这种方式，SDS不仅提供了高效的性能，还解决了C语言字符串的一些常见问题，如缓冲区溢出和二进制不安全等。 线程模型Redis为什么快？ Redis以其极高的性能而闻名，官方基准测试结果显示，单线程的Redis吞吐量可以达到每秒10万次操作（100,000 ops&#x2F;s）。Redis之所以能够实现如此高的性能，主要有以下几个原因： 内存操作 Redis的大部分操作都是在内存中完成的。内存的访问速度远远快于磁盘I&#x2F;O，因此数据操作的性能瓶颈通常不在于CPU，而在于数据的I&#x2F;O操作。Redis基于内存操作，将性能瓶颈从磁盘I&#x2F;O转移到了内存和网络传输上。此外，Redis还采用了高性能的数据结构，如哈希表、跳表等，进一步提升了操作效率。 单线程模型 Redis采用单线程模型来处理网络I&#x2F;O和请求数据。单线程模型有以下几个优势： 避免线程竞争：多线程程序中，线程间的竞争和同步开销较大。单线程模型避免了线程间的竞争问题，减少了线程切换的开销。 简化设计：单线程模型简化了程序设计，避免了复杂的线程同步和锁机制，降低了出错的概率。 I&#x2F;O多路复用机制 Redis采用I&#x2F;O多路复用机制来处理大量的客户端socket请求。I&#x2F;O多路复用机制允许一个线程同时处理多个I&#x2F;O流，具体来说： 内核监听：在Redis单线程的情况下，I&#x2F;O多路复用机制允许内核同时监听多个socket上的连接请求和数据请求。 请求处理：一旦有请求到达，内核会将请求交给Redis线程处理，从而实现了一个Redis线程处理多个I&#x2F;O流的效果。 高效的数据结构 Redis内部使用了多种高效的数据结构，如哈希表、跳表、压缩列表等。这些数据结构在内存中操作时，能够提供高效的插入、删除和查找操作，进一步提升了Redis的性能。 Redis对多线程的使用Redis的单线程模型指的是“接收客户端请求 -&gt; 解析客户端请求 -&gt; 进行数据操作 -&gt; 返回数据给客户端”这个过程由一个主线程完成。 虽然Redis在处理客户端请求时采用单线程模型，但这并不意味着Redis程序本身是单线程的。实际上，Redis在启动时会启动多个后台线程（BIO，Background I&#x2F;O）来处理一些耗时的任务，从而避免这些任务占用主线程的资源，影响Redis的性能。 在Redis2.6，后台会启动线程分别完成关闭文件和AOF刷盘任务； 在Redis4.0版本后，新增了一个线程用于异步释放内存操作，也就是lazyfree。例如，执行unlink key &#x2F; flushdb async &#x2F; flushall async等命令，异步释放内存，这样的好处是不占用主线程。 将这些“关闭文件”、“AOF算盘”、“释放空间”任务交由创建的独立线程完成，能够极大地提升Redis的处理效率，因为这些操作都是极为耗时的，若由主线程完成可能会造成阻塞，同时也没法处理其他socket请求了，严重影响了Redis的性能。 虽然Redis的主要工作（网络I&#x2F;O和执行命令）一直是单线程模型，但在Redis 6.0版本也引入了多个线程来处理网络I&#x2F;O请求。这是因为随着网络硬件性能的提升，Redis的性能瓶颈有时候会出现在处理网络I&#x2F;O上。 多线程网络I&#x2F;O的优势 提升网络I&#x2F;O并行度：通过引入多线程处理网络I&#x2F;O请求，Redis能够更高效地处理大量的并发连接和数据传输，从而提升整体的性能。 不影响命令执行：尽管引入了多线程处理网络I&#x2F;O，但对于执行命令，Redis仍然采用单线程模型。这种设计确保了命令执行的顺序性和一致性，避免了多线程带来的复杂性和潜在的竞争问题。 Redis如何实现IO多路复用Redis采用单线程模型来执行命令，这意味着所有的任务都按照顺序执行。然而，由于输入输出（I&#x2F;O）操作是阻塞的，如果一个文件的I&#x2F;O操作阻塞，整个进程将无法为其他客户端提供服务。为了解决这个问题，Redis采用了I&#x2F;O多路复用技术。 I&#x2F;O多路复用的概念I&#x2F;O多路复用（I&#x2F;O Multiplexing）是一种允许单个线程同时监视多个文件描述符（如socket）的技术。通过这种技术，单个线程可以检查多个socket的I&#x2F;O就绪状态，从而在单个线程中处理多个I&#x2F;O流。 Redis中的I&#x2F;O多路复用在Redis中，I&#x2F;O多路复用主要用于处理多个客户端连接的网络I&#x2F;O操作。Redis使用了一种称为epoll的机制来实现I&#x2F;O多路复用。epoll是Linux系统中的一种高效的I&#x2F;O多路复用技术，能够显著提高Redis在高并发环境下的性能。其模型参考一张网络来源图： 监听多个socket：Redis主线程会监听多个客户端连接的socket。每个socket代表一个客户端连接。 事件通知：当某个socket上有数据到达（如客户端发送请求），epoll机制会通知Redis主线程。 处理事件：Redis主线程接收到事件通知后，会处理该socket上的请求，执行相应的命令，并将结果返回给客户端。epoll机制使用非阻塞I&#x2F;O操作。当某个文件描述符上的I&#x2F;O操作无法立即完成时，I&#x2F;O多路复用机制会立即返回，并继续监听其他文件描述符上的事件。 继续监听：处理完一个事件后，Redis主线程继续监听其他socket，等待下一个事件的到来。 假设我们有一个Redis服务器，它需要处理多个客户端的请求。在传统的阻塞I&#x2F;O模型中，每个客户端连接都需要一个独立的线程来处理，这会导致线程数量过多，资源消耗大。而在Redis的I&#x2F;O多路复用模型中，所有客户端连接的socket都由一个主线程监听和处理。 例如，当客户端A发送一个请求时，epoll机制会通知Redis主线程处理该请求；同时，客户端B的请求也会被epoll监听到，并交给Redis主线程处理。通过这种方式，Redis能够高效地处理大量的并发请求，而不会因为线程切换和竞争导致性能下降。 Redis通过采用I&#x2F;O多路复用技术，实现了在单个线程中高效处理多个客户端连接的请求。这种设计使得Redis能够在高并发环境下提供极高的性能，同时确保系统的稳定性和响应速度。通过epoll机制，Redis能够监听多个socket，并在事件发生时及时处理，避免了传统阻塞I&#x2F;O模型中的性能瓶颈。 Redis网络模型Redis在6.0版本之前，采用的是单Reactor单线程模型。这种模型虽然简单，但在高并发环境下存在一些性能瓶颈。为了进一步提升性能，Redis在6.0版本引入了多线程处理网络I&#x2F;O，但命令的执行仍然保持单线程模式。 单Reactor单线程模型在Redis 6.0之前，Redis采用的是单Reactor单线程模型。缺点： 无法充分利用多核CPU：单线程模型无法充分利用多核CPU的计算能力，限制了Redis在高并发环境下的性能。 业务处理延时：在进行业务处理时，无法执行其他连接的事件。如果业务处理时间较长，会造成较大的延时，影响系统的响应速度。 Redis 6.0的多线程网络I&#x2F;O为了解决单Reactor单线程模型的性能瓶颈，Redis在6.0版本引入了多线程处理网络I&#x2F;O。具体来说： 多线程处理网络I&#x2F;O：Redis 6.0将网络I&#x2F;O操作从主线程中分离出来，使用多个线程来处理网络I&#x2F;O请求，从而提高网络I&#x2F;O的并行度和处理效率。 单线程执行命令：尽管网络I&#x2F;O采用了多线程处理，但对于命令的执行，Redis仍然保持单线程模式。这种设计确保了命令执行的顺序性和一致性，避免了多线程带来的复杂性和潜在的竞争问题。 优点 提升网络I&#x2F;O并行度：通过多线程处理网络I&#x2F;O，Redis能够更高效地处理大量的并发连接和数据传输，从而提升整体的性能。 不影响命令执行：尽管引入了多线程处理网络I&#x2F;O，但对于命令的执行，Redis仍然采用单线程模型。这种设计确保了命令执行的顺序性和一致性，避免了多线程带来的复杂性和潜在的竞争问题。 假设我们有一个Redis服务器，它需要处理大量的客户端请求。在Redis 6.0之前，所有的网络I&#x2F;O和命令执行都在一个主线程中进行。如果某个客户端的请求处理时间较长，会导致主线程阻塞，无法处理其他客户端的请求。 在Redis 6.0中，网络I&#x2F;O操作被分离出来，由多个线程处理。例如，当客户端A发送一个请求时，网络I&#x2F;O线程会处理该请求的读取和写入操作；同时，客户端B的请求也会被其他网络I&#x2F;O线程处理。这样，即使某个客户端的请求处理时间较长，也不会影响其他客户端的请求处理。 Redis在6.0版本之前采用单Reactor单线程模型，虽然简单，但在高并发环境下存在性能瓶颈。为了进一步提升性能，Redis在6.0版本引入了多线程处理网络I&#x2F;O，但命令的执行仍然保持单线程模式。这种设计使得Redis能够在高并发环境下提供极高的性能，同时确保系统的稳定性和响应速度。"},{"title":"DDD架构设计","date":"2024-09-25T00:19:37.000Z","url":"/2024/09/25/DDD%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/","tags":[["DDD","/tags/DDD/"]],"categories":[["架构","/categories/%E6%9E%B6%E6%9E%84/"]],"content":"领域驱动设计（DDD）概述什么是领域驱动设计（DDD）？领域驱动设计（Domain-Driven Design，简称DDD）是一种软件设计方法论，旨在通过将业务领域模型与软件实现紧密结合，来指导复杂软件系统的开发。DDD的核心在于“领域”（Domain），即业务领域，并通过一系列关键概念如界限上下文、实体、值对象、聚合、仓储和领域服务来实现对复杂业务需求的有效管理。 DDD的两大设计阶段DDD将软件设计过程分为两个主要阶段：战略设计和战术设计。 战略设计战略设计主要目标是应对复杂的业务需求，通过抽象和分治的设计过程，将业务领域拆分为多个独立的界限上下文（Bounded Context），每个界限上下文对应一个微服务或子系统。战略设计的成功在于能否确保每个界限上下文具有明确的职责，避免职责交叉和功能重叠。 战术设计战术设计主要目标是基于面向对象思想，运用领域模型来实现业务逻辑。通过设计一个能够准确表达业务领域的概念模型，并运用实体、聚合和领域服务来承载业务逻辑，战术设计旨在降低系统的复杂度，提升代码的可读性和可维护性。 总结 领域驱动设计（DDD）通过战略设计和战术设计两个阶段，帮助开发团队在复杂业务需求的背景下，构建出清晰、可维护且能够准确表达业务需求的软件系统。战略设计通过抽象和分治策略，将复杂的业务领域拆分为多个独立的界限上下文，确保每个界限上下文具有明确的职责。战术设计则通过领域模型、实体、聚合和领域服务的合理运用，实现业务逻辑的清晰表达和高效维护。通过DDD，开发团队可以在开发前期投入更多精力进行设计，规划出更加合理且可持续更新迭代的工程设计。 DDD的概念什么是充血模型？实体、值对象、聚合对象都有什么区别？把他们搞懂”为什么需要“，才能更好地进行设计。 充血模型充血模型是一种设计模式，它将对象的属性和行为逻辑聚合到一个类中。与传统的贫血模型（Anemic Model）不同，充血模型强调对象不仅包含数据（属性），还包含操作这些数据的行为（方法）。这种设计模式的优势在于： 内聚性：对象的属性和行为紧密结合，使得对象更加内聚，减少了重复代码的编写。 封装性：对象的行为被封装在类内部，外部调用者只需通过接口与对象交互，而不需要了解内部实现细节。 可维护性：由于行为和数据紧密结合，修改和扩展对象的行为变得更加容易，系统的可维护性得到提升。 充血模型不仅适用于类的设计，还可以应用于包结构设计。例如，在设计一个模块时，可以将相关的类和接口组织在一起，形成一个内聚的包结构。 领域模型领域模型是对特定业务领域内业务规则、策略以及业务流程的抽象和封装。通过领域模型，可以将复杂的业务逻辑分解为多个独立的界限上下文（Bounded Context），每个界限上下文都有其独立的领域模型。领域模型的设计手段包括： 领域对象：包括实体（Entity）、值对象（Value Object）和聚合（Aggregate）。实体具有唯一标识，值对象通过属性值来区分，聚合是一组相关实体和值对象的集合。 领域服务：用于封装那些不适合放在实体或值对象中的业务逻辑。 仓储（Repository）：用于管理聚合的持久化操作，提供了一种抽象，使得业务逻辑与数据访问层分离。 工厂（Factory）：用于创建复杂的领域对象。 端口适配器（Port Adapter）：用于定义与外部系统交互的接口标准，确保领域模型只关注业务实现，而不直接依赖外部系统。 领域模型与贫血模型的对比在传统的贫血模型中，业务逻辑通常被平铺在Service层，导致Service层变得扁平化和复杂化。贫血模型的主要问题在于： 职责分离不明确：Service层承担了过多的业务逻辑，导致职责不明确，代码难以维护。 对象行为缺失：对象仅包含数据，缺乏行为，导致对象之间的交互复杂，系统难以扩展。 在充血模型和领域模型的指导下，系统设计发生了显著变化： 职责分离：业务逻辑被分配到领域对象和领域服务中，Service层仅负责协调和调用领域对象。 对象行为丰富：对象不仅包含数据，还包含操作这些数据的行为，使得对象更加内聚和可维护。 防腐层：通过端口适配器，领域模型与外部系统解耦，确保领域模型只关注业务实现，而不直接依赖外部系统。 领域模型的优势 业务逻辑清晰：通过领域模型，业务逻辑被清晰地表达和封装，使得系统更加易于理解和维护。 可扩展性：领域模型通过职责分离和对象行为的丰富化，使得系统更加易于扩展和修改。 防腐设计：通过端口适配器，领域模型与外部系统解耦，确保领域模型只关注业务实现，而不直接依赖外部系统。 "},{"title":"Python算竞教程","date":"2024-09-20T00:08:08.000Z","url":"/2024/09/20/%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8Python%E5%8F%82%E5%8A%A0%E7%AE%97%E7%AB%9E/","categories":[["Python","/categories/Python/"]],"content":" 注 本文转载自：如何用Python参加算法竞赛 - Mxrurush - 博客园 (cnblogs.com) 如何用Python参加算法竞赛前言本文适合有一定c++基础且初步了解Python，并想开发自己第二竞赛用语言的人群阅读。 本文仅介绍Python3，更低版本Python请自行了解。 Python的优点在于在应对代码编写简单的题目时，在无电子板子的赛场环境可以一定缩短codeing时间。但在面对代码编写要求较高、时间限制较紧的情况，并**无法取代c++**。因此c++仍然是打算法竞赛的第一选择。 Python的适用场合有如下几种： 代码简单的，如一些思维题、构造题等 字符串处理，Python提供的字符串处理函数比c++丰富许多。 对拍器和数据生成器 注一： python与其他语言不同的一点在于，同样的算法，用标准库的永远比自己写的速度快。因为标准库算法大部分是用C语言写的，python由于语言限制永远到达不了C的速度，也即标准库的速度。 注二： python的官方中文文档比起一些别的语言已经算非常好了，如果看别人代码或者题解有不懂的函数或容器，可以直接搜官方文档的对应内容。本文对于一些内容也不会讲太细，可以直接搜官方文档看 注三： python语言并不适合递归算法，因为其递归深度，语言自身就有限制，就算去除限制，其也会开辟大量空间。蓝桥杯也会依据语言出题，python组用递归算法的题很少很少。所以平时应多注意迭代算法的积累，以及递归算法转迭代算法的方式 Python基本数据类型python的基本数据类型有六种，数值、字符串、列表、元组、字典、集合，常用的有int，str，bool，float，list，tuple，dict，set int（整数）没有长度限制，大数字乘法复杂度O(nlogn)O(nlogn)（补：因为当int达到高精度时，内部会使用FFT算法加速多项式乘法），非常方便。 float（浮点数）大概注意一下精度就行，[2.2250738585072014e−308,1.7976931348623157e+308][2.2250738585072014e−308,1.7976931348623157e+308] bool（布尔）有True，False两个值（注意大小写） list（列表）最常用的数据类型之一，可当成C++中数组。 由于python中没有C++的栈，该结构可作栈使用 还可以append添加元素，pop删除尾部最后一个元素（O(1)），删除中间元素（最坏O(n)），count计数（O(n)），index定位元素（O(n)），并且重载了加法（即同维数组连接） 加法示例 tuple（元组）和list差不多，初始化用括号 支持list的很多操作，唯独不能对一个tuple自身进行修改 所以 dict 因为要求 key 值不可变，当想对插入一个 （list，int）键值对时，必须将 list 转为 tuple str（字符串）和 C++ 中字符串类似，但是无法修改其中字符，因此经常用如下方法转换为一个list再进行操作。 重载了加法，加法即是字符串连接 同时也有count，index，find等函数 多了一个C++没有，很好用的 split split 默认以不可见字符进行分割，也可传入固定字符，以固定字符进行分割字符串，将子串存入list中 dict（字典）相当于C++的map容器，但是其内部是哈希表实现的，无序，大部分操作都是 O(1)O(1) 的 需要注意的是，其通过下标访问一个不存在的key时，会报异常，这点可以用后文的defaultdict解决 set（集合）set是一个数学意义集合（不可重，无序）的程序实现（内部由哈希表实现）。支持各种集合操作。 该类型重载了位运算，可以灵活的求集合交，并，补 其可迭代，故也可以 这样遍历 类型转换类型可以函数化，并互相转换 如最常用的 int，str 转换 还有 list 与 set 互相转换以实现去重操作 Python基础语法本部分，我将直接列出c++基础语法，并给出在Python上的等价替代。 主函数体c++main函数基础结构： Python主函数并不是必要的，完全直接在空文件编写代码，如： 在Python中可以直接写为： 当然，如果实在不习惯，想要和c++风格更加类似，可以按如下写法： 第一行if __name__ == &quot;__main__&quot;:的意思：字面上，这是一个if判断，而__name__是一个内置的特殊变量，当我们希望将一个python模块（就是写好的py文件）导入其他python模块时，就只会执行if __name__ == &quot;__main__&quot;:的语句，比如： print(123)就不会被执行。 但对于算法竞赛来说，一般不需要多模块操作，该写法只是为了更好的向c++代码风格靠拢。 运算符python中新添 ** 乘方运算符 无自增 ++ 运算符，无自减运算符 – 条件连接符 python 中均以英文表示条件连接，可读性好些 python C and &amp;&amp; or || not ! 基础语句循环： 需要注意的是，for i in range(n):实际上是对range生成的对象遍历，可以简单理解为对一个[0,1,2…,n−3,n−2,n−1][0,1,2…,n−3,n−2,n−1]的列表遍历，因此我们在循环中修改ii并不会改变之后的循环。比如： 并不会让循环按照0→2→4⋅⋅⋅0→2→4···的顺序进行。 可见，Python中的for循环不如c++中的灵活，因此while的使用频率大大提高了。 关于range函数： 三个参数分别代表，起点，终点和步长 range返回的区间是左闭右开的，也就是[start,end)[start,end) 第1和第3个参数可以缺省。 给几个使用实例 分支： 和c++差别不大，给个实例： 可以发现区别只在于Python将else if合并为了elif。 但因为引入了in这个关键字，有了一些更加方便的用法 函数Python中函数定义方法很简单： Python允许函数定义出现在函数内部 Output： 1 2 Python允许函数返回多个值 Output: 11 12 Python中函数内部如果想修改外部数字变量，需要使用nonlocal或者global关键字 如果将global t注释掉程序会报错。 如果想要使用的变量不是被定义在全局区，而是某个函数体内部则要使用nonlocal关键字 “头文件”Python除内置库外，有一些功能需要手动导入模块，有如下几种方法 第一种方法和后两种调用时有所区别 第一种： 后两种： 可见区别就是使用时是否要明确库名，一般在算法竞赛中为了代码简洁，推荐使用后者，但如果要使用from math import *的方法，将存在一定变量名冲突的风险。 因此，更推荐部分导入。 “宏定义”Python中没有宏定义，但有替代可以缩短一定码量。如下： 我们定义一个及其鬼畜的函数abcdefgasdas(x)并在之后给其“取别名”为func，调用func就等价调用了abcdefgasdas从而在某些要调用内置函数时，起一个更短的名字，降低码量。 附：之所以可以这样是因为python之中，一切皆对象，故可以一切皆变量（包括函数） 输入输出输入 Python中的读入和C++还是有很大不同的，需要一定时间适应。 Python读入时都是调用input()其将返回标准输入中的一行数据（不包括末尾的\\n），其返回的类型统一为字符串，因此还要对其进行变量类型转换。 在算法竞赛中，读入一行数字一般分为可数的几个整数，和一个很长的数组两种形式，我举例说明如何读入： Input 5 1 3 2 4 2 5 3 2 1 2 3 4 5 字符串读入方法就很简单了 读入优化 Python中的真读入优化需要码量巨大，在正式比赛中并不常用，但仍然可以使用如下方法提高一定的读入效率。 将其放在Python文件头部即可。可以提高一定效率，但没有c++那般明显。 PS：使用该方法行末的\\n将不会被忽略，在读入字符串数据时尤其要注意 输出 使用print()进行输出 将输出数据类型转换为字符串，并且将所有中间输出全部加入到此字符串中，最后一次性输出，有时可以提高一定效率，但并不明显。 文件读写由于前几年蓝桥杯 C++ 组有需要文件读写的情况，所以在此稍微讲解常用用法，具体可见标准库 r 以只读方式打开文件。文件的指针将会放在文件的开头。 w+ 打开一个文件用于读写。如果该文件已存在则打开文件，并从开头开始编辑，即原有内容会被删除。如果该文件不存在，创建新文件。 Python库和函数介绍一些常用的库和函数，着重和C++的STL对比。 简单函数 数学函数 math 库中的 sort自定义排序，Python不如C++灵活。首先它只可以对整个序列排序，而无法对部分序列排序，其次自定义方法不如C++的lamda表达式方便。 当然，很多时候我们只是想让它根据列表的某一维度排序，这时也可以用python的lambda表达式，代码量少很多。 sort是没有返回值的原地排序，如果我们希望获取到这个排序后列表，且不想改变原来的列表时，可以用sorted函数。自定义 map （映射）通过一个函数，对可迭代对象的所有值对象进行修改（创建副本，非原地修改） collections这个库里常用的有deque，defaultdict，Counter dequedeque对标c++中的双端队列，可以快速在头尾弹出和加入元素。速度比普通队列快，因此在需要队列的场合，统一使用deque defaultdict即当键值不存在时，有默认返回值的 dict，其余操作差不多 由于defaultdict对于key下标运算返回的是value的引用，若不存在则只能创建一个对象再返回，因此通过下标判断存在与否的方式不推荐，建议使用 in 来判断是否存在 用下标运算来插入与修改 Counter调用Counter函数计数，返回一个 defaultdict(int) PS：dict、set和其子类都是用的hash实现，而不是c++中的红黑树，因此没有自动排序功能，目前没有太好的替代。 如果是非标准库的话，有Sorted Container，比较好用。让我们祝福它早日进标准库 heapq（优先队列）Python中其实有优先队列，但是速度没有heapq快，因此用heapq代替。 heapq提供函数对一个list进行原地的小根堆的维护。 heapq并没有提供方便的重载为大根堆的方法，如果想使用大根堆，一般的技巧是加入值取负值，弹出后再恢复。 基础操作差不多这么多，还有一些其他功能可自行了解。 zip、enumerate函数这两个函数，都是使得枚举进一步简单化的函数。 zip函数可以同时访问不同list的同偏移量的元素 Output： 1 52 43 34 25 1 enumerate则是在访问list中元素时，同时给出元素的下标，下标默认从0开始。 Output: 0 11 22 33 44 5 itertools这个库里的大多函数方法，都是返回一个可迭代对象，因此若要变成list还需list()转换 permutations、combinationspermutations，combinations分别是返回一个可迭代对象（一般是list）的所有排列和组合。使用时需要导入itertools模块 用法如下： Output: (1, 2, 3)(1, 3, 2)(2, 1, 3)(2, 3, 1)(3, 1, 2)(3, 2, 1)(1, 2)(1, 3)(2, 3) accumulate（累计） pairwise（成对遍历） functoolsreduce （聚合）其位于functools库里面 对于可迭代对象进行使用，将可迭代对象里的所有值对象，两两聚合，最后返回一个值对象 Python小技巧交换没有swap函数，但可以这么写，也很方便 列表（其实可以是任何可以迭代对象）解析式创建列表时，可以用如下方法简化代码 列表解析式中中括号中返回的是一个可迭代对象，这个在很多函数中都是可接受的数据类型。结合上面说的“聚合函数”，就可以这样写 多维数组很可惜，python自身没有天然支持固定长度的多维数组（即如C++的int a[5][5][5];这样的），需要numpy才能很好的使用 但是仍然可以创建，方式如下 这是创建了一个 4 * 2 的 二维数组 有人可能疑惑，为什么不能这样创 这是后果 第一列全部被修改 最外层的乘4，相当于只是创建了四个引用，引用的都是一个[0] * 2 所以不行 三目表达式和c++中的三目表达式?:类似，Python中也有何其类似的语法。 快速创建一个字典"},{"title":"MySQL-性能调优","date":"2024-09-19T21:20:00.000Z","url":"/2024/09/20/MySQL-%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98/","tags":[["索引","/tags/%E7%B4%A2%E5%BC%95/"],["SQL调优","/tags/SQL%E8%B0%83%E4%BC%98/"]],"categories":[["MySQL","/categories/MySQL/"]],"content":"在MySQL性能调优中，EXPLAIN命令是关键工具，用于分析查询执行计划。本文将介绍如何通过EXPLAIN识别性能瓶颈，并提供优化策略，包括索引创建、查询语句优化、避免文件排序和临时表的使用，以及缓存技术的应用。此外，还将探讨FORCE INDEX命令的使用，以强制使用指定索引。对于高并发场景，主从同步和分库分表策略同样重要，以确保系统稳定性和性能。通过这些方法，可以显著提升MySQL数据库的查询效率和整体性能。 性能调优EXPLAINEXPLAIN命令是MySQL中用于分析和优化查询性能的重要工具。通过EXPLAIN，我们可以查看一条SELECT语句的执行计划，了解查询的执行过程，例如是否使用了索引、是否实现了索引覆盖等。 以下是一条全表扫描查询语句的EXPLAIN结果示例： 执行计划参数 type：表示扫描数据的类型，下面会详细讲解。 possible_keys：表示可能用到的索引。 key：表示实际用到的索引，如果为null，则表示没有用到索引。 rows：表示扫描的记录行数。 扫描类型（type）type表示扫描数据时采用的方式，从性能上由低到高排列如下： ALL：全表扫描，性能最差，应尽量避免。全表扫描意味着数据库引擎需要读取表中的每一行数据，开销巨大，尤其是在大数据量的情况下。 INDEX：全索引表扫描，虽然扫描的是索引表，不需要对数据进行排序，但开销依旧很大。全索引扫描意味着数据库引擎需要读取索引中的每一行数据，尽管索引通常比数据表小，但仍然是一个昂贵的操作。 RANGE：采用了索引范围扫描，只需查找指定范围的索引。尽量让查询达到RANGE级别以上，越往上的级别索引作用越明显、效率越高。范围扫描通常用于WHERE子句中的范围条件（如&gt;、&lt;、BETWEEN等）。 REF（非唯一索引查询）：采用了非唯一索引或唯一索引的非唯一索引前缀，返回数据是多条的。虽然有的表会存在相同的索引，但一般这种索引重复记录条数不多，且在磁盘中已经按顺序排列，查询的范围会小很多。 EQ_REF（唯一索引查询）：使用主键索引或唯一索引产生的查询，通常用于多表连接查询。例如，使用学生ID查询学生信息和学科成绩信息，两表的stu_id是相同的。可以采用小表驱动大表进行多表查询。 CONST：表示使用了主键或唯一索引与常量进行比较查询，一般结果只有一条或采用了唯一索引扫描。与EQ_REF不同的地方是，CONST与常量进行比较，效率会快很多，EQ_REF通常用于多表级联查询。 Extra显示结果Extra显示的结果有几个重要的参考指标： Using filesort：采用了GROUP BY操作，但无法利用索引进行排序。应尽量避免。文件排序意味着数据库引擎需要将数据加载到内存中进行排序，这是一个昂贵的操作，尤其是在大数据量的情况下。 Using temporary：使用了临时表保存中间查询数据，常见于排序GROUP BY查询和分组GROUP BY查询。使用临时表意味着数据库引擎需要额外的内存和磁盘空间来存储中间结果，这会增加查询的开销。 Using index：所需要的数据直接通过扫描索引即可获得，不需要查询表中的数据或进行回表操作，也就是索引覆盖。索引覆盖意味着查询所需的所有数据都包含在索引中，因此不需要回表，这可以显著提高查询性能。 深入分析全表扫描（ALL）全表扫描是最低效的扫描方式，通常发生在没有索引或查询条件无法利用索引的情况下。为了避免全表扫描，可以考虑以下优化措施： 创建合适的索引：为查询条件中的字段创建索引，尤其是高频查询的字段。 优化查询条件：确保查询条件能够利用索引，避免使用函数操作或模糊查询（如LIKE &#39;%keyword&#39;）。 索引覆盖（Using index）索引覆盖是一种高效的查询方式，通过合理设计索引，可以使查询所需的所有数据都包含在索引中，从而避免回表操作。实现索引覆盖的关键在于： 选择合适的索引字段：确保查询所需的所有字段都包含在索引中。 避免不必要的字段：如果查询只需要部分字段，可以考虑创建覆盖索引，只包含这些字段。 文件排序（Using filesort）文件排序是一种昂贵的操作，通常发生在ORDER BY或GROUP BY操作无法利用索引的情况下。为了避免文件排序，可以考虑以下优化措施： 创建排序索引：为ORDER BY或GROUP BY的字段创建索引，确保排序操作可以利用索引。 优化查询语句：尽量减少排序操作，或者将排序操作放在应用程序层进行。 通过合理使用EXPLAIN命令，可以深入了解查询的执行计划，从而进行针对性的性能调优，提高查询效率。 查询优化查询优化是提升数据库性能的关键步骤。通过分析查询语句、创建或优化索引、减少不必要的数据查询、优化数据库结构以及使用缓存技术，可以显著提高查询效率。 1. 分析查询语句使用EXPLAIN命令分析查询语句的执行计划，了解查询的执行过程。通过查看扫描类型（type）、采用的索引（key）、扫描的记录行数（rows）等信息，判断查询是否走了索引，是否存在全表扫描等问题。 2. 创建或优化索引根据查询条件创建适用的索引，以提高查询效率。索引的选择应考虑以下因素： 高频查询字段：为经常出现在查询条件中的字段创建索引。 区分度高的字段：选择区分度高的字段作为索引的前缀，以提高索引的选择性。 联合索引：合理设计联合索引，遵循最左匹配原则，确保查询条件能够充分利用索引。 3. 查询优化只查询需要的数据，避免使用SELECT *，尽量能够命中索引，避免索引失效情况。具体措施包括： 选择性查询：只查询必要的字段，避免查询不需要的数据。 避免函数操作：对索引字段进行函数操作（如LOWER(column)）会导致索引失效，应尽量避免。 避免模糊查询：使用通配符开头的模糊查询（如LIKE &#39;%keyword&#39;）通常会导致索引失效，应尽量避免。 4. 优化数据库避免单表数据量过大，可以使用数据库集群和分表机制来优化数据库结构。具体措施包括： 分表分库：将大表拆分为多个小表，或者将数据分布到多个数据库中，以减少单表数据量。 数据库集群：使用数据库集群技术，将数据分布到多个节点上，提高数据库的并发处理能力。 5. 使用缓存技术缓存读写要比磁盘I&#x2F;O速度快得多，可以将数据写入缓存层（如Redis），以减少数据库的读写压力。具体措施包括： 缓存热点数据：将高频访问的数据缓存到Redis等缓存系统中，减少数据库的读取次数。 缓存查询结果：将复杂的查询结果缓存起来，避免重复计算，提高查询效率。 示例假设有一个订单表orders，包含字段order_id、customer_id、order_date等。以下是一些优化措施： 创建索引：为order_id和customer_id创建索引，提高查询效率。 查询优化：避免使用SELECT *，只查询必要的字段，如SELECT order_id, customer_id FROM orders WHERE order_id = 123。 分表分库：根据order_date字段将订单表拆分为多个小表，或者将数据分布到多个数据库中。 使用缓存：将高频查询的订单数据缓存到Redis中，减少数据库的读取次数。 扩展如果在执行查询计划时发现并没有使用正确的索引，可以使用FORCE INDEX命令，强制使用指定索引来优化查询。FORCE INDEX命令可以显式地告诉MySQL使用特定的索引，而不依赖于MySQL的查询优化器选择。 FORCE INDEX命令的语法如下： 示例 假设有一个订单表orders，包含字段order_id、customer_id、order_date等，并且有一个联合索引idx_customer_order基于customer_id和order_date。 未使用正确索引的查询 如果MySQL的查询优化器没有选择使用idx_customer_order索引，而是选择了全表扫描，可以通过FORCE INDEX命令强制使用该索引： 使用FORCE INDEX的查询 注意事项 索引选择：虽然FORCE INDEX可以强制使用指定索引，但并不总是最佳选择。在某些情况下，MySQL的查询优化器可能会选择更优的执行计划。因此，使用FORCE INDEX时应谨慎，最好结合EXPLAIN分析结果进行判断。 性能影响：强制使用索引可能会带来性能提升，但也可能导致性能下降。例如，如果强制使用的索引不是最优的，可能会增加查询的开销。 临时解决方案：FORCE INDEX通常作为临时解决方案，用于调试和优化查询。长期来看，应通过优化索引设计和查询语句来提高查询性能。 进一步优化 除了使用FORCE INDEX，还可以通过以下方式进一步优化查询： 索引覆盖：确保查询所需的所有字段都包含在索引中，避免回表操作。 查询重写：重写查询语句，使其更符合索引的使用规则，例如避免函数操作和模糊查询。 数据库分区：根据查询条件对数据库进行分区，减少查询的数据量。 通过合理使用FORCE INDEX命令，并结合其他优化措施，可以显著提高查询性能，减少数据库的I&#x2F;O操作，提升系统的整体性能。 架构优化主从同步【键盘都敲冒烟啦！！！】 分库分表【键盘都敲冒烟啦！！！】"},{"title":"MySQL日志可以用来干啥？","date":"2024-09-17T06:21:45.000Z","url":"/2024/09/17/MySQL%E6%97%A5%E5%BF%97%E5%8F%AF%E4%BB%A5%E7%94%A8%E6%9D%A5%E5%B9%B2%E5%95%A5%EF%BC%9F/","categories":[["MySQL","/categories/MySQL/"],["日志","/categories/MySQL/%E6%97%A5%E5%BF%97/"]],"content":"了解MySQL的童靴们都知道，MySQL有好几种日志——undo log（回滚日志）、redo log（重做日志）还有binlog（归档日志），为啥需要这么多日志？这些日志分别都是干啥用的？在进一步探讨这么些问题之前，我们需要先了解一下一条SQL语句的执行过程。 笔者作为一名初学小白，时常感到好奇：当执行了 SQL 语句对数据记录进行修改时，如果突然遭遇系统关机、服务器卡死等故障，这段记录修改该如何是好？ 小伙伴们可能会不假思索地回答：“通过事务回滚恢复到执行增删改之前的状态！” 没错，这确实是 MySQL 保障数据安全的重要机制之一。即使我们没有显式地开启事务和提交事务，MySQL 也会隐式地启动事务执行“增删改”语句，并在执行完后自动提交事务（MySQL 默认开启了 autocommit 参数）。 但你是否想过，MySQL 是如何实现这种“时光倒流”般的神奇操作的呢？这就要归功于 MySQL 的“时光机”—— undolog、redolog 和 binlog。它们就像数据库的“守护天使”，默默地记录着数据的每一次变化，在关键时刻挺身而出，保障数据的安全性和一致性。 undolog、redolog 和 binlog 是 MySQL 保障数据安全的三大利器，它们各司其职，共同构建了 MySQL 强大的数据保护机制： undolog ：负责事务的原子性和 MVCC，确保数据的一致性。 redolog ：负责事务的持久性，确保数据不会因故障而丢失。 binlog ：负责数据的备份和主从复制，确保数据的可靠性和高可用性。 接下来，我们来进一步探讨这三种日志如何实现数据库神操作。 Undo Log 是干啥的在前言我们提到，MySQL 会隐式开启事务执行“增删改”语句，当操作过程中发生崩溃时，事务会进行回滚。那么，回滚操作中旧的数据要从哪里来呢？ 想象一下，如果在执行“增删改”操作之前，我们将要操作的数据记录做一个备份，那么当我们想恢复到执行操作之前的状态时，只要对照备份的信息就可以了。 当然，每次执行操作都要进行备份会很麻烦，但我们可以根据需求进行相应的操作记录。例如： 执行删除操作之前，记录要删除的记录信息，若想恢复，我们再把记录插回去； 执行新增操作之前，记下新增记录的ID，撤销新增只需要把对应ID记录删除即可； 执行修改操作之前，记录修改前的数据，撤销修改时只需将数据恢复到修改前的状态。 这种记录操作前数据的方式，正是 MySQL 中 Undo Log （回滚日志）的核心思想。Undo Log 记录了事务执行过程中对数据的修改操作，用于在事务回滚时撤销这些修改，将数据恢复到事务开始前的状态，它保证了事务的ACID特性中的原子性。 undo log 是一种用于撤销回退的日志。在事务没提交之前，MySQL 会先记录更新前的数据到 undo log 日志文件里面，当事务回滚时，可以利用 undo log 来进行回滚。如下图: 每当 InnoD8 引擎对一条记录进行操作(修改、删除、新增)时，要把回滚时需要的信息都记录到 undo log 里，发生回滚时，就读取undo log日志记录的数据，执行相反的操作来完成数据恢复。 需要注意的是，不同的操作，因需求不同，其undo log格式也不同，此处仅以更新操作的日志为例。每条记录的每一次更新操作产生的 Undo Log 格式中，都包含一个 roll_pointer 指针和一个 trx_id 事务 ID： trx_id 事务 ID：用于标识该记录是被哪个事务修改的，帮助系统追踪事务的执行顺序。 roll_pointer 指针：将这些 Undo Log 串成一个链表，这个链表就被称为版本链。版本链记录了该记录的所有历史版本，使得系统可以在需要时回滚到任意一个历史状态。 版本链的结构如下图所示： 另外，Undo Log 通过 ReadView + Undo Log 实现 MVCC（多版本并发控制）。 对于「读提交」和「可重复读」隔离级别的事务： 「读提交」：每次 SELECT 生成新的 Read View，可能导致同一事务中多次读取同一条数据时结果不一致。 「可重复读」：事务启动时生成 Read View，并在整个事务期间使用，确保读取的数据一致。 这两个隔离级别通过「事务的 Read View 里的字段」和「记录中的隐藏列（trx_id 和 roll_pointer）」进行比对，如果不满足可见性条件，就会顺着 Undo Log 版本链找到满足其可见性的记录，实现 MVCC。 因此，Undo Log 的两大作用是： 实现事务回滚，保障事务的原子性：在事务处理过程中，如果出现错误或用户执行 ROLLBACK 语句，MySQL 可以利用 Undo Log 中的历史数据将数据恢复到事务开始之前的状态。 实现 MVCC（多版本并发控制）的关键因素之一：MVCC 通过 ReadView + Undo Log 实现。Undo Log 为每条记录保存多份历史数据，MySQL 在执行快照读（普通 SELECT 语句）时，会根据事务的 Read View 里的信息，顺着 Undo Log 的版本链找到满足其可见性的记录。 Buffer Poll是干啥的【更新中。。。】"},{"title":"MySQL-事务与日志","date":"2024-09-14T21:20:03.000Z","url":"/2024/09/15/MySQL-%E4%BA%8B%E5%8A%A1%E4%B8%8E%E6%97%A5%E5%BF%97/","tags":[["事务","/tags/%E4%BA%8B%E5%8A%A1/"],["日志","/tags/%E6%97%A5%E5%BF%97/"],["锁","/tags/%E9%94%81/"]],"categories":[["MySQL","/categories/MySQL/"]],"content":"这篇文章好像丢失了喔。。。T _ T "},{"title":"MySQL-索引与查询","date":"2024-09-14T21:20:01.000Z","url":"/2024/09/15/MySQL-%E7%B4%A2%E5%BC%95%E4%B8%8E%E6%9F%A5%E8%AF%A2/","tags":[["索引","/tags/%E7%B4%A2%E5%BC%95/"],["查询","/tags/%E6%9F%A5%E8%AF%A2/"]],"categories":[["MySQL","/categories/MySQL/"]],"content":"在数据库管理中，索引是提升查询性能的关键工具。本文将深入探讨MySQL中的索引类型，从数据结构、物理存储、字段特性和字段个数等多个维度进行详细分类和解析。 索引分类详解与深入探讨MySQL中索引的分类可以从多个维度进行划分，包括数据结构、物理存储、字段特性和字段个数等。以下是对这些分类的详细解释和示例代码。 数据结构分类B+Tree索引结构特点与应用场景：B+Tree索引是一种平衡多路搜索树，所有数据存储在叶子节点，非叶子节点仅存储索引键值。这种结构保证了高效的查找、插入和删除操作，适用于范围查询、排序操作和频繁的插入、删除操作。B+Tree索引在大多数数据库系统中被广泛使用，因其平衡性和高效性。 Hash索引结构特点与应用场景：Hash索引通过哈希函数将索引键值映射到存储位置，实现快速查找。哈希索引的查找时间复杂度为O(1)，适用于等值查询，如用户登录验证、唯一性检查等场景。但由于不支持范围查询和排序，应用场景较为有限。 Full-text索引结构特点与应用场景：Full-text索引专门用于全文搜索，支持对文本内容进行分词、词干提取和倒排索引等操作，实现高效的全文检索。适用于需要进行文本分析和搜索的应用场景，如搜索引擎、文档管理系统等。 物理存储分类聚簇索引（主键索引）结构特点与应用场景：聚簇索引将数据行与索引结构存储在一起，主键索引即为聚簇索引。聚簇索引决定了数据在磁盘上的物理存储顺序，数据行的物理顺序与索引顺序一致，适用于频繁访问的数据，如用户表的主键索引。聚簇索引能够提高数据访问的局部性，减少磁盘I&#x2F;O操作。 二级索引（辅助索引）结构特点与应用场景：二级索引存储索引键值和指向数据行的指针，不直接存储数据行。二级索引适用于非主键字段的查询，可以加速查询操作，如用户表中的邮箱字段索引。二级索引可以提高查询效率，但会增加额外的存储空间和维护成本。 字段特性分类主键索引结构特点与应用场景：主键索引是唯一标识表中每一行的索引，具有唯一性和非空性。主键索引通常是聚簇索引，适用于需要唯一标识每一行的场景，如用户ID、订单ID等。主键索引能够确保数据的唯一性和完整性。 示例代码 唯一索引结构特点与应用场景：唯一索引确保索引字段的值唯一，但不要求非空。唯一索引适用于需要确保数据唯一性的场景，如用户表中的邮箱字段。唯一索引可以防止重复数据的插入。 示例代码 普通索引结构特点与应用场景：普通索引是最基本的索引类型，不具有唯一性约束，适用于加速查询操作。普通索引可以提高查询效率，但不会影响数据的唯一性，如用户表中的姓名字段。 示例代码 前缀索引结构特点与应用场景：前缀索引是对字段的前缀部分创建的索引，适用于长字段或文本字段的索引。前缀索引可以减少索引存储空间和提高查询效率，如用户表中的地址字段。 示例代码 字段个数分类单列索引结构特点与应用场景：单列索引是基于单个字段创建的索引，适用于单字段查询场景。单列索引可以提高单字段查询的效率，如用户表中的姓名字段。 联合索引结构特点与应用场景：联合索引是基于多个字段创建的索引，适用于多字段查询场景。联合索引可以提高多字段查询的效率，但需要注意索引字段的顺序和查询条件的匹配，遵循最左匹配原则，如用户表中的姓名和年龄字段。 聚簇索引与非聚簇索引 数据存储 聚簇索引的数据行按照键值顺序存储，索引的叶子节点包含了实际的数据行。这意味着数据行的物理存储顺序与索引顺序一致，数据行的位置由聚簇索引决定。 非聚簇索引的叶子节点存放的是索引键值和指向数据行的指针，而不是完整的数据行。这意味着非聚簇索引不直接影响数据行的物理存储顺序。 索引与数据关系 通过聚簇索引查找数据时，直接返回叶子节点中的完整数据行，无需额外的查找操作。 通过非聚簇索引查找数据时，首先查找到叶子节点，获取存放的聚簇索引数据，再通过聚簇索引查表获取完整数据行。这个通过非聚簇索引获取聚簇索引数据并回溯查表的过程称为回表。 唯一性 聚簇索引通常由主键构成，因此一个表只能有一个聚簇索引。聚簇索引决定了数据行的物理存储顺序，具有唯一性。 一个表可以有多个非聚簇索引，因为它们不直接影响数据行的物理存储顺序。非聚簇索引可以基于多个字段创建，具有较高的灵活性。 效率 聚簇索引直接返回叶子节点中的完整数据行，无需额外的查找操作，因此在查找效率上通常优于非聚簇索引。 非聚簇索引可能需要进行回表操作，即通过非聚簇索引获取聚簇索引数据，再通过聚簇索引查表获取完整数据行。回表操作会增加额外的I&#x2F;O开销，因此在查找效率上通常低于聚簇索引。 索引选择：自增ID vs UUID在选择主键索引时，自增ID和UUID是两种常见的选项。以下是对这两种选择的详细分析，特别是从索引性能和存储效率的角度进行探讨。 自增ID优点 顺序存储：自增ID是顺序生成的，因此数据行在磁盘上的存储顺序与索引顺序一致。这使得B+树的叶子节点更加紧凑，减少了内存碎片。 高效插入：由于自增ID的顺序性，新插入的数据行总是添加到B+树的末尾，减少了B+树的调整操作，提高了插入效率。 减少IO操作：顺序存储的数据行更容易被缓存，减少了磁盘I&#x2F;O操作，提高了查询效率。 缺点 可预测性：自增ID的可预测性可能带来安全风险，尤其是在分布式系统中，容易暴露业务信息。 分布式系统中的问题：在分布式系统中，自增ID的生成和管理可能变得复杂，需要额外的机制来保证全局唯一性。 UUID优点 全局唯一性：UUID由系统算法生成，保证了全局唯一性，适用于分布式系统中的数据唯一标识。 安全性：UUID的随机性使得其难以预测，提高了数据的安全性。 缺点 乱序存储：UUID的随机性导致数据行在磁盘上的存储顺序是乱序的，使得B+树的叶子节点变得稀疏，增加了内存碎片。 插入效率低：由于UUID的乱序性，新插入的数据行可能需要频繁调整B+树的结构，降低了插入效率。 增加IO操作：稀疏的数据分布导致查询时可能需要多次提取数据页，增加了磁盘I&#x2F;O操作，降低了查询效率。 选择建议自增ID 适用场景：适用于单机或集中式数据库系统，特别是需要高效插入和查询的场景。 示例：用户表、订单表等。 UUID 适用场景：适用于分布式系统，特别是需要全局唯一性和安全性的场景。 示例：分布式系统中的用户标识、订单标识等。 优化建议自增ID优化 使用自增ID作为主键：在单机或集中式数据库系统中，使用自增ID作为主键，可以提高插入和查询效率。 分布式系统中的自增ID：在分布式系统中，可以使用分布式ID生成器（如Snowflake算法）来生成全局唯一的自增ID。 UUID优化 使用UUID作为辅助索引：在需要全局唯一性的场景中，可以使用UUID作为辅助索引，而不是主键。 UUID的顺序化处理：在生成UUID时，可以考虑使用顺序UUID（如UUID v1），以减少B+树的稀疏性。 最左匹配原则最左匹配原则是联合索引的核心特性之一，它规定了在查询中如何利用联合索引。具体来说，最左匹配原则要求查询条件必须从联合索引的最左边的字段开始匹配，才能有效利用该索引。 详细解释联合索引在物理存储特性分类上归于聚簇索引或非聚簇索引，具体取决于数据库的实现。对于非聚簇索引，存储的数据通常是对应记录的主键或其他唯一标识符，因此可能需要执行回表操作来获取完整的数据。 假设我们有一个联合索引，基于字段A、B和C创建。在往联合索引表新增索引数据时，首先会根据字段A进行排序，然后在A的基础上根据字段B进行排序，依此类推。总结来说，字段B、C是全局无序的，仅相对于上一个索引字段局部有序。 完全匹配：查询条件包含所有索引字段，如WHERE A = &#39;value1&#39; AND B = &#39;value2&#39; AND C = &#39;value3&#39;。这种情况下，查询可以直接利用联合索引进行快速查找。 部分匹配：查询条件包含部分索引字段，但必须从最左边的字段开始，如WHERE A = &#39;value1&#39; AND B = &#39;value2&#39;。这种情况下，查询可以利用索引的前两个字段进行查找。 单字段匹配：查询条件只包含最左边的字段，如WHERE A = &#39;value1&#39;。这种情况下，查询可以利用索引的第一个字段进行查找。 无法利用索引的情况以下几种查询条件无法利用联合索引： 跳过字段：查询条件跳过了最左边的字段，如WHERE B = &#39;value2&#39; AND C = &#39;value3&#39;。这种情况下，查询无法利用联合索引，因为索引的构建顺序是从字段A开始的。 范围查询：在联合索引中，范围查询（如&gt;、&lt;、BETWEEN等）可能会导致后续字段的索引失效。例如，如果查询条件是WHERE A &gt; &#39;value1&#39; AND B = &#39;value2&#39;，那么字段B的索引可能无法被有效利用，因为数据库引擎需要扫描所有满足 A &gt; &#39;value1&#39; 的记录。 函数操作：对索引字段进行函数操作（如LOWER(column)）会导致索引失效，因为数据库无法直接使用索引进行比较。 在实际应用中，理解和遵循最左匹配原则对于优化查询性能至关重要。通过合理设计和使用联合索引，可以显著提高查询效率，减少数据库的I&#x2F;O操作。例如，在设计联合索引时，应优先选择区分度高的字段作为索引的前缀，以确保索引的高效利用。 总之，最左匹配原则是联合索引的核心，理解并遵循这一原则可以帮助我们更好地设计和优化数据库索引，从而提升系统的整体性能。 索引失效 不满足最左匹配原则：联合索引（Composite Index）是按照索引字段的顺序进行排序的。如果查询条件不从最左边的索引字段开始匹配，数据库优化器无法利用索引的有序性，导致索引失效。 使用函数或计算公式：在查询条件中对索引字段使用函数或计算公式会导致索引失效，因为数据库无法直接利用索引的有序性。 类型转换：查询条件中的数据类型与索引字段的数据类型不匹配，导致隐式类型转换，索引可能失效。隐式类型转换本质上也是一种函数操作。 使用 OR 条件：在某些数据库中，使用 OR 条件可能会导致索引失效，因为数据库优化器可能无法同时利用多个索引。 范围查询：范围查询（如 &gt;、&lt;、BETWEEN）可能会导致索引失效，尤其是当范围查询在联合索引的中间字段时。 索引下推索引下推（Index Condition Pushdown, ICP）的核心思想是在索引扫描阶段就应用部分查询条件，从而减少从表中读取数据的次数。为了在不读取数据的情况下知道条件是否符合，ICP 利用了索引的结构和特性。 索引的结构索引通常是按照索引字段的顺序存储的，并且每个索引条目通常包含索引字段的值和指向对应数据行的指针（如主键或行标识符）。对于复合索引，索引条目会按照索引字段的顺序进行排序。 ICP 的工作原理 索引扫描： 数据库引擎首先使用索引查找满足索引条件的记录。例如，对于复合索引 (customer_id, order_date)，引擎会查找所有 customer_id = 123 的记录。 应用部分查询条件： 在索引扫描阶段，数据库引擎会应用部分查询条件（非索引条件）。例如，对于查询 WHERE customer_id = 123 AND order_date &gt; &#39;2023-01-01&#39;，引擎会在索引扫描阶段就应用 order_date &gt; &#39;2023-01-01&#39; 的条件。 过滤索引条目： 由于索引是按照索引字段的顺序存储的，引擎可以在索引扫描阶段直接比较 order_date 的值，而不需要回表读取完整的数据行。如果 order_date 不满足条件，引擎可以直接跳过该索引条目，从而减少回表操作。 示例假设有一个表 orders，其中有一个复合索引 (customer_id, order_date)，并且执行以下查询： 没有 ICP 的情况： 使用索引查找所有 customer_id = 123 的记录。 根据这些记录的主键回表读取完整的数据行。 在读取完整数据行后，应用 order_date &gt; &#39;2023-01-01&#39; 的条件来过滤数据。 启用 ICP 的情况： 在索引扫描阶段，数据库引擎查找所有 customer_id = 123 的记录。 在查找过程中，引擎直接比较 order_date 的值，如果 order_date 不满足 order_date &gt; &#39;2023-01-01&#39; 的条件，引擎可以直接跳过该索引条目。 只有满足 customer_id = 123 且 order_date &gt; &#39;2023-01-01&#39; 的记录才会被回表读取。 总结通过在索引扫描阶段就应用部分查询条件，ICP 可以减少从表中读取数据的次数，从而提高查询性能。ICP 利用了索引的结构和特性，在索引扫描阶段直接比较索引字段的值，从而在不读取数据的情况下知道条件是否符合。这种优化技术特别适用于复合索引和范围查询，能够显著减少不必要的回表操作。 索引下推和最左匹配原则最左匹配原则只能按照从左到右一个个索引的匹配顺序进行索引查询，若只实现了部分索引查询，剩下的索引条件则全部失效，最后会扫描并查找所有符合部分索引的查询； 而索引下推则在扫描索引阶段应用所有索引条件，无需满足最左匹配原则，若不满足索引条件则直接扫描下一条索引记录。 区别 匹配顺序： 最左匹配原则要求查询条件从最左边的索引字段开始匹配，确保索引能够被有效利用。 索引下推（ICP）则允许在索引扫描阶段就应用部分查询条件，无需满足最左匹配原则。 应用阶段： 最左匹配原则主要关注查询条件的匹配顺序，确保查询条件从最左边的索引字段开始匹配。 索引下推（ICP）则关注在索引扫描阶段就应用部分查询条件，减少回表操作。 联系 联合索引的利用：最左匹配原则和 ICP 都依赖于联合索引的结构。最左匹配原则要求查询条件从最左边的索引字段开始匹配，而 ICP 则利用联合索引的有序性在索引扫描阶段应用部分查询条件。 提高查询性能：最左匹配原则和 ICP 都可以提高查询性能。最左匹配原则通过确保查询条件从最左边的索引字段开始匹配，使得数据库能够有效利用索引的有序性。ICP 则通过在索引扫描阶段就应用部分查询条件，减少回表操作，从而提高查询性能。 回表与覆盖索引回表根据索引的物理存储特性，索引可以分为聚簇索引和非聚簇索引。 聚簇索引：在B+树中存放的是一条完整的记录行，即索引和记录是放在一起的。因此，通过聚簇索引可以直接获取到完整的记录数据。 非聚簇索引：存放的是索引值和对应记录的聚簇索引地址。当通过非聚簇索引查找记录时，只能拿到指向对应记录的索引地址，然后需要根据这个地址再次查找聚簇索引，最终返回数据表中的完整记录。这个从非聚簇索引查找到聚簇索引后再次返回数据表进行查询的过程称为回表。 覆盖索引在使用非聚簇索引时，如果查询所需的所有数据都包含在非聚簇索引的记录中，那么就不需要进行回表操作，直接返回结果。这种情况称为覆盖索引。 覆盖索引的优势 减少I&#x2F;O操作：由于不需要回表，减少了额外的磁盘I&#x2F;O操作，提高了查询效率。 简化查询过程：查询可以直接从索引中获取所需数据，简化了查询过程。 实现覆盖索引的条件 查询字段包含在索引中：查询所需的所有字段都必须是索引的一部分。 避免回表：确保查询结果可以直接从索引中获取，而不需要额外的回表操作。 示例假设有一个表orders，包含字段order_id、customer_id和order_date，并且有一个联合索引(order_id, customer_id)。 非覆盖索引查询：SELECT * FROM orders WHERE order_id = 123。由于查询需要所有字段，而索引只包含order_id和customer_id，因此需要回表。 覆盖索引查询：SELECT order_id, customer_id FROM orders WHERE order_id = 123。由于查询的字段都包含在索引中，因此不需要回表，直接从索引中返回结果。 "},{"title":"MySQL-SQL基础","date":"2024-09-14T21:20:00.000Z","url":"/2024/09/15/MySQL-SQL%E5%9F%BA%E7%A1%80/","tags":[["MySQL基础","/tags/MySQL%E5%9F%BA%E7%A1%80/"]],"categories":[["MySQL","/categories/MySQL/"]],"content":"在数据库管理中，SQL（Structured Query Language）是操作关系型数据库的核心工具。本文将深入探讨MySQL中的SQL基础知识，从数据库类型选择、设计范式、连接查询、数据插入、字符串类型、外键约束、关键字使用、内置函数、查询执行顺序、请求执行过程到存储引擎等多个方面进行详细解析。 SQL与NoSQL数据库概述SQL数据库SQL（Structured Query Language）代表关系型数据库管理系统（RDBMS），常见的代表包括SQL Server、Oracle、MySQL和PostgreSQL。关系型数据库以结构化方式存储数据，数据逻辑通过二维表（即行和列）来表示。每一列代表数据的属性，每一行则代表一个数据实体。 NoSQL数据库NoSQL（Not Only SQL）代表非关系型数据库，主要代表有MongoDB和Redis。NoSQL数据库不使用传统的二维表结构，而是采用如JSON文档、键值对、列族、图等多种数据模型来存储数据。 选择数据库的考量因素ACID与BASE关系型数据库通常支持ACID特性（原子性、一致性、隔离性、持久性），确保数据的强一致性和事务的完整性。而NoSQL数据库通常采用BASE模型（基本可用性、软状态、最终一致性），提供更高的灵活性和可扩展性，但可能在一致性方面有所妥协。 选择数据库时需根据具体应用场景来决定。例如，银行系统需要严格遵守ACID特性以防止资金重复使用，而社交软件则可以容忍一定程度的延迟和数据不一致。 扩展性NoSQL数据库由于其非关系型数据结构，数据之间通常不存在强关联，因此更容易实现水平扩展。例如，Redis提供了主从复制、哨兵模式和切片集群等扩展机制。 相比之下，SQL数据库中的数据可能存在复杂的关联关系，扩展时需要解决分布式事务等复杂问题。 数据库设计三大范式第一范式（1NF）第一范式要求数据库表中的每一列都必须是不可再分的原子项。这意味着每一列中的数据项必须是单一的、不可分割的值。 举例说明假设有一张表存储用户信息，其中包含“联系方式”列，该列包含电话和电子邮件。为了满足1NF，应将“联系方式”拆分为“电话”和“电子邮件”两列。 不满足1NF的表结构 用户ID 用户名 联系方式 1 张三 123-4567,&#122;&#x68;&#97;&#110;&#x67;&#x73;&#x61;&#x6e;&#x40;&#101;&#120;&#97;&#x6d;&#x70;&#x6c;&#101;&#x2e;&#x63;&#111;&#109; 2 李四 890-1234,&#x6c;&#105;&#x73;&#105;&#x40;&#x65;&#x78;&#97;&#x6d;&#x70;&#108;&#x65;&#46;&#99;&#x6f;&#109; 满足1NF的表结构 用户ID 用户名 电话 电子邮件 1 张三 123-4567 &#122;&#x68;&#97;&#x6e;&#103;&#115;&#x61;&#110;&#64;&#x65;&#120;&#x61;&#x6d;&#x70;&#108;&#101;&#46;&#99;&#111;&#109; 2 李四 890-1234 &#x6c;&#105;&#x73;&#105;&#x40;&#x65;&#x78;&#97;&#109;&#112;&#x6c;&#x65;&#x2e;&#x63;&#x6f;&#x6d; 第二范式（2NF）第二范式在满足1NF的基础上，要求非主属性必须完全依赖于候选码（即主键）。换句话说，非主属性不能部分依赖于主键的一部分。 举例说明假设有一张订单表，主键为“订单ID”和“产品ID”。如果表中有一列“产品名称”，它只依赖于“产品ID”，而不依赖于“订单ID”，则该表不满足2NF。应将“产品名称”移到另一张产品表中。 不满足2NF的表结构 订单ID 产品ID 产品名称 数量 1 101 苹果 5 2 102 香蕉 3 3 101 苹果 2 满足2NF的表结构订单表 订单ID 产品ID 数量 1 101 5 2 102 3 3 101 2 产品表 产品ID 产品名称 101 苹果 102 香蕉 第三范式（3NF）第三范式在满足2NF的基础上，要求非主属性不依赖于其他的非主属性（即消除传递依赖）。 举例说明假设有一张员工表，包含“员工ID”、“员工姓名”、“部门ID”和“部门名称”。如果“部门名称”依赖于“部门ID”，而“部门ID”依赖于“员工ID”，则存在传递依赖，不满足3NF。应将“部门名称”移到另一张部门表中。 不满足3NF的表结构 员工ID 员工姓名 部门ID 部门名称 1 张三 D01 研发部 2 李四 D02 销售部 3 王五 D01 研发部 满足3NF的表结构员工表 员工ID 员工姓名 部门ID 1 张三 D01 2 李四 D02 3 王五 D01 部门表 部门ID 部门名称 D01 研发部 D02 销售部 数据库连接查询在数据库查询中，连接（Join）操作用于将两个或多个表中的数据组合在一起。常见的连接类型包括内连接、左外连接、右外连接和全外连接。以下是每种连接类型的详细说明及其SQL语法示例。 1. 内连接（Inner Join）内连接返回两个表中具有匹配关系的行。只有当两个表中的记录在连接条件上匹配时，才会返回结果。 示例解释 假设有两个表：Orders（订单表）和Customers（客户表），我们希望查询所有有订单的客户信息。 2. 左外连接（Left Outer Join）左外连接返回左表中的所有行，即使右表中没有匹配的行。对于右表中没有匹配的行，结果集中对应的数据为NULL。 示例解释 假设我们希望查询所有客户及其订单信息，包括那些没有订单的客户。 3. 右外连接（Right Outer Join）右外连接与左外连接相似，返回右表中的所有行，即使左表中没有匹配的行。对于左表中没有匹配的行，结果集中对应的数据为NULL。 示例解释 假设我们希望查询所有订单及其对应的客户信息，包括那些没有客户的订单。 4. 全外连接（Full Outer Join）全外连接返回两个表中的所有行，包括那些在另一个表中没有匹配的行。对于没有匹配的行，结果集中对应的数据为NULL。 示例解释 假设我们希望查询所有客户和订单的信息，包括那些没有订单的客户和没有客户的订单。 MySQL如何避免插入重复数据在MySQL中，有多种方法可以避免插入重复数据。以下是三种常见的方法及其详细说明。 方式一：使用UNIQUE约束UNIQUE约束用于确保表中某一列或一组列的值是唯一的。如果在插入数据时违反了UNIQUE约束，MySQL将拒绝插入该数据。 创建表时添加UNIQUE约束 如果尝试插入重复的email，MySQL将返回错误。 方式二：使用 INSERT ... ON DUPLICATE KEY UPDATEINSERT ... ON DUPLICATE KEY UPDATE语句在插入数据时，如果遇到重复键值（如UNIQUE约束或PRIMARY KEY），可以选择更新原有记录为新插入的记录。 插入或更新数据 如果product_id为1的记录已经存在，则更新其product_name和price字段。 方式三：使用 INSERT IGNOREINSERT IGNORE语句在插入数据时，如果遇到重复键值（如UNIQUE约束或PRIMARY KEY），将忽略该插入操作，不会抛出错误。 如果customer_id为1的记录已经存在，则忽略该插入操作，不会抛出错误。 MySQL中的字符串类型在MySQL中，字符串类型用于存储文本数据。常见的字符串类型包括CHAR、VARCHAR和TEXT。每种类型都有其特定的用途和存储特性。 CHARCHAR是一种固定长度的字符串类型。在定义时需要指定长度，存储时会在末尾填充空格以达到指定的长度。 特点 固定长度：无论实际存储的字符串长度如何，都会占用指定长度的存储空间。 存储效率：对于长度固定的字符串（如国家代码、性别等），CHAR类型可以提高存储效率。 VARCHARVARCHAR是一种可变长度的字符串类型。在定义时需要指定最大长度，存储时根据实际长度占用存储空间。 特点 可变长度：实际存储的字符串长度决定了占用的存储空间，节省存储空间。 灵活性：适用于长度不固定的字符串（如用户名、地址等）。 TEXTTEXT用于存储超长文本数据。TEXT类型有多种子类型，包括TEXT、MEDIUMTEXT和LONGTEXT，分别用于存储不同大小的文本。 特点 大容量存储：适用于存储大段文本（如文章内容、日志等）。 存储限制： TEXT：最大存储65,535字节（约64KB）。 MEDIUMTEXT：最大存储16,777,215字节（约16MB）。 LONGTEXT：最大存储4,294,967,295字节（约4GB）。 **CHAR**：适用于固定长度的字符串，存储效率高。 **VARCHAR**：适用于长度不固定的字符串，节省存储空间。 **TEXT**：适用于存储超长文本，有多种子类型满足不同存储需求。 根据具体需求选择合适的字符串类型，可以优化数据库的存储和查询性能。 外键约束外键约束（Foreign Key Constraint）是关系型数据库中用于维护表与表之间关系的一种机制。它确保数据的完整性和一致性，防止在关联表中插入无效数据。 作用 维护数据完整性：外键约束确保在子表中插入或更新的记录在父表中存在对应的记录。如果父表中不存在对应的记录，数据库将拒绝插入或更新操作。 防止无效数据：外键约束防止在子表中插入或更新无效数据，从而保持数据的正确性和一致性。 级联操作：外键约束可以配置级联操作，如级联删除（CASCADE DELETE）或级联更新（CASCADE UPDATE），以确保在父表中的记录被删除或更新时，子表中的相关记录也相应地被删除或更新。 假设有两个表：Orders（订单表）和Customers（客户表），我们希望在Orders表中定义一个外键约束，确保每个订单都关联到一个有效的客户。 MySQL关键字：IN 和 EXISTS在MySQL中，IN和EXISTS是两个常用的关键字，用于在查询中进行条件判断。它们各自有不同的用途和特点。 IN 关键字IN关键字用于检查左边的表达式是否存在于右边的列表或子查询中。如果存在，则返回true，否则返回false。 假设我们有一个Orders表，我们希望查询所有订单ID为1、2或3的订单。 或者使用子查询： EXISTS 关键字EXISTS关键字用于检查子查询是否至少返回一行数据。它不关心子查询返回的具体数据，只关注是否有返回数据。如果有返回数据，则返回true，否则返回false。 假设我们有一个Customers表和一个Orders表，我们希望查询所有有订单的客户。 区别与适用场景IN 适用场景 简单列表匹配：当需要检查某个值是否存在于一个固定的列表中时，IN非常适用。 子查询结果匹配：当需要检查某个值是否存在于子查询的结果集中时，IN也很适用。 EXISTS 适用场景 存在性检查：当只需要检查是否存在满足条件的记录，而不关心具体返回的数据时，EXISTS非常适用。 性能优化：在某些情况下，EXISTS的性能可能优于IN，特别是在子查询返回大量数据时。 MySQL基本函数MySQL提供了丰富的内置函数，用于处理字符串、数值、日期和聚合数据。以下是一些常用的MySQL函数及其说明。 字符串函数CONCAT(str1, str2, ...)连接多个字符串，返回拼接结果。 LENGTH(str)返回字符串的长度（字符数）。 SUBSTRING(str, start, length)从指定位置开始，截取指定长度的字符串。 REPLACE(str, from_str, to_str)将字符串中的指定字符替换为另一个字符。 数值函数ABS(num)返回数值的绝对值。 POWER(num, n)返回数值的n次幂。 日期函数NOW()返回当前日期和时间。 CURDATE()返回当前日期。 聚合函数COUNT(column)计算指定列中的非NULL值的个数。 SUM(column)计算指定列的总和。 AVG(column)计算指定列的平均值。 MAX(column)返回指定列的最大值。 MIN(column)返回指定列的最小值。 SQL查询执行顺序所有的查询语句都是从FROM开始执行，在执行过程中，每个步骤都会生成一个虚拟表，这个虚拟表将作为下一个执行步骤的输入，最后一个步骤产生的虚拟表即为输出结果。执行顺序如下： sql查询语句执行顺序注释： SQL请求执行过程详解 连接管理 连接器：客户端通过连接器与MySQL服务器建立连接。连接器负责验证客户端的身份和权限，并维护连接状态。 查询缓存 缓存查询：在MySQL 5.7及之前版本中，查询缓存功能默认关闭，而在MySQL 8.0中已被移除。如果查询缓存功能开启且命中缓存，服务器将直接返回缓存结果，从而提高查询效率。 语法解析 解析器：解析器负责对SQL语句进行词法和语法分析。词法分析确保SQL语句中的关键词和标识符正确无误，语法分析则验证SQL语句的结构是否符合语法规则。解析完成后，生成一棵语法树（AST）。 预处理 预处理阶段：预处理器对语法树进行进一步处理，检查表和字段是否存在，并验证SQL语句的语义正确性。此阶段还会处理SQL语句中的占位符，确保查询的完整性和一致性。 查询优化 优化器：优化器是SQL执行过程中的核心组件，负责选择最优的执行计划。优化器会评估多种可能的执行路径，并根据成本模型选择查询成本最小的执行计划。优化过程包括但不限于索引选择、表连接顺序优化、子查询优化等。 执行引擎 执行阶段：执行引擎根据优化器生成的执行计划，从存储引擎中读取数据。执行过程中，数据可能被缓存以提高后续查询的效率。最终，执行引擎将结果集返回给客户端。 MySQL存储引擎InnoDB 默认引擎：InnoDB是MySQL的默认存储引擎，适用于高并发场景。 事务支持：提供ACID（原子性、一致性、隔离性、持久性）事务特性，确保数据的一致性和完整性。 锁机制：支持行级锁，减少锁冲突，提高并发性能。 外键约束：支持外键约束，确保表之间的数据完整性。 MyISAM 存储优化：MyISAM具有较低的存储和内存消耗，适用于大量读操作的场景。 性能特点：不支持事务，没有行级锁和外键约束，因此在高并发写操作场景下性能较差。 适用场景：适合读密集型应用，如数据仓库、日志记录等。 Memory 内存存储：Memory引擎将数据存储在内存中，适用于需要快速读取的场景。 性能优势：由于数据存储在内存中，读取速度极快，适合临时数据存储和高频读取操作。 数据持久性：不支持事务、行级锁和外键索引。数据在服务器重启或崩溃时会丢失，因此不适合需要持久化的数据存储。 通过选择合适的存储引擎，可以根据应用的具体需求优化数据库性能和数据管理策略。InnoDB适用于需要高并发和事务支持的场景，MyISAM适合读密集型应用，而Memory引擎则适用于需要快速读取的临时数据存储。 数据文件在MySQL中，我们可以创建一个测试数据库test_db和一张测试表test_order。在数据库的存储路径下，可以看到以下三个文件： db.opt：该文件记录了当前数据库的默认字符集和校验规则。 test_order.frm：此文件存储了表的结构信息，包括字段定义、索引等，主要用于描述表的结构。 test_order.idb：所有的元数据和实际数据都存储在这个文件中，包括表的数据、索引等。 联合索引联合索引是由多个字段共同组成的索引。例如，索引可以基于字段A、B和C创建。联合索引的构建遵循最左匹配原则，即首先按照联合索引中的第一个字段进行分组排序，然后在此基础上按第二个字段分组排序，依此类推。 最左匹配原则最左匹配原则意味着查询必须从联合索引的最左边的字段开始匹配。例如，如果联合索引是基于字段A、B和C创建的，那么查询条件中必须包含字段A，才能利用该索引。如果查询条件只包含字段B和C，则无法利用该联合索引，因为往后的索引是全局无序的，而只是相对上一个字段局部有序。 索引区分度的重要性在构建联合索引时，优先选择区分度高的字段作为前缀。区分度的计算公式为：区分度 = (不同值的数量) / (总记录数)。区分度越高，索引的选择性越好，查询效率也越高。例如，使用性别作为联合索引的首个字段，由于其区分度极低（接近于0），即使通过索引找到了结果，由于是非聚簇索引，仍需执行回表操作，增加IO次数，因此不建议使用。 索引失效的情况从索引的物理存储特性来看，以下行为可能导致索引失效： 模糊查询：使用通配符开头的模糊查询（如LIKE &#39;%keyword&#39;）通常会导致索引失效，因为数据库无法利用索引来快速定位匹配的记录。 范围查询：在联合索引中，范围查询（如&gt;、&lt;、BETWEEN等）可能会导致后续字段的索引失效。例如，如果查询条件是A &gt; 10 AND B = 5，那么字段B的索引可能无法被有效利用。 函数操作：对索引字段进行函数操作（如LOWER(column)）会导致索引失效，因为数据库无法直接使用索引进行比较。 通过合理设计和使用联合索引，可以显著提高查询性能，减少数据库的I&#x2F;O操作。"},{"title":"Java并发编程-线程池篇","date":"2024-09-10T00:08:10.000Z","url":"/2024/09/10/Java%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B-%E7%BA%BF%E7%A8%8B%E6%B1%A0%E7%AF%87/","tags":[["线程池","/tags/%E7%BA%BF%E7%A8%8B%E6%B1%A0/"]],"categories":[["Java","/categories/Java/"],["并发编程","/categories/Java/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"]],"content":"Java 提供了强大的并发编程工具，其中线程池（ThreadPool）是管理和复用线程的核心机制。本文将深入探讨 Java 线程池的工作原理、核心组件、创建参数及其在实际应用中的使用场景。 线程池原理线程池是为了减少频繁创建和销毁线程带来的损耗，通过复用线程来提高系统的性能和稳定性。线程池的工作原理如下： 线程池的组成部分线程池主要由以下几个部分组成： 核心线程池：线程池中保持活跃的线程数量，即使这些线程处于空闲状态也不会被销毁。 线程池容量：线程池中允许的最大线程数量。 等待任务队列：当线程池中的线程都在执行任务时，新提交的任务会被放入等待任务队列中。 线程池的创建参数详解在 Java 中，ThreadPoolExecutor 是创建线程池的主要类。它提供了多个构造函数，其中最常用的是包含七个可选参数的构造函数。这些参数用于配置线程池的行为和特性。 以下是 ThreadPoolExecutor 构造函数的七个可选参数及其详细说明： 1. corePoolSize 类型：int 描述：核心线程池大小，即线程池中保持活跃的线程数量。即使这些线程处于空闲状态也不会被销毁。 默认值：无默认值，必须指定。 2. maximumPoolSize 类型：int 描述：线程池中允许的最大线程数量。当等待任务队列已满且核心线程池已满时，线程池会创建新的线程，直到达到最大线程数量。 默认值：无默认值，必须指定。 3. keepAliveTime 类型：long 描述：线程空闲时间，即当线程池中的线程数量超过核心线程池大小时，空闲线程在等待新任务的时间超过 keepAliveTime 后会被销毁。 默认值：无默认值，必须指定。 4. unit 类型：TimeUnit 描述：keepAliveTime 的时间单位，如秒、毫秒等。 默认值：无默认值，必须指定。 5. workQueue 类型：BlockingQueue&lt;Runnable&gt; 描述：等待任务队列，用于存放等待执行的任务。当线程池中的线程都在执行任务时，新提交的任务会被放入等待任务队列中。 默认值：无默认值，必须指定。 6. threadFactory 类型：ThreadFactory 描述：线程工厂，用于创建新的线程。可以通过自定义线程工厂来设置线程的名称、优先级等属性。 默认值：Executors.defaultThreadFactory()，使用默认的线程工厂。 7. handler 类型：RejectedExecutionHandler 描述：拒绝策略，当线程池容量已满且等待任务队列已满时，线程池会拒绝新提交的任务，并根据拒绝策略处理该任务。 默认值：AbortPolicy，直接抛出 RejectedExecutionException 异常。 以下是一个使用 ThreadPoolExecutor 创建线程池的示例代码： 线程池的工作流程工作流程如下图所示： 提交任务：当一个任务被提交到线程池时，线程池会首先检查核心线程池是否已满。 核心线程池是否已满： 如果核心线程池未满，线程池会创建一个新的线程来执行任务。 如果核心线程池已满，线程池会检查等待任务队列是否已满。 等待任务队列是否已满： 如果等待任务队列未满，线程池会将任务放入等待任务队列中。 如果等待任务队列已满，线程池会检查线程池容量是否已满。 线程池容量是否已满： 如果线程池容量未满，线程池会创建一个新的线程来执行任务。 如果线程池容量已满，线程池会拒绝任务，并根据拒绝策略处理该任务。 线程池的拒绝策略当线程池容量已满且等待任务队列已满时，线程池会拒绝新提交的任务。Java 提供了以下几种预置拒绝策略： AbortPolicy：默认策略，直接抛出 RejectedExecutionException 异常。 CallerRunsPolicy：由提交任务的线程执行该任务。 DiscardPolicy：直接丢弃任务，不抛出异常。 DiscardOldestPolicy：丢弃等待队列中最旧的任务，然后尝试重新提交当前任务。 其他线程池参数设置在设置线程池参数时，需要根据具体的应用场景和任务类型来调整线程池的核心线程数、最大线程数、等待任务队列和拒绝策略等参数。以下是一些常见的线程池参数设置建议。 CPU 密集型任务：对于 CPU 密集型任务，线程池的核心线程数可以设置为 CPU 核数加 1。这样可以确保线程池中的线程数量与 CPU 核心数量相匹配，避免过多的线程竞争 CPU 资源。 IO 密集型任务：对于 IO 密集型任务，线程池的核心线程数可以设置为 CPU 核数的两倍。这样可以确保线程池中有足够的线程来处理 IO 操作，避免线程等待 IO 操作完成时阻塞。 核心线程数可以设置为 0 吗？可以。将核心线程数设置为 0 时，线程池在初始状态下不会创建任何线程。当有任务提交时，任务会先进入等待任务队列。当等待任务队列已满时，线程池才会创建新的线程来执行任务。 线程池的种类在 Java 中，java.util.concurrent 包提供了多种线程池的实现，每种线程池都有其特定的用途和特点。以下是常见的几种线程池及其特点： ScheduledThreadPool ScheduledThreadPool 是一种可以设置定期执行任务的线程池。它允许你安排任务在给定的延迟后执行，或者定期重复执行。 特点 定期执行任务：可以设置任务在给定的延迟后执行，或者定期重复执行。 核心线程数固定：核心线程数和最大线程数相同。 FixedThreadPool FixedThreadPool 是一种核心线程数和最大线程数相同的线程池。它适用于需要固定数量线程来处理任务的场景。 特点 固定线程数：核心线程数和最大线程数相同。 等待任务队列：使用 LinkedBlockingQueue，容量为 Integer.MAX_VALUE。 CachedThreadPool CachedThreadPool 是一种可以成为缓存线程池的线程池。它的任务等待队列为 SynchronousQueue，容量为 0，仅做任务流转，效率很高。它的特点在于线程数可以一直增加，甚至达到 Integer.MAX_VALUE（即 2^31-1）。 特点 动态线程数：线程数可以一直增加，直到达到 Integer.MAX_VALUE。 等待任务队列：使用 SynchronousQueue，容量为 0，仅做任务流转。 SingleThreadExecutor SingleThreadExecutor 是一种只有一个线程的线程池。它适用于需要顺序执行任务的场景。 特点 单线程：只有一个线程，任务按顺序执行。 等待任务队列：使用 LinkedBlockingQueue，容量为 Integer.MAX_VALUE。 SingleThreadScheduledExecutor SingleThreadScheduledExecutor 是一种只有一个线程的线程池，可以设置定期执行任务。 特点 单线程：只有一个线程，任务按顺序执行。 定期执行任务：可以设置任务在给定的延迟后执行，或者定期重复执行。 shutdown 和 shutdownNow 方法详解在 Java 中，ThreadPoolExecutor 提供了两种关闭线程池的方法：shutdown 和 shutdownNow。这两种方法用于优雅地关闭线程池，但它们的行为有所不同。 shutdown 方法shutdown 方法用于优雅地关闭线程池。它会将状态置为SHUTDOWN，拒绝新提交的任务，但会等待当前正在执行的任务和已经在等待队列中的任务完成后再关闭线程池。 以下是 ThreadPoolExecutor 类中 shutdown 方法的源码： 关键步骤 获取锁：获取线程池的主锁 mainLock。 检查权限：调用 checkShutdownAccess() 方法检查是否有权限关闭线程池。 更新状态：调用 advanceRunState(SHUTDOWN) 方法将线程池的状态更新为 SHUTDOWN。 中断空闲线程：调用 interruptIdleWorkers() 方法中断所有空闲的线程。 调用钩子方法：调用 onShutdown() 方法，这是一个钩子方法，用于在关闭线程池时执行一些自定义操作。 释放锁：释放线程池的主锁 mainLock。 尝试终止：调用 tryTerminate() 方法尝试终止线程池。 shutdownNow 方法shutdownNow 方法用于立即关闭线程池。它会立即将线程池的状态设置为 STOP，并尝试中断所有正在执行的任务，同时返回等待队列中尚未执行的任务列表。 shutdownNow 试图通过调用 Thread.interrupt() 方法来终止线程。然而，这种方法的效果有限，如果线程中没有使用 sleep、wait、condition、定时锁等阻塞操作，interrupt() 方法可能无法中断当前的线程。因此，shutdownNow 并不保证线程池能够立即退出，它可能需要等待所有正在执行的任务完成才能真正退出。 以下是 ThreadPoolExecutor 类中 shutdownNow 方法的源码： 关键步骤 获取锁：获取线程池的主锁 mainLock。 检查权限：调用 checkShutdownAccess() 方法检查是否有权限关闭线程池。 更新状态：调用 advanceRunState(STOP) 方法将线程池的状态更新为 STOP。 中断所有线程：调用 interruptWorkers() 方法中断所有线程，包括正在执行任务的线程。 清空等待队列：调用 drainQueue() 方法清空等待队列，并返回尚未执行的任务列表。 释放锁：释放线程池的主锁 mainLock。 尝试终止：调用 tryTerminate() 方法尝试终止线程池。 提交到线程池的任务可以撤回？是的，当向线程池提交任务时，会得到一个 Future 对象。这个 Future 对象提供了几种方法来管理任务的执行，包括取消任务。取消任务的主要方法是 Future 接口中的 cancel(boolean mayInterruptIfRunning) 方法。这个方法尝试取消执行的任务。参数 mayInterruptIfRunning 指示是否允许中断正在执行的任务。 Future 接口Future 接口表示一个异步计算的结果。它提供了以下几个主要方法： **cancel(boolean mayInterruptIfRunning)**：尝试取消任务的执行。 **isCancelled()**：判断任务是否已被取消。 **isDone()**：判断任务是否已完成（包括正常完成、异常完成或被取消）。 **get()**：获取任务的执行结果，如果任务尚未完成，则阻塞等待。 **get(long timeout, TimeUnit unit)**：在指定时间内获取任务的执行结果，如果任务尚未完成，则阻塞等待。 多线程场景示例：按照顺序打印奇偶数在多线程编程中，实现按照顺序打印奇偶数是一个常见的场景。可以通过使用 synchronized 关键字、Lock 接口或 Semaphore 等同步机制来实现线程间的协作。 方法一：使用 synchronized 关键字实现思路 使用 synchronized 关键字同步两个线程的执行。 通过一个共享的变量来控制打印奇数和偶数的顺序。 输出结果 方法二：使用 Lock 接口和 Condition实现思路 使用 ReentrantLock 来实现线程间的同步。 使用 Condition 来控制线程的等待和唤醒。 示例代码 输出结果 方法三：使用 Semaphore实现思路 使用两个 Semaphore 来控制线程的执行顺序。 一个 Semaphore 用于控制奇数线程的执行，另一个 Semaphore 用于控制偶数线程的执行。 示例代码 输出结果 "},{"title":"Java并发编程-并发安全篇","date":"2024-09-10T00:08:09.000Z","url":"/2024/09/10/Java%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B-%E5%B9%B6%E5%8F%91%E5%AE%89%E5%85%A8%E7%AF%87/","tags":[["并发安全","/tags/%E5%B9%B6%E5%8F%91%E5%AE%89%E5%85%A8/"]],"categories":[["Java","/categories/Java/"],["并发编程","/categories/Java/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"]],"content":"Java提供了多种机制来保证线程安全，包括内置锁、显式锁、原子类、线程局部变量和并发集合等。本文将深入探讨Java中的并发安全机制，涵盖线程同步、锁机制、原子操作、线程局部变量以及并发集合等内容。 如何保证多线程安全在 Java 中，保证多线程安全主要有以下几种方式： 1.synchronized 关键字 使用 synchronized 关键字来同步代码块或方法，确保同一时刻只有一个线程能访问这些代码。 优点：简单易用，适用于简单的同步需求。 缺点：可能会导致性能问题，特别是在高并发场景下。可能会导致死锁。 2. volatile 关键字 使用 volatile 关键字，确保所有的线程都能看到该变量的最新值，而不是可能存储在本地寄存器中的副本。 优点：确保变量的可见性，适用于简单的状态标志。 缺点：不能保证复合操作的原子性，如 count++。 3. Lock 接口和 ReentrantLock 类 使用 Lock 接口和 ReentrantLock 类来实现更灵活的锁机制。 优点：提供更灵活的锁机制，支持可中断锁、公平锁等。 缺点：需要手动管理锁的获取和释放，容易出错。 4. 原子类 Java 并发库提供了原子类，这些类提供原子操作，可以用来更新基本数据类型而无需同步。 优点：提供原子操作，无需手动同步。 缺点：仅适用于基本数据类型的原子操作。 5. 线程局部变量 ThreadLocal 可以为每个线程创建独立的副本，这样每个副本都拥有自己的变量，消除竞争条件。 优点：每个线程拥有独立的变量副本，消除竞争条件。 缺点：可能会导致内存泄漏，特别是在线程池中使用时。 6. 并发集合 java.util.concurrent 包中提供了线程安全的集合，已实现线程安全逻辑。 优点：提供线程安全的集合操作，无需手动同步。 缺点：可能会导致性能问题，特别是在高并发场景下。 总结 synchronized 关键字：适用于简单的同步需求，但可能会导致性能问题和死锁。 volatile 关键字：确保变量的可见性，适用于简单的状态标志。 Lock 接口和 ReentrantLock 类：提供更灵活的锁机制，但需要手动管理锁的获取和释放。 原子类：提供原子操作，无需手动同步，但仅适用于基本数据类型的原子操作。 **线程局部变量 ThreadLocal**：每个线程拥有独立的变量副本，消除竞争条件，但可能会导致内存泄漏。 并发集合：提供线程安全的集合操作，无需手动同步，但可能会导致性能问题。 Java 中常用的锁及其使用场景在 Java 中，锁是用于管理多线程并发访问共享资源的关键机制。锁可以确保在任意给定时间内只有一个线程可以访问特定的资源，从而避免数据竞争和不一致性。Java 提供了多种锁机制，以下是常用的锁及其使用场景： 1. 内置锁 (synchronized) synchronized 关键字是 Java 内置的锁机制，可以用于方法或代码块。当一个线程进入 synchronized 代码块或方法时，它会获取关联对象的锁；当线程离开该代码块或方法时，锁会被释放。 优点：简单易用，适用于简单的同步需求。 缺点：可能会导致性能问题，特别是在高并发场景下。可能会导致死锁。 使用场景：适用于简单的同步需求，如单个对象的同步访问。 示例代码： 2. ReentrantLock java.util.concurrent.locks.ReentrantLock 是一个显式的锁类，提供了比 synchronized 更高级的功能，如可中断的锁等待、定时锁等待、公平锁选项等。 优点：提供更灵活的锁机制，支持可中断锁、公平锁等。 缺点：需要手动管理锁的获取和释放，容易出错。 使用场景：适用于需要更高级锁功能的场景，如可中断锁、公平锁等。 示例代码： 3. 读写锁 (ReadWriteLock) java.util.concurrent.locks.ReadWriteLock 接口定义了一种锁，允许多个读取者同时访问共享资源，但只允许一个写入者。 优点：适用于读取远多于写入的场景，提高并发性。 缺点：实现复杂，需要管理读锁和写锁的获取和释放。 使用场景：适用于读取操作远多于写入操作的场景，如缓存系统。 示例代码： 4. 乐观锁和悲观锁 **悲观锁 (Pessimistic Locking)**：在访问数据前就锁定资源，假设最坏的情况即数据很可能被其他线程修改。synchronized 和 ReentrantLock 都是悲观锁的例子。 **乐观锁 (Optimistic Locking)**：通常不锁定资源，而是在更新数据时检查数据是否已被其他线程修改。乐观锁常使用版本号或时间戳来实现。 优点：乐观锁适用于冲突较少的场景，减少锁的开销；悲观锁适用于冲突较多的场景，确保数据一致性。 缺点：乐观锁在冲突较多时性能较差；悲观锁在冲突较少时性能较差。 使用场景： 乐观锁适用于读多写少的场景，如版本控制系统。 悲观锁适用于写操作频繁的场景，如数据库事务。 示例代码： 5. 自旋锁 自旋锁是一种锁机制，线程在等待锁时会持续循环检查锁是否可用，而不是放弃 CPU 并阻塞。通常可以使用 CAS（Compare-And-Swap）来实现。 优点：在锁等待时间很短的情况下可以提高性能。 缺点：过度自旋会浪费 CPU 资源。 使用场景：适用于锁等待时间很短的场景，如轻量级同步。 示例代码： 总结 **内置锁 (synchronized)**：适用于简单的同步需求，但可能会导致性能问题和死锁。 **ReentrantLock**：提供更灵活的锁机制，但需要手动管理锁的获取和释放。 **读写锁 (ReadWriteLock)**：适用于读取操作远多于写入操作的场景，提高并发性。 乐观锁和悲观锁：乐观锁适用于冲突较少的场景，悲观锁适用于冲突较多的场景。 自旋锁：适用于锁等待时间很短的场景，但过度自旋会浪费 CPU 资源。 什么是可重入锁可重入锁（Reentrant Lock）是指同一个线程在获取了锁之后，可以再次重复获取该锁而不会造成死锁或其他问题。当一个线程持有锁时，如果再次尝试获取该锁，就会成功获取而不会被阻塞。 可重入锁的工作原理ReentrantLock 实现可重入锁的机制是基于线程持有锁的计数器。具体工作原理如下： 计数器初始化：当一个线程第一次获取锁时，计数器会加 1，表示该线程持有了锁。 重复获取锁：在此之后，如果同一个线程再次获取锁，计数器会再次加 1。每次线程成功获取锁时，都会将计数器加 1。 释放锁：当线程释放锁时，计数器会相应地减 1。只有当计数器减到 0 时，锁才会完全释放，其他线程才有机会获取锁。 避免死锁：这种计数器的设计使得同一个线程可以多次获取同一个锁，而不会造成死锁或其他问题。每次获取锁时计数器加 1；每次释放锁时，计数器减 1。只有当计数器减到 0 时，锁才会完全释放。 synchronized 和 ReentrantLock 的区别synchronized 工作原理synchronized 是 Java 提供的原子性内置锁，这种内置的并且使用者看不到的锁也被称为监视器锁。使用 synchronized 之后，会在编译之后在同步的代码块前后加上 monitorenter 和 monitorexit 字节码指令，它依赖操作系统底层互斥锁实现。它的作用主要就是实现原子性操作和解决共享变量的内存可见性问题。 工作原理： 执行 monitorenter 指令时会尝试获取对象锁，如果对象没有被锁定或者已经获得了锁，锁的计数器 +1。此时其他竞争锁的线程则会进入等待队列中。 执行 monitorexit 指令时则会把计数器 -1，当计数器值为 0 时锁释放，处于等待队列中的线程再继续竞争锁。 特点： synchronized 是排它锁，当一个线程获得锁之后，其他线程必须等待该线程释放锁后才能获得锁。 由于 Java 中的线程和操作系统原生线程是一一对应的，线程被阻塞或者唤醒时会从用户态切换到内核态，这种转换非常消耗性能。 从内存语义来说，加锁的过程会清除工作内存中的共享变量，再从主内存读取，而释放锁的过程则是将工作内存中的共享变量写回主内存。 ReentrantLock 工作原理ReentrantLock 的底层实现主要依赖于 AbstractQueuedSynchronizer (AQS) 这个抽象类。AQS 是一个提供了基本同步机制的框架，其中包括了队列、状态值等。 工作原理： ReentrantLock 在 AQS 的基础上通过内部类 Sync 来实现具体的锁操作。不同的 Sync 子类实现了公平锁和非公平锁的不同逻辑。 ReentrantLock 提供了更灵活的锁机制，支持可中断的锁等待、定时锁等待、公平锁选项等。 特点： 可见性：ReentrantLock 通过 volatile 变量来保证锁状态的可见性。 设置超时时间：ReentrantLock 支持在获取锁时设置超时时间，避免无限等待。 公平锁和非公平锁：ReentrantLock 提供了公平锁和非公平锁的选项，公平锁按照线程请求锁的顺序来分配锁，非公平锁不保证锁分配的顺序。 多个条件变量：ReentrantLock 支持多个条件变量，可以更细粒度地控制线程的等待和唤醒。 可重入性：ReentrantLock 支持可重入性，即同一个线程可以多次获取同一个锁。 区别synchronized 和 ReentrantLock 都是 Java 中提供的可重入锁，但它们在用法、获取和释放锁的方式、锁类型、响应中断以及底层实现等方面存在显著差异。 1.用法不同 **synchronized**：可以用来修饰普通方法、静态方法和代码块。 **ReentrantLock**：只能用在代码块中。 2.获取锁和释放锁方式不同 **synchronized**：会自动加锁和释放锁。当进入 synchronized 修饰的代码块之后会自动加锁，当离开 synchronized 的代码段之后会自动释放锁。 **ReentrantLock**：需要手动加锁和释放锁。通过 lock() 方法获取锁，通过 unlock() 方法释放锁。 3.锁类型不同 **synchronized**：属于非公平锁。 **ReentrantLock**：既可以是公平锁也可以是非公平锁。通过构造函数可以指定锁的类型。 4.响应中断不同 **ReentrantLock**：可以响应中断，解决死锁的问题。通过 lockInterruptibly() 方法可以实现可中断的锁等待。 **synchronized**：不能响应中断。 5.底层实现不同 **synchronized**：是 JVM 层面通过监视器（Monitor）实现的。在编译后的字节码中会生成 monitorenter 和 monitorexit 指令。 **ReentrantLock**：是基于 AQS（AbstractQueuedSynchronizer）实现的。AQS 是一个提供了基本同步机制的框架，其中包括了队列、状态值等。 总结 **synchronized**：适用于简单的同步需求，自动获取和释放锁，但可能导致性能问题和死锁。 **ReentrantLock**：提供更灵活的锁机制，支持可中断锁、公平锁、超时设置等，但需要手动管理锁的获取和释放。 synchronized 锁升级过程synchronized 锁在 Java 中的升级过程是一个逐步优化的过程，从无锁状态到偏向锁、轻量级锁，最终升级为重量级锁。这个过程旨在根据不同的竞争情况，动态调整锁的实现方式，以提高性能。 锁升级过程1. 无锁状态 描述：这是还没有开启偏向锁时的状态。JVM 启动后会有一个偏向延时，延迟一段时间后才会开启偏向锁。 特点：无锁状态下，对象的 Mark Word 中存储的是对象的哈希码和分代年龄等信息。 2. 偏向锁 描述：偏向锁开启后的锁状态。如果无线程拿到该锁，这个状态叫匿名偏向。当一个线程想要竞争该锁时，只需要拿线程 ID 和 Mark Word 中存储的线程 ID 比较，如果线程 ID 相同则直接获取锁（即锁偏向于这个线程），不需要进行 CAS 操作和将线程挂起。 特点：偏向锁减少了无竞争情况下的锁开销，适用于单线程访问的场景。 3. 轻量级锁 描述：在这个状态下，线程主要通过 CAS（Compare-And-Swap）操作实现。将对象的 Mark Word 存储到线程的虚拟栈上，然后将对象的 Mark Word 更新为指向线程栈中锁记录的指针。 特点：轻量级锁适用于竞争不激烈的场景，通过 CAS 操作避免了线程挂起和唤醒的开销。 4. 重量级锁 描述：当两个以上的线程获取锁时，轻量级锁就会升级为重量级锁。因为 CAS 操作如果没有成功的话，线程会自旋等待，进行 while 循环操作，非常消耗 CPU 资源。 特点：重量级锁通过操作系统底层的互斥锁实现，适用于高并发竞争场景。 锁升级的触发条件 无锁到偏向锁：JVM 启动后经过偏向延时，默认情况下偏向锁是开启的。 偏向锁到轻量级锁：当有其他线程尝试获取偏向锁时，偏向锁会升级为轻量级锁。 轻量级锁到重量级锁：当多个线程竞争同一个锁时，轻量级锁会升级为重量级锁。 synchronized 锁的升级过程是一个动态优化的过程，从无锁状态到偏向锁、轻量级锁，最终升级为重量级锁。这个过程根据不同的竞争情况，动态调整锁的实现方式，以提高性能。 总结 无锁状态：JVM 启动后经过偏向延时，默认情况下偏向锁是开启的。 偏向锁：减少了无竞争情况下的锁开销，适用于单线程访问的场景。 轻量级锁：通过 CAS 操作避免了线程挂起和唤醒的开销，适用于竞争不激烈的场景。 重量级锁：通过操作系统底层的互斥锁实现，适用于高并发竞争场景。 AQSAbstractQueuedSynchronizer（简称 AQS）是 Java 中的一个抽象类，是用于构建锁、同步器、协作工具类的工具类（框架）。AQS 提供了一个基于 FIFO 队列的阻塞锁和相关的同步器（如信号量、事件等）的框架，是 Java 并发包（java.util.concurrent）的基础。 AQS 的核心思想AQS 的核心思想是，如果当前请求的资源空闲，那么就将当前请求资源的线程设置为有效工作线程，将共享资源锁定；如果资源被占用，就需要一定的等待阻塞唤醒机制来保证锁的分配。这个机制主要用的是 CLH 队列变体实现的，将暂时获取不到锁的线程加入到队列中。 CLH 队列CLH（Craig, Landin, and Hagersten）队列是一种基于链表的自旋锁队列。AQS 使用 CLH 队列的变体来管理等待线程的队列。 AQS 的核心组成部分AQS 最核心的就是三大部分： 状态（State）： AQS 使用一个 volatile 的 int 类型的成员变量 state 来表示同步状态。state 的值可以表示锁的状态、信号量的计数等。 通过 getState()、setState() 和 compareAndSetState() 方法来操作 state 的值。 FIFO 队列： AQS 内置了一个 FIFO 队列来管理等待线程。当线程获取锁失败时，会被加入到这个队列中等待。 队列中的每个节点代表一个等待线程，节点之间通过 prev 和 next 指针连接。 获取&#x2F;释放操作（重写）： AQS 定义了获取和释放资源的方法，但具体的实现需要子类去重写。 子类需要实现 tryAcquire()、tryRelease()、tryAcquireShared()、tryReleaseShared() 等方法，来定义资源的获取和释放逻辑。 AQS 的工作原理 获取资源： 线程调用 acquire() 方法尝试获取资源。 如果 tryAcquire() 返回 true，表示获取成功，线程继续执行。 如果 tryAcquire() 返回 false，表示获取失败，线程会被加入到等待队列中，并进入阻塞状态。 释放资源： 线程调用 release() 方法释放资源。 如果 tryRelease() 返回 true，表示释放成功，AQS 会唤醒等待队列中的一个或多个线程，让它们重新竞争资源。 以下是一个简单的自定义锁的示例，展示了如何使用 AQS 实现一个独占锁： ThreadLocal 详解ThreadLocal 是 Java 中为了线程安全设置的一种机制，每个线程可以设置局部变量，也就是允许设置自己线程的一个数据副本，线程对副本的修改不会影响到线程间的资源共享和同步问题。 ThreadLocal 的作用 线程隔离：每个线程都有自己独立的 ThreadLocal 变量副本，线程之间的数据互不影响。 降低耦合度：在同一个线程的多个函数或组件之间，使用 ThreadLocal 可以减少参数的传递，降低代码之间的耦合度，使得模块清晰化。 性能优势：由于 ThreadLocal 避免了线程间的同步开销，所以大量线程并发执行时，相比传统的锁机制，它可以提供更好的性能。 ThreadLocal 的原理ThreadLocal 的实现依赖于 Thread 类中的一个 ThreadLocalMap 字段，这是一个存储 ThreadLocal 变量本身和对应值的映射。每个线程都有自己的 ThreadLocalMap 实例，用于存储该线程所持有的所有 ThreadLocal 变量的值。 核心操作 get() 方法： 当调用 ThreadLocal 的 get() 方法时，ThreadLocal 会检查当前线程的 ThreadLocalMap 中是否有与之关联的值。 如果有，则返回值；如果没有，会调用 initialValue() 方法初始化该值，然后将其放入 ThreadLocalMap 中并返回。 set() 方法： 当调用 set() 方法时，ThreadLocal 会将当前线程与给定的值关联起来，即向 ThreadLocalMap 中存入键值对，键为当前 ThreadLocal 对象本身，值为给定的值。 remove() 方法： 当调用 remove() 方法时，ThreadLocal 会从当前线程的 ThreadLocalMap 中移除与当前 ThreadLocal 对象关联的键值对。 可能存在的问题内存泄漏问题 原因：ThreadLocalMap 中的 Entry 对象持有对 ThreadLocal 对象的强引用，如果 ThreadLocal 对象没有被显式移除，即使线程结束，Entry 对象仍然存在，导致 ThreadLocal 对象无法被垃圾回收。 解决方法：在不再需要 ThreadLocal 变量时，显式调用 remove() 方法，确保 ThreadLocal 对象能够被及时回收。 以下是一个简单的示例代码，展示了 ThreadLocal 的使用： 乐观锁&#x2F;悲观锁乐观锁总是假设最好的情况，认为共享资源每次被访问的时候不会出现问题，线程可以不停地执行，无需加锁也无需等待，只是在提交修改的时候去验证对应的资源（也就是数据）是否被其它线程修改了（具体方法可以使用版本号机制或 CAS 算法），如果没有被修改，则更新资源；如果被修改，则重试操作。 悲观锁总是假设最坏的情况，认为共享资源每次被访问的时候就会出现问题(比如共享数据被修改)，所以每次在获取资源操作的时候都会上锁，这样其他线程想拿到这个资源就会阻塞直到锁被上一个持有者释放。也就是说，共享资源每次只给一个线程使用，其它线程阻塞，用完后再把资源转让给其它线程。 Java 实现乐观锁的方式在 Java 中，实现乐观锁的方式主要有以下几种： CAS（Compare-and-Swap）操作 CAS 是乐观锁的基础，Java 提供了原子类包（java.util.concurrent.atomic），包含各种原子变量类操作，这些类通过使用 CAS 操作方式，实现了线程安全的原子操作，可用来实现乐观锁。 以下是一个使用 AtomicInteger 实现乐观锁的示例代码： 2. 版本号控制 增加一个字段记录更新的版本，每次更新递增版本号。在更新时，同时比较版本号，如果一致则替换更新完成，若不一致则更新失败。 以下是一个使用版本号控制实现乐观锁的示例代码： 时间戳 使用时间戳记录更新时的时间，每次更新时比较时间戳，如果一致则替换更新完成，若不一致则更新失败。 以下是一个使用时间戳实现乐观锁的示例代码： CAS 的缺点CAS（Compare-and-Swap）操作是实现乐观锁的基础，但它也存在一些缺点，主要包括以下三个方面： ABA 问题 ABA 问题是指在 CAS 操作中，一个变量在操作过程中经历了从 A 到 B 再回到 A 的变化，而 CAS 操作只比较变量的当前值和预期值是否一致，无法检测到这种中间变化。 解决方案 版本号：在变量中增加一个版本号字段，每次更新时递增版本号，CAS 操作同时比较变量值和版本号。 时间戳：使用时间戳记录变量的更新时间，CAS 操作同时比较变量值和时间戳。 循环时间过长 若 CAS 无法更新成功，线程会一直自旋（循环），长时间占用 CPU 资源，带来无用的花销。这也就造成了不能所有锁都使用CAS。 解决方案 自旋次数限制：设置自旋次数上限，超过次数后放弃自旋，进入阻塞状态。 自旋时间限制：设置自旋时间上限，超过时间后放弃自旋，进入阻塞状态。 只能保证一个共享变量的原子性 CAS 操作只能保证单个共享变量的原子性，无法保证多个共享变量的原子性。 解决方案 锁机制：使用 synchronized 或 ReentrantLock 等锁机制，保证多个共享变量的原子性。 组合操作：将多个共享变量封装在一个对象中，使用 AtomicReference 进行 CAS 操作。 volatilevolatile 是 Java 中的一个关键字，主要用于修饰变量。它具有两个主要作用：保证变量对所有线程的可见性和禁止指令重排序优化。 保证变量对所有线程的可见性当一个变量被声明为 volatile 时，它会保证对这个变量的写操作会立即刷新到主存中，而对这个变量的读操作会直接从主存中读取，从而确保了多线程环境下对该变量访问的可见性。这意味着一个线程修改了 volatile 变量的值，其他线程能够立刻看到这个修改，不会受到各自线程工作内存的影响。 禁止指令重排序优化volatile 关键字在 Java 中主要通过内存屏障来禁止特定类型的指令重排序。内存屏障分为以下几种： 写-写（Write-Write）屏障： 在对 volatile 变量执行写操作之前，会插入一个写屏障。这确保了在该变量写操作之前的所有普通写操作都已完成，防止了这些写操作被移到 volatile 写操作之后。 读-写（Read-Write）屏障： 在对 volatile 变量执行读操作之后，会插入一个读屏障。它确保了对 volatile 变量的读操作之后的所有普通读操作都不会被提前到 volatile 读之前执行，保证了读取到的数据是最新的。 写-读（Write-Read）屏障： 这是最重要的一个屏障，它发生在 volatile 写之后和 volatile 读之前。这个屏障确保了 volatile 写操作之前的所有内存操作（包括写操作）都不会被重排序到 volatile 读之后，同时也确保了 volatile 读操作之后的所有内存操作（包括读操作）都不会被重排序到 volatile 写之前。 volatile 不能完全保证线程安全volatile 关键字在 Java 中主要用于保证变量对所有线程的可见性和禁止指令重排序优化。然而，volatile 并不能完全保证线程安全，因为它没有保证数据操作的原子性。在多线程环境下，进行复合操作（如自增、自减等，自增、自减包含读取、修改和写入三个步骤，可能会出现覆盖问题）时，volatile 无法保证操作的原子性，因此可能会导致线程安全问题。 保证线程安全的解决方案为了保证复合操作的线程安全，可以使用以下方法： synchronized 关键字：使用 synchronized 关键字来同步代码块或方法，确保同一时刻只有一个线程能访问这些代码。 Lock 接口和 ReentrantLock 类：使用 Lock 接口和 ReentrantLock 类来实现更灵活的锁机制，确保同一时刻只有一个线程能访问这些代码。 原子类：使用 java.util.concurrent.atomic 包中的原子类（如 AtomicInteger）来实现原子操作，确保操作的原子性。 指令重排的原理在执行程序时，为了提高性能，处理器和编译器往往会对指令进行重排优化。指令重排的目的是在不改变程序运行结果的前提下，优化指令的执行顺序，以提高处理器的执行效率。 指令重排的原则指令重排遵循以下两个原则： 不能改变程序的运行结果：指令重排不能改变单线程程序的运行结果。也就是说，无论指令如何重排，单线程程序的执行结果必须保持一致。 存在依赖关系的指令不能进行重排：如果两条指令之间存在数据依赖关系（即一条指令的执行结果会影响另一条指令的执行），那么这两条指令不能进行重排。 指令重排的类型指令重排可以分为以下几种类型： 编译器重排：编译器在生成机器码时，可能会对指令进行重排，以优化代码的执行顺序。 处理器重排：处理器在执行指令时，可能会对指令进行重排，以提高指令流水线的效率。 指令重排的示例以下是一个简单的示例代码，展示了指令重排的效果： 在这个示例中，t1 线程中的两条指令 a = 1 和 b = 2 之间没有数据依赖关系，因此编译器和处理器可能会对这两条指令进行重排。重排后的执行顺序可能是 b = 2 先执行，a = 1 后执行。 指令重排的影响指令重排在单线程环境下通常不会影响程序的运行结果，但在多线程环境下可能会导致不可预期的结果。例如，在上述示例中，如果 t2 线程在 t1 线程完成 a = 1 之前读取了 b 的值，那么 t2 线程可能会输出 x = 2, y = 0，这与预期的 x = 2, y = 1 不一致。 公平锁与非公平锁在多线程编程中，锁机制是保证线程安全的重要手段。根据线程获取锁的顺序，锁可以分为公平锁和非公平锁。 公平锁公平锁（Fair Lock）是指多个线程按照申请锁的顺序来获取锁，线程直接进入队列中排队，队列中的第一个线程才能获得锁。 流程 获取锁: 线程尝试获取锁，若锁已被占用，则将自身加入等待队列队尾，并进入休眠状态。 释放锁: 持有锁的线程释放锁后，会唤醒等待队列队首的线程，该线程尝试获取锁。 状态切换: 线程在运行和休眠状态之间切换，每次切换都需要进行用户态和内核态的转换，这种转换开销较大，导致公平锁执行速度较慢。 非公平锁非公平锁（Non-Fair Lock）是指多个线程加锁时直接尝试获取锁，能抢到锁的线程直接占有锁，抢不到才会到等待队列的队尾等待。 流程 获取锁: 线程尝试通过CAS操作直接获取锁，若成功则直接持有锁，无需进入等待队列。 竞争锁: 若CAS失败，线程才会进入等待队列，等待下次获取锁的机会。 效率提升: 非公平锁避免了线程频繁的休眠和唤醒操作，减少了用户态和内核态的切换开销，从而提高了程序执行效率。 对比公平锁与非公平锁的优缺点对比: 特性 公平锁 非公平锁 获取锁顺序 严格按照等待队列顺序 不保证顺序，可能出现“插队”现象 吞吐量 较低，频繁的线程切换开销大 较高，减少了线程切换开销 响应时间 较长，新线程需要等待 较短，新线程有机会立即获取锁 饥饿问题 不易发生 可能发生，某些线程可能长时间无法获取锁 适用场景 对公平性要求较高，例如银行排队系统 对性能要求较高，例如高并发场景 扩展 Synchronized 是不公平锁，ReentrantLock 默认情况下也是不公平锁，但可以通过构造函数参数指定为公平锁（在其获取锁的方法中，设置前置判断条件 !hasQueuedPredecessors()）。 "},{"title":"Java并发编程-多线程篇","date":"2024-09-10T00:08:08.000Z","url":"/2024/09/10/Java%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B-%E5%A4%9A%E7%BA%BF%E7%A8%8B%E7%AF%87/","tags":[["多线程","/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"]],"categories":[["Java","/categories/Java/"],["并发编程","/categories/Java/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"]],"content":"Java作为一门广泛使用的编程语言，提供了丰富的多线程编程接口和工具，使得开发者能够轻松地创建和管理线程。然而，多线程编程并非易事，它涉及到线程的创建、启动、关闭、同步等多个复杂问题。本文将深入探讨Java中的多线程编程，涵盖线程的基本概念、线程与操作系统的关系、线程的创建和管理方法。 Java中的多线程与操作系统中的多线程在探讨Java中的多线程与操作系统中的多线程之间的关系时，我们首先需要理解两者在底层实现上的联系。尽管Java语言本身提供了丰富的多线程编程接口，但其底层实现依赖于操作系统的线程机制。 Java语言通过java.lang.Thread类提供了多线程编程的支持。然而，Java虚拟机（JVM）在实现这些线程时，依赖于操作系统的线程机制。具体来说，JVM在大多数操作系统上使用POSIX线程（pthread）库来创建和管理线程。 在Linux系统中，JVM通过调用pthread_create函数来创建线程。pthread_create是POSIX线程库中的一个函数，用于在操作系统级别创建一个新的线程。因此，从底层实现的角度来看，Java中的线程实际上是操作系统线程的封装。 Java线程与操作系统线程之间的关系通常被称为“1对1线程模型”。在这种模型中，每个Java线程都直接映射到一个操作系统线程。这意味着： 资源管理：操作系统负责管理线程的资源分配，如CPU时间、内存等。 调度：操作系统的调度器负责决定哪个线程在何时执行。 上下文切换：线程的上下文切换由操作系统内核完成。 由于Java线程直接映射到操作系统线程，因此Java线程的行为和性能特征在很大程度上受到操作系统线程机制的影响。 使用多线程需要注意的问题在多线程编程中，确保线程安全是至关重要的。线程安全指的是在多线程环境下，程序能够正确地处理共享数据，避免数据竞争和不一致性问题。Java提供了多种机制来保证线程安全，主要包括原子性、可见性和有序性。 原子性 原子性是指一个操作要么全部执行，要么全部不执行，不存在中间状态。在多线程环境中，原子性确保了同一时间只有一个线程能够对共享数据进行操作，从而避免了数据竞争。 实现 java.util.concurrent.atomic包：提供了多种原子类（如AtomicInteger、AtomicLong等），这些类通过CAS（Compare-And-Swap）操作实现原子性。 synchronized关键字：通过监视器锁（monitor lock）确保方法或代码块在同一时间只能被一个线程执行。 可见性 可见性确保一个线程对数据的修改对其他线程是可见的。在多线程环境中，由于CPU缓存和编译器优化，可能会导致一个线程的修改对其他线程不可见。 实现 volatile关键字：确保变量的修改立即对所有线程可见，禁止CPU缓存和编译器优化。 synchronized关键字：在进入和退出同步块时，确保变量的可见性。 3. 有序性 有序性确保指令按照程序的顺序执行。在多线程环境中，由于编译器和CPU的指令重排序优化，可能会导致指令的执行顺序与程序代码的顺序不一致。 实现 volatile关键字：禁止指令重排序，确保变量的读写操作按顺序执行。 synchronized关键字：确保同步块内的代码按顺序执行。 使用了happens-before原则来确保有序性。 Java中保证数据一致性的科学方案在Java应用中，确保数据一致性是关键任务之一。以下是几种科学且专业的方案，旨在帮助读者理解并实施有效的数据一致性策略： 事务管理事务管理是保证数据一致性的基础手段。通过数据库事务，可以确保一系列数据操作要么全部成功提交，要么全部失败回滚。这一机制依赖于事务的ACID属性： 原子性（Atomicity）：事务中的所有操作要么全部完成，要么全部不完成，不存在部分执行的情况。 一致性（Consistency）：事务执行前后，数据库从一个一致状态转变到另一个一致状态。 隔离性（Isolation）：并发执行的事务之间相互隔离，一个事务的执行不会影响其他事务。 持久性（Durability）：一旦事务提交，其结果将永久保存在数据库中，即使系统发生故障。 锁机制锁机制是另一种重要的数据一致性保障手段。通过锁，可以实现对数据的互斥访问，确保同一时间只有一个事务能够对特定数据进行操作。常见的锁类型包括： 共享锁（Shared Lock）：允许多个事务同时读取同一数据，但阻止写操作。 排他锁（Exclusive Lock）：阻止其他事务读取或写入同一数据，确保数据修改的独占性。 版本控制版本控制是一种乐观的并发控制策略，通过记录数据的版本信息来保证数据一致性。具体实现方式如下： 乐观锁（Optimistic Locking）：在更新数据时，检查数据的版本号。如果版本号与预期一致，则允许更新并递增版本号；否则，拒绝更新操作。 这种策略适用于读多写少的场景，能够减少锁竞争，提高系统并发性能。 如何创建线程在 Java 中，创建线程主要有以下几种方式： 继承 Thread 类 通过继承 Thread 类并重写 run() 方法来创建线程。 优点：简单直接，易于理解和实现。 缺点：由于 Java 不支持多重继承，继承 Thread 类后无法再继承其他类。线程管理和复用性较差。 实现 Runnable 接口 通过实现 Runnable 接口并重写 run() 方法来创建线程。 优点：避免了单继承的限制，可以继承其他类。代码更加灵活，适用于需要实现多线程的场景。 缺点：编程稍微复杂，如果需要访问当前线程，必须使用Thread.currentThread()方法。 实现 Callable 和 FutureTask 通过实现 Callable 接口并使用 FutureTask 来创建线程。Callable 接口允许线程返回结果，并且可以抛出异常。要执行Callable任务，需将它包装进一个FutureTask，因为Thread类的构造器只接受Runnable参数，而FutureTask实现了Runnable接囗。 优点：允许线程返回结果，并且可以抛出异常。适用于需要获取线程执行结果的场景。 缺点：代码相对复杂，需要处理 FutureTask 和 Callable。 使用线程池（Executor） 通过使用 Executor 框架来创建和管理线程池。Executor 框架提供了多种线程池实现，如 FixedThreadPool、CachedThreadPool、SingleThreadExecutor 等。 优点：提高线程的复用性和管理性，减少线程创建和销毁的开销。适用于需要管理多个线程的场景。 缺点：代码相对复杂，需要理解线程池的概念和配置。 总结 继承 Thread 类：适用于简单的线程创建，但无法继承其他类。 实现 Runnable 接口：适用于需要实现多线程的场景，并且可以继承其他类。 **实现 Callable 和 FutureTask**：适用于需要返回结果或抛出异常的线程。 使用线程池（Executor）：适用于需要管理多个线程的场景，提高线程的复用性和管理性。 如何启动&#x2F;关闭线程？ 启动线程 启动线程通过 Thread 类的 start() 方法。 关闭线程 关闭线程主要有以下几种方法： 异常停止：通过抛出异常来停止线程。 优点：优雅地停止线程，避免资源泄漏。 缺点：需要在线程代码中处理异常。 在沉睡中停止：通过在 sleep() 方法中抛出 InterruptedException 来停止线程。 优点：适用于线程在沉睡中停止的场景。 缺点：需要在线程代码中处理异常。 stop() 暴力停止：使用 Thread 类的 stop() 方法来暴力停止线程。 优点：简单直接，易于使用。 缺点：不安全，可能导致资源泄漏或数据不一致。stop() 方法已被弃用，不推荐使用。 使用 return 停止：通过在 run() 方法中使用 return 语句来停止线程。 优点：优雅地停止线程，避免资源泄漏。适用于需要控制线程停止的场景。 缺点：需要在线程代码中添加停止标志。 调用 interrupt 如何让线程抛出异常在Java中，线程的中断机制是通过一个布尔属性来表示线程的中断状态。初始状态下，线程的中断状态为 false。当一个线程被其他线程调用 Thread.interrupt() 方法中断时，会根据线程当前的执行状态做出不同的响应。 中断机制的工作原理 中断状态的设置：当调用 Thread.interrupt() 方法时，目标线程的中断状态会被设置为 true。 响应中断： 如果目标线程当前正在执行低级别的可中断方法（如 Thread.sleep()、Thread.join() 或 Object.wait()），这些方法会检查线程的中断状态。 如果发现中断状态为 true，这些方法会立即解除阻塞，并抛出 InterruptedException 异常。 轮询中断状态： 如果目标线程当前没有执行可中断方法，Thread.interrupt() 方法仅会设置线程的中断状态为 true。 被中断的线程可以通过轮询中断状态（使用 Thread.currentThread().isInterrupted() 方法）来决定是否停止当前正在执行的任务。 示例代码 以下是一个示例，展示了如何通过 interrupt 方法让线程抛出 InterruptedException 异常： 关键点解析 可中断方法：Thread.sleep()、Thread.join() 和 Object.wait() 等方法是可中断的。当线程在这些方法中被中断时，会立即抛出 InterruptedException 异常。 中断状态的轮询：如果线程没有执行可中断方法，可以通过 Thread.currentThread().isInterrupted() 方法轮询中断状态，以决定是否停止当前任务。 重新设置中断状态：在捕获 InterruptedException 异常后，通常需要重新设置中断状态（使用 Thread.currentThread().interrupt()），以确保中断状态不会丢失。 通过调用 Thread.interrupt() 方法，可以设置线程的中断状态，并根据线程当前的执行状态做出不同的响应。如果线程正在执行可中断方法，会立即抛出 InterruptedException 异常；否则，线程可以通过轮询中断状态来决定是否停止当前任务。这种机制确保了线程能够优雅地响应中断请求，避免资源泄露和不一致状态。 Java 线程状态详解状态在Java中，线程的生命周期可以通过其状态来描述。线程的状态反映了线程当前的执行情况和行为。Java线程的状态由 Thread.State 枚举类定义，主要包括以下几种状态： NEW（新建） 描述：线程对象已经被创建，但尚未调用 start() 方法启动。 状态转换：从 NEW 状态调用 start() 方法后，线程进入 RUNNABLE 状态。 RUNNABLE（可运行） 描述：线程正在Java虚拟机中执行，但它可能正在等待操作系统的其他资源（如CPU时间片）。 状态转换： 从 NEW 状态调用 start() 方法后进入 RUNNABLE 状态。刚调用start()等待系统调度时是READY状态，当执行任务时为RUNNING状态。 从 BLOCKED、WAITING、TIMED_WAITING 状态恢复后进入 RUNNABLE 状态。 BLOCKED（阻塞） 描述：线程正在等待获取监视器锁（monitor lock）以进入同步代码块或方法。 状态转换： 当线程尝试进入同步代码块或方法但锁已被其他线程占用时，进入 BLOCKED 状态。 当获取到锁后，线程从 BLOCKED 状态进入 RUNNABLE 状态。 WAITING（等待） 描述：线程正在无限期地等待另一个线程执行特定操作（如 Object.wait()、Thread.join() 或 LockSupport.park()）。 状态转换： 通过调用 Object.wait()、Thread.join() 或 LockSupport.park() 方法进入 WAITING 状态。 当其他线程调用 Object.notify()、Object.notifyAll() 或 LockSupport.unpark() 方法时，线程从 WAITING 状态进入 RUNNABLE 状态。 TIMED_WAITING（计时等待） 描述：线程正在等待另一个线程执行特定操作，但有一个超时时间（如 Thread.sleep(long)、Object.wait(long)、Thread.join(long) 或 LockSupport.parkNanos(long)）。 状态转换： 通过调用 Thread.sleep(long)、Object.wait(long)、Thread.join(long) 或 LockSupport.parkNanos(long) 方法进入 TIMED_WAITING 状态。 当超时时间到达或被其他线程唤醒时，线程从 TIMED_WAITING 状态进入 RUNNABLE 状态。 TERMINATED（终止） 描述：线程已经执行完毕，run() 方法正常退出或抛出未捕获的异常。 状态转换： 当线程的 run() 方法执行完毕或抛出未捕获的异常时，线程进入 TERMINATED 状态。 notify 和 notifyAll 的区别在Java中，notify 和 notifyAll 都是用于唤醒等待在对象监视器上的线程，但它们的行为有所不同。 notify 功能：notify 方法会随机唤醒一个正在等待该对象监视器的线程。 特点：只唤醒一个线程，其他线程仍处于 WAITING 状态。如果其他线程没有被再次调用 notify 或 notifyAll，它们可能会一直等待，直到超时或被中断。 notifyAll 功能：notifyAll 方法会唤醒所有正在等待该对象监视器的线程。 特点：所有线程都会被唤醒，但只有一个线程能获得锁，其他线程会继续竞争锁。所有线程都会从 WAITING 状态进入 RUNNABLE 状态，开始竞争锁。 以下是一个示例代码，展示了 notify 和 notifyAll 的区别： 总结 **notify**：适用于只需要唤醒一个线程的场景，但需要注意其他线程可能会一直等待。 **notifyAll**：适用于需要唤醒所有线程的场景，确保所有线程都有机会竞争锁。 wait 和 sleep 的区别wait 和 sleep 都是用于线程的等待操作，但它们的行为和使用场景有所不同。 wait 所属类：Object 类的方法。 功能：使当前线程进入等待状态，直到被唤醒（通过 notify 或 notifyAll）或超时。 特点： 必须在同步代码块（synchronized）中调用。 调用 wait 方法会释放对象的监视器锁（monitor lock）。 线程进入 WAITING 或 TIMED_WAITING 状态。 sleep 所属类：Thread 类的方法。 功能：使当前线程暂停执行指定的时间。 特点： 可以在任何地方调用，不需要在同步代码块中。 调用 sleep 方法不会释放对象的监视器锁。 线程进入 TIMED_WAITING 状态。 以下是一个示例代码，展示了 wait 和 sleep 的区别： 总结 **wait**：适用于需要在同步代码块中等待并释放锁的场景，通常用于线程间的协调和通信。 **sleep**：适用于需要暂停线程执行一段时间的场景，不会释放锁，通常用于简单的延迟操作。 notify会唤醒哪个线程？查看源码注释： 大致的意思是： 唤醒一个正在等待该对象监视器的单个线程。如果有任何线程正在等待该对象，其中一个线程将被选择并唤醒。选择是任意的，并由实现自行决定。线程通过调用其中一个 wait 方法来等待对象的监视器。 也就是说，依赖于JVM的具体实现。JVM有很多实现，比较流行的就是hotspot，hotspot对notofy0的实现并不是我们以为的随机唤醒，而是“先进先出”的顺序唤醒。"},{"title":"Java集合-Set篇","date":"2024-09-09T05:14:03.000Z","url":"/2024/09/09/Java%E9%9B%86%E5%90%88-Set%E7%AF%87/","tags":[["Set","/tags/Set/"]],"categories":[["Java","/categories/Java/"],["集合","/categories/Java/%E9%9B%86%E5%90%88/"]],"content":"在Java集合框架中，Set是一种不包含重复元素的集合，具有唯一性、无序性和不可变性等特点。Set通过哈希表或红黑树实现元素的唯一性，常见的实现类包括HashSet、TreeSet和LinkedHashSet。HashSet基于哈希表，TreeSet基于红黑树，而LinkedHashSet结合了哈希表和双向链表，既能保证元素的唯一性，又能记录插入顺序。理解这些集合类型的特点和实现原理，有助于在实际编程中选择合适的集合类型，提高代码的效率和可维护性。 Set集合特点Set集合是一种不包含重复元素的集合，它具有以下特点： 唯一性：Set集合中的元素是唯一的，不允许有重复的元素。 无序性：Set集合中的元素没有特定的顺序，即元素的存储顺序与插入顺序无关。 不可变性：Set集合中的元素一旦插入，通常不能被修改（除非删除后重新插入）。 Set集合key无重复原理Set集合通过内部的数据结构来实现元素的唯一性。常见的实现方式包括使用哈希表（HashMap）或红黑树（TreeMap）等数据结构。以下是Set集合实现key无重复的基本原理： 哈希表（HashMap）实现在Java中，HashSet是基于HashMap实现的。HashSet内部维护了一个HashMap，其中元素作为HashMap的key，而HashMap的value是一个固定的虚拟对象（通常是一个常量对象）。 插入元素的过程： 计算哈希值：当向HashSet中插入一个元素时，首先会计算该元素的哈希值（通过hashCode()方法）。 确定存储位置：根据哈希值确定元素在哈希表中的存储位置。 检查重复：在存储位置上，通过equals()方法检查是否已经存在相同的元素。如果存在相同的元素，则不插入；否则，将元素插入到哈希表中。 红黑树（TreeMap）实现在Java中，TreeSet是基于TreeMap实现的。TreeSet内部维护了一个TreeMap，其中元素作为TreeMap的key，而TreeMap的value是一个固定的虚拟对象。 插入元素的过程： 比较元素：当向TreeSet中插入一个元素时，首先会通过元素的compareTo()方法（或Comparator）进行比较。 检查重复：如果比较结果表明元素已经存在（即compareTo()返回0），则不插入；否则，将元素插入到红黑树中。 总结 无论是基于哈希表还是红黑树，Set集合实现key无重复的核心原理都是通过比较元素的哈希值或直接比较元素本身来确保集合中的元素唯一。具体步骤如下： 计算哈希值或比较元素：根据元素的哈希值或直接比较元素。 检查重复：通过equals()方法或compareTo()方法检查是否已经存在相同的元素。 插入或拒绝：如果元素不存在，则插入；否则，拒绝插入。 有序的Set集合在Java中，TreeSet和LinkedHashSet是两种常见的Set集合实现，它们分别提供了有序性和记录插入顺序的功能。 TreeSetTreeSet是基于红黑树（Red-Black Tree）实现的，它保证了元素的自然顺序。红黑树是一种自平衡的二叉查找树，能够在插入和删除操作后自动调整树的结构，以保持树的平衡。 特点： 有序性：TreeSet中的元素按照自然顺序（或通过自定义的Comparator）进行排序。 唯一性：TreeSet中的元素是唯一的，不允许重复。 性能：插入、删除和查找操作的时间复杂度为O(log n)。 LinkedHashSetLinkedHashSet是基于哈希表和双向链表实现的，它保证了元素的插入顺序。哈希表用于快速查找元素，而双向链表用于维护元素的插入顺序。 特点： 插入顺序：LinkedHashSet中的元素按照插入顺序进行存储和遍历。 唯一性：LinkedHashSet中的元素是唯一的，不允许重复。 性能：插入、删除和查找操作的时间复杂度为O(1)。 记录插入顺序的集合通常指的是LinkedHashSet。LinkedHashSet通过维护一个双向链表来记录元素的插入顺序，因此它能够保证元素按照插入顺序进行存储和遍历。 以下是一个使用LinkedHashSet来记录插入顺序的代码示例： 由于LinkedHashSet不允许重复元素，因此插入重复元素不会改变集合的内容，插入顺序保持不变。 运行上述代码后，输出结果如下： 可以看到，LinkedHashSet成功地记录了元素的插入顺序，并且重复元素不会被插入。"},{"title":"Java集合-Map篇(上)","date":"2024-09-09T05:14:02.000Z","url":"/2024/09/09/Java%E9%9B%86%E5%90%88-Map%E7%AF%87(%E4%B8%8A)/","tags":[["Map","/tags/Map/"]],"categories":[["Java","/categories/Java/"],["集合","/categories/Java/%E9%9B%86%E5%90%88/"]],"content":"在Java集合框架中，Map接口提供了多种实现类，其中HashMap是最常用的键值对存储结构。HashMap的底层实现经历了多次优化，从Java 1.7及之前的数组+链表结构，到Java 1.8引入的红黑树优化，显著提高了查询性能。HashMap通过哈希算法将键值映射到数组槽位，解决哈希冲突的方法包括链表法、开放寻址法、再哈希法和哈希桶扩容。HashMap在多线程环境下存在数据丢失和死循环问题，可以通过Collections.synchronizedMap、Hashtable或ConcurrentHashMap实现线程安全。HashMap的核心操作包括put和get方法，依赖于哈希算法和数组结构。选择红黑树而非平衡二叉树是为了在保证查询性能的同时，减少插入和删除操作的开销。HashMap支持null作为键和值，但null作为键只能有一个。理解这些原理和实现细节，有助于在实际编程中选择合适的集合类型，提高代码的效率和可维护性。 HashMap 原理HashMap 是 Java 中常用的键值对存储结构，其底层实现经历了多次优化。在 Java 1.7 之前，HashMap 的存储结构为数组 + 链表，而在 Java 1.8 中引入了红黑树来优化链表过长导致的性能问题。 Java 1.7 及之前的 HashMap在Java 1.7 及之前的HashMap存储结构为数组 + 链表，通过哈希算法将元素的键值映射到数组中的槽位（bucket），如果多个键映射到同一个槽位上，它们就会使用链表连接在一起。 由此也就引发了一个问题：当哈希冲突严重时，链表会变得非常长，查询性能会下降到 O(n)，导致性能变差。 Java 1.8 的优化在Java 1.8 之后，对HashMap进行了优化，采用数组 + 链表 + 红黑树的数据结构：当链表长度大于 8 时，链表会转化为红黑树，查询性能提升到 O(log n)；当链表长度小于 6 时，红黑树会退化为链表。 关键点 哈希算法：HashMap 使用哈希算法将键值映射到数组的槽位，哈希算法的设计直接影响哈希冲突的概率和性能。 链表与红黑树的转换： 链表转红黑树： 当链表长度大于 8 时，链表会转化为红黑树。 红黑树转链表： 当红黑树节点数小于 6 时，红黑树会退化为链表。 红黑树的特性： 自平衡： 红黑树是一种自平衡的二叉查找树，能够在插入和删除操作后自动调整树的结构，保持树的高度平衡。 查询性能： 红黑树的查询、插入和删除操作的平均时间复杂度为 O(log n)。 以下是 Java 1.8 中 HashMap 的部分源码： Java 1.7 及之前： HashMap 使用数组 + 链表的结构，链表查询复杂度为 O(n)。 Java 1.8 及之后： 引入了红黑树，当链表长度大于 8 时转化为红黑树，查询复杂度提升到 O(log n)，当链表长度小于 6 时退化为链表。 这种优化显著提高了 HashMap 在哈希冲突严重时的查询性能，使其在实际应用中更加高效。 哈希冲突解决办法哈希冲突是指不同的键值通过哈希函数计算后，映射到同一个哈希桶（bucket）中。为了解决哈希冲突，常见的解决方法有以下几种： 1.链表法（Separate Chaining） 使用链表等数据结构存储冲突的键值，将它们连接在同一个桶里。 每个桶（bucket）维护一个链表，当发生哈希冲突时，将新元素插入到链表的尾部。 2. 开放寻址法（Open Addressing） 在哈希表中找一个可用的位置来存放冲突的键值，而不使用同一个链表进行存储。 常见的开放寻址法有线性探测、二次探测和双重哈希。 3. 再哈希法（Rehashing） 当哈希冲突时，使用另一个哈希函数进行二次哈希，直到找到一个可用的空槽。 再哈希函数的选择需要避免再次冲突。 4. 哈希桶扩容（Resize） 动态增加哈希桶的容量，重新分配键值对，即可减少哈希冲突。 当哈希表的负载因子（load factor）达到一定阈值时，进行扩容操作。 HashMap 线程安全吗？HashMap 是线程不安全的，在多线程情况下会出现以下问题： Java 1.7 及之前的问题在 Java 1.7 及之前，HashMap 的数据结构为数组 + 链表。在多线程环境下，多个线程同时进行扩容操作时，可能会导致链表形成环状结构（由于此前版本在扩容复制新链表时，采用的是头插法，在新的链表中指针的顺序会进行翻转），从而引发Entry 链死循环；当多个线程同时进行插入操作时，可能会导致数据丢失。 Java 1.8 及之后的问题在 Java 1.8 及之后，HashMap 采用了数组 + 链表 + 红黑树的数据结构，优化了之前版本的问题（采用了尾插的形式，不会导致环形链表进入死循环）。但在多线程背景下，put 方法仍然存在数据丢失的问题（例如，两个线程同时检测到某个索引位置为空，并同时插入新节点，导致其中一个线程插入的数据被覆盖。）。 线程安全的解决方案如果想要保证 HashMap 的线程安全，可以使用以下方式： 使用 Collections.synchronizedMap 方法进行加锁 底层实现： Collections.synchronizedMap 方法会返回一个包装了原始 HashMap 的同步视图。 其底层实现原理是为每个方法调用添加一个同步块（synchronized block），确保同一时刻只有一个线程可以访问该 Map。 缺点： 性能开销较大，因为每次方法调用都需要获取和释放锁。 迭代时需要手动同步，否则可能会抛出 ConcurrentModificationException。 ###使用 Hashtable 底层实现： Hashtable 是线程安全的 Map 实现，其所有方法都使用 synchronized 关键字进行同步。 使用 ConcurrentHashMap 底层实现： ConcurrentHashMap 是 java.util.concurrent 包中的一个线程安全 Map 实现。 采用分段锁（Segment）机制，将 Map 分成多个段（Segment），每个段独立加锁，从而提高并发性能。 总结 HashMap： 线程不安全，多线程环境下可能会出现死循环和数据丢失问题。 Collections.synchronizedMap： 简单易用，但性能开销较大。 Hashtable： 线程安全，但性能较差。 ConcurrentHashMap： 线程安全，性能较高，适用于高并发场景。 HashMap的“put”过程在多线程背景下，HashMap 的 put 方法可能会出现数据丢失或覆盖等问题。为了深入理解这些问题，我们来看看 put 方法的具体流程。 1.根据键计算哈希码获得索引： 使用键的哈希码计算出在数组中的索引位置。 计算公式：index = hash(key) &amp; (table.length - 1) 2.检查该索引位置是否为空：如果该索引位置为空，直接将新节点插入到该位置。 3.如果索引已存在，则对比键值是否相同：遍历该索引位置的链表或红黑树，查找是否存在相同的键，如果找到相同的键，则直接覆盖该位置的值，完成更新。 4.如果键值不同，则插入新节点：如果链表长度小于 8，将新节点插入到链表的尾部。如果链表长度大于等于 8，将链表转化为红黑树，并将新节点插入到红黑树中。 put(K key, V val)和get(K key)HashMap 是 Java 中常用的键值对存储结构，其核心操作包括 put(K key, V val) 和 get(K key) 方法。这两个方法分别用于存储对象和读取对象，其底层实现依赖于哈希算法和数组结构。 put(K key, V val) 方法： 计算哈希值： 使用传入的 key 计算哈希值。 计算公式：hash = hash(key) 计算数组索引： 使用哈希值计算出在数组中的索引位置。 计算公式：index = hash &amp; (table.length - 1) 检查索引位置： 如果该索引位置为空，直接将新节点插入到该位置。 如果该索引位置已存在节点，则遍历链表或红黑树，查找是否存在相同的键。 处理冲突： 如果找到相同的键，则直接覆盖该位置的值，完成更新。 如果键值不同，则插入新节点： 如果链表长度小于 8，将新节点插入到链表的尾部。 如果链表长度大于等于 8，将链表转化为红黑树，并将新节点插入到红黑树中。 检查负载因子： 如果插入后达到了 HashMap 设置的负载阈值（默认为 0.75），则需要扩容 100%。 扩容操作会创建一个新的数组，并将原数组中的元素重新分配到新数组中。 代码： get(K key) 方法 计算哈希值： 使用传入的 key 计算哈希值。 计算公式：hash = hash(key) 计算数组索引： 使用哈希值计算出在数组中的索引位置。 计算公式：index = hash &amp; (table.length - 1) 检查索引位置： 如果该索引位置为空，返回 null。 如果该索引位置已存在节点，则遍历链表或红黑树，查找是否存在相同的键。 处理哈希冲突： 如果节点是链表结构，遍历链表查找键值。 如果节点是红黑树结构，调用红黑树的查找方法。 返回值： 如果找到相同的键，返回对应的值。 如果未找到相同的键，返回 null。 代码： 为什么 HashMap 使用的是红黑树而不是其他？选择红黑树的主要原因是为了优化查询性能，因此选用了查询性能优秀的平衡树一类。 为什么不是平衡二叉树？平衡二叉树（如 AVL 树）追求一种“完美平衡”，即任何节点的子树高度差都不超过 1。这种严格的平衡性确保了查询操作的时间复杂度为 O(log n)，但在插入或删除数据时，很容易破坏这种平衡。为了保持平衡，树会进行频繁的旋转操作，从而消耗大量性能。 红黑树的优势红黑树是一种自平衡的二叉查找树，它通过引入颜色标记和一些规则来保持树的平衡。红黑树的平衡性要求相对较弱，不需要频繁维护树的平衡，从而减少了开销。 红黑树的特性 自平衡： 红黑树通过颜色标记和旋转操作来保持树的平衡，插入和删除操作的时间复杂度为 O(log n)。 弱平衡： 红黑树的平衡性要求相对较弱（整个树的最长路径不会超过最短路径的2倍），不需要频繁进行旋转操作，减少了维护平衡的开销。 查询性能： 红黑树的查询性能略逊于平衡二叉树，但仍然为 O(log n)，与平衡二叉树相差不大。 红黑树与平衡二叉树的对比 特性 红黑树 平衡二叉树（如 AVL 树） 平衡性要求 弱平衡 严格平衡 旋转操作 较少 频繁 插入&#x2F;删除性能 较好 较差 查询性能 O(log n) O(log n) 实现复杂度 中等 较高 为什么选择红黑树？综合考虑以下因素，选择红黑树更为合适： 查询性能： 红黑树的查询性能为 O(log n)，与平衡二叉树相差不大。 插入&#x2F;删除性能： 红黑树的插入和删除操作性能较好，因为不需要频繁进行旋转操作。 实现复杂度： 红黑树的实现复杂度适中，易于理解和实现。 总结 红黑树： 自平衡、弱平衡、查询性能为 O(log n)、插入&#x2F;删除性能较好、实现复杂度适中。 平衡二叉树： 严格平衡、查询性能为 O(log n)、插入&#x2F;删除性能较差、实现复杂度较高。 在 HashMap 中，选择红黑树是为了在保证查询性能的同时，减少插入和删除操作的开销，从而提高整体性能。 HashMap的key可以为null吗？答案是可以的。 hashMap中使用hash()方法来计算key的哈希值，当key为空时，直接令key的哈希值为0，不走key.hashcode()方法; HashMap虽然支持key和value为null，但是null作为key只能有一个，null作为value可以有多个。因为HashMap中，如果key值一样，那么会覆盖相同key值的value为最新，所以key为nul只能有一个。 HashCode.equals和hashMap.hashCode在 HashMap 中比较元素时，首先会通过 hashCode 进行比较，如果 hashCode 相同，再通过 equals 方法进行比较。因此，如果两个对象通过 equals 方法比较是相等的，那么它们的 hashCode 必须相等。然而，hashCode 相等的两个对象，equals 方法的比较结果不一定相等（例如，在发生哈希冲突的情况下）。 如果这些方法没有被正确地实现，可能会导致两个不同的 Key 产生相同的哈希码和 equals() 输出，从而导致 HashMap 认为它们是相同的，进而覆盖它们，而不是将它们存储到不同的地方。 如果在重写 equals 方法时没有同时重写 hashCode 方法，可能会导致 equals 方法返回 true，而 hashCode 方法返回不同的值。这种情况的后果是，在 HashMap 等类中可能会存储多个实际上相同的对象，从而导致数据覆盖的问题。这与 HashMap 中每个键必须是唯一的规范不符。 重写equals和hashCode方法应该保持以下原则： 如果 o1.equals(o2)，那么 o1.hashCode() == o2.hashCode() 总是为 true。 如果 o1.hashCode() == o2.hashCode()，并不意味着 o1.equals(o2) 会为 true。 "},{"title":"Java集合-Map篇(下)","date":"2024-09-09T05:14:02.000Z","url":"/2024/09/09/Java%E9%9B%86%E5%90%88-Map%E7%AF%87(%E4%B8%8B)/","tags":[["Map","/tags/Map/"]],"categories":[["Java","/categories/Java/"],["集合","/categories/Java/%E9%9B%86%E5%90%88/"]],"content":"在Java集合框架中，Map接口提供了多种实现类，其中HashMap和HashTable是最常用的键值对存储结构。HashMap通过哈希算法和数组+链表&#x2F;红黑树结构，实现了高效的查询和插入操作。HashTable通过同步方法实现了线程安全，但性能较差。ConcurrentHashMap在Java 1.7及之前版本采用分段锁技术，而在Java 1.8及之后版本通过数组+链表&#x2F;红黑树结构和volatile+CAS或synchronized机制，实现了更高的并发性能。ConcurrentHashMap综合运用了乐观锁和悲观锁，通过CAS操作实现无锁的初始化和空桶设置，通过synchronized关键字确保非空桶操作的线程安全。理解这些原理和实现细节，有助于在实际编程中选择合适的集合类型，提高代码的效率和可维护性。 HashMap的扩容机制简述HashMap默认的负载因子（load factor）是0.75。负载因子定义了HashMap在触发扩容之前，允许的元素数量与容量的比例。具体来说，当HashMap中的元素个数超过当前容量的75%时，就会触发扩容操作。 扩容操作分为两个主要步骤： 扩展哈希表的长度：HashMap会将当前的容量扩展为原来的两倍。例如，如果当前容量是16，扩容后容量将变为32。 重新分配数据：扩容后，HashMap需要将旧哈希表中的数据重新分配到新的哈希表中。由于新的容量是原来的两倍，元素在新哈希表中的位置可能会发生变化。 负载因子为何选择0.75？负载因子的选择是一个权衡性能和空间利用率的过程。负载因子为0.75是一个经验值，它在以下两个方面取得了平衡： 减少哈希冲突：当负载因子较大时（例如0.8或0.9），数组中的元素密度增加，导致哈希冲突的概率上升，从而降低查询和插入操作的效率。 避免频繁扩容：当负载因子较小时（例如0.5或0.6），虽然哈希冲突减少，但扩容的频率增加，导致空间利用率降低，且频繁的扩容操作也会带来额外的性能开销。 为什么是扩容2倍？扩容2倍，其实是一个非常巧妙的设计。在扩容过程中，HashMap并不需要重新计算每个元素的哈希值。这是因为HashMap的容量总是2的幂次（例如16、32、64等），这使得扩容后的新索引可以通过简单的位运算来确定。 具体来说，当容量从n扩展到2n时，新的索引位置可以通过以下方式计算： 如果元素的哈希值在高位新增的bit为0，则元素在新哈希表中的位置与原位置相同。 如果元素的哈希值在高位新增的bit为1，则元素在新哈希表中的位置为原位置加上旧容量（即原索引 + oldCap）。 如下图示，元素在重新计算hash之后，因为n变为2倍，那么n-1的mask范围在高位多1bit(红色)，因此新的index遵循上述规则计算： 扩展：为什么Hash计算时有一个右移16位操作？在Java的HashMap中，哈希值的计算并不仅仅依赖于对象的hashCode()方法，而是通过一个额外的位运算来进一步优化哈希值的分布。具体来说，HashMap在计算哈希值时，会进行一个右移16位的操作，然后将结果与原哈希值进行异或运算。这个操作的目的是为了减少哈希碰撞，提高HashMap的性能。 源码分析 我们来看一下HashMap中计算哈希值的源码： 在这段代码中，h是对象的原始哈希值，h &gt;&gt;&gt; 16表示将h右移16位。然后，将右移后的结果与原哈希值进行异或运算（^），得到最终的哈希值。 为什么需要右移16位？ 哈希值h是一个32位的整数。如果不进行任何处理，直接使用h作为哈希值，可能会导致哈希碰撞的概率增加。这是因为hashCode()方法返回的哈希值在低位可能会有较多的重复，尤其是在处理较小的数据集时。 通过将h右移16位，相当于将哈希值的高16位与低16位进行混合。这种混合操作可以有效地将高位信息引入到低位，从而减少哈希碰撞的可能性。具体来说： 右移16位：将哈希值的高16位移到低16位，这样低16位就包含了高16位的信息。 异或运算：通过异或运算，将高16位和低16位的信息进行混合，使得最终的哈希值在低位也包含了高位的信息。 通过右移16位并进行异或运算，HashMap能够更有效地利用哈希值的高位信息，减少哈希碰撞的概率。这种设计使得HashMap在处理大量数据时仍能保持较高的性能，确保键值对的快速查找和插入。 HashTable原理HashTable是一种基于哈希表的数据结构，用于存储键值对。其内部实现主要依赖于数组和链表的结合，以解决哈希冲突问题。 数据结构 数组：HashTable的主体是一个数组，数组的每个元素称为“桶”（bucket）。数组的大小通常是固定的，或者可以根据需要进行动态调整。 链表：当不同的键值对通过哈希函数计算得到的哈希值相同，即发生哈希冲突时，HashTable使用链表来存储这些键值对。每个桶中可以存储一个链表，链表中的每个节点包含一个键值对。 线程安全 HashTable的所有公共方法都使用了synchronized关键字进行修饰，这意味着每个方法在执行时都会获取对象级别的锁。这种设计确保了HashTable在多线程环境下的线程安全性，但同时也带来了性能上的开销，因为每次方法调用都会导致线程阻塞。 HashMap和HashTable的区别HashMap和HashTable都是Java中用于存储键值对的数据结构，但它们在实现和使用上有一些关键的区别。以下是它们的主要区别： 1. 线程安全性 HashMap：HashMap是线程不安全的。这意味着在多线程环境下，如果多个线程同时对同一个HashMap进行操作，可能会导致数据不一致或其他并发问题。 HashTable：HashTable是线程安全的。HashTable的所有公共方法都使用了synchronized关键字进行修饰，确保在多线程环境下操作的安全性。例如： 这意味着在同一时刻，只有一个线程可以执行HashTable的某个方法，从而避免了并发问题。 2. 性能 HashMap：由于HashMap不是线程安全的，因此在单线程环境下，HashMap的性能通常优于HashTable。HashMap不需要额外的同步开销，因此在读写操作上更快。 HashTable：由于HashTable的方法都使用了synchronized关键字，因此在多线程环境下，HashTable的性能可能会受到影响。每次方法调用都需要获取锁，这会增加额外的开销。 3. 允许null值 HashMap：HashMap允许键和值为null。也就是说，你可以将null作为键或值存储在HashMap中。 HashTable：HashTable不允许键或值为null。如果尝试将null作为键或值存储在HashTable中，会抛出NullPointerException。 4. 迭代器 HashMap：HashMap的迭代器是快速失败的（fail-fast）。如果在迭代过程中，HashMap的结构发生了变化（例如添加或删除元素），迭代器会抛出ConcurrentModificationException。 HashTable：HashTable的迭代器也是快速失败的，但它的迭代器实现方式与HashMap略有不同。 总结 HashMap和HashTable在实现和使用上有显著的区别。HashMap适用于单线程环境，性能更好，允许null键和值；而HashTable适用于多线程环境，线程安全，但不允许null键和值，性能相对较差。在现代Java编程中，推荐使用ConcurrentHashMap来替代HashTable，以获得更好的性能和扩展性。 ConcurrentHashMap原理ConcurrentHashMap是Java中用于并发环境下的高效键值对存储数据结构。它在Java 1.7及之前版本和Java 1.8及之后版本有不同的实现方式。以下是ConcurrentHashMap在不同版本中的实现原理及其优化的详细介绍。 Java 1.7及之前版本的实现在Java 1.7及之前版本中，ConcurrentHashMap采用了分段锁（Segment）技术来实现线程安全。其核心结构是数组+链表，具体分为以下几个部分： Segment数组：ConcurrentHashMap内部包含一个Segment数组，每个Segment相当于一个小的HashMap，并且是一个可重入锁（ReentrantLock）。 HashEntry数组：每个Segment内部包含一个HashEntry数组，HashEntry用于存储键值对数据。每个HashEntry是一个链表结构的元素。 分段锁技术： ConcurrentHashMap将数据分成多个段（Segment），每个段相当于一个小的HashMap，并且有自己的锁。 当一个线程访问某个段的数据时，只需要锁住该段，而不影响其他段的数据访问。这样就实现了并发访问，提高了并发性能。 缺点： 虽然分段锁技术提高了并发性能，但由于使用了链表结构，当链表过长时，访问速度会变慢，因为需要遍历链表。 Java 1.8及之后版本的实现在Java 1.8及之后版本中，ConcurrentHashMap进行了优化，采用了数组+链表&#x2F;红黑树的数据结构，并使用volatile+CAS或synchronized来实现线程安全。具体实现如下： 数组+链表&#x2F;红黑树：ConcurrentHashMap内部使用一个数组来存储数据，每个数组元素（桶）可以是一个链表或红黑树。当链表长度超过一定阈值时，链表会转换为红黑树，以提高查找效率。 volatile+CAS：用于实现无锁的并发操作，例如初始化容器或设置节点。 synchronized：用于在发生冲突时对桶的头节点加锁，确保线程安全。 添加元素的过程： 初始化容器：如果容器为空，使用volatile+CAS来初始化容器。 计算桶位置：根据存储的元素计算桶的位置。 CAS设置节点：如果计算结果为空，则利用CAS设置该节点。 synchronized加锁：如果桶不为空，则使用synchronized对桶的头节点加锁，然后遍历桶中的元素，并替换或新增节点到桶中。 转换为红黑树：最后判断是否需要将链表转换为红黑树，以提高查找效率。 优点： 锁粒度更小：通过只对桶的头节点加锁，锁的粒度相比分段锁更小，减少了锁的竞争，提高了并发性能。 红黑树优化：当链表过长时，转换为红黑树，提高了查找效率。 总结 ConcurrentHashMap在Java 1.8及之后版本中通过数组+链表&#x2F;红黑树的数据结构和volatile+CAS或synchronized的并发控制机制，实现了高效的并发访问。相比Java 1.7及之前版本的分段锁技术，Java 1.8及之后版本的ConcurrentHashMap在锁粒度和查找效率上都有显著提升，更适合高并发的场景。 一句话归纳：Java 1.8及之后版本的ConcurrentHashMap通过对桶的头节点加锁，锁的粒度更小，减少了锁的竞争，同时通过红黑树优化提高了查找效率，从而实现了更高的并发性能。 分段锁怎么加锁的？在 ConcurrentHashMap 中，将整个数据结构分为多个 Segment，每个 Segment 都类似于小的 HashMap，每个 Segment 都有自己的锁，不同 Segment 之间的操作互不影响，从而提高并发性能。 在 ConcurrentHashMap 中，对于插入、更新、删除等操作，需要先定位到具体的 Segment,然后再在该 Segment 上加锁，而不是像传统的 HashMap 一样对整个数据结构加锁。这样可以使得不同 Segment 之间的操作并行进行，提高了并发性能。 什么是可重入锁？可重入锁（Reentrant Lock）是一种同步机制，允许同一个线程多次获取同一个锁，而不会导致死锁。它是 Java 中 java.util.concurrent.locks.ReentrantLock 类的实现。 同一个线程可以多次获取同一个锁，而不会被自己阻塞。每次获取锁时，锁的计数器会递增；每次释放锁时，计数器会递减。只有当计数器归零时，锁才会完全释放。 JDK 1.7 ConcurrentHashMap中的分段锁是用了 ReentrantLock，是一个可重入的锁。 为什么使用了synchronized还要使用CAS？CAS是一种无锁的并发控制机制，它通过硬件级别的原子操作来实现线程安全。CAS操作包括三个参数：内存位置、预期值和更新值。CAS操作会先比较内存位置的当前值是否等于预期值，如果相等，则将内存位置的值更新为新值，并返回成功；否则，返回失败。CAS的主要作用是： 无锁操作：CAS操作不需要加锁，因此不会阻塞线程，减少了线程切换的开销。 原子性：CAS操作是原子的，可以确保在多线程环境下对共享变量的修改是安全的。 在ConcurrentHashMap中，CAS主要用于一些不需要加锁的简单操作，例如初始化容器、设置节点等。 综合原因 在ConcurrentHashMap中，synchronized和CAS结合使用的原因如下： 减少锁竞争：CAS操作是无锁的，可以在不加锁的情况下完成一些简单的操作，减少了锁的竞争，提高了并发性能。 优化初始化：在初始化ConcurrentHashMap时，使用CAS操作可以确保只有一个线程能够成功初始化容器，避免了多个线程同时初始化容器的问题。 提高并发性能：对于一些不需要遍历链表或红黑树的操作，使用CAS可以避免加锁，从而提高并发性能。例如，在添加元素时，如果桶为空，可以直接使用CAS操作设置节点，而不需要加锁。 细粒度锁控制：synchronized用于在发生哈希冲突时对桶的头节点加锁，确保线程安全地操作链表或红黑树。通过只对头节点加锁，锁的粒度更小，减少了锁的竞争，提高了并发性能。 ConcurrentHashMap使用了乐观锁还是悲观锁？ConcurrentHashMap在实现并发控制时，综合运用了乐观锁和悲观锁的机制。 容器初始化： ​ 当容器为空时，ConcurrentHashMap使用volatile关键字和CAS（Compare-And-Swap）操作进行初始化。volatile确保了变量的可见性，而CAS则是一种乐观锁机制，通过原子操作来确保初始化的线程安全性。 元素添加： 如果容器不为空，ConcurrentHashMap会根据元素的哈希值计算其在桶中的位置。 如果计算出的位置为空，则再次使用CAS操作来设置该节点，这是一种乐观锁的实现方式，通过原子操作来避免锁的开销。 如果计算出的位置不为空，ConcurrentHashMap会使用synchronized关键字对桶进行锁定，这是一种悲观锁的实现方式。锁定后，线程会遍历桶中的数据，并根据需要替换或新增节点。如果桶中的元素数量达到一定阈值，还会将链表结构转换为红黑树，以优化查找性能。 总结 ConcurrentHashMap在并发控制中灵活运用了乐观锁和悲观锁： 乐观锁：主要用于初始化和空桶位置的设置，通过CAS操作实现，减少了锁的开销。 悲观锁：用于非空桶的访问和修改，通过synchronized关键字实现，确保了操作的原子性和线程安全。 "},{"title":"Java集合-List篇","date":"2024-09-09T05:14:01.000Z","url":"/2024/09/09/Java%E9%9B%86%E5%90%88-List%E7%AF%87/","tags":[["List","/tags/List/"]],"categories":[["Java","/categories/Java/"],["集合","/categories/Java/%E9%9B%86%E5%90%88/"]],"content":"在Java集合框架中，List接口提供了多种实现类，如Vector、ArrayList和LinkedList，每种实现类都有其特定的特点和适用场景。Vector是线程安全的动态数组，适用于多线程环境；ArrayList是线程不安全的动态数组，适用于单线程环境，性能较高；LinkedList是双向链表，适用于频繁插入和删除元素的场景。ArrayList在多线程环境下存在数据不一致的问题，可以通过Collections.synchronizedList()、CopyOnWriteArrayList或手动同步来实现线程安全。CopyOnWriteArrayList通过写时复制机制和ReentrantLock保证线程安全，适用于读多写少的场景。理解这些集合类型的特点和实现原理，有助于在实际编程中选择合适的集合类型，提高代码的效率和可维护性。 List的实现List接口是Java中常用的集合接口之一，提供了多种实现类，以满足不同的需求。以下是List接口的三个主要实现类及其特点和适用场景。 1. VectorVector是一个线程安全的动态数组，实现了List接口。Vector的所有方法都是同步的，因此适用于多线程环境。 特点 线程安全：所有方法都使用synchronized关键字进行同步。 动态调整大小：可以根据需要动态调整大小。 存储结构：存储的是对象数组，当空间不足时会创建一个新的数组，并将原来的数组拷贝过去。 性能较低：由于同步机制，Vector的性能通常低于非线程安全的ArrayList。 适用场景 需要线程安全的场景。 对性能要求不高的场景。 2. ArrayListArrayList是一个线程不安全的动态数组，实现了List接口。ArrayList在性能上比Vector快很多，适用于单线程环境。 特点 线程不安全：没有同步机制，性能较高。 动态调整大小：可以根据需要动态调整大小。 存储结构：存储的是对象数组，当空间不足时会创建一个新的数组，并将原来的数组拷贝过去。 扩容机制：扩容时增加50%的容量。 适用场景 单线程环境。 对性能要求较高的场景。 3. LinkedListLinkedList是一个双向链表，实现了List接口。LinkedList也是线程不安全的，适用于需要频繁插入和删除元素的场景。 特点 线程不安全：没有同步机制，性能较高。 存储结构：使用链表结构，插入和删除元素效率高。 随机访问较慢：由于不是顺序存储，访问元素时需要遍历链表，效率较低。 适用场景 需要频繁插入和删除元素的场景。 对随机访问性能要求不高的场景。 示例代码 概括 Vector：线程安全，适用于多线程环境，但性能较低。 ArrayList：线程不安全，适用于单线程环境，性能较高，适合随机访问。 LinkedList：线程不安全，适用于频繁插入和删除元素的场景，但随机访问性能较低。 了解ArrayList为什么 ArrayList 不是线程安全的？在高并发添加数据的情况下，ArrayList 会暴露以下三个问题： 部分值为 null（此前我们没有插入过 null 值） 索引越界 数组的 size 大小与插入 add 情况不一致 原因分析ArrayList 的 add 方法源码如下： 可以看到，插入一个元素的操作分为三步： step1：判断当前数组空间是否足够插入一个元素，不够则调用 grow 方法扩容。 step2：在 size 索引位置设置值为新插入的元素。 step3：维护 size 值加 1。 问题根源1. 部分值为 null： 在高并发情况下，多个线程可能同时执行 elementData[size] = e;，导致某些线程覆盖了其他线程插入的值，也就是在同一个索引位置设置值，但最后不同的线程都会给size++，最终导致部分值为 null。 2. 索引越界： 线程1走到扩容那里发现当前size是9，数组容量是10不用扩容，cpu让出执行权，线程2也发现不用扩容，这时候数组的容量就是10，而线程1 set完之后size++，这时候线程2再进来size就是10，数组的大小只有10，而你要设置下标索引为10的就会越界(数组的下标索引从0开始): 3. 数组的 size 大小与插入 add 情况不一致： 由于 size++ 操作不是原子的，多个线程同时执行 size++ ，可能取得size值都是同一个(比如size为10，线程1将把size赋值为11，在线程1未完成赋值时线程二也在执行，此时获取到的size值还是10，最后执行了两次size++，实际上只有效一次size++)，会导致 size 值与实际插入的元素数量不一致。 如何将ArrayList变成线程安全的？ArrayList 是 Java 中常用的动态数组实现，但它并非线程安全。这意味着在多线程环境下，多个线程同时访问和修改 ArrayList 可能会导致数据不一致或其他并发问题。 使用 Collections.synchronizedList() 底层实现： Collections.synchronizedList() 方法会返回一个包装了原始 ArrayList 的同步视图。其底层实现原理是为每个方法调用添加一个同步块（synchronized block），确保同一时刻只有一个线程可以访问该列表。 使用 CopyOnWriteArrayList 底层实现： CopyOnWriteArrayList 是 java.util.concurrent 包中的一个线程安全列表实现。其核心思想是**写时复制 (Copy-On-Write)**：当列表发生修改时，会创建一个列表的副本，并在副本上进行修改，而原始列表保持不变。 手动同步 底层实现： 手动同步需要开发者显式地使用 synchronized 关键字来控制对 ArrayList 的访问。 ArrayList 的扩容机制当向 ArrayList 中新增元素时，如果下一个索引位置超出了当前数组的容量，则会触发扩容机制。扩容机制的具体步骤如下： 扩容步骤 计算新的容量：一般情况下，新的容量为原来容量的 1.5 倍。 计算公式：newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1) 创建新的数组：根据计算出的新容量，创建一个新的数组。 复制原有数组元素：将原有数组中的元素逐个复制到新的数组中。 更新引用：将 ArrayList 内部的数组引用更新为新的数组。 完成扩容：扩容完成后，可以继续插入新的元素。 代码示例 以下是 ArrayList 扩容机制的部分源码： 关键点 扩容因子： 通常为 1.5 倍，但具体实现可能会根据需求调整。 数组复制： 使用 Arrays.copyOf() 方法进行数组复制，效率较高。 内存开销： 扩容会导致内存占用增加，因此在初始化 ArrayList 时，合理设置初始容量可以减少扩容次数，提高性能。 线程安全的 List 如何实现线程安全的？以 CopyOnWriteArrayList 为例，其底层也是使用数组保存数据。CopyOnWriteArrayList 通过以下方式实现线程安全： 1. 使用 volatile 关键字修饰数组CopyOnWriteArrayList 使用 volatile 关键字修饰数组，确保线程对数组对象重新赋值后，其他线程可以感知到。 2. 写时复制 (Copy-On-Write) 机制CopyOnWriteArrayList 的核心思想是**写时复制 (Copy-On-Write)**：当列表发生修改时，会创建一个列表的副本，并在副本上进行修改，而原始列表保持不变。 关键方法： add 方法： setArray 方法： 3. 读操作无需加锁由于写操作是在副本上进行的，读操作可以直接访问原始数组，无需加锁，从而提高了读操作的性能。 4. 使用 ReentrantLock 保证写操作的线程安全在写操作（如 add、remove 等）时，CopyOnWriteArrayList 使用 ReentrantLock 保证同一时刻只有一个线程可以进行写操作，从而确保线程安全。 总结 CopyOnWriteArrayList 通过以下方式实现线程安全： 使用 volatile 关键字修饰数组，确保线程对数组对象重新赋值后，其他线程可以感知到。 采用写时复制 (Copy-On-Write) 机制，写操作在副本上进行，读操作无需加锁。 使用 ReentrantLock 保证写操作的线程安全。 这种设计使得 CopyOnWriteArrayList 在读多写少的场景下具有较高的性能，但在写操作频繁的场景下，由于需要频繁复制数组，性能会受到影响。 "},{"title":"Java集合-概念篇","date":"2024-09-09T05:14:00.000Z","url":"/2024/09/09/Java%E9%9B%86%E5%90%88-%E6%A6%82%E5%BF%B5%E7%AF%87/","categories":[["Java","/categories/Java/"],["集合","/categories/Java/%E9%9B%86%E5%90%88/"]],"content":"在Java编程中，集合（Collection）是一种用于存储和操作一组对象的核心数据结构。Java集合框架（Java Collections Framework, JCF）提供了丰富的集合类型，以满足不同的编程需求。 什么是集合？在计算机科学中，集合（Collection）是一种用于存储和操作一组对象的数据结构。集合框架提供了一系列接口和类，用于处理不同类型的集合。Java的集合框架（Java Collections Framework, JCF）是Java标准库的一部分，提供了丰富的集合类型，以满足不同的编程需求。 集合的分类1. List：List是一种有序集合，允许存储重复元素。List接口提供了精确控制每个元素插入位置的能力，并且可以通过索引访问指定元素。 实现类： ArrayList：基于动态数组实现，支持高效的随机访问，但在插入和删除元素时可能需要移动大量元素。 Vector：类似于ArrayList，但线程安全，适用于多线程环境。 Stack：继承自Vector，实现后进先出（LIFO）的数据结构。 2.Set：Set是一种不允许存储重复元素的集合，每个元素都是唯一的。Set接口不保证元素的顺序。 实现类： HashSet：基于哈希表实现，提供了平均时间复杂度为O(1)的插入、删除和查找操作。 TreeSet：基于红黑树实现，元素按自然顺序或自定义顺序排序。 LinkedHashSet：结合了HashSet和LinkedList的特性，既保证了元素的唯一性，又维护了插入顺序。 3. Map：Map是一种键值对（Key-Value）的集合，存储键和值之间的映射关系。Map中的键是无序且唯一的，而值则可以重复。Map接口没有继承Collection接口，但它是集合框架的一部分。 实现类： HashMap：基于哈希表实现，提供了平均时间复杂度为O(1)的插入、删除和查找操作。 TreeMap：基于红黑树实现，键按自然顺序或自定义顺序排序。 Hashtable：类似于HashMap，但线程安全，适用于多线程环境。 特点 动态大小：集合的大小是动态的，可以根据需要添加或删除元素，而数组的大小是固定的。 类型安全：集合通常只能存储对象，而不能直接存储基本数据类型。然而，Java提供了自动装箱（Autoboxing）机制，使得基本数据类型可以自动转换为对应的包装类，从而存储在集合中。 丰富的操作：集合框架提供了丰富的操作方法，如添加、删除、查找、排序等，使得开发者可以方便地对集合进行操作。 集合是Java中用于存储和操作一组对象的重要数据结构。通过使用集合框架，开发者可以灵活地处理不同类型的数据，提高代码的效率和可维护性。理解不同集合类型的特点和适用场景，有助于在实际编程中做出更合理的选择。 数组与集合的对比分析概述在计算机科学中，数组（Array）和集合（Collection）是两种常见的数据结构，它们在存储和操作数据方面有着显著的区别。理解这些区别对于编写高效、可维护的代码至关重要。 主要区别 长度特性：数组的长度在初始化时是固定的，无法动态调整。这意味着一旦数组被创建，其大小就无法改变。集合的长度是动态的，可以根据需要添加或删除元素。集合的实现通常基于动态数据结构，如链表或动态数组，允许在运行时调整大小。 数据类型：数组可以存储基本数据类型（如int、char、float等）以及对象（如String、Object等）。数组中的所有元素必须是相同的数据类型。集合通常只能存储对象，而不能直接存储基本数据类型。然而，Java等语言提供了自动装箱（Autoboxing）机制，使得基本数据类型可以自动转换为对应的包装类（如Integer、Character等），从而存储在集合中。 访问机制：数组中的元素通过索引直接访问，时间复杂度为O(1)。这意味着访问数组中的任意元素都非常高效。集合中的元素通常需要通过迭代器（Iterator）或其他访问方法来获取。访问集合中的元素的时间复杂度可能因集合的实现方式而异，通常为O(n)或O(log n)。 常见集合类型 ArrayList：基于动态数组实现的集合，支持随机访问，但在插入和删除元素时可能需要移动大量元素，导致性能下降。适用于需要频繁随机访问元素的场景。 Map：键值对（Key-Value）的集合，每个键唯一对应一个值。常见的实现包括HashMap和TreeMap。适用于需要通过键快速查找值的场景。 HashMap：基于哈希表实现的Map，提供了平均时间复杂度为O(1)的插入、删除和查找操作。适用于需要高效查找和插入操作的场景。 TreeMap：基于红黑树（Red-Black Tree）实现的Map，元素按自然顺序或自定义顺序排序。适用于需要有序访问键值对的场景。 PriorityQueue：基于堆（Heap）实现的优先队列，元素按优先级排序，支持高效的插入和删除操作。适用于需要按优先级处理元素的场景，如任务调度、事件处理等。 总结 数组和集合各有优缺点，选择合适的数据结构取决于具体的应用场景和需求。数组适用于需要固定大小且高效随机访问的场景，而集合则适用于需要动态调整大小和灵活操作的场景。理解这些区别有助于开发者在实际编程中做出更合理的选择，从而提高代码的性能和可维护性。 Java中线程安全的集合在多线程编程中，确保数据的一致性和线程安全是至关重要的。Java的java.util包中只有少数几个类是线程安全的，而大多数集合类是非线程安全的。为了满足高并发环境下的需求，Java提供了java.util.concurrent包，其中包含多种线程安全的集合类。 java.util包中的线程安全集合1. VectorVector是一个线程安全的动态数组，实现了List接口。Vector的所有方法都是同步的，因此适用于多线程环境。 线程安全：所有方法都使用synchronized关键字进行同步。 性能较低：由于同步机制，Vector的性能通常低于非线程安全的ArrayList。 2. HashtableHashtable是一个线程安全的哈希表，实现了Map接口。Hashtable的所有方法都是同步的，因此适用于多线程环境。 线程安全：所有方法都使用synchronized关键字进行同步。 性能较低：由于同步机制，Hashtable的性能通常低于非线程安全的HashMap。 java.util.concurrent包中的线程安全集合1. 并发Set并发Set是一种线程安全的集合，不允许存储重复元素。 ConcurrentSkipListSet：基于跳表（Skip List）实现的有序集合，适用于高并发环境下的插入、删除和查找操作。 CopyOnWriteArraySet：基于CopyOnWriteArrayList实现，适用于读多写少的场景，写操作会创建一个新的副本，读操作则直接访问当前副本。 2. 并发Map并发Map是一种线程安全的键值对集合，存储键和值之间的映射关系。 ConcurrentHashMap：它与HashTable的区别在于二者加锁的粒度不同。ConcurrentHashMap基于分段锁（Segmented Locking）实现的哈希表，提供了高效的并发访问能力，适用于高并发环境下的插入、删除和查找操作。 ConcurrentSkipListMap：基于跳表实现的有序映射，适用于高并发环境下的插入、删除和查找操作。 3. 并发Queue并发Queue是一种线程安全的队列，支持先进先出（FIFO）的数据结构。 ConcurrentLinkedQueue：基于链表实现的无界队列，适用于高并发环境下的插入和删除操作。 ArrayBlockingQueue：基于数组实现的有界阻塞队列，适用于生产者-消费者模型。 LinkedBlockingQueue：基于链表实现的有界阻塞队列，适用于生产者-消费者模型。 PriorityBlockingQueue：基于堆实现的无界阻塞队列，元素按优先级排序。 4. 并发List并发List是一种线程安全的列表，允许存储重复元素。 CopyOnWriteArrayList：基于CopyOnWrite机制实现，适用于读多写少的场景，写操作会创建一个新的副本，读操作则直接访问当前副本。 5. 并发Dequeue并发Dequeue是一种线程安全的双端队列，支持在队列的两端进行插入和删除操作。 ConcurrentLinkedDeque：基于链表实现的无界双端队列，适用于高并发环境下的插入和删除操作。 LinkedBlockingDeque：基于链表实现的有界阻塞双端队列，适用于生产者-消费者模型。 总结Java的java.util.concurrent包提供了多种线程安全的集合类，适用于不同的并发场景。这些集合类通过各种并发控制机制（如分段锁、跳表、CopyOnWrite机制等）确保了在多线程环境下的数据一致性和线程安全。理解这些集合类的特点和适用场景，有助于开发者在实际编程中选择合适的并发集合，从而提高系统的并发性能和可靠性。 Collection与Collections在Java集合框架中，Collections和Collection是两个关键的概念，它们在集合操作中扮演着不同的角色。理解它们的区别和联系对于掌握Java集合框架至关重要。 Collection接口Collection是Java集合框架中的一个基础接口，位于java.util包中。它是所有集合类的基础接口，定义了一系列通用的集合操作方法。 主要功能： 遍历：Collection接口提供了iterator()方法，用于遍历集合中的元素。 插入：Collection接口提供了add()和addAll()方法，用于向集合中插入元素。 删除：Collection接口提供了remove()和removeAll()方法，用于从集合中删除元素。 查询：Collection接口提供了contains()和containsAll()方法，用于查询集合中是否包含指定元素。 大小：Collection接口提供了size()方法，用于获取集合的大小。 Collection接口有许多实现类，如ArrayList、LinkedList、HashSet、TreeSet等，它们分别实现了不同的集合类型和特性。 Collections工具类Collections是Java提供的一个工具类，位于java.util包中。它提供了一系列静态方法，用于对集合进行各种操作，如排序、查找、替换、反转等。 主要功能： 排序：Collections.sort()方法可以对实现了List接口的集合进行排序。 查找：Collections.binarySearch()方法可以在有序集合中进行二分查找。 替换：Collections.replaceAll()方法可以替换集合中的所有指定元素。 反转：Collections.reverse()方法可以反转集合中元素的顺序。 同步：Collections.synchronizedCollection()方法可以将集合包装为线程安全的集合。 不可变集合：Collections.unmodifiableCollection()方法可以创建一个不可变的集合视图。 Collections工具类的方法可以对实现了Collection接口的类进行操作，如List和Set。 区别与联系区别 类型：Collections是一个工具类，而Collection是一个接口。 功能：Collections提供了一系列静态方法，用于对集合进行各种操作；而Collection定义了集合的基本操作方法。 使用方式：Collections的方法通常通过类名直接调用，如Collections.sort(list)；而Collection的方法需要通过集合对象调用，如list.add(element)。 联系 依赖关系：Collections工具类的方法通常作用于实现了Collection接口的集合对象。 共同目标：Collections和Collection都是为了方便开发者对集合进行操作和管理，提高代码的效率和可维护性。 集合遍历在Java中，集合遍历是常见的操作之一。不同的遍历方式适用于不同的场景，选择合适的遍历方式可以提高代码的可读性和性能。以下是几种常见的集合遍历方式及其示例代码片段。 1. 使用foreach循环foreach循环是Java中最简单和常用的遍历方式之一。它适用于遍历任何实现了Iterable接口的集合。 2. 使用Iterator迭代器Iterator是一种传统的遍历方式，适用于需要在遍历过程中修改集合的情况。 3. 使用Stream API（Java 8+）Stream API是Java 8引入的一种函数式编程风格，适用于对集合进行复杂的操作和转换。 "},{"title":"What is Java ?（四）","date":"2024-07-24T05:14:00.000Z","url":"/2024/07/24/What-is-Java-%EF%BC%88%E5%9B%9B%EF%BC%89/","tags":[["序列化","/tags/%E5%BA%8F%E5%88%97%E5%8C%96/"],["I/O","/tags/I-O/"],["其他","/tags/%E5%85%B6%E4%BB%96/"]],"categories":[["Java","/categories/Java/"],["基础","/categories/Java/%E5%9F%BA%E7%A1%80/"]],"content":"内容：序列化、I/O、其他 本篇博客是笔者作为初学者记录自己对Java一些基本概念的理解。内容参考了大量网络资源，篇幅很长，旨在作为个人学习笔记，供自己日后回顾和复习。 序列化怎么把一个对象从一个JVM转移到另一个JVM？ 使用序列化和反序列化：将对象序列化为字节流（objectoutputstream），发送到另一个JVM中再进行字节流反序列化（objectinputstream）。 使用消息传递机制：可以使用消息队列等方式，通过网络传输对象。常见的消息队列系统包括 RabbitMQ、Kafka 等。 远程调用（RPC）：使用远程调用框架（如 RMI、gRPC、Dubbo 等）进行跨 JVM 的对象调用。 使用数据共享：使用数据共享，如将对象所需的数据存入数据库或共享缓存中，能够让其他JVM访问得到。 序列化和反序列化有没有更好的设计？Java默认的序列化虽然方便，但也存在一些问题： 无法跨语言：Java序列化格式是Java特有的，它依赖于Java的内部数据结构和类型系统。因此，生成的序列化数据无法直接被其他编程语言（如Python、C++、JavaScript等）解析和使用。这意味着如果你需要在不同的编程语言之间共享数据，Java序列化机制就无法满足需求。为了实现跨语言的互操作性，通常需要使用更通用的序列化格式，如JSON、XML、Protocol Buffers、Avro等。 容易被攻击：Java序列化机制存在安全漏洞，尤其是在反序列化过程中。攻击者可以通过构造恶意的序列化数据，在反序列化时执行任意代码，从而导致安全问题。这种攻击被称为“反序列化漏洞”或“反序列化攻击”。为了防止这种攻击，开发者需要非常小心地处理反序列化过程，或者使用更安全的序列化机制，如JSON、Protocol Buffers等，这些机制通常不会引入类似的安全风险。 性能差：Java序列化机制在性能方面表现不佳，尤其是在处理大量数据时。主要原因包括： 序列化后的数据体积较大：Java序列化生成的数据通常比其他序列化格式（如Protocol Buffers）更大，这会导致更高的网络传输成本和存储成本。 序列化和反序列化过程较慢：Java序列化机制在处理复杂对象时，性能开销较大。尤其是在需要频繁进行序列化和反序列化操作的场景中，性能问题会更加明显。 更好的设计 为了解决上述问题，可以使用以下几种替代方案： 1. JSON 序列化JSON（JavaScript Object Notation）是一种轻量级的数据交换格式，易于阅读和编写，同时也易于解析和生成。许多编程语言都支持JSON序列化，因此可以实现跨语言的数据交换。 示例代码（使用 Jackson 库） 2. Protocol BuffersProtocol Buffers（ProtoBuf）是Google开发的一种轻量级、高效的序列化格式，支持多种编程语言，并且具有更好的性能和安全性。 示例代码（使用 Protocol Buffers） 首先，定义一个 .proto 文件： 然后，生成Java类并使用： 3. ThriftApache Thrift 是另一种高效的序列化框架，支持多种编程语言，并且具有良好的性能和扩展性。 示例代码（使用 Thrift） 首先，定义一个 .thrift 文件： 然后，生成Java类并使用： 为了解决Java默认序列化机制存在的问题，可以使用JSON、Protocol Buffers和Thrift等替代方案。这些方案具有更好的跨语言支持、更高的安全性和更好的性能，适用于不同的应用场景。 I&#x2F;OBIO、NIO、AIO：Java I&#x2F;O模型的演进在Java编程中，I&#x2F;O操作是不可或缺的一部分。随着技术的发展，Java提供了多种I&#x2F;O模型，以满足不同场景下的需求。本文将简要介绍三种主要的I&#x2F;O模型：BIO（Blocking I&#x2F;O）、NIO（Non-blocking I&#x2F;O）和AIO（Asynchronous I&#x2F;O）。 1. BIO（Blocking I&#x2F;O）BIO是Java传统的I&#x2F;O模型，基于java.io包实现。它通过字节流（Byte Stream）和字符流（Character Stream）来处理数据。BIO的核心特点是同步阻塞，即在进行I&#x2F;O操作时，线程会被阻塞，直到操作完成。这种模型的执行顺序是线性的，代码编写简单直观，但处理效率较低，扩展性有限。 优缺点： 代码简单，易于理解和维护；适用于简单的I&#x2F;O操作场景。 处理效率低，尤其是在高并发环境下，线程阻塞会导致资源浪费；扩展性差，难以应对大规模并发请求。 2. NIO（Non-blocking I&#x2F;O）NIO是Java 1.4引入的一种新型I&#x2F;O模型，旨在解决BIO在高并发环境下的性能瓶颈。NIO的核心思想是同步非阻塞，通过以下三大组件实现： 通道（Channel）：类似于流，但支持双向数据传输。 缓冲区（Buffer）：用于存储数据的容器，支持直接内存操作，提高数据处理效率。 多路复用器（Selector）：用于管理多个通道，实现非阻塞I&#x2F;O操作。 NIO通过Selector机制，允许单个线程管理多个通道，从而避免了线程阻塞，提高了系统的并发处理能力。 优缺点： 非阻塞I&#x2F;O操作，提高了系统的并发处理能力；适用于高并发、低延迟的网络应用。 代码复杂度增加，需要理解Channel、Buffer和Selector等概念；调试和维护相对困难。 3. AIO（Asynchronous I&#x2F;O）AIO是NIO的进一步演进，提供了异步非阻塞的I&#x2F;O操作方式。在AIO模型中，当发起I&#x2F;O操作后，线程不会被阻塞，而是继续执行其他任务，I&#x2F;O操作由后台线程处理完成后，通过回调机制通知主线程。 AIO的核心组件包括： 异步通道（Asynchronous Channel）：支持异步I&#x2F;O操作的通道。 CompletionHandler：用于处理I&#x2F;O操作完成后的回调。 优缺点： 异步非阻塞，进一步提高了系统的并发处理能力；适用于需要高并发、高吞吐量的应用场景。 实现复杂，需要处理回调和异步编程的复杂性；对开发者的技术要求较高。 总结 BIO、NIO和AIO代表了Java I&#x2F;O模型的不同阶段，各自适用于不同的应用场景。BIO简单易用，但处理效率低；NIO通过非阻塞机制提高了并发处理能力，但增加了代码复杂度；AIO则进一步通过异步机制提升了系统的吞吐量，但实现难度较大。选择合适的I&#x2F;O模型，需要根据具体的应用需求和技术栈来决定。 NIO原理详解NIO（Non-blocking I&#x2F;O）是Java 1.4引入的一种新型I&#x2F;O模型，旨在提高I&#x2F;O操作的效率和系统的并发处理能力。NIO的核心思想是同步非阻塞，通过以下三大组件实现： 1. 核心组件 Selector（选择器&#x2F;多路复用器）：Selector是NIO同步机制的核心。它负责轮询多个Channel，检查它们是否准备好进行I&#x2F;O操作（如读、写等）。Selector的引入避免了线程在等待I&#x2F;O操作时的阻塞，从而提高了系统的并发处理能力。 Channel（通道）：Channel类似于传统的流（Stream），但支持双向数据传输。与流不同的是，Channel可以直接与Buffer进行数据交换，无需线程等待。常见的Channel类型包括FileChannel、SocketChannel和ServerSocketChannel。 Buffer（缓冲区）：Buffer是用于存储数据的容器，支持直接内存操作，提高了数据处理的效率。Buffer有多种类型，如ByteBuffer、CharBuffer等，分别用于处理不同类型的数据。 2. 工作原理NIO的工作原理可以概括为以下几个步骤： 注册Channel到Selector：首先，将需要监听的Channel注册到Selector上，并指定感兴趣的事件（如连接、读、写等）。 Selector轮询：Selector会定期轮询所有注册的Channel，检查它们是否准备好进行I&#x2F;O操作。如果某个Channel准备好，Selector会返回一个SelectionKey，表示该Channel可以进行相应的I&#x2F;O操作。 处理I&#x2F;O操作：当Selector检测到某个Channel准备好进行I&#x2F;O操作时，应用程序可以通过SelectionKey获取对应的Channel，并进行读写操作。数据在Channel和Buffer之间进行传输，无需线程等待。 非阻塞机制：由于Selector的轮询机制，线程在等待I&#x2F;O操作时不会被阻塞，可以继续处理其他任务。这种非阻塞机制大大提高了系统的并发处理能力。 3. 事件驱动机制NIO采用了事件驱动机制，当某个I&#x2F;O事件（如连接、读、写等）发生时，Selector会立即触发相应的事件处理逻辑，无需线程不断监视。这种机制减少了线程的空闲等待时间，提高了系统的响应速度。 4. 线程通信在NIO中，线程间通过notify和wait机制进行通信，减少了线程切换的开销。当某个I&#x2F;O操作完成时，线程可以通过notify通知其他线程继续处理，避免了不必要的线程切换。 总结 NIO通过Selector、Channel和Buffer三大组件，实现了同步非阻塞的I&#x2F;O操作。Selector负责轮询Channel，避免了线程在等待I&#x2F;O操作时的阻塞；Channel和Buffer支持高效的数据传输，无需线程等待。NIO的事件驱动机制和线程通信优化，进一步提高了系统的并发处理能力和响应速度。NIO适用于高并发、低延迟的网络应用场景，但需要开发者理解其复杂的工作原理和组件间的协作关系。 其他代理模式和适配器模式有什么区别？代理模式（Proxy Pattern）和适配器模式（Adapter Pattern）是两种常见的设计模式，它们在软件设计中有着不同的用途和实现方式。以下是它们的主要区别： 1. 定义和目的代理模式 定义：代理模式为其他对象提供一个代理或占位符，以控制对这个对象的访问。 目的：主要用于控制对对象的访问，可以在不改变原始对象的情况下，增加额外的功能（如权限控制、延迟初始化、日志记录等）。 适配器模式 定义：适配器模式将一个类的接口转换成客户端所期望的另一个接口。 目的：主要用于解决接口不兼容的问题，使得原本由于接口不匹配而无法一起工作的类可以协同工作。 2. 结构和实现代理模式 结构：代理模式通常包含一个代理类和一个真实主题类。代理类和真实主题类实现相同的接口，代理类内部持有真实主题类的引用。 实现：代理类在调用真实主题类的方法前后，可以执行额外的操作（如权限检查、日志记录等）。 适配器模式 结构：适配器模式通常包含一个适配器类、一个目标接口和一个被适配者类。适配器类实现目标接口，并在内部持有被适配者类的引用。 实现：适配器类将目标接口的方法调用转换为被适配者类的方法调用。 3. 使用场景代理模式 场景：当需要控制对某个对象的访问时，可以使用代理模式。例如： 远程代理：控制对远程对象的访问。 虚拟代理：延迟加载对象，直到真正需要时才创建。 保护代理：控制对敏感对象的访问权限。 日志代理：在方法调用前后记录日志。 适配器模式 场景：当需要将一个类的接口转换为另一个接口，以便与现有代码兼容时，可以使用适配器模式。例如： 旧系统与新系统的接口不兼容。 第三方库的接口与现有代码不匹配。 需要复用已有的类，但其接口不符合需求。 总结 代理模式：主要用于控制对对象的访问，可以在不改变原始对象的情况下，增加额外的功能。 适配器模式：主要用于解决接口不兼容的问题，使得原本由于接口不匹配而无法一起工作的类可以协同工作。 集合多属性排序假如有一个学生数组，想要按照成绩降序、学号升序排序，如何实现？ 在Java中，可以使用Comparator接口来实现集合的多属性排序。以下是一个示例，展示了如何对学生数组按照成绩降序、学号升序进行排序。 示例代码 代码说明 Student类：定义了一个学生类，包含学号（id）、姓名（name）和成绩（score）三个属性。 Main类：包含主方法，用于创建学生数组并进行排序。 排序逻辑： 使用Arrays.sort方法对学生数组进行排序。 通过Comparator接口实现多属性排序： 首先按成绩降序排序（Double.compare(s2.getScore(), s1.getScore())）。 如果成绩相同，按学号升序排序（Integer.compare(s1.getId(), s2.getId())）。 输出结果：排序后的学生数组将按照成绩降序、学号升序的顺序输出。 输出示例 tips 理解Comparator接口的用法，特别是与Collections.sort()方法结合使用时，关键在于理解compare方法的返回值如何影响排序结果。 Comparator接口的compare方法 Comparator接口的compare方法定义如下： 这个方法的返回值决定了o1和o2的相对顺序： 如果返回负值，表示o1应该排在o2之前（即o1小于o2）。 如果返回0，表示o1和o2相等，顺序不变。 如果返回正值，表示o1应该排在o2之后（即o1大于o2）。 升序和降序的实现 为了实现升序或降序排序，你需要根据compare方法的返回值来调整对象的相对顺序。 升序排序 升序排序意味着较小的元素应该排在前面。因此，如果o1小于o2，compare方法应该返回负值。 降序排序 降序排序意味着较大的元素应该排在前面。因此，如果o1小于o2，compare方法应该返回正值。 native方法native方法是Java中的一种特殊方法，它使用native关键字进行声明，表示该方法的实现是由非Java代码（通常是C&#x2F;C++代码）提供的。native方法允许Java程序调用底层操作系统或其他语言编写的库，从而实现Java与本地代码的交互。 volatile 和 synchronized 的区别volatile 和 synchronized 是 Java 中用于处理并发问题的关键字，但它们的作用和使用场景有所不同。 1. volatile作用： 保证可见性： 当一个线程修改了 volatile 变量的值时，其他线程能够立即看到这个修改。 禁止指令重排序： volatile 变量的读写操作不会被 JVM 优化重排序，从而保证有序性。 适用场景： 单个变量的读写： volatile 适用于单个变量的读写操作，特别是当这个变量被多个线程共享时。 状态标志： 例如，用于控制线程是否继续运行的标志变量。 代码示例： 2. synchronized作用： 互斥访问： synchronized 关键字用于实现互斥访问，确保同一时刻只有一个线程可以执行被 synchronized 修饰的代码块或方法。 保证可见性： 进入 synchronized 代码块或方法时，会清空工作内存中的变量副本，从主内存中重新加载；退出时，会将工作内存中的变量值刷新到主内存。 适用场景： 多个变量的读写： synchronized 适用于多个变量的读写操作，特别是当这些变量需要保持一致性时。 复杂的同步逻辑： 例如，需要对多个操作进行同步的场景。 代码示例： 区别总结 特性 volatile synchronized 作用 保证可见性、禁止指令重排序 互斥访问、保证可见性 适用场景 单个变量的读写、状态标志 多个变量的读写、复杂的同步逻辑 性能 相对较高，因为不需要加锁 相对较低，因为需要加锁 使用范围 仅限于变量 可以用于方法、代码块 原子性 不能保证复合操作的原子性 可以保证复合操作的原子性 "},{"title":"What is Java ?（三）","date":"2024-07-23T05:14:00.000Z","url":"/2024/07/23/Java-is-What-%EF%BC%88%E4%B8%89%EF%BC%89/","tags":[["注解","/tags/%E6%B3%A8%E8%A7%A3/"],["异常","/tags/%E5%BC%82%E5%B8%B8/"],["Object","/tags/Object/"],["Java8新特性","/tags/Java8%E6%96%B0%E7%89%B9%E6%80%A7/"]],"categories":[["Java","/categories/Java/"],["基础","/categories/Java/%E5%9F%BA%E7%A1%80/"]],"content":"内容：注解、异常、Object、Java8新特性 本篇博客是笔者作为初学者记录自己对Java一些基本概念的理解。内容参考了大量网络资源，篇幅很长，旨在作为个人学习笔记，供自己日后回顾和复习。 注解在Java中，注解（Annotation）是一种元数据（metadata），它提供了关于程序代码的额外信息，但本身并不直接影响程序的执行。注解可以用于类、方法、字段、参数、局部变量等程序元素上，用于在编译时、运行时或部署时提供额外的信息。 注解本质是一个继承了Annotation的特殊接口，其具体实现类是Java运行时生成的动态代理类。我们通过反射获取注解时，返回的是Java运行时生成的动态代理对象。通过代理对象调用自定义注解的方法，会最终调用AnnotationlnvocationHandler的invoke方法。该方法会从memberValues这个Map中索引出对应的值。而memberValues的来源是Java常量池。 注解的原理 定义注解：注解是通过@interface关键字定义的。例如： 这个注解MyAnnotation有两个元素：value和count。value是必需的，而count有一个默认值1。 元注解：元注解是用于注解其他注解的注解。Java提供了几个内置的元注解，用于控制注解的行为： @Retention：指定注解的保留策略，即注解在什么阶段有效（源码、编译时、运行时）。 RetentionPolicy.SOURCE：注解仅在源码中保留，编译时丢弃。 RetentionPolicy.CLASS：注解在编译时保留，但运行时不可见。 RetentionPolicy.RUNTIME：注解在运行时保留，可以通过反射获取。 @Target：指定注解可以应用的目标类型（类、方法、字段等）。 ElementType.TYPE：类、接口、枚举。 ElementType.METHOD：方法。 ElementType.FIELD：字段。 ElementType.PARAMETER：方法参数。 ElementType.CONSTRUCTOR：构造函数。 ElementType.LOCAL_VARIABLE：局部变量。 ElementType.ANNOTATION_TYPE：注解类型。 ElementType.PACKAGE：包。 @Documented：指定注解是否包含在JavaDoc中。 @Inherited：指定注解是否可以被子类继承。 @Repeatable：指定注解是否可以重复应用在同一个元素上。 使用注解：注解可以应用在类、方法、字段等程序元素上。例如： 处理注解：注解本身并不做任何事情，它们需要通过某种方式被处理才能发挥作用。处理注解的方式主要有两种： 编译时处理：使用注解处理器（Annotation Processor）在编译时处理注解。例如，Lombok库使用注解处理器在编译时生成代码。 运行时处理：使用反射（Reflection）在运行时获取注解信息。例如： 这个方法通过反射检查类上是否存在MyAnnotation注解，并获取注解的值。 总结 注解的原理可以概括为以下几点： 定义注解：使用@interface关键字定义注解，并指定注解的元素。 元注解：使用元注解控制注解的行为，如保留策略、目标类型等。 使用注解：将注解应用在程序元素上。 处理注解：通过编译时处理或运行时反射来处理注解，使其发挥作用。 应用作用域在Java中，注解可以应用于多种程序元素，包括类、方法、字段（属性）、参数、局部变量等。注解的作用域（即注解可以应用的目标类型）由@Target元注解指定。以下是一些常见的注解作用域及其对应的ElementType枚举值： 1. 类注解可以应用于类、接口、枚举等类型定义上。对应的ElementType是TYPE。 使用示例： 2. 方法注解可以应用于方法定义上。对应的ElementType是METHOD。 使用示例： 3. 属性（字段）注解可以应用于字段（属性）定义上。对应的ElementType是FIELD。 使用示例： 其他作用域除了上述常见的类、方法和字段，注解还可以应用于其他程序元素： 参数：注解可以应用于方法参数上。对应的ElementType是PARAMETER。 使用示例： 构造函数：注解可以应用于构造函数上。对应的ElementType是CONSTRUCTOR。 使用示例： 局部变量：注解可以应用于局部变量上。对应的ElementType是LOCAL_VARIABLE。 使用示例： 注解类型：注解可以应用于其他注解类型上。对应的ElementType是ANNOTATION_TYPE。 使用示例： 包：注解可以应用于包声明上。对应的ElementType是PACKAGE。 使用示例： 异常啥是异常？Java异常主要基于两大类：Throwable类及其子类。Throwable的子类主要有两个重要的子类：Error和Exception，它们分别代表了不同类型的异常情况。 ErrorError表示运行环境错误，极难恢复，不能指望程序自己处理这些异常。比如系统崩溃、连接错误等。比如OutOfMemoryError内存不足错误、StackOverflowError栈溢出错误。通常程序不应该去捕获这些错误，因为它们表示系统级别的严重问题，程序无法自行恢复。 ExceptionException表示运行程序错误，根据发生时期又可以分为编译时异常和运行时异常。 编译时异常（Checked Exception）在代码编译时出现的异常，必须显式处理（捕获或声明抛出）。这些异常通常是程序外部的异常，比如文件不存在、无法找到类等。对于这些异常必须使用try-catch块捕获异常，或者在方法签名中使用throws关键字声明抛出异常。 运行时异常（Unchecked Exception）程序运行过程中出现的异常，通常由程序逻辑错误引起，不需要显式处理。 常见异常： NullPointerException：空指针异常。 IllegalArgumentException：非法参数异常。 ClassCastException：类转换异常。 IndexOutOfBoundsException：数组越界异常。 虽然运行时异常不需要显式处理，但建议在代码中进行适当的检查和处理，以提高程序的健壮性。 异常处理机制Java提供了异常处理机制，通过try-catch语句块来捕获和处理异常。以下是Java常见的异常处理方式： try块：包含可能抛出异常的代码。 catch块：捕获并处理异常。 throw语句：用于手动抛出异常。 finally块：无论是否发生异常，都会执行的代码块，通常用于资源清理。 示例代码 以下是一个完整的异常处理示例，展示了如何使用try-catch语句块、throw语句和finally块： 抛出异常为什么不用throws？如果说异常是未检查异常（Unchecked Exception）或已经在方法内部处理，就不需要再使用throws声明了。 Unchecked Exception：未检查异常，是继承自RuntimeException类或者Error类的异常，编译器不强制要求进行异常处理。因此对于这些异常，不需要在方法签名中使用throws来声明。 捕获和异常处理：另一种常见情况是已经在方法内部捕获了可能抛出的异常并在方法内部处理它们。 try-catch的执行顺序正常情况下会按顺序执行try块中的代码，当运行过程中出现异常则跳转到相应的catch异常捕获块，最后无论是否出现异常，总会执行finally块。 常见问题 以下这段代码最后会返回什么？ 答案是返回&#39;b&#39;。因为try的return语句先执行，压入返回栈中，而finally中的return方法后执行，也压入栈中，返回结果先弹出栈上方的元素，所以会返回&#39;b&#39;，也就是说finally中的return会覆盖try块的返回语句。 示例代码 以下是一个示例，展示了try-catch-finally块的执行顺序： 输出结果： 在这个示例中，try块中的return &#39;a&#39;语句先执行，但被finally块中的return &#39;b&#39;语句覆盖，因此最终返回值为&#39;b&#39;。 Object“&#x3D;&#x3D;”与“equals”有什么区别？对于字符串变量，==与equals方法是不同的。==判断的是两个对象的引用是否相同，即比较两个对象的内存首地址是否指向同一个对象，而equals则判断的是两个对象的值是否相同。 示例代码片段，对于字符串来说： 对于非字符串来说，若没有对equals方法重写，则==和equals是相同的，都是比较两个对象的内存首地址是否相同，即比较两个对象的引用是否指向同一个变量。 示例代码片段，对于非字符串对象： “equals”与“hashCode”equals方法用于比较两个对象是否相等，而hashCode方法返回对象的哈希码值。在Java中，如果两个对象通过equals方法比较相等，那么它们的hashCode值必须相同。反之，如果两个对象的hashCode值相同，它们不一定相等。 示例代码片段 StringBuilder和StringBuffer由于String类型是不可变的（immutable），每次对String进行修改操作时，都会创建一个新的String对象，这可能会导致性能问题。为了解决这个问题，Java提供了StringBuilder和StringBuffer类，它们是可变的（mutable），允许在原有对象上进行修改操作。 区别 线程安全： StringBuffer是线程安全的，适用于多线程环境。 StringBuilder不是线程安全的，适用于单线程环境，性能更高。 性能： 通常情况下，StringBuilder的性能优于StringBuffer，因为StringBuffer需要维护线程安全，会带来额外的开销。 String的性能通常是最差的，因为每次修改都会创建新的对象。 使用场景： 在单线程环境中，推荐使用StringBuilder以获得最佳性能。 在多线程环境中，如果需要线程安全，使用StringBuffer。 示例代码片段 Java 1.8 新特性Stream APIJava 8 引入了 Stream API，提供了一种更加高效的数据处理方式，特别是对于集合的操作如过滤、排序、映射等。使用 Stream 能够充分利用多核处理器的优势进行并行处理。 示例 以下是一个简单的示例，展示了如何使用 Stream API 对集合进行操作： 解释 创建列表： 使用 Arrays.asList 创建一个包含整数的列表。 使用 Stream API： numbers.stream()：创建一个顺序流。 filter(n -&gt; n % 2 == 0)：过滤出偶数。 map(n -&gt; n * n)：将每个偶数计算平方。 collect(Collectors.toList())：将结果收集到一个列表中。 使用并行流： numbers.parallelStream()：创建一个并行流，充分利用多核处理器的优势。 输出 总结 Stream API 提供了一种简洁、高效的方式来处理集合数据，支持顺序和并行处理，能够显著提高数据处理的性能。通过合理使用 Stream API，可以简化代码并提高程序的可读性和可维护性。 Stream流的并行API即 ParallelStream。并行流其实带着“分而治之”的思想，在处理源数据时，将数据分成多个子流，然后将处理结果汇总为一个流对象。底层逻辑是使用 Fork&#x2F;Join 框架来实现并行处理。 对CPU密集型的任务来说，并行流使用ForkJoinPool线程池，为每个CPU分配一个任务，这是非常有效率的，但是如果任务不是CPU密集的，而是I&#x2F;O密集的，并且任务数相对线程数比较大，那么直接用Parallelstream并不是很好的选择。 CompletableFutureCompletableFuture 是 Java 8 引入的一个类，用于支持异步编程和非阻塞操作。它实现了 Future 接口，并提供了更强大的功能，如组合多个异步任务、处理异常、以及在任务完成时执行回调等。 主要功能 异步执行任务：使用 CompletableFuture.supplyAsync 或 CompletableFuture.runAsync 方法来异步执行任务。 任务组合：使用 thenApply、thenAccept、thenRun 等方法来组合多个异步任务。 异常处理：使用 exceptionally 方法来处理异常。 任务完成时的回调：使用 whenComplete 方法在任务完成时执行回调。 示例 以下是一个简单的示例，展示了如何使用 CompletableFuture 进行异步编程： 解释 异步执行任务：CompletableFuture.supplyAsync(() -&gt; &#123; ... &#125;)：异步执行一个返回值为 String 的任务。 任务完成时的回调：future.thenAccept(result -&gt; &#123; ... &#125;)：在任务完成时执行回调，输出结果。 异常处理：future.exceptionally(ex -&gt; &#123; ... &#125;)：处理任务执行过程中可能抛出的异常。 等待任务完成：future.get()：等待任务完成并获取结果。 输出 再来一个简单的组合示例： "},{"title":"What is Java ?（二）","date":"2024-07-20T05:14:00.000Z","url":"/2024/07/20/What-is-Java-%EF%BC%88%E4%BA%8C%EF%BC%89/","tags":[["拷贝","/tags/%E6%8B%B7%E8%B4%9D/"],["泛型","/tags/%E6%B3%9B%E5%9E%8B/"],["对象","/tags/%E5%AF%B9%E8%B1%A1/"],["反射","/tags/%E5%8F%8D%E5%B0%84/"]],"categories":[["Java","/categories/Java/"],["基础","/categories/Java/%E5%9F%BA%E7%A1%80/"]],"content":"内容：拷贝、泛型、对象、反射 本篇博客是笔者作为初学者记录自己对Java一些基本概念的理解。内容参考了大量网络资源，篇幅很长，旨在作为个人学习笔记，供自己日后回顾和复习。 拷贝浅拷贝和深拷贝的区别浅拷贝（Shallow Copy）浅拷贝复制了一个对实例对象的引用，因此在内存中这两个对象指向的是同一个对象。换句话说，浅拷贝只复制了对象的引用，而不是对象本身。 示例代码 解释：original 和 copy 指向同一个对象，因此修改 copy 的值也会影响 original。 深拷贝（Deep Copy）深拷贝新建一个一模一样的实例对象，两个对象的引用指向的是不同的地址。换句话说，深拷贝复制了对象本身，而不是对象的引用。 示例代码 解释：original 和 copy 指向不同的对象，因此修改 copy 的值不会影响 original。 图示 实现深拷贝的方法常用的深拷贝方法有三种： 实现 Cloneable 接口的 clone 方法 使用序列化和反序列化 手写递归复制 1. 实现 Cloneable 接口的 clone 方法通过实现 Cloneable 接口并重写 clone 方法，可以实现深拷贝。需要注意的是，clone 方法默认是浅拷贝，因此需要手动处理对象的深拷贝。 示例代码 2. 使用序列化和反序列化通过将对象序列化为字节流，然后再反序列化为新的对象，可以实现深拷贝。这种方法适用于实现了 Serializable 接口的对象。 示例代码 3. 手写递归复制通过手写递归方法，逐层复制对象的每个字段，可以实现深拷贝。这种方法适用于任何对象，但需要手动处理每个字段的复制。 示例代码 总结 实现 Cloneable 接口的 clone 方法：适用于简单的对象，需要手动处理深拷贝。 使用序列化和反序列化：适用于实现了 Serializable 接口的对象，可以自动处理深拷贝。 手写递归复制：适用于任何对象，需要手动处理每个字段的复制。 泛型什么是泛型？泛型是 Java 语言中的一个重要特性，它允许类、接口和方法在定义时使用一个或多个类型参数，而这些参数在实际运行时才会指定具体的参数类型。泛型提供了一种在编译时进行类型检查的机制，从而提高代码的类型安全性和可读性。 为什么需要泛型？泛型的主要目的是提高代码的类型安全性和可读性，具体体现在以下几个方面： 适用于多种类型执行相同的代码： 泛型允许在定义类、接口和方法时使用类型参数，从而可以在不同的类型上执行相同的代码。 类型安全： 泛型在编译时进行类型检查，确保类型的一致性，避免运行时类型转换错误。 使用泛型可以减少强制类型转换的需求，提高代码的可读性和安全性。 示例代码 总结 泛型：允许在定义类、接口和方法时使用类型参数，提高代码的类型安全性和可读性。 类型安全：泛型在编译时进行类型检查，避免运行时类型转换错误。 减少强制类型转换：使用泛型可以减少强制类型转换的需求，提高代码的可读性和安全性。 通过这些特性，泛型在 Java 编程中提供了更强大的类型检查和代码复用能力，使得代码更加健壮和易于维护。 对象创建对象的方式 使用new关键字： 这是最常见和最直接的对象创建方式。通过调用类的构造函数来实例化对象。 示例： 使用clone方法： 通过调用对象的clone方法来创建对象的副本。需要注意的是，类必须实现Cloneable接口。 示例： 使用反序列化： 通过将对象序列化为字节流，然后再反序列化来创建对象。这通常用于对象的持久化存储和传输。 示例： 使用Class类的newInstance方法： 通过调用Class类的newInstance方法来创建对象。需要注意的是，该方法要求类具有无参构造函数。 示例： 使用Constructor的newInstance方法： 通过调用Constructor类的newInstance方法来创建对象。这种方式允许使用带参数的构造函数。 示例： new的对象什么时候回收？通过关键字new创建的对象，由Java的垃圾回收器（Garbage Collector, GC）负责回收。垃圾回收器的工作是在程序运行过程中自动进行的，它会周期性地检测不再被引用的对象，并将其回收以释放内存。 回收时机 Java对象的回收时机是由垃圾回收器根据一些算法来决定的，主要有以下几种情况： 引用计数法：当某个对象的引用计数为0时，表示该对象不再被引用，可以被回收。然而，Java并不采用引用计数法，因为它无法解决循环引用的问题。 可达性分析算法：从根对象（如方法区中的类静态属性、方法中的局部变量等）出发，通过对象之间的引用链进行遍历。如果存在一条引用链到达某个对象，则说明该对象是可达的；反之，不可达的对象将被回收。可达性分析算法是Java垃圾回收器主要采用的方法。 终结器（Finalizer）：如果对象重写了finalize()方法，垃圾回收器会在回收该对象之前调用finalize()方法。对象可以在finalize()方法中进行一些清理操作。然而，终结器机制的使用不被推荐，因为它的执行时间是不确定的，可能会导致不可预测的性能问题。 流程如下： 反射什么是反射？Java反射机制是指在运行状态中，任意一个类都能知道这个类中的所有方法和属性，并且任意对象都能调用这个类对象的属性和方法。这种动态获取的信息和调用对象方法的功能称为Java的反射机制。 反射机制如图所示： 动态性： 反射允许在运行时动态地获取类的完整结构信息，包括类名、父类、方法和属性等，并调用其方法（包括私有方法），而不需要在编译时确定。 示例：通过Class.forName()方法动态加载类，并使用getMethods()、getFields()等方法获取类的结构信息。 灵活性： 反射提供了灵活的编程方式，可以在运行时根据需要创建对象、调用方法和访问属性。 示例：使用反射API动态地创建对象实例，即使在编译时不知道具体的类名。这是通过Class类的newInstance()方法或Constructor对象的newInstance()方法实现的。 访问私有成员： 反射可以访问类的私有成员（如私有方法和私有属性），这在正常情况下是不允许的。 示例：通过Field类的setAccessible(true)方法绕过访问控制，使用get()和set()方法访问和修改私有字段的值。 反射常见应用场景 框架开发：许多框架（如Spring、Hibernate）使用反射来动态加载和配置类，实现依赖注入和AOP（面向切面编程）等功能。 序列化和反序列化：在对象的序列化和反序列化过程中，反射用于动态地访问和设置对象的属性。 动态代理：反射与动态代理结合使用，可以在运行时创建代理对象，实现方法的拦截和增强。 单元测试：单元测试框架（如JUnit）使用反射来动态地发现和执行测试方法。 插件化系统：反射用于动态加载和执行插件，使得系统具有扩展性和灵活性。 ORM框架：ORM（对象关系映射）框架使用反射来将数据库表映射到Java对象，并动态地生成SQL语句。 反射的优缺点优点 灵活性：反射提供了极大的灵活性，允许在运行时动态地操作类和对象。 扩展性：反射使得系统具有更好的扩展性，可以通过插件或配置文件动态加载和执行代码。 缺点 性能开销：反射操作通常比直接调用方法或访问属性要慢，因为它涉及到动态解析和安全检查。 安全风险：反射可以访问和修改类的私有成员，这可能会导致安全问题。 代码可读性：反射代码通常比直接调用方法或访问属性的代码更复杂，可读性较差。 "},{"title":"What is Java ?（一）","date":"2024-07-15T05:14:00.000Z","url":"/2024/07/15/What-is-Java-%EF%BC%88%E4%B8%80%EF%BC%89/","tags":[["Java基本概念","/tags/Java%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/"],["数据类型","/tags/%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/"],["面向对象","/tags/%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1/"]],"categories":[["Java","/categories/Java/"],["基础","/categories/Java/%E5%9F%BA%E7%A1%80/"]],"content":"内容：Java基本概念、数据类型、面向对象 本篇博客是笔者作为初学者记录自己对Java一些基本概念的理解。内容参考了大量网络资源，篇幅很长，旨在作为个人学习笔记，供自己日后回顾和复习。 概念Java的特点Java语言以其三大核心特点著称： 跨平台性：Java的口号“一次编译，处处运行”体现了其强大的跨平台能力。Java源代码经过编译后生成字节码文件（.class文件），这些字节码文件可以在任何安装了Java虚拟机（JVM）的平台上运行。需要注意的是，虽然Java语言本身是跨平台的，但JVM并非跨平台，因此在不同的操作系统上需要安装相应的JDK（Java Development Kit）。 面向对象：Java是一门严格遵循面向对象编程范式的语言。它将现实世界中的业务逻辑抽象为对象，并通过对象的属性和行为来描述这些逻辑，从而使得代码更贴近现实世界的模型，便于理解和维护。 自动内存管理：Java内置了垃圾回收机制，能够自动回收不再使用的内存资源，避免了开发者手动管理内存的繁琐工作。这一特性大大减少了内存泄漏和内存溢出等常见问题，提升了程序的稳定性和开发效率。 Java如何实现跨平台Java之所以能够实现跨平台运行，关键在于其核心组件——Java虚拟机（Java Virtual Machine，简称JVM）。JVM是Java Development Kit（JDK）中的一个重要组成部分，它负责将编译后的字节码文件解释并执行。 具体来说，Java源代码首先被编译成与平台无关的字节码文件（.class文件）。这些字节码文件随后被JVM解释执行。由于JVM在不同的操作系统上都有相应的实现版本，因此相同的字节码文件可以在安装了相应JVM的任何操作系统上运行。 这种机制使得Java具备了“一次编译，处处运行”的特性，极大地提高了代码的可移植性。开发者只需编写一次代码，并将其编译成字节码，就可以在多种平台上运行，而无需针对不同平台进行额外的编译工作。 Java与其他编程语言的区别与人类能够理解的自然语言不同，计算机只能理解由“0”和“1”组成的机器指令集。常见的编程语言如C&#x2F;C++、Java、Python、TypeScript等属于高级语言，这些语言编写的代码机器本身无法直接理解，需要经过特定的处理才能转化为机器指令。根据处理方式的不同，编程语言可以分为两大类： 编译型语言： 代表语言：C&#x2F;C++ 特点：源代码在运行前需要通过编译器编译成机器码，生成可执行文件。这种方式的优点是执行速度快，但缺点是可移植性较差，因为生成的机器码通常是针对特定平台的。 解释型语言： 代表语言：Python 特点：源代码在运行时由解释器逐行解释并执行。这种方式的优点是跨平台性好，但缺点是执行速度相对较慢。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Java结合了编译型和解释型语言的特点，采用了编译+解释+即时编译（Just-In-Time Compilation，JIT）的执行方式，JVM解释执行流程图如下： 编译阶段： Java源代码首先被编译成字节码文件（.class文件），这些字节码文件是与平台无关的中间代码。 解释阶段： 字节码文件在运行时由Java虚拟机（JVM）解释执行，JVM将字节码翻译成特定平台的机器指令。 需要注意的是，字节码文件在JVM中并不仅仅被解释执行，同时也会使用即时编译技术进行优化。 即时编译（JIT）： 即时编译技术允许JVM在运行时将频繁执行的字节码直接编译成机器码，从而提高执行效率。 在JVM中，使用程序计数器（Program Counter，PC）来跟踪当前执行的字节码指令。当某个字节码指令被执行到一定次数时，JVM会启用即时编译技术。 JIT编译器会监控字节码的执行频率，当发现某些代码块频繁执行时，会将这些代码块编译成机器码，并缓存起来，以便后续执行时直接使用机器码，从而提高执行速度。 这种混合执行方式使得Java既具备了编译型语言的高效性，又具备了解释型语言的跨平台性。开发者只需编写一次代码，并将其编译成字节码，就可以在安装了JVM的任何平台上运行，从而实现了“一次编译，处处运行”的特性。 总结来说，Java通过其独特的编译+解释执行方式，在保持高效性的同时，实现了高度的跨平台性，这是它与其他编程语言的主要区别之一。 JDK、JRE、JVMJDK、JRE和JVM是Java开发和运行环境中的三个核心组件，它们之间的关系如下： JDK（Java Development Kit）：JDK是Java开发工具包，包含了开发Java应用程序所需的所有工具和库。主要组件包括编译器（javac）、调试工具（jdb）、Java标准库和其他开发工具所需的库。JDK中包含了JRE，因此开发者可以在本地运行和测试他们编写的Java程序。 JRE（Java Runtime Environment）：JRE是Java程序运行时所需的最小环境，包括一组Java库和JVM。主要组件包括Java标准库和JVM，确保Java程序能够在任何安装了JRE的系统上运行。 JVM（Java Virtual Machine）：JVM是Java虚拟机，是Java程序运行的核心环境。主要功能包括字节码解释执行、内存管理（包括垃圾回收）、安全性和跨平台性。JVM使得Java程序能够在不同的操作系统上运行，实现了“一次编译，处处运行”的特性。 三者的关系 JDK包含JRE：JDK是开发工具包，包含了开发Java应用程序所需的所有工具和库，其中就包括JRE。 JRE包含JVM：JRE是运行Java程序所需的最小环境，包含了Java库和JVM。 简而言之，JDK是开发工具包，JRE是运行环境，JVM是执行引擎。JDK包含JRE，JRE包含JVM。 数据类型基本数据类型Java中有8种基本数据类型，主要分为3类： 数值型： 整型：byte、short、int、long 浮点型：float、double 字符型：char 布尔型：boolean 各个数据类型所占字节数和取值范围表示如下（一个字节占8个bit位）： 数据类型 字节数 默认值 取值范围 byte 1 0 -128 到 127（-2^7~2^7-1） short 2 0 -32,768 到 32,767（-2^15~2^15-1） int 4 0 -2,147,483,648 到 2,147,483,647（-2^31~2^31-1） long 8 0L -9,223,372,036,854,775,808 到 9,223,372,036,854,775,807（-2^63~2^63-1） float 4 0.0f 大约 ±3.4E+38（有效位数为6-7位） double 8 0.0d 大约 ±1.7E+308（有效位数为15位） char 2 ‘\\u0000’ 0 到 65,535（Unicode字符） boolean 1 false true 或 false 数据类型转换数据类型转换方式在Java中，数据类型转换主要有以下几种方式： 自动类型转换（隐式转换） 当目标类型的范围大于源类型时，Java会自动将源类型转换为目标类型，无需显式的类型转换。例如： 将 int 转换为 long 将 float 转换为 double 强制类型转换（显式转换） 当目标类型的范围小于源类型时，需要使用强制类型转换将源类型转换为目标类型。这可能导致数据丢失或溢出。语法为： 例如： 将 long 转换为 int 将 double 转换为 int 字符串转换 Java提供了将字符串表示的数据转换为其他类型数据的方法。例如： 将字符串转换为整型 int，可以使用 Integer.parseInt() 方法。 将字符串转换为浮点型 double，可以使用 Double.parseDouble() 方法。 数值之间的转换 Java提供了一些数值类型之间的转换方法，如将整型转换为字符型、将字符型转换为整型等。这些转换方式可以通过类型的包装类来实现，例如 Character 类、Integer 类等提供了相应的转换方法。 类型互转可能出现的问题 数据丢失 当将一个范围较大的数据类型转换为一个范围较小的数据类型时，可能会发生数据丢失。例如：将一个 long 类型的值转换为 int 类型时，如果 long 值超出了 int 类型的范围，转换结果将是截断后的低位部分，高位部分的数据将丢失。 数据溢出 与数据丢失相反，当将一个范围较小的数据类型转换为一个范围较大的数据类型时，可能会发生数据溢出。例如：将一个 int 类型的值转换为 long 类型时，转换结果会填充额外的高位空间，但原始数据仍然保持不变。 精度损失 在进行浮点数类型的转换时，可能会发生精度损失。例如：将一个单精度浮点数（float）转换为双精度浮点数（double）时，精度可能会损失。 类型不匹配导致的错误 在进行类型转换时，需要确保源类型和目标类型是兼容的。如果两者不兼容，可能会导致编译错误或运行时错误。 基本数据类型与包装类为何需要包装类？在Java中，包装类（Wrapper Classes）的存在有以下几个重要原因： 对象封装： 包装类将基本数据类型（如 int、char、boolean 等）封装成对象，使得这些基本数据类型可以像对象一样进行操作。例如，Integer 类不仅封装了 int 类型的数据，还提供了许多处理 int 数据的方法，如 parseInt()、valueOf() 等。 集合类的支持： Java中的集合类（如 ArrayList、HashMap 等）只能存储对象，不能直接存储基本数据类型。因此，如果需要将基本数据类型存储在集合中，必须将其包装成对应的包装类对象。例如，将 int 类型的数据存储在 ArrayList 中时，需要将其转换为 Integer 对象。 方法参数和返回值： 许多Java方法和API要求使用对象作为参数或返回值，而不是基本数据类型。例如，java.util.Collections 类中的许多方法都要求使用 List&lt;Integer&gt; 而不是 List&lt;int&gt;。 提供额外功能： 包装类提供了许多有用的方法来处理基本数据类型，如类型转换、字符串解析、比较等。例如，Integer 类提供了parseInt() 方法将字符串转换为 int，Double 类提供了 parseDouble() 方法将字符串转换为 double。 以下是包装类应用的示例代码： 包装类及其对应的基本数据类型： 包装类 对应的基本数据类型 Byte byte Short short Integer int Long long Float float Double double Character char Boolean boolean 通过使用包装类，Java开发者可以更方便地处理基本数据类型，并充分利用面向对象编程的优势。 基本数据类型与包装类的转换：装箱和拆箱在Java中，装箱（Boxing）和拆箱（Unboxing）是基本数据类型与其对应的包装类之间的自动转换过程。 装箱（Boxing）装箱是指将基本数据类型转换为其对应的包装类对象。Java编译器会自动完成这个过程，称为自动装箱。例如： 在这个例子中，int 类型的 num 被自动转换为 Integer 对象 wrappedNum。 拆箱（Unboxing）拆箱是指将包装类对象转换为其对应的基本数据类型。Java编译器也会自动完成这个过程，称为自动拆箱。例如： 在这个例子中，Integer 对象 wrappedNum 被自动转换为 int 类型的 num。 装箱和拆箱的应用场景 集合类：集合类（如 ArrayList、HashMap 等）只能存储对象，因此需要将基本数据类型装箱后才能存储在集合中。例如： 方法参数和返回值：许多方法要求使用对象作为参数或返回值，因此需要将基本数据类型装箱后传递给这些方法。例如： 通过装箱和拆箱，Java开发者可以更方便地在基本数据类型和包装类之间进行转换，从而充分利用面向对象编程的优势。 自动装拆箱的弊端虽然自动装箱（Autoboxing）和自动拆箱（Auto-unboxing）为Java开发者提供了便利，但它们也存在一些潜在的弊端和需要注意的问题： 性能开销：自动装箱和拆箱涉及到对象的创建和销毁，这会带来一定的性能开销。频繁的装箱和拆箱操作可能会导致性能下降，尤其是在循环或大量数据处理的情况下。 空指针异常：自动拆箱时，如果包装类对象为 null，会抛出 NullPointerException。例如： 代码可读性：过多的自动装箱和拆箱可能会降低代码的可读性，尤其是在复杂的表达式中。例如： 类型转换错误：自动装箱和拆箱可能会导致类型转换错误，尤其是在混合使用不同类型的包装类时。例如： 虽然自动装箱和拆箱为Java开发者提供了便利，但在使用时需要注意其潜在的性能开销、空指针异常、代码可读性和类型转换错误等问题。合理使用自动装箱和拆箱，可以提高代码的简洁性和可读性，但过度依赖可能会带来不必要的麻烦。 有了包装类，还留着基本数据类型干啥？在Java中，保留基本数据类型（Primitive Types）而不全部使用包装类（Wrapper Classes）有以下几个重要原因： 性能优势： 内存占用：基本数据类型直接存储在栈内存中，占用空间小，访问速度快。而包装类对象存储在堆内存中，占用空间较大，访问速度相对较慢。 操作效率：基本数据类型的操作（如算术运算、逻辑运算）直接在硬件层面上进行，效率更高。而包装类对象的操作需要通过方法调用，效率较低。 简化编程： 代码简洁性：基本数据类型的使用使得代码更加简洁明了，减少了不必要的对象创建和销毁。 避免空指针异常：基本数据类型没有 null 值，因此不会出现空指针异常。而包装类对象可能为 null，需要额外的空值检查。 语言设计的一致性： 历史兼容性：Java从一开始就设计了基本数据类型，许多现有的代码库和框架都依赖于基本数据类型。完全移除基本数据类型会破坏大量的现有代码。 语言特性：基本数据类型是Java语言的一部分，提供了语言设计的一致性和完整性。 基本数据类型在内存占用、操作效率和代码简洁性方面具有显著优势，因此在性能敏感的场景中，使用基本数据类型是更好的选择。而包装类则提供了对象封装、集合类支持和额外功能等优势，适用于需要对象操作和面向对象编程的场景。 Java通过保留基本数据类型和提供包装类，兼顾了性能和功能需求，使得开发者可以根据具体场景选择合适的数据类型，从而实现高效、灵活的编程。 面向对象面向对象编程简介面向对象编程（Object-Oriented Programming, OOP）是一种编程范式，通过构建对象（对象具有属性和行为）来表示现实世界中的实体及其行为。这种编程思想使得代码更易于理解和维护。 面向对象编程的核心特性包括： 封装（Encapsulation）：将对象的属性和行为结合在一起，隐藏内部实现细节，仅通过接口与外界交互。封装增强了代码的安全性和独立性，简化了编程复杂度。 继承（Inheritance）：子类可以继承父类的属性和方法，从而实现代码的复用。继承有助于构建层次化的类结构，减少重复代码。 多态（Polymorphism）：多态允许不同的类对象对同一消息做出不同的响应。多态分为两种类型： 编译时多态（静态多态），通过方法重载实现，即同一个方法名在不同参数下有不同的实现。 运行时多态（动态多态），通过方法重写实现，即子类重写父类的方法，在运行时根据对象类型调用相应的方法。（接口的实现也属于运行时多态。） 啥是多态？以上对多态的解释有点点抽象，我们可以进一步讲讲。 多态的体现多态（Polymorphism）是面向对象编程中的一个核心概念，它允许不同的对象对同一消息做出不同的响应。多态性使得代码更加灵活、可扩展和易于维护。多态性主要体现在以下几个方面： 1. 方法重载（Overloading）方法重载是指在同一个类中定义多个同名方法，但这些方法的参数列表不同（参数类型、数量或顺序不同）。编译器在编译时根据调用时提供的参数类型和数量来决定调用哪个方法。 示例： 在这个示例中，Calculator 类中有三个 add 方法，但它们的参数列表不同。编译器根据调用时提供的参数类型和数量来决定调用哪个方法。 2. 方法重写（Overriding）方法重写是指子类重新定义父类中已有的方法，以实现不同的操作逻辑。重写的方法需要加上 @Override 注解。在程序运行时，系统会根据引用对象的实际类型来调用具体版本的方法。 示例： 在这个示例中，Dog 和 Cat 类都重写了 Animal 类的 makeSound 方法。在运行时，根据实际对象类型调用相应的方法。 3. 接口实现（Interface Implementation）接口实现是指多个类可以实现同一个接口，并提供各自的方法实现。接口实现体现了多态性，因为不同的类可以对同一个接口方法提供不同的实现。 示例： 在这个示例中，Circle 和 Rectangle 类都实现了 Shape 接口，并提供了各自的 draw 方法实现。在运行时，根据实际对象类型调用相应的方法。 4. 上转型与下转型（Upcasting and Downcasting） 上转型（Upcasting）：将子类对象赋值给父类引用，称为上转型。上转型是安全的，因为子类对象包含了父类的所有属性和方法。 下转型（Downcasting）：将父类引用强制转换为子类引用，称为下转型。下转型需要谨慎使用，因为如果父类引用指向的对象不是子类类型，会导致运行时错误。 示例： 在这个示例中，myAnimal 是 Animal 类型的引用，但实际上指向 Dog 对象。通过上转型，可以调用 Dog 重写的 makeSound 方法。通过下转型，可以调用 Dog 特有的 fetch 方法。 多态能够用来干啥？多态（Polymorphism）是面向对象编程中的一个核心特性，它允许子类替换父类，并在实际代码运行过程中调用子类的方法实现。多态性需要编程语言提供特殊的语法机制来实现，比如继承、接口类等。多态可以提高代码的扩展性和复用性，是许多设计模式、设计原则和编程技巧的基础。 面向对象设计原则：SOLID原则面向对象设计中有常见的五大设计原则，简称SOLID原则。SOLID原则是一组指导原则，旨在帮助开发者创建更灵活、可维护和可扩展的软件系统。这些原则分别是：单一职责原则（SRP）、开闭原则（OCP）、里氏替换原则（LSP）、接口隔离原则（ISP）和依赖倒置原则（DIP）。 1. 单一职责原则（Single Responsibility Principle, SRP）定义：一个类应该只有一个引起它变化的原因，即一个类应该只负责一个职责。 简单示例： 不好的设计：一个类既负责计算工资，又负责保存员工信息。 好的设计：将计算工资和保存员工信息分别放在两个不同的类中。 2. 开闭原则（Open&#x2F;Closed Principle, OCP）定义：软件实体（类、模块、函数等）应该对扩展开放，对修改关闭。即在不修改现有代码的情况下，可以通过扩展来增加新功能。 简单示例： 不好的设计：每次增加新图形时，都需要修改计算面积的代码。 好的设计：通过定义一个抽象的图形接口，新增图形时只需实现该接口，而不需要修改现有代码。 3. 里氏替换原则（Liskov Substitution Principle, LSP）定义：子类应该能够替换所有其父类的引用，而不会影响程序的正确性。为了保证数据安全，子类的行为应该与父类一致或更严格。 简单示例： 不好的设计：鸟类可以飞，但企鹅不能飞，子类行为与父类不一致。 好的设计：将飞行的行为抽象出来，只有能飞的鸟类才实现该行为。 4. 接口隔离原则（Interface Segregation Principle, ISP）定义：客户端不应该依赖于它不需要的接口，即接口应该小而精、细粒度。 简单示例： 不好的设计：一个接口包含多个方法，但某些类只需要其中一部分方法。 好的设计：将接口拆分为多个小接口，每个接口只包含相关的方法。 5. 依赖倒置原则（Dependency Inversion Principle, DIP）定义：高层模块不应该依赖于低层模块，二者都应该依赖于抽象。抽象不应该依赖于细节，细节应该依赖于抽象。 简单示例： 不好的设计：高层模块直接依赖于低层模块的具体实现。例如，一个高层模块直接创建并使用低层模块的对象。 好的设计：通过依赖抽象接口，高层模块不直接依赖于低层模块的具体实现，而是通过接口注入的形式调用实现。例如，高层模块依赖于一个抽象接口，并通过构造函数或setter方法注入具体的实现类。 抽象类和普通类、抽象类和接口的区别抽象类与普通类的区别抽象类和普通类都可以被继承，但它们在功能和使用场景上存在显著差异： 实例化能力： 抽象类：无法被实例化，通常作为基类使用，用于定义子类的通用行为和属性。 普通类：可以被实例化，用于创建具体的对象。 方法实现： 抽象类：可以包含抽象方法（没有具体实现的方法），也可以包含具体实现的方法。抽象类不能使用 final 修饰符，因为 final 修饰符用于禁止该类被继承或方法被子类重写，这与抽象类的设计目的相冲突。 普通类：必须实现所有方法，不能包含抽象方法。 静态方法： 抽象类：允许包含静态方法，但静态方法无法访问抽象类的实例成员，因为抽象类无法实例化。 普通类：允许包含静态方法，静态方法可以访问类的实例成员。 抽象类与接口的区别抽象类和接口在设计目的和使用方式上有所不同： 设计目的： 抽象类：用于定义类的通用行为和属性，提供部分实现，子类可以继承并扩展这些行为。 接口：用于定义一组行为契约，实现类必须遵循这些契约，接口不提供任何实现。 构造方法： 抽象类：可以包含构造方法，用于初始化抽象类的成员变量。 接口：不能包含构造方法，因为接口不涉及实例化。 方法实现： 抽象类：可以包含具体实现的方法，子类可以选择性地覆盖这些方法。 接口：除了定义静态方法外，其他方法默认是抽象的，必须由实现类来实现。但从 Java 8 开始，接口可以包含默认方法（default 方法），这些方法可以有具体实现，并且实现类可以选择性地覆盖这些默认方法。但注意，静态方法不能被实现类覆盖。 继承与实现： 抽象类：一个类只能继承一个抽象类。 接口：一个类可以实现多个接口。 成员变量： 抽象类：可以包含成员变量，这些变量可以是静态的、非静态的、常量等。 接口：只能包含静态常量（默认是 public static final）且必须赋予初始值，不能包含非静态成员变量。 访问修饰符： 抽象类：方法和成员变量可以使用所有访问修饰符（public、protected、private）。 接口：所有方法默认是 public，不能使用其他访问修饰符。成员变量默认是 public static final。 静态了解了面向对象的多态特性，那么Java中的静态也一同了解一下吧~ 静态变量和静态方法在 Java 中，静态变量和静态方法与类本身关联，而不与类的实例化对象关联。它们在内存中独此一份，可以被类的所有实例化对象共享。 静态变量（类变量）静态变量是通过 static 关键字修饰的变量，属于类而不属于实例对象。静态变量在类被加载时初始化，只会分配一次内存。所有的实例对象都能共享该静态变量，也就是说，如果一个实例对象修改了该静态变量，其他实例对象调用该变量时也会看到修改后的值。静态变量可以通过类名访问，也可以通过实例对象访问（但推荐使用类名访问）。 静态方法静态方法也是通过 static 关键字修饰的方法，属于类而不属于实例对象。静态方法在类被加载时初始化，可以被类的所有实例化对象共享。静态方法可以通过类名直接调用，不需要创建类的实例对象。 总结 静态变量：属于类，所有实例对象共享，可以通过类名或实例对象访问（推荐使用类名）。 静态方法：属于类，可以通过类名直接调用，不需要创建实例对象。 静态内部类静态内部类是使用 static 关键字修饰的内部类。与静态变量和静态方法类似，静态内部类属于外部类本身，而不是外部类的实例对象。 静态内部类与非静态内部类的区别 访问方式：静态内部类可以通过外部类名直接访问，不需要创建外部类的实例对象；非静态内部类依赖于外部类的实例，需要通过外部类的实例对象来访问。 访问权限： 静态内部类：只能访问外部类的静态变量和静态方法。不能直接访问外部类的私有成员变量和方法，必须通过外部类的实例来访问（为什么呢？因为private 修饰符表示成员只能在声明它的类内部访问，即使是私有静态成员变量和方法，对于静态内部类来说也是不可见的）。 非静态内部类：可以访问外部类的实例变量和方法，包括私有成员变量和方法。 实例化方式：静态内部类可以独立实例化，不需要依赖外部类的实例；非静态内部类必须等待外部类实例化后，才能实例化自己的对象。 示例代码 编译器如何实现非静态内部类直接访问其外部类方法？非静态内部类可以直接访问外部类的实例变量和方法，包括私有成员。这是通过编译器在内部类中生成一个隐式的外部类引用实现的。 编译器生成的代码 编译器在生成非静态内部类的字节码时，会自动为内部类添加一个指向外部类实例的引用。这个引用通常命名为 this$0，用于访问外部类的实例成员。 编译器生成的字节码大致如下： 通过这种方式，非静态内部类可以直接访问外部类的实例成员，而不需要显式地传递外部类的实例。 在继承关系中，实例化子类时静态加载顺序在继承关系中，当一个父类与子类都存在静态变量、静态方法时，实例化子类时的加载顺序如下： 加载父类的静态代码块：父类的静态代码块（即静态变量、静态方法等）在首次使用到与父类相关的代码时加载，并且仅加载一次。 加载子类的静态代码块：子类的静态代码块（即静态变量、静态方法等）在首次使用到与子类相关的代码时加载，并且仅加载一次。 加载父类的构造函数：父类的构造函数在实例化子类时首先被调用。 加载子类的构造函数：子类的构造函数在父类的构造函数执行完毕后被调用。 示例代码 输出结果 解释 在首次使用到与父类相关的代码时（即实例化子类时），父类的静态代码块首先被加载并执行。接着，子类的静态代码块在首次使用到与子类相关的代码时（即实例化子类时）被加载并执行。然后，父类的构造函数在实例化子类时被调用。最后，子类的构造函数在父类的构造函数执行完毕后被调用。 总结 在继承关系中，实例化子类时的静态加载顺序是： 父类的静态代码块（仅在首次使用时加载） 子类的静态代码块（仅在首次使用时加载） 父类的构造函数 子类的构造函数 "},{"date":"2024-09-28T11:46:22.016Z","url":"/CSS/custom.css","categories":[["undefined",""]],"content":"/* 对所有段落应用缩进，但不包括列表项 */ p:not(li p) { text-indent: 2em; } /* 自定义加粗字体的颜色 */ strong { color: rgb(0, 115, 255); /* 这里使用 RGB 色号，0, 0, 255 对应蓝色 */ }"}]